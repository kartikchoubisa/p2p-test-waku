const symbol$5 = Symbol.for('@libp2p/peer-id');
function isPeerId(other) {
    return other != null && Boolean(other[symbol$5]);
}

/**
 * When this error is thrown it means an operation was aborted,
 * usually in response to the `abort` event being emitted by an
 * AbortSignal.
 */
let AbortError$8 = class AbortError extends Error {
    code;
    type;
    constructor(message = 'The operation was aborted') {
        super(message);
        this.code = AbortError.code;
        this.type = AbortError.type;
    }
    static code = 'ABORT_ERR';
    static type = 'aborted';
};
let CodeError$3 = class CodeError extends Error {
    code;
    props;
    constructor(message, code, props) {
        super(message);
        this.code = code;
        this.name = props?.name ?? 'CodeError';
        this.props = props ?? {}; // eslint-disable-line @typescript-eslint/consistent-type-assertions
    }
};
class UnexpectedPeerError extends Error {
    code;
    constructor(message = 'Unexpected Peer') {
        super(message);
        this.code = UnexpectedPeerError.code;
    }
    static code = 'ERR_UNEXPECTED_PEER';
}
class InvalidCryptoExchangeError extends Error {
    code;
    constructor(message = 'Invalid crypto exchange') {
        super(message);
        this.code = InvalidCryptoExchangeError.code;
    }
    static code = 'ERR_INVALID_CRYPTO_EXCHANGE';
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$f (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$e = base$f;

var _brrp__multiformats_scope_baseX$e = src$e;

/**
 * @param {Uint8Array} aa
 * @param {Uint8Array} bb
 */
const equals$6 = (aa, bb) => {
  if (aa === bb) return true
  if (aa.byteLength !== bb.byteLength) {
    return false
  }

  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false
    }
  }

  return true
};

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$e = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
const fromString$5 = str => (new TextEncoder()).encode(str);

/**
 * @param {Uint8Array} b
 * @returns {string}
 */
const toString$b = b => (new TextDecoder()).decode(b);

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$g = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$g = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$f(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$e = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$f(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$f = (left, right) => new ComposedDecoder$e(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$e = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$g(name, prefix, baseEncode);
    this.decoder = new Decoder$g(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$n = ({ name, prefix, encode, decode }) =>
  new Codec$e(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$e = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$e(alphabet, name);
  return from$n({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$e(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$D = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$H = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$e = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$n({
    prefix,
    name,
    encode (input) {
      return encode$H(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$D(input, alphabet, bitsPerChar, name)
    }
  })
};

const base58btc$d = baseX$e({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

const base58flickr$3 = baseX$e({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var base58$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base58btc: base58btc$d,
    base58flickr: base58flickr$3
});

var encode_1$9 = encode$G;

var MSB$c = 0x80
  , REST$c = 0x7F
  , MSBALL$9 = ~REST$c
  , INT$9 = Math.pow(2, 31);

function encode$G(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$9) {
    out[offset++] = (num & 0xFF) | MSB$c;
    num /= 128;
  }
  while(num & MSBALL$9) {
    out[offset++] = (num & 0xFF) | MSB$c;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$G.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$C = read$a;

var MSB$1$8 = 0x80
  , REST$1$8 = 0x7F;

function read$a(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$a.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$8) << shift
      : (b & REST$1$8) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$8)

  read$a.bytes = counter - offset;

  return res
}

var N1$a = Math.pow(2,  7);
var N2$a = Math.pow(2, 14);
var N3$a = Math.pow(2, 21);
var N4$a = Math.pow(2, 28);
var N5$a = Math.pow(2, 35);
var N6$a = Math.pow(2, 42);
var N7$a = Math.pow(2, 49);
var N8$a = Math.pow(2, 56);
var N9$a = Math.pow(2, 63);

var length$9 = function (value) {
  return (
    value < N1$a ? 1
  : value < N2$a ? 2
  : value < N3$a ? 3
  : value < N4$a ? 4
  : value < N5$a ? 5
  : value < N6$a ? 6
  : value < N7$a ? 7
  : value < N8$a ? 8
  : value < N9$a ? 9
  :              10
  )
};

var varint$a = {
    encode: encode_1$9
  , decode: decode$C
  , encodingLength: length$9
};

var _brrp_varint$8 = varint$a;

/**
 * @param {Uint8Array} data
 * @param {number} [offset=0]
 * @returns {[number, number]}
 */
const decode$B = (data, offset = 0) => {
  const code = _brrp_varint$8.decode(data, offset);
  return [code, _brrp_varint$8.decode.bytes]
};

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo$8 = (int, target, offset = 0) => {
  _brrp_varint$8.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$a = (int) => {
  return _brrp_varint$8.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$h = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$a(code);
  const digestOffset = sizeOffset + encodingLength$a(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo$8(code, bytes, 0);
  encodeTo$8(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest$8(code, size, digest, bytes)
};

/**
 * Turns bytes representation of multihash digest into an instance.
 *
 * @param {Uint8Array} multihash
 * @returns {MultihashDigest}
 */
const decode$A = (multihash) => {
  const bytes = coerce$e(multihash);
  const [code, sizeOffset] = decode$B(bytes);
  const [size, digestOffset] = decode$B(bytes.subarray(sizeOffset));
  const digest = bytes.subarray(sizeOffset + digestOffset);

  if (digest.byteLength !== size) {
    throw new Error('Incorrect length')
  }

  return new Digest$8(code, size, digest, bytes)
};

/**
 * @param {MultihashDigest} a
 * @param {unknown} b
 * @returns {b is MultihashDigest}
 */
const equals$5 = (a, b) => {
  if (a === b) {
    return true
  } else {
    const data = /** @type {{code?:unknown, size?:unknown, bytes?:unknown}} */(b);

    return (
      a.code === data.code &&
      a.size === data.size &&
      data.bytes instanceof Uint8Array &&
      equals$6(a.bytes, data.bytes)
    )
  }
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
let Digest$8 = class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
};

const base32$g = rfc4648$e({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

const base32upper$3 = rfc4648$e({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

const base32pad$3 = rfc4648$e({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

const base32padupper$3 = rfc4648$e({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

const base32hex$3 = rfc4648$e({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

const base32hexupper$3 = rfc4648$e({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

const base32hexpad$3 = rfc4648$e({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

const base32hexpadupper$3 = rfc4648$e({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

const base32z$3 = rfc4648$e({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

var base32$h = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base32: base32$g,
    base32hex: base32hex$3,
    base32hexpad: base32hexpad$3,
    base32hexpadupper: base32hexpadupper$3,
    base32hexupper: base32hexupper$3,
    base32pad: base32pad$3,
    base32padupper: base32padupper$3,
    base32upper: base32upper$3,
    base32z: base32z$3
});

/**
 * @template {API.Link<unknown, number, number, API.Version>} T
 * @template {string} Prefix
 * @param {T} link
 * @param {API.MultibaseEncoder<Prefix>} [base]
 * @returns {API.ToString<T, Prefix>}
 */
const format$5 = (link, base) => {
  const { bytes, version } = link;
  switch (version) {
    case 0:
      return toStringV0$2(
        bytes,
        baseCache$2(link),
        /** @type {API.MultibaseEncoder<"z">} */ (base) || base58btc$d.encoder
      )
    default:
      return toStringV1$2(
        bytes,
        baseCache$2(link),
        /** @type {API.MultibaseEncoder<Prefix>} */ (base || base32$g.encoder)
      )
  }
};

/** @type {WeakMap<API.UnknownLink, Map<string, string>>} */
const cache$3 = new WeakMap();

/**
 * @param {API.UnknownLink} cid
 * @returns {Map<string, string>}
 */
const baseCache$2 = cid => {
  const baseCache = cache$3.get(cid);
  if (baseCache == null) {
    const baseCache = new Map();
    cache$3.set(cid, baseCache);
    return baseCache
  }
  return baseCache
};

/**
 * @template {unknown} [Data=unknown]
 * @template {number} [Format=number]
 * @template {number} [Alg=number]
 * @template {API.Version} [Version=API.Version]
 * @implements {API.Link<Data, Format, Alg, Version>}
 */

let CID$2 = class CID {
  /**
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} multihash - (Multi)hash of the of the content.
   * @param {Uint8Array} bytes
   *
   */
  constructor (version, code, multihash, bytes) {
    /** @readonly */
    this.code = code;
    /** @readonly */
    this.version = version;
    /** @readonly */
    this.multihash = multihash;
    /** @readonly */
    this.bytes = bytes;

    // flag to serializers that this is a CID and
    // should be treated specially
    /** @readonly */
    this['/'] = bytes;
  }

  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID () {
    return this
  }

  // ArrayBufferView
  get byteOffset () {
    return this.bytes.byteOffset
  }

  // ArrayBufferView
  get byteLength () {
    return this.bytes.byteLength
  }

  /**
   * @returns {CID<Data, API.DAG_PB, API.SHA_256, 0>}
   */
  toV0 () {
    switch (this.version) {
      case 0: {
        return /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */ (this)
      }
      case 1: {
        const { code, multihash } = this;

        if (code !== DAG_PB_CODE$2) {
          throw new Error('Cannot convert a non dag-pb CID to CIDv0')
        }

        // sha2-256
        if (multihash.code !== SHA_256_CODE$2) {
          throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0')
        }

        return /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */ (
          CID.createV0(
            /** @type {API.MultihashDigest<API.SHA_256>} */ (multihash)
          )
        )
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 0. This is a bug please report`
        )
      }
    }
  }

  /**
   * @returns {CID<Data, Format, Alg, 1>}
   */
  toV1 () {
    switch (this.version) {
      case 0: {
        const { code, digest } = this.multihash;
        const multihash = create$h(code, digest);
        return /** @type {CID<Data, Format, Alg, 1>} */ (
          CID.createV1(this.code, multihash)
        )
      }
      case 1: {
        return /** @type {CID<Data, Format, Alg, 1>} */ (this)
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 1. This is a bug please report`
        )
      }
    }
  }

  /**
   * @param {unknown} other
   * @returns {other is CID<Data, Format, Alg, Version>}
   */
  equals (other) {
    return CID.equals(this, other)
  }

  /**
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {API.Link<Data, Format, Alg, Version>} self
   * @param {unknown} other
   * @returns {other is CID}
   */
  static equals (self, other) {
    const unknown =
      /** @type {{code?:unknown, version?:unknown, multihash?:unknown}} */ (
        other
      );
    return (
      unknown &&
      self.code === unknown.code &&
      self.version === unknown.version &&
      equals$5(self.multihash, unknown.multihash)
    )
  }

  /**
   * @param {API.MultibaseEncoder<string>} [base]
   * @returns {string}
   */
  toString (base) {
    return format$5(this, base)
  }

  toJSON () {
    return { '/': format$5(this) }
  }

  link () {
    return this
  }

  get [Symbol.toStringTag] () {
    return 'CID'
  }

  // Legacy

  [Symbol.for('nodejs.util.inspect.custom')] () {
    return `CID(${this.toString()})`
  }

  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @template {unknown} U
   * @param {API.Link<Data, Format, Alg, Version>|U} input
   * @returns {CID<Data, Format, Alg, Version>|null}
   */
  static asCID (input) {
    if (input == null) {
      return null
    }

    const value = /** @type {any} */ (input);
    if (value instanceof CID) {
      // If value is instance of CID then we're all set.
      return value
    } else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {
      // If value isn't instance of this CID class but `this.asCID === this` or
      // `value['/'] === value.bytes` is true it is CID instance coming from a
      // different implementation (diff version or duplicate). In that case we
      // rebase it to this `CID` implementation so caller is guaranteed to get
      // instance with expected API.
      const { version, code, multihash, bytes } = value;
      return new CID(
        version,
        code,
        /** @type {API.MultihashDigest<Alg>} */ (multihash),
        bytes || encodeCID$2(version, code, multihash.bytes)
      )
    } else if (value[cidSymbol$2] === true) {
      // If value is a CID from older implementation that used to be tagged via
      // symbol we still rebase it to the this `CID` implementation by
      // delegating that to a constructor.
      const { version, multihash, code } = value;
      const digest =
        /** @type {API.MultihashDigest<Alg>} */
        (decode$A(multihash));
      return CID.create(version, code, digest)
    } else {
      // Otherwise value is not a CID (or an incompatible version of it) in
      // which case we return `null`.
      return null
    }
  }

  /**
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} digest - (Multi)hash of the of the content.
   * @returns {CID<Data, Format, Alg, Version>}
   */
  static create (version, code, digest) {
    if (typeof code !== 'number') {
      throw new Error('String codecs are no longer supported')
    }

    if (!(digest.bytes instanceof Uint8Array)) {
      throw new Error('Invalid digest')
    }

    switch (version) {
      case 0: {
        if (code !== DAG_PB_CODE$2) {
          throw new Error(
            `Version 0 CID must use dag-pb (code: ${DAG_PB_CODE$2}) block encoding`
          )
        } else {
          return new CID(version, code, digest, digest.bytes)
        }
      }
      case 1: {
        const bytes = encodeCID$2(version, code, digest.bytes);
        return new CID(version, code, digest, bytes)
      }
      default: {
        throw new Error('Invalid version')
      }
    }
  }

  /**
   * Simplified version of `create` for CIDv0.
   *
   * @template {unknown} [T=unknown]
   * @param {API.MultihashDigest<typeof SHA_256_CODE>} digest - Multihash.
   * @returns {CID<T, typeof DAG_PB_CODE, typeof SHA_256_CODE, 0>}
   */
  static createV0 (digest) {
    return CID.create(0, DAG_PB_CODE$2, digest)
  }

  /**
   * Simplified version of `create` for CIDv1.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @param {Code} code - Content encoding format code.
   * @param {API.MultihashDigest<Alg>} digest - Miltihash of the content.
   * @returns {CID<Data, Code, Alg, 1>}
   */
  static createV1 (code, digest) {
    return CID.create(1, code, digest)
  }

  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ByteView<API.Link<Data, Code, Alg, Ver>>} bytes
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static decode (bytes) {
    const [cid, remainder] = CID.decodeFirst(bytes);
    if (remainder.length) {
      throw new Error('Incorrect length')
    }
    return cid
  }

  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} bytes
   * @returns {[CID<T, C, A, V>, Uint8Array]}
   */
  static decodeFirst (bytes) {
    const specs = CID.inspectBytes(bytes);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce$e(
      bytes.subarray(prefixSize, prefixSize + specs.multihashSize)
    );
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error('Incorrect length')
    }
    const digestBytes = multihashBytes.subarray(
      specs.multihashSize - specs.digestSize
    );
    const digest = new Digest$8(
      specs.multihashCode,
      specs.digestSize,
      digestBytes,
      multihashBytes
    );
    const cid =
      specs.version === 0
        ? CID.createV0(/** @type {API.MultihashDigest<API.SHA_256>} */ (digest))
        : CID.createV1(specs.codec, digest);
    return [/** @type {CID<T, C, A, V>} */(cid), bytes.subarray(specs.size)]
  }

  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} initialBytes
   * @returns {{ version:V, codec:C, multihashCode:A, digestSize:number, multihashSize:number, size:number }}
   */
  static inspectBytes (initialBytes) {
    let offset = 0;
    const next = () => {
      const [i, length] = decode$B(initialBytes.subarray(offset));
      offset += length;
      return i
    };

    let version = /** @type {V} */ (next());
    let codec = /** @type {C} */ (DAG_PB_CODE$2);
    if (/** @type {number} */(version) === 18) {
      // CIDv0
      version = /** @type {V} */ (0);
      offset = 0;
    } else {
      codec = /** @type {C} */ (next());
    }

    if (version !== 0 && version !== 1) {
      throw new RangeError(`Invalid CID version ${version}`)
    }

    const prefixSize = offset;
    const multihashCode = /** @type {A} */ (next()); // multihash code
    const digestSize = next(); // multihash length
    const size = offset + digestSize;
    const multihashSize = size - prefixSize;

    return { version, codec, multihashCode, digestSize, multihashSize, size }
  }

  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   *
   * @template {string} Prefix
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
   * @param {API.MultibaseDecoder<Prefix>} [base]
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static parse (source, base) {
    const [prefix, bytes] = parseCIDtoBytes$2(source, base);

    const cid = CID.decode(bytes);

    if (cid.version === 0 && source[0] !== 'Q') {
      throw Error('Version 0 CID string must not include multibase prefix')
    }

    // Cache string representation to avoid computing it on `this.toString()`
    baseCache$2(cid).set(prefix, source);

    return cid
  }
};

/**
 * @template {string} Prefix
 * @template {unknown} Data
 * @template {number} Code
 * @template {number} Alg
 * @template {API.Version} Ver
 * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
 * @param {API.MultibaseDecoder<Prefix>} [base]
 * @returns {[Prefix, API.ByteView<API.Link<Data, Code, Alg, Ver>>]}
 */
const parseCIDtoBytes$2 = (source, base) => {
  switch (source[0]) {
    // CIDv0 is parsed differently
    case 'Q': {
      const decoder = base || base58btc$d;
      return [
        /** @type {Prefix} */ (base58btc$d.prefix),
        decoder.decode(`${base58btc$d.prefix}${source}`)
      ]
    }
    case base58btc$d.prefix: {
      const decoder = base || base58btc$d;
      return [/** @type {Prefix} */(base58btc$d.prefix), decoder.decode(source)]
    }
    case base32$g.prefix: {
      const decoder = base || base32$g;
      return [/** @type {Prefix} */(base32$g.prefix), decoder.decode(source)]
    }
    default: {
      if (base == null) {
        throw Error(
          'To parse non base32 or base58btc encoded CID multibase decoder must be provided'
        )
      }
      return [/** @type {Prefix} */(source[0]), base.decode(source)]
    }
  }
};

/**
 *
 * @param {Uint8Array} bytes
 * @param {Map<string, string>} cache
 * @param {API.MultibaseEncoder<'z'>} base
 */
const toStringV0$2 = (bytes, cache, base) => {
  const { prefix } = base;
  if (prefix !== base58btc$d.prefix) {
    throw Error(`Cannot string encode V0 in ${base.name} encoding`)
  }

  const cid = cache.get(prefix);
  if (cid == null) {
    const cid = base.encode(bytes).slice(1);
    cache.set(prefix, cid);
    return cid
  } else {
    return cid
  }
};

/**
 * @template {string} Prefix
 * @param {Uint8Array} bytes
 * @param {Map<string, string>} cache
 * @param {API.MultibaseEncoder<Prefix>} base
 */
const toStringV1$2 = (bytes, cache, base) => {
  const { prefix } = base;
  const cid = cache.get(prefix);
  if (cid == null) {
    const cid = base.encode(bytes);
    cache.set(prefix, cid);
    return cid
  } else {
    return cid
  }
};

const DAG_PB_CODE$2 = 0x70;
const SHA_256_CODE$2 = 0x12;

/**
 * @param {API.Version} version
 * @param {number} code
 * @param {Uint8Array} multihash
 * @returns {Uint8Array}
 */
const encodeCID$2 = (version, code, multihash) => {
  const codeOffset = encodingLength$a(version);
  const hashOffset = codeOffset + encodingLength$a(code);
  const bytes = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo$8(version, bytes, 0);
  encodeTo$8(code, bytes, codeOffset);
  bytes.set(multihash, hashOffset);
  return bytes
};

const cidSymbol$2 = Symbol.for('@ipld/js-cid/CID');

/**
 * Returns true if the two passed Uint8Arrays have the same content
 */
function equals$4(a, b) {
    if (a === b) {
        return true;
    }
    if (a.byteLength !== b.byteLength) {
        return false;
    }
    for (let i = 0; i < a.byteLength; i++) {
        if (a[i] !== b[i]) {
            return false;
        }
    }
    return true;
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$e (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$d = base$e;

var _brrp__multiformats_scope_baseX$d = src$d;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$d = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
const fromString$4 = str => (new TextEncoder()).encode(str);

/**
 * @param {Uint8Array} b
 * @returns {string}
 */
const toString$a = b => (new TextDecoder()).decode(b);

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$f = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$f = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$e(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$d = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$e(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$e = (left, right) => new ComposedDecoder$d(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$d = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$f(name, prefix, baseEncode);
    this.decoder = new Decoder$f(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$m = ({ name, prefix, encode, decode }) =>
  new Codec$d(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$d = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$d(alphabet, name);
  return from$m({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$d(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$z = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$F = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$d = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$m({
    prefix,
    name,
    encode (input) {
      return encode$F(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$z(input, alphabet, bitsPerChar, name)
    }
  })
};

// @ts-check


const identity$b = from$m({
  prefix: '\x00',
  name: 'identity',
  encode: (buf) => toString$a(buf),
  decode: (str) => fromString$4(str)
});

var identityBase$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identity: identity$b
});

// @ts-check


const base2$6 = rfc4648$d({
  prefix: '0',
  name: 'base2',
  alphabet: '01',
  bitsPerChar: 1
});

var base2$7 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base2: base2$6
});

// @ts-check


const base8$6 = rfc4648$d({
  prefix: '7',
  name: 'base8',
  alphabet: '01234567',
  bitsPerChar: 3
});

var base8$7 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base8: base8$6
});

const base10$6 = baseX$d({
  prefix: '9',
  name: 'base10',
  alphabet: '0123456789'
});

var base10$7 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base10: base10$6
});

// @ts-check


const base16$6 = rfc4648$d({
  prefix: 'f',
  name: 'base16',
  alphabet: '0123456789abcdef',
  bitsPerChar: 4
});

const base16upper$3 = rfc4648$d({
  prefix: 'F',
  name: 'base16upper',
  alphabet: '0123456789ABCDEF',
  bitsPerChar: 4
});

var base16$7 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base16: base16$6,
    base16upper: base16upper$3
});

const base32$e = rfc4648$d({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

const base32upper$2 = rfc4648$d({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

const base32pad$2 = rfc4648$d({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

const base32padupper$2 = rfc4648$d({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

const base32hex$2 = rfc4648$d({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

const base32hexupper$2 = rfc4648$d({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

const base32hexpad$2 = rfc4648$d({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

const base32hexpadupper$2 = rfc4648$d({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

const base32z$2 = rfc4648$d({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

var base32$f = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base32: base32$e,
    base32hex: base32hex$2,
    base32hexpad: base32hexpad$2,
    base32hexpadupper: base32hexpadupper$2,
    base32hexupper: base32hexupper$2,
    base32pad: base32pad$2,
    base32padupper: base32padupper$2,
    base32upper: base32upper$2,
    base32z: base32z$2
});

const base36$6 = baseX$d({
  prefix: 'k',
  name: 'base36',
  alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'
});

const base36upper$3 = baseX$d({
  prefix: 'K',
  name: 'base36upper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
});

var base36$7 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base36: base36$6,
    base36upper: base36upper$3
});

const base58btc$c = baseX$d({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

const base58flickr$2 = baseX$d({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var base58$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base58btc: base58btc$c,
    base58flickr: base58flickr$2
});

// @ts-check


const base64$i = rfc4648$d({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

const base64pad$3 = rfc4648$d({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

const base64url$3 = rfc4648$d({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

const base64urlpad$3 = rfc4648$d({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

var base64$j = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base64: base64$i,
    base64pad: base64pad$3,
    base64url: base64url$3,
    base64urlpad: base64urlpad$3
});

const alphabet$3 = Array.from('🚀🪐☄🛰🌌🌑🌒🌓🌔🌕🌖🌗🌘🌍🌏🌎🐉☀💻🖥💾💿😂❤😍🤣😊🙏💕😭😘👍😅👏😁🔥🥰💔💖💙😢🤔😆🙄💪😉☺👌🤗💜😔😎😇🌹🤦🎉💞✌✨🤷😱😌🌸🙌😋💗💚😏💛🙂💓🤩😄😀🖤😃💯🙈👇🎶😒🤭❣😜💋👀😪😑💥🙋😞😩😡🤪👊🥳😥🤤👉💃😳✋😚😝😴🌟😬🙃🍀🌷😻😓⭐✅🥺🌈😈🤘💦✔😣🏃💐☹🎊💘😠☝😕🌺🎂🌻😐🖕💝🙊😹🗣💫💀👑🎵🤞😛🔴😤🌼😫⚽🤙☕🏆🤫👈😮🙆🍻🍃🐶💁😲🌿🧡🎁⚡🌞🎈❌✊👋😰🤨😶🤝🚶💰🍓💢🤟🙁🚨💨🤬✈🎀🍺🤓😙💟🌱😖👶🥴▶➡❓💎💸⬇😨🌚🦋😷🕺⚠🙅😟😵👎🤲🤠🤧📌🔵💅🧐🐾🍒😗🤑🌊🤯🐷☎💧😯💆👆🎤🙇🍑❄🌴💣🐸💌📍🥀🤢👅💡💩👐📸👻🤐🤮🎼🥵🚩🍎🍊👼💍📣🥂');
const alphabetBytesToChars$3 = /** @type {string[]} */ (alphabet$3.reduce((p, c, i) => { p[i] = c; return p }, /** @type {string[]} */([])));
const alphabetCharsToBytes$3 = /** @type {number[]} */ (alphabet$3.reduce((p, c, i) => { p[/** @type {number} */ (c.codePointAt(0))] = i; return p }, /** @type {number[]} */([])));

/**
 * @param {Uint8Array} data
 * @returns {string}
 */
function encode$E (data) {
  return data.reduce((p, c) => {
    p += alphabetBytesToChars$3[c];
    return p
  }, '')
}

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
function decode$y (str) {
  const byts = [];
  for (const char of str) {
    const byt = alphabetCharsToBytes$3[/** @type {number} */ (char.codePointAt(0))];
    if (byt === undefined) {
      throw new Error(`Non-base256emoji character: ${char}`)
    }
    byts.push(byt);
  }
  return new Uint8Array(byts)
}

const base256emoji$6 = from$m({
  prefix: '🚀',
  name: 'base256emoji',
  encode: encode$E,
  decode: decode$y
});

var base256emoji$7 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base256emoji: base256emoji$6
});

// @ts-check

/**
 * @template T
 * @typedef {import('./interface.js').ByteView<T>} ByteView
 */

new TextEncoder();
new TextDecoder();

// @ts-check


const bases$3 = { ...identityBase$3, ...base2$7, ...base8$7, ...base10$7, ...base16$7, ...base32$f, ...base36$7, ...base58$2, ...base64$j, ...base256emoji$7 };

/**
 * To guarantee Uint8Array semantics, convert nodejs Buffers
 * into vanilla Uint8Arrays
 */
function asUint8Array(buf) {
    if (globalThis.Buffer != null) {
        return new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength);
    }
    return buf;
}

/**
 * Returns a `Uint8Array` of the requested size. Referenced memory will
 * be initialized to 0.
 */
function alloc$1(size = 0) {
    if (globalThis.Buffer?.alloc != null) {
        return asUint8Array(globalThis.Buffer.alloc(size));
    }
    return new Uint8Array(size);
}
/**
 * Where possible returns a Uint8Array of the requested size that references
 * uninitialized memory. Only use if you are certain you will immediately
 * overwrite every value in the returned `Uint8Array`.
 */
function allocUnsafe$2(size = 0) {
    if (globalThis.Buffer?.allocUnsafe != null) {
        return asUint8Array(globalThis.Buffer.allocUnsafe(size));
    }
    return new Uint8Array(size);
}

function createCodec$1(name, prefix, encode, decode) {
    return {
        name,
        prefix,
        encoder: {
            name,
            prefix,
            encode
        },
        decoder: {
            decode
        }
    };
}
const string$1 = createCodec$1('utf8', 'u', (buf) => {
    const decoder = new TextDecoder('utf8');
    return 'u' + decoder.decode(buf);
}, (str) => {
    const encoder = new TextEncoder();
    return encoder.encode(str.substring(1));
});
const ascii = createCodec$1('ascii', 'a', (buf) => {
    let string = 'a';
    for (let i = 0; i < buf.length; i++) {
        string += String.fromCharCode(buf[i]);
    }
    return string;
}, (str) => {
    str = str.substring(1);
    const buf = allocUnsafe$2(str.length);
    for (let i = 0; i < str.length; i++) {
        buf[i] = str.charCodeAt(i);
    }
    return buf;
});
const BASES = {
    utf8: string$1,
    'utf-8': string$1,
    hex: bases$3.base16,
    latin1: ascii,
    ascii,
    binary: ascii,
    ...bases$3
};

/**
 * Turns a `Uint8Array` into a string.
 *
 * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.
 *
 * Also `ascii` which is similar to node's 'binary' encoding.
 */
function toString$9(array, encoding = 'utf8') {
    const base = BASES[encoding];
    if (base == null) {
        throw new Error(`Unsupported encoding "${encoding}"`);
    }
    if ((encoding === 'utf8' || encoding === 'utf-8') && globalThis.Buffer != null && globalThis.Buffer.from != null) {
        return globalThis.Buffer.from(array.buffer, array.byteOffset, array.byteLength).toString('utf8');
    }
    // strip multibase prefix
    return base.encoder.encode(array).substring(1);
}

/**
 * Returns a new Uint8Array created by concatenating the passed ArrayLikes
 */
function concat$1(arrays, length) {
    if (length == null) {
        length = arrays.reduce((acc, curr) => acc + curr.length, 0);
    }
    const output = allocUnsafe$2(length);
    let offset = 0;
    for (const arr of arrays) {
        output.set(arr, offset);
        offset += arr.length;
    }
    return asUint8Array(output);
}

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

function getDefaultExportFromCjs (x) {
	return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;
}

function getAugmentedNamespace(n) {
  if (n.__esModule) return n;
  var f = n.default;
	if (typeof f == "function") {
		var a = function a () {
			if (this instanceof a) {
        return Reflect.construct(f, arguments, this.constructor);
			}
			return f.apply(this, arguments);
		};
		a.prototype = f.prototype;
  } else a = {};
  Object.defineProperty(a, '__esModule', {value: true});
	Object.keys(n).forEach(function (k) {
		var d = Object.getOwnPropertyDescriptor(n, k);
		Object.defineProperty(a, k, d.get ? d : {
			enumerable: true,
			get: function () {
				return n[k];
			}
		});
	});
	return a;
}

var encode_1$8 = encode$D;

var MSB$b = 0x80
  , REST$b = 0x7F
  , MSBALL$8 = ~REST$b
  , INT$8 = Math.pow(2, 31);

function encode$D(num, out, offset) {
  if (Number.MAX_SAFE_INTEGER && num > Number.MAX_SAFE_INTEGER) {
    encode$D.bytes = 0;
    throw new RangeError('Could not encode varint')
  }
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$8) {
    out[offset++] = (num & 0xFF) | MSB$b;
    num /= 128;
  }
  while(num & MSBALL$8) {
    out[offset++] = (num & 0xFF) | MSB$b;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$D.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$x = read$9;

var MSB$a = 0x80
  , REST$a = 0x7F;

function read$9(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l || shift > 49) {
      read$9.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$a) << shift
      : (b & REST$a) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$a)

  read$9.bytes = counter - offset;

  return res
}

var N1$9 = Math.pow(2,  7);
var N2$9 = Math.pow(2, 14);
var N3$9 = Math.pow(2, 21);
var N4$9 = Math.pow(2, 28);
var N5$9 = Math.pow(2, 35);
var N6$9 = Math.pow(2, 42);
var N7$9 = Math.pow(2, 49);
var N8$9 = Math.pow(2, 56);
var N9$9 = Math.pow(2, 63);

var length$8 = function (value) {
  return (
    value < N1$9 ? 1
  : value < N2$9 ? 2
  : value < N3$9 ? 3
  : value < N4$9 ? 4
  : value < N5$9 ? 5
  : value < N6$9 ? 6
  : value < N7$9 ? 7
  : value < N8$9 ? 8
  : value < N9$9 ? 9
  :              10
  )
};

var varint$8 = {
    encode: encode_1$8
  , decode: decode$x
  , encodingLength: length$8
};

var varint$9 = /*@__PURE__*/getDefaultExportFromCjs(varint$8);

/* eslint-disable @typescript-eslint/no-unsafe-return */
class Parser {
    index = 0;
    input = "";
    new(input) {
        this.index = 0;
        this.input = input;
        return this;
    }
    /** Run a parser, and restore the pre-parse state if it fails. */
    readAtomically(fn) {
        const index = this.index;
        const result = fn();
        if (result === undefined) {
            this.index = index;
        }
        return result;
    }
    /** Run a parser, but fail if the entire input wasn't consumed. Doesn't run atomically. */
    parseWith(fn) {
        const result = fn();
        if (this.index !== this.input.length) {
            return undefined;
        }
        return result;
    }
    /** Peek the next character from the input */
    peekChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index];
    }
    /** Read the next character from the input */
    readChar() {
        if (this.index >= this.input.length) {
            return undefined;
        }
        return this.input[this.index++];
    }
    /** Read the next character from the input if it matches the target. */
    readGivenChar(target) {
        return this.readAtomically(() => {
            const char = this.readChar();
            if (char !== target) {
                return undefined;
            }
            return char;
        });
    }
    /**
     * Helper for reading separators in an indexed loop. Reads the separator
     * character iff index > 0, then runs the parser. When used in a loop,
     * the separator character will only be read on index > 0 (see
     * readIPv4Addr for an example)
     */
    readSeparator(sep, index, inner) {
        return this.readAtomically(() => {
            if (index > 0) {
                if (this.readGivenChar(sep) === undefined) {
                    return undefined;
                }
            }
            return inner();
        });
    }
    /**
     * Read a number off the front of the input in the given radix, stopping
     * at the first non-digit character or eof. Fails if the number has more
     * digits than max_digits or if there is no number.
     */
    readNumber(radix, maxDigits, allowZeroPrefix, maxBytes) {
        return this.readAtomically(() => {
            let result = 0;
            let digitCount = 0;
            const leadingChar = this.peekChar();
            if (leadingChar === undefined) {
                return undefined;
            }
            const hasLeadingZero = leadingChar === "0";
            const maxValue = 2 ** (8 * maxBytes) - 1;
            // eslint-disable-next-line no-constant-condition
            while (true) {
                const digit = this.readAtomically(() => {
                    const char = this.readChar();
                    if (char === undefined) {
                        return undefined;
                    }
                    const num = Number.parseInt(char, radix);
                    if (Number.isNaN(num)) {
                        return undefined;
                    }
                    return num;
                });
                if (digit === undefined) {
                    break;
                }
                result *= radix;
                result += digit;
                if (result > maxValue) {
                    return undefined;
                }
                digitCount += 1;
                if (maxDigits !== undefined) {
                    if (digitCount > maxDigits) {
                        return undefined;
                    }
                }
            }
            if (digitCount === 0) {
                return undefined;
            }
            else if (!allowZeroPrefix && hasLeadingZero && digitCount > 1) {
                return undefined;
            }
            else {
                return result;
            }
        });
    }
    /** Read an IPv4 address. */
    readIPv4Addr() {
        return this.readAtomically(() => {
            const out = new Uint8Array(4);
            for (let i = 0; i < out.length; i++) {
                const ix = this.readSeparator(".", i, () => this.readNumber(10, 3, false, 1));
                if (ix === undefined) {
                    return undefined;
                }
                out[i] = ix;
            }
            return out;
        });
    }
    /** Read an IPv6 Address. */
    readIPv6Addr() {
        /**
         * Read a chunk of an IPv6 address into `groups`. Returns the number
         * of groups read, along with a bool indicating if an embedded
         * trailing IPv4 address was read. Specifically, read a series of
         * colon-separated IPv6 groups (0x0000 - 0xFFFF), with an optional
         * trailing embedded IPv4 address.
         */
        const readGroups = (groups) => {
            for (let i = 0; i < groups.length / 2; i++) {
                const ix = i * 2;
                // Try to read a trailing embedded IPv4 address. There must be at least 4 groups left.
                if (i < groups.length - 3) {
                    const ipv4 = this.readSeparator(":", i, () => this.readIPv4Addr());
                    if (ipv4 !== undefined) {
                        groups[ix] = ipv4[0];
                        groups[ix + 1] = ipv4[1];
                        groups[ix + 2] = ipv4[2];
                        groups[ix + 3] = ipv4[3];
                        return [ix + 4, true];
                    }
                }
                const group = this.readSeparator(":", i, () => this.readNumber(16, 4, true, 2));
                if (group === undefined) {
                    return [ix, false];
                }
                groups[ix] = group >> 8;
                groups[ix + 1] = group & 255;
            }
            return [groups.length, false];
        };
        return this.readAtomically(() => {
            // Read the front part of the address; either the whole thing, or up to the first ::
            const head = new Uint8Array(16);
            const [headSize, headIp4] = readGroups(head);
            if (headSize === 16) {
                return head;
            }
            // IPv4 part is not allowed before `::`
            if (headIp4) {
                return undefined;
            }
            // Read `::` if previous code parsed less than 8 groups.
            // `::` indicates one or more groups of 16 bits of zeros.
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            if (this.readGivenChar(":") === undefined) {
                return undefined;
            }
            // Read the back part of the address. The :: must contain at least one
            // set of zeroes, so our max length is 7.
            const tail = new Uint8Array(14);
            const limit = 16 - (headSize + 2);
            const [tailSize] = readGroups(tail.subarray(0, limit));
            // Concat the head and tail of the IP address
            head.set(tail.subarray(0, tailSize), 16 - tailSize);
            return head;
        });
    }
    /** Read an IP Address, either IPv4 or IPv6. */
    readIPAddr() {
        return this.readIPv4Addr() ?? this.readIPv6Addr();
    }
}

// See https://stackoverflow.com/questions/166132/maximum-length-of-the-textual-representation-of-an-ipv6-address
const MAX_IPV6_LENGTH = 45;
const MAX_IPV4_LENGTH = 15;
const parser = new Parser();
/** Parse `input` into IPv4 bytes. */
function parseIPv4(input) {
    if (input.length > MAX_IPV4_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv4Addr());
}
/** Parse `input` into IPv6 bytes. */
function parseIPv6(input) {
    // strip zone index if it is present
    if (input.includes("%")) {
        input = input.split("%")[0];
    }
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPv6Addr());
}
/** Parse `input` into IPv4 or IPv6 bytes. */
function parseIP(input) {
    // strip zone index if it is present
    if (input.includes("%")) {
        input = input.split("%")[0];
    }
    if (input.length > MAX_IPV6_LENGTH) {
        return undefined;
    }
    return parser.new(input).parseWith(() => parser.readIPAddr());
}

// @ts-check


const identity$a = from$n({
  prefix: '\x00',
  name: 'identity',
  encode: (buf) => toString$b(buf),
  decode: (str) => fromString$5(str)
});

var identityBase$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identity: identity$a
});

// @ts-check


const base2$4 = rfc4648$e({
  prefix: '0',
  name: 'base2',
  alphabet: '01',
  bitsPerChar: 1
});

var base2$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base2: base2$4
});

// @ts-check


const base8$4 = rfc4648$e({
  prefix: '7',
  name: 'base8',
  alphabet: '01234567',
  bitsPerChar: 3
});

var base8$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base8: base8$4
});

const base10$4 = baseX$e({
  prefix: '9',
  name: 'base10',
  alphabet: '0123456789'
});

var base10$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base10: base10$4
});

// @ts-check


const base16$4 = rfc4648$e({
  prefix: 'f',
  name: 'base16',
  alphabet: '0123456789abcdef',
  bitsPerChar: 4
});

const base16upper$2 = rfc4648$e({
  prefix: 'F',
  name: 'base16upper',
  alphabet: '0123456789ABCDEF',
  bitsPerChar: 4
});

var base16$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base16: base16$4,
    base16upper: base16upper$2
});

const base36$4 = baseX$e({
  prefix: 'k',
  name: 'base36',
  alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'
});

const base36upper$2 = baseX$e({
  prefix: 'K',
  name: 'base36upper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
});

var base36$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base36: base36$4,
    base36upper: base36upper$2
});

// @ts-check


const base64$g = rfc4648$e({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

const base64pad$2 = rfc4648$e({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

const base64url$2 = rfc4648$e({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

const base64urlpad$2 = rfc4648$e({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

var base64$h = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base64: base64$g,
    base64pad: base64pad$2,
    base64url: base64url$2,
    base64urlpad: base64urlpad$2
});

const alphabet$2 = Array.from('🚀🪐☄🛰🌌🌑🌒🌓🌔🌕🌖🌗🌘🌍🌏🌎🐉☀💻🖥💾💿😂❤😍🤣😊🙏💕😭😘👍😅👏😁🔥🥰💔💖💙😢🤔😆🙄💪😉☺👌🤗💜😔😎😇🌹🤦🎉💞✌✨🤷😱😌🌸🙌😋💗💚😏💛🙂💓🤩😄😀🖤😃💯🙈👇🎶😒🤭❣😜💋👀😪😑💥🙋😞😩😡🤪👊🥳😥🤤👉💃😳✋😚😝😴🌟😬🙃🍀🌷😻😓⭐✅🥺🌈😈🤘💦✔😣🏃💐☹🎊💘😠☝😕🌺🎂🌻😐🖕💝🙊😹🗣💫💀👑🎵🤞😛🔴😤🌼😫⚽🤙☕🏆🤫👈😮🙆🍻🍃🐶💁😲🌿🧡🎁⚡🌞🎈❌✊👋😰🤨😶🤝🚶💰🍓💢🤟🙁🚨💨🤬✈🎀🍺🤓😙💟🌱😖👶🥴▶➡❓💎💸⬇😨🌚🦋😷🕺⚠🙅😟😵👎🤲🤠🤧📌🔵💅🧐🐾🍒😗🤑🌊🤯🐷☎💧😯💆👆🎤🙇🍑❄🌴💣🐸💌📍🥀🤢👅💡💩👐📸👻🤐🤮🎼🥵🚩🍎🍊👼💍📣🥂');
const alphabetBytesToChars$2 = /** @type {string[]} */ (alphabet$2.reduce((p, c, i) => { p[i] = c; return p }, /** @type {string[]} */([])));
const alphabetCharsToBytes$2 = /** @type {number[]} */ (alphabet$2.reduce((p, c, i) => { p[/** @type {number} */ (c.codePointAt(0))] = i; return p }, /** @type {number[]} */([])));

/**
 * @param {Uint8Array} data
 * @returns {string}
 */
function encode$C (data) {
  return data.reduce((p, c) => {
    p += alphabetBytesToChars$2[c];
    return p
  }, '')
}

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
function decode$w (str) {
  const byts = [];
  for (const char of str) {
    const byt = alphabetCharsToBytes$2[/** @type {number} */ (char.codePointAt(0))];
    if (byt === undefined) {
      throw new Error(`Non-base256emoji character: ${char}`)
    }
    byts.push(byt);
  }
  return new Uint8Array(byts)
}

const base256emoji$4 = from$n({
  prefix: '🚀',
  name: 'base256emoji',
  encode: encode$C,
  decode: decode$w
});

var base256emoji$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base256emoji: base256emoji$4
});

// @ts-check

/**
 * @template T
 * @typedef {import('./interface.js').ByteView<T>} ByteView
 */

new TextEncoder();
new TextDecoder();

// @ts-check


const bases$2 = { ...identityBase$2, ...base2$5, ...base8$5, ...base10$5, ...base16$5, ...base32$h, ...base36$5, ...base58$3, ...base64$h, ...base256emoji$5 };

/**
 * Create a `Uint8Array` from the passed string
 *
 * Supports `utf8`, `utf-8`, `hex`, and any encoding supported by the multiformats module.
 *
 * Also `ascii` which is similar to node's 'binary' encoding.
 */
function fromString$3(string, encoding = 'utf8') {
    const base = BASES[encoding];
    if (base == null) {
        throw new Error(`Unsupported encoding "${encoding}"`);
    }
    if ((encoding === 'utf8' || encoding === 'utf-8') && globalThis.Buffer != null && globalThis.Buffer.from != null) {
        return asUint8Array(globalThis.Buffer.from(string, 'utf-8'));
    }
    // add multibase prefix
    return base.decoder.decode(`${base.prefix}${string}`); // eslint-disable-line @typescript-eslint/restrict-template-expressions
}

/** Check if `input` is IPv4. */
function isIPv4(input) {
    return Boolean(parseIPv4(input));
}
/** Check if `input` is IPv6. */
function isIPv6(input) {
    return Boolean(parseIPv6(input));
}
/** Check if `input` is IPv4 or IPv6. */
function isIP(input) {
    return Boolean(parseIP(input));
}

const isV4$1 = isIPv4;
const isV6$1 = isIPv6;
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const toBytes$4 = function (ip) {
    let offset = 0;
    ip = ip.toString().trim();
    if (isV4$1(ip)) {
        const bytes = new Uint8Array(offset + 4);
        ip.split(/\./g).forEach((byte) => {
            bytes[offset++] = parseInt(byte, 10) & 0xff;
        });
        return bytes;
    }
    if (isV6$1(ip)) {
        const sections = ip.split(':', 8);
        let i;
        for (i = 0; i < sections.length; i++) {
            const isv4 = isV4$1(sections[i]);
            let v4Buffer;
            if (isv4) {
                v4Buffer = toBytes$4(sections[i]);
                sections[i] = toString$9(v4Buffer.slice(0, 2), 'base16');
            }
            if (v4Buffer != null && ++i < 8) {
                sections.splice(i, 0, toString$9(v4Buffer.slice(2, 4), 'base16'));
            }
        }
        if (sections[0] === '') {
            while (sections.length < 8)
                sections.unshift('0');
        }
        else if (sections[sections.length - 1] === '') {
            while (sections.length < 8)
                sections.push('0');
        }
        else if (sections.length < 8) {
            for (i = 0; i < sections.length && sections[i] !== ''; i++)
                ;
            const argv = [i, 1];
            for (i = 9 - sections.length; i > 0; i--) {
                argv.push('0');
            }
            sections.splice.apply(sections, argv);
        }
        const bytes = new Uint8Array(offset + 16);
        for (i = 0; i < sections.length; i++) {
            const word = parseInt(sections[i], 16);
            bytes[offset++] = (word >> 8) & 0xff;
            bytes[offset++] = word & 0xff;
        }
        return bytes;
    }
    throw new Error('invalid ip address');
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L63
const toString$8 = function (buf, offset = 0, length) {
    offset = ~~offset;
    length = length ?? (buf.length - offset);
    const view = new DataView(buf.buffer);
    if (length === 4) {
        const result = [];
        // IPv4
        for (let i = 0; i < length; i++) {
            result.push(buf[offset + i]);
        }
        return result.join('.');
    }
    if (length === 16) {
        const result = [];
        // IPv6
        for (let i = 0; i < length; i += 2) {
            result.push(view.getUint16(offset + i).toString(16));
        }
        return result.join(':')
            .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')
            .replace(/:{3,4}/, '::');
    }
    return '';
};

const V$1 = -1;
const names$1 = {};
const codes$5 = {};
const table$1 = [
    [4, 32, 'ip4'],
    [6, 16, 'tcp'],
    [33, 16, 'dccp'],
    [41, 128, 'ip6'],
    [42, V$1, 'ip6zone'],
    [43, 8, 'ipcidr'],
    [53, V$1, 'dns', true],
    [54, V$1, 'dns4', true],
    [55, V$1, 'dns6', true],
    [56, V$1, 'dnsaddr', true],
    [132, 16, 'sctp'],
    [273, 16, 'udp'],
    [275, 0, 'p2p-webrtc-star'],
    [276, 0, 'p2p-webrtc-direct'],
    [277, 0, 'p2p-stardust'],
    [280, 0, 'webrtc-direct'],
    [281, 0, 'webrtc'],
    [290, 0, 'p2p-circuit'],
    [301, 0, 'udt'],
    [302, 0, 'utp'],
    [400, V$1, 'unix', false, true],
    // `ipfs` is added before `p2p` for legacy support.
    // All text representations will default to `p2p`, but `ipfs` will
    // still be supported
    [421, V$1, 'ipfs'],
    // `p2p` is the preferred name for 421, and is now the default
    [421, V$1, 'p2p'],
    [443, 0, 'https'],
    [444, 96, 'onion'],
    [445, 296, 'onion3'],
    [446, V$1, 'garlic64'],
    [448, 0, 'tls'],
    [449, V$1, 'sni'],
    [460, 0, 'quic'],
    [461, 0, 'quic-v1'],
    [465, 0, 'webtransport'],
    [466, V$1, 'certhash'],
    [477, 0, 'ws'],
    [478, 0, 'wss'],
    [479, 0, 'p2p-websocket-star'],
    [480, 0, 'http'],
    [777, V$1, 'memory']
];
// populate tables
table$1.forEach(row => {
    const proto = createProtocol$1(...row);
    codes$5[proto.code] = proto;
    names$1[proto.name] = proto;
});
function createProtocol$1(code, size, name, resolvable, path) {
    return {
        code,
        size,
        name,
        resolvable: Boolean(resolvable),
        path: Boolean(path)
    };
}
/**
 * For the passed proto string or number, return a {@link Protocol}
 *
 * @example
 *
 * ```js
 * import { protocol } from '@multiformats/multiaddr'
 *
 * console.info(protocol(4))
 * // { code: 4, size: 32, name: 'ip4', resolvable: false, path: false }
 * ```
 */
function getProtocol$1(proto) {
    if (typeof proto === 'number') {
        if (codes$5[proto] != null) {
            return codes$5[proto];
        }
        throw new Error(`no protocol with code: ${proto}`);
    }
    else if (typeof proto === 'string') {
        if (names$1[proto] != null) {
            return names$1[proto];
        }
        throw new Error(`no protocol with name: ${proto}`);
    }
    throw new Error(`invalid protocol id type: ${typeof proto}`);
}

/**
 * @packageDocumentation
 *
 * Provides methods for converting
 */
getProtocol$1('ip4');
getProtocol$1('ip6');
getProtocol$1('ipcidr');
/**
 * Convert [code,Uint8Array] to string
 */
function convertToString$1(proto, buf) {
    const protocol = getProtocol$1(proto);
    switch (protocol.code) {
        case 4: // ipv4
        case 41: // ipv6
            return bytes2ip$1(buf);
        case 42: // ipv6zone
            return bytes2str$1(buf);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return bytes2port$1(buf).toString();
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return bytes2str$1(buf);
        case 421: // ipfs
            return bytes2mh$1(buf);
        case 444: // onion
            return bytes2onion$1(buf);
        case 445: // onion3
            return bytes2onion$1(buf);
        case 466: // certhash
            return bytes2mb$1(buf);
        default:
            return toString$9(buf, 'base16'); // no clue. convert to hex
    }
}
function convertToBytes$1(proto, str) {
    const protocol = getProtocol$1(proto);
    switch (protocol.code) {
        case 4: // ipv4
            return ip2bytes$1(str);
        case 41: // ipv6
            return ip2bytes$1(str);
        case 42: // ipv6zone
            return str2bytes$1(str);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return port2bytes$1(parseInt(str, 10));
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return str2bytes$1(str);
        case 421: // ipfs
            return mh2bytes$1(str);
        case 444: // onion
            return onion2bytes$1(str);
        case 445: // onion3
            return onion32bytes$1(str);
        case 466: // certhash
            return mb2bytes$1(str);
        default:
            return fromString$3(str, 'base16'); // no clue. convert from hex
    }
}
const decoders$1 = Object.values(bases$2).map((c) => c.decoder);
const anybaseDecoder$1 = (function () {
    let acc = decoders$1[0].or(decoders$1[1]);
    decoders$1.slice(2).forEach((d) => (acc = acc.or(d)));
    return acc;
})();
function ip2bytes$1(ipString) {
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return toBytes$4(ipString);
}
function bytes2ip$1(ipBuff) {
    const ipString = toString$8(ipBuff, 0, ipBuff.length);
    if (ipString == null) {
        throw new Error('ipBuff is required');
    }
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return ipString;
}
function port2bytes$1(port) {
    const buf = new ArrayBuffer(2);
    const view = new DataView(buf);
    view.setUint16(0, port);
    return new Uint8Array(buf);
}
function bytes2port$1(buf) {
    const view = new DataView(buf.buffer);
    return view.getUint16(buf.byteOffset);
}
function str2bytes$1(str) {
    const buf = fromString$3(str);
    const size = Uint8Array.from(varint$9.encode(buf.length));
    return concat$1([size, buf], size.length + buf.length);
}
function bytes2str$1(buf) {
    const size = varint$9.decode(buf);
    buf = buf.slice(varint$9.decode.bytes);
    if (buf.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$9(buf);
}
function mh2bytes$1(hash) {
    let mh;
    if (hash[0] === 'Q' || hash[0] === '1') {
        mh = decode$A(base58btc$d.decode(`z${hash}`)).bytes;
    }
    else {
        mh = CID$2.parse(hash).multihash.bytes;
    }
    // the address is a varint prefixed multihash string representation
    const size = Uint8Array.from(varint$9.encode(mh.length));
    return concat$1([size, mh], size.length + mh.length);
}
function mb2bytes$1(mbstr) {
    const mb = anybaseDecoder$1.decode(mbstr);
    const size = Uint8Array.from(varint$9.encode(mb.length));
    return concat$1([size, mb], size.length + mb.length);
}
function bytes2mb$1(buf) {
    const size = varint$9.decode(buf);
    const hash = buf.slice(varint$9.decode.bytes);
    if (hash.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return 'u' + toString$9(hash, 'base64url');
}
/**
 * Converts bytes to bas58btc string
 */
function bytes2mh$1(buf) {
    const size = varint$9.decode(buf);
    const address = buf.slice(varint$9.decode.bytes);
    if (address.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$9(address, 'base58btc');
}
function onion2bytes$1(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 16) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$g.decode('b' + addr[0]);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes$1(port);
    return concat$1([buf, portBuf], buf.length + portBuf.length);
}
function onion32bytes$1(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 56) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion3 address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$g.decode(`b${addr[0]}`);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes$1(port);
    return concat$1([buf, portBuf], buf.length + portBuf.length);
}
function bytes2onion$1(buf) {
    const addrBytes = buf.slice(0, buf.length - 2);
    const portBytes = buf.slice(buf.length - 2);
    const addr = toString$9(addrBytes, 'base32');
    const port = bytes2port$1(portBytes);
    return `${addr}:${port}`;
}

function stringToMultiaddrParts(str) {
    str = cleanPath$1(str);
    const tuples = [];
    const stringTuples = [];
    let path = null;
    const parts = str.split('/').slice(1);
    if (parts.length === 1 && parts[0] === '') {
        return {
            bytes: new Uint8Array(),
            string: '/',
            tuples: [],
            stringTuples: [],
            path: null
        };
    }
    for (let p = 0; p < parts.length; p++) {
        const part = parts[p];
        const proto = getProtocol$1(part);
        if (proto.size === 0) {
            tuples.push([proto.code]);
            stringTuples.push([proto.code]);
            // eslint-disable-next-line no-continue
            continue;
        }
        p++; // advance addr part
        if (p >= parts.length) {
            throw ParseError$1('invalid address: ' + str);
        }
        // if it's a path proto, take the rest
        if (proto.path === true) {
            // should we need to check each path part to see if it's a proto?
            // This would allow for other protocols to be added after a unix path,
            // however it would have issues if the path had a protocol name in the path
            path = cleanPath$1(parts.slice(p).join('/'));
            tuples.push([proto.code, convertToBytes$1(proto.code, path)]);
            stringTuples.push([proto.code, path]);
            break;
        }
        const bytes = convertToBytes$1(proto.code, parts[p]);
        tuples.push([proto.code, bytes]);
        stringTuples.push([proto.code, convertToString$1(proto.code, bytes)]);
    }
    return {
        string: stringTuplesToString$1(stringTuples),
        bytes: tuplesToBytes$1(tuples),
        tuples,
        stringTuples,
        path
    };
}
function bytesToMultiaddrParts(bytes) {
    const tuples = [];
    const stringTuples = [];
    let path = null;
    let i = 0;
    while (i < bytes.length) {
        const code = varint$9.decode(bytes, i);
        const n = varint$9.decode.bytes ?? 0;
        const p = getProtocol$1(code);
        const size = sizeForAddr$1(p, bytes.slice(i + n));
        if (size === 0) {
            tuples.push([code]);
            stringTuples.push([code]);
            i += n;
            // eslint-disable-next-line no-continue
            continue;
        }
        const addr = bytes.slice(i + n, i + n + size);
        i += (size + n);
        if (i > bytes.length) { // did not end _exactly_ at buffer.length
            throw ParseError$1('Invalid address Uint8Array: ' + toString$9(bytes, 'base16'));
        }
        // ok, tuple seems good.
        tuples.push([code, addr]);
        const stringAddr = convertToString$1(code, addr);
        stringTuples.push([code, stringAddr]);
        if (p.path === true) {
            // should we need to check each path part to see if it's a proto?
            // This would allow for other protocols to be added after a unix path,
            // however it would have issues if the path had a protocol name in the path
            path = stringAddr;
            break;
        }
    }
    return {
        bytes: Uint8Array.from(bytes),
        string: stringTuplesToString$1(stringTuples),
        tuples,
        stringTuples,
        path
    };
}
/**
 * [[str name, str addr]... ] -> string
 */
function stringTuplesToString$1(tuples) {
    const parts = [];
    tuples.map((tup) => {
        const proto = getProtocol$1(tup[0]);
        parts.push(proto.name);
        if (tup.length > 1 && tup[1] != null) {
            parts.push(tup[1]);
        }
        return null;
    });
    return cleanPath$1(parts.join('/'));
}
/**
 * [[int code, Uint8Array ]... ] -> Uint8Array
 */
function tuplesToBytes$1(tuples) {
    return concat$1(tuples.map((tup) => {
        const proto = getProtocol$1(tup[0]);
        let buf = Uint8Array.from(varint$9.encode(proto.code));
        if (tup.length > 1 && tup[1] != null) {
            buf = concat$1([buf, tup[1]]); // add address buffer
        }
        return buf;
    }));
}
/**
 * For the passed address, return the serialized size
 */
function sizeForAddr$1(p, addr) {
    if (p.size > 0) {
        return p.size / 8;
    }
    else if (p.size === 0) {
        return 0;
    }
    else {
        const size = varint$9.decode(addr);
        return size + (varint$9.decode.bytes ?? 0);
    }
}
function cleanPath$1(str) {
    return '/' + str.trim().split('/').filter((a) => a).join('/');
}
function ParseError$1(str) {
    return new Error('Error parsing address: ' + str);
}

/**
 * @packageDocumentation
 *
 * An implementation of a Multiaddr in JavaScript
 *
 * @example
 *
 * ```js
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const ma = multiaddr('/ip4/127.0.0.1/tcp/1234')
 * ```
 */
const inspect$2 = Symbol.for('nodejs.util.inspect.custom');
const DNS_CODES$1 = [
    getProtocol$1('dns').code,
    getProtocol$1('dns4').code,
    getProtocol$1('dns6').code,
    getProtocol$1('dnsaddr').code
];
/**
 * All configured {@link Resolver}s
 */
const resolvers$2 = new Map();
const symbol$4 = Symbol.for('@multiformats/js-multiaddr/multiaddr');
/**
 * Check if object is a {@link Multiaddr} instance
 *
 * @example
 *
 * ```js
 * import { isMultiaddr, multiaddr } from '@multiformats/multiaddr'
 *
 * isMultiaddr(5)
 * // false
 * isMultiaddr(multiaddr('/ip4/127.0.0.1'))
 * // true
 * ```
 */
function isMultiaddr$1(value) {
    return Boolean(value?.[symbol$4]);
}
/**
 * Creates a {@link Multiaddr} from a {@link MultiaddrInput}
 */
let DefaultMultiaddr$1 = class DefaultMultiaddr {
    bytes;
    #string;
    #tuples;
    #stringTuples;
    #path;
    [symbol$4] = true;
    constructor(addr) {
        // default
        if (addr == null) {
            addr = '';
        }
        let parts;
        if (addr instanceof Uint8Array) {
            parts = bytesToMultiaddrParts(addr);
        }
        else if (typeof addr === 'string') {
            if (addr.length > 0 && addr.charAt(0) !== '/') {
                throw new Error(`multiaddr "${addr}" must start with a "/"`);
            }
            parts = stringToMultiaddrParts(addr);
        }
        else if (isMultiaddr$1(addr)) { // Multiaddr
            parts = bytesToMultiaddrParts(addr.bytes);
        }
        else {
            throw new Error('addr must be a string, Buffer, or another Multiaddr');
        }
        this.bytes = parts.bytes;
        this.#string = parts.string;
        this.#tuples = parts.tuples;
        this.#stringTuples = parts.stringTuples;
        this.#path = parts.path;
    }
    toString() {
        return this.#string;
    }
    toJSON() {
        return this.toString();
    }
    toOptions() {
        let family;
        let transport;
        let host;
        let port;
        let zone = '';
        const tcp = getProtocol$1('tcp');
        const udp = getProtocol$1('udp');
        const ip4 = getProtocol$1('ip4');
        const ip6 = getProtocol$1('ip6');
        const dns6 = getProtocol$1('dns6');
        const ip6zone = getProtocol$1('ip6zone');
        for (const [code, value] of this.stringTuples()) {
            if (code === ip6zone.code) {
                zone = `%${value ?? ''}`;
            }
            // default to https when protocol & port are omitted from DNS addrs
            if (DNS_CODES$1.includes(code)) {
                transport = tcp.name;
                port = 443;
                host = `${value ?? ''}${zone}`;
                family = code === dns6.code ? 6 : 4;
            }
            if (code === tcp.code || code === udp.code) {
                transport = getProtocol$1(code).name;
                port = parseInt(value ?? '');
            }
            if (code === ip4.code || code === ip6.code) {
                transport = getProtocol$1(code).name;
                host = `${value ?? ''}${zone}`;
                family = code === ip6.code ? 6 : 4;
            }
        }
        if (family == null || transport == null || host == null || port == null) {
            throw new Error('multiaddr must have a valid format: "/{ip4, ip6, dns4, dns6, dnsaddr}/{address}/{tcp, udp}/{port}".');
        }
        const opts = {
            family,
            host,
            transport,
            port
        };
        return opts;
    }
    protos() {
        return this.#tuples.map(([code]) => Object.assign({}, getProtocol$1(code)));
    }
    protoCodes() {
        return this.#tuples.map(([code]) => code);
    }
    protoNames() {
        return this.#tuples.map(([code]) => getProtocol$1(code).name);
    }
    tuples() {
        return this.#tuples;
    }
    stringTuples() {
        return this.#stringTuples;
    }
    encapsulate(addr) {
        addr = new DefaultMultiaddr(addr);
        return new DefaultMultiaddr(this.toString() + addr.toString());
    }
    decapsulate(addr) {
        const addrString = addr.toString();
        const s = this.toString();
        const i = s.lastIndexOf(addrString);
        if (i < 0) {
            throw new Error(`Address ${this.toString()} does not contain subaddress: ${addr.toString()}`);
        }
        return new DefaultMultiaddr(s.slice(0, i));
    }
    decapsulateCode(code) {
        const tuples = this.tuples();
        for (let i = tuples.length - 1; i >= 0; i--) {
            if (tuples[i][0] === code) {
                return new DefaultMultiaddr(tuplesToBytes$1(tuples.slice(0, i)));
            }
        }
        return this;
    }
    getPeerId() {
        try {
            let tuples = [];
            this.stringTuples().forEach(([code, name]) => {
                if (code === names$1.p2p.code) {
                    tuples.push([code, name]);
                }
                // if this is a p2p-circuit address, return the target peer id if present
                // not the peer id of the relay
                if (code === names$1['p2p-circuit'].code) {
                    tuples = [];
                }
            });
            // Get the last ipfs tuple ['p2p', 'peerid string']
            const tuple = tuples.pop();
            if (tuple?.[1] != null) {
                const peerIdStr = tuple[1];
                // peer id is base58btc encoded string but not multibase encoded so add the `z`
                // prefix so we can validate that it is correctly encoded
                if (peerIdStr[0] === 'Q' || peerIdStr[0] === '1') {
                    return toString$9(base58btc$d.decode(`z${peerIdStr}`), 'base58btc');
                }
                // try to parse peer id as CID
                return toString$9(CID$2.parse(peerIdStr).multihash.bytes, 'base58btc');
            }
            return null;
        }
        catch (e) {
            return null;
        }
    }
    getPath() {
        return this.#path;
    }
    equals(addr) {
        return equals$4(this.bytes, addr.bytes);
    }
    async resolve(options) {
        const resolvableProto = this.protos().find((p) => p.resolvable);
        // Multiaddr is not resolvable?
        if (resolvableProto == null) {
            return [this];
        }
        const resolver = resolvers$2.get(resolvableProto.name);
        if (resolver == null) {
            throw new CodeError$3(`no available resolver for ${resolvableProto.name}`, 'ERR_NO_AVAILABLE_RESOLVER');
        }
        const addresses = await resolver(this, options);
        return addresses.map((a) => new DefaultMultiaddr(a));
    }
    nodeAddress() {
        const options = this.toOptions();
        if (options.transport !== 'tcp' && options.transport !== 'udp') {
            throw new Error(`multiaddr must have a valid format - no protocol with name: "${options.transport}". Must have a valid transport protocol: "{tcp, udp}"`);
        }
        return {
            family: options.family,
            address: options.host,
            port: options.port
        };
    }
    isThinWaistAddress(addr) {
        const protos = (addr ?? this).protos();
        if (protos.length !== 2) {
            return false;
        }
        if (protos[0].code !== 4 && protos[0].code !== 41) {
            return false;
        }
        if (protos[1].code !== 6 && protos[1].code !== 273) {
            return false;
        }
        return true;
    }
    /**
     * Returns Multiaddr as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { multiaddr } from '@multiformats/multiaddr'
     *
     * console.info(multiaddr('/ip4/127.0.0.1/tcp/4001'))
     * // 'Multiaddr(/ip4/127.0.0.1/tcp/4001)'
     * ```
     */
    [inspect$2]() {
        return `Multiaddr(${this.#string})`;
    }
};
/**
 * A function that takes a {@link MultiaddrInput} and returns a {@link Multiaddr}
 *
 * @example
 * ```js
 * import { multiaddr } from '@libp2p/multiaddr'
 *
 * multiaddr('/ip4/127.0.0.1/tcp/4001')
 * // Multiaddr(/ip4/127.0.0.1/tcp/4001)
 * ```
 *
 * @param {MultiaddrInput} [addr] - If String or Uint8Array, needs to adhere to the address format of a [multiaddr](https://github.com/multiformats/multiaddr#string-format)
 */
function multiaddr$1(addr) {
    return new DefaultMultiaddr$1(addr);
}

var Protocols;
(function (Protocols) {
    Protocols["Relay"] = "relay";
    Protocols["Store"] = "store";
    Protocols["LightPush"] = "lightpush";
    Protocols["Filter"] = "filter";
})(Protocols || (Protocols = {}));
var SendError;
(function (SendError) {
    SendError["GENERIC_FAIL"] = "Generic error";
    SendError["ENCODE_FAILED"] = "Failed to encode";
    SendError["DECODE_FAILED"] = "Failed to decode";
    SendError["SIZE_TOO_BIG"] = "Size is too big";
    SendError["NO_RPC_RESPONSE"] = "No RPC response";
})(SendError || (SendError = {}));

var PageDirection$1;
(function (PageDirection) {
    PageDirection["BACKWARD"] = "backward";
    PageDirection["FORWARD"] = "forward";
})(PageDirection$1 || (PageDirection$1 = {}));

var Tags;
(function (Tags) {
    Tags["BOOTSTRAP"] = "bootstrap";
    Tags["PEER_EXCHANGE"] = "peer-exchange";
})(Tags || (Tags = {}));
var EPeersByDiscoveryEvents;
(function (EPeersByDiscoveryEvents) {
    EPeersByDiscoveryEvents["PEER_DISCOVERY_BOOTSTRAP"] = "peer:discovery:bootstrap";
    EPeersByDiscoveryEvents["PEER_DISCOVERY_PEER_EXCHANGE"] = "peer:discovery:peer-exchange";
    EPeersByDiscoveryEvents["PEER_CONNECT_BOOTSTRAP"] = "peer:connected:bootstrap";
    EPeersByDiscoveryEvents["PEER_CONNECT_PEER_EXCHANGE"] = "peer:connected:peer-exchange";
})(EPeersByDiscoveryEvents || (EPeersByDiscoveryEvents = {}));

var browser$2 = {exports: {}};

/**
 * Helpers.
 */

var ms;
var hasRequiredMs;

function requireMs () {
	if (hasRequiredMs) return ms;
	hasRequiredMs = 1;
	var s = 1000;
	var m = s * 60;
	var h = m * 60;
	var d = h * 24;
	var w = d * 7;
	var y = d * 365.25;

	/**
	 * Parse or format the given `val`.
	 *
	 * Options:
	 *
	 *  - `long` verbose formatting [false]
	 *
	 * @param {String|Number} val
	 * @param {Object} [options]
	 * @throws {Error} throw an error if val is not a non-empty string or a number
	 * @return {String|Number}
	 * @api public
	 */

	ms = function(val, options) {
	  options = options || {};
	  var type = typeof val;
	  if (type === 'string' && val.length > 0) {
	    return parse(val);
	  } else if (type === 'number' && isFinite(val)) {
	    return options.long ? fmtLong(val) : fmtShort(val);
	  }
	  throw new Error(
	    'val is not a non-empty string or a valid number. val=' +
	      JSON.stringify(val)
	  );
	};

	/**
	 * Parse the given `str` and return milliseconds.
	 *
	 * @param {String} str
	 * @return {Number}
	 * @api private
	 */

	function parse(str) {
	  str = String(str);
	  if (str.length > 100) {
	    return;
	  }
	  var match = /^(-?(?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(
	    str
	  );
	  if (!match) {
	    return;
	  }
	  var n = parseFloat(match[1]);
	  var type = (match[2] || 'ms').toLowerCase();
	  switch (type) {
	    case 'years':
	    case 'year':
	    case 'yrs':
	    case 'yr':
	    case 'y':
	      return n * y;
	    case 'weeks':
	    case 'week':
	    case 'w':
	      return n * w;
	    case 'days':
	    case 'day':
	    case 'd':
	      return n * d;
	    case 'hours':
	    case 'hour':
	    case 'hrs':
	    case 'hr':
	    case 'h':
	      return n * h;
	    case 'minutes':
	    case 'minute':
	    case 'mins':
	    case 'min':
	    case 'm':
	      return n * m;
	    case 'seconds':
	    case 'second':
	    case 'secs':
	    case 'sec':
	    case 's':
	      return n * s;
	    case 'milliseconds':
	    case 'millisecond':
	    case 'msecs':
	    case 'msec':
	    case 'ms':
	      return n;
	    default:
	      return undefined;
	  }
	}

	/**
	 * Short format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtShort(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return Math.round(ms / d) + 'd';
	  }
	  if (msAbs >= h) {
	    return Math.round(ms / h) + 'h';
	  }
	  if (msAbs >= m) {
	    return Math.round(ms / m) + 'm';
	  }
	  if (msAbs >= s) {
	    return Math.round(ms / s) + 's';
	  }
	  return ms + 'ms';
	}

	/**
	 * Long format for `ms`.
	 *
	 * @param {Number} ms
	 * @return {String}
	 * @api private
	 */

	function fmtLong(ms) {
	  var msAbs = Math.abs(ms);
	  if (msAbs >= d) {
	    return plural(ms, msAbs, d, 'day');
	  }
	  if (msAbs >= h) {
	    return plural(ms, msAbs, h, 'hour');
	  }
	  if (msAbs >= m) {
	    return plural(ms, msAbs, m, 'minute');
	  }
	  if (msAbs >= s) {
	    return plural(ms, msAbs, s, 'second');
	  }
	  return ms + ' ms';
	}

	/**
	 * Pluralization helper.
	 */

	function plural(ms, msAbs, n, name) {
	  var isPlural = msAbs >= n * 1.5;
	  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');
	}
	return ms;
}

/**
 * This is the common logic for both the Node.js and web browser
 * implementations of `debug()`.
 */

function setup(env) {
	createDebug.debug = createDebug;
	createDebug.default = createDebug;
	createDebug.coerce = coerce;
	createDebug.disable = disable;
	createDebug.enable = enable;
	createDebug.enabled = enabled;
	createDebug.humanize = requireMs();
	createDebug.destroy = destroy;

	Object.keys(env).forEach(key => {
		createDebug[key] = env[key];
	});

	/**
	* The currently active debug mode names, and names to skip.
	*/

	createDebug.names = [];
	createDebug.skips = [];

	/**
	* Map of special "%n" handling functions, for the debug "format" argument.
	*
	* Valid key names are a single, lower or upper-case letter, i.e. "n" and "N".
	*/
	createDebug.formatters = {};

	/**
	* Selects a color for a debug namespace
	* @param {String} namespace The namespace string for the debug instance to be colored
	* @return {Number|String} An ANSI color code for the given namespace
	* @api private
	*/
	function selectColor(namespace) {
		let hash = 0;

		for (let i = 0; i < namespace.length; i++) {
			hash = ((hash << 5) - hash) + namespace.charCodeAt(i);
			hash |= 0; // Convert to 32bit integer
		}

		return createDebug.colors[Math.abs(hash) % createDebug.colors.length];
	}
	createDebug.selectColor = selectColor;

	/**
	* Create a debugger with the given `namespace`.
	*
	* @param {String} namespace
	* @return {Function}
	* @api public
	*/
	function createDebug(namespace) {
		let prevTime;
		let enableOverride = null;
		let namespacesCache;
		let enabledCache;

		function debug(...args) {
			// Disabled?
			if (!debug.enabled) {
				return;
			}

			const self = debug;

			// Set `diff` timestamp
			const curr = Number(new Date());
			const ms = curr - (prevTime || curr);
			self.diff = ms;
			self.prev = prevTime;
			self.curr = curr;
			prevTime = curr;

			args[0] = createDebug.coerce(args[0]);

			if (typeof args[0] !== 'string') {
				// Anything else let's inspect with %O
				args.unshift('%O');
			}

			// Apply any `formatters` transformations
			let index = 0;
			args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {
				// If we encounter an escaped % then don't increase the array index
				if (match === '%%') {
					return '%';
				}
				index++;
				const formatter = createDebug.formatters[format];
				if (typeof formatter === 'function') {
					const val = args[index];
					match = formatter.call(self, val);

					// Now we need to remove `args[index]` since it's inlined in the `format`
					args.splice(index, 1);
					index--;
				}
				return match;
			});

			// Apply env-specific formatting (colors, etc.)
			createDebug.formatArgs.call(self, args);

			const logFn = self.log || createDebug.log;
			logFn.apply(self, args);
		}

		debug.namespace = namespace;
		debug.useColors = createDebug.useColors();
		debug.color = createDebug.selectColor(namespace);
		debug.extend = extend;
		debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.

		Object.defineProperty(debug, 'enabled', {
			enumerable: true,
			configurable: false,
			get: () => {
				if (enableOverride !== null) {
					return enableOverride;
				}
				if (namespacesCache !== createDebug.namespaces) {
					namespacesCache = createDebug.namespaces;
					enabledCache = createDebug.enabled(namespace);
				}

				return enabledCache;
			},
			set: v => {
				enableOverride = v;
			}
		});

		// Env-specific initialization logic for debug instances
		if (typeof createDebug.init === 'function') {
			createDebug.init(debug);
		}

		return debug;
	}

	function extend(namespace, delimiter) {
		const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);
		newDebug.log = this.log;
		return newDebug;
	}

	/**
	* Enables a debug mode by namespaces. This can include modes
	* separated by a colon and wildcards.
	*
	* @param {String} namespaces
	* @api public
	*/
	function enable(namespaces) {
		createDebug.save(namespaces);
		createDebug.namespaces = namespaces;

		createDebug.names = [];
		createDebug.skips = [];

		let i;
		const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\s,]+/);
		const len = split.length;

		for (i = 0; i < len; i++) {
			if (!split[i]) {
				// ignore empty strings
				continue;
			}

			namespaces = split[i].replace(/\*/g, '.*?');

			if (namespaces[0] === '-') {
				createDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));
			} else {
				createDebug.names.push(new RegExp('^' + namespaces + '$'));
			}
		}
	}

	/**
	* Disable debug output.
	*
	* @return {String} namespaces
	* @api public
	*/
	function disable() {
		const namespaces = [
			...createDebug.names.map(toNamespace),
			...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)
		].join(',');
		createDebug.enable('');
		return namespaces;
	}

	/**
	* Returns true if the given mode name is enabled, false otherwise.
	*
	* @param {String} name
	* @return {Boolean}
	* @api public
	*/
	function enabled(name) {
		if (name[name.length - 1] === '*') {
			return true;
		}

		let i;
		let len;

		for (i = 0, len = createDebug.skips.length; i < len; i++) {
			if (createDebug.skips[i].test(name)) {
				return false;
			}
		}

		for (i = 0, len = createDebug.names.length; i < len; i++) {
			if (createDebug.names[i].test(name)) {
				return true;
			}
		}

		return false;
	}

	/**
	* Convert regexp to namespace
	*
	* @param {RegExp} regxep
	* @return {String} namespace
	* @api private
	*/
	function toNamespace(regexp) {
		return regexp.toString()
			.substring(2, regexp.toString().length - 2)
			.replace(/\.\*\?$/, '*');
	}

	/**
	* Coerce `val`.
	*
	* @param {Mixed} val
	* @return {Mixed}
	* @api private
	*/
	function coerce(val) {
		if (val instanceof Error) {
			return val.stack || val.message;
		}
		return val;
	}

	/**
	* XXX DO NOT USE. This is a temporary stub function.
	* XXX It WILL be removed in the next major release.
	*/
	function destroy() {
		console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
	}

	createDebug.enable(createDebug.load());

	return createDebug;
}

var common = setup;

/* eslint-env browser */

(function (module, exports) {
	/**
	 * This is the web browser implementation of `debug()`.
	 */

	exports.formatArgs = formatArgs;
	exports.save = save;
	exports.load = load;
	exports.useColors = useColors;
	exports.storage = localstorage();
	exports.destroy = (() => {
		let warned = false;

		return () => {
			if (!warned) {
				warned = true;
				console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');
			}
		};
	})();

	/**
	 * Colors.
	 */

	exports.colors = [
		'#0000CC',
		'#0000FF',
		'#0033CC',
		'#0033FF',
		'#0066CC',
		'#0066FF',
		'#0099CC',
		'#0099FF',
		'#00CC00',
		'#00CC33',
		'#00CC66',
		'#00CC99',
		'#00CCCC',
		'#00CCFF',
		'#3300CC',
		'#3300FF',
		'#3333CC',
		'#3333FF',
		'#3366CC',
		'#3366FF',
		'#3399CC',
		'#3399FF',
		'#33CC00',
		'#33CC33',
		'#33CC66',
		'#33CC99',
		'#33CCCC',
		'#33CCFF',
		'#6600CC',
		'#6600FF',
		'#6633CC',
		'#6633FF',
		'#66CC00',
		'#66CC33',
		'#9900CC',
		'#9900FF',
		'#9933CC',
		'#9933FF',
		'#99CC00',
		'#99CC33',
		'#CC0000',
		'#CC0033',
		'#CC0066',
		'#CC0099',
		'#CC00CC',
		'#CC00FF',
		'#CC3300',
		'#CC3333',
		'#CC3366',
		'#CC3399',
		'#CC33CC',
		'#CC33FF',
		'#CC6600',
		'#CC6633',
		'#CC9900',
		'#CC9933',
		'#CCCC00',
		'#CCCC33',
		'#FF0000',
		'#FF0033',
		'#FF0066',
		'#FF0099',
		'#FF00CC',
		'#FF00FF',
		'#FF3300',
		'#FF3333',
		'#FF3366',
		'#FF3399',
		'#FF33CC',
		'#FF33FF',
		'#FF6600',
		'#FF6633',
		'#FF9900',
		'#FF9933',
		'#FFCC00',
		'#FFCC33'
	];

	/**
	 * Currently only WebKit-based Web Inspectors, Firefox >= v31,
	 * and the Firebug extension (any Firefox version) are known
	 * to support "%c" CSS customizations.
	 *
	 * TODO: add a `localStorage` variable to explicitly enable/disable colors
	 */

	// eslint-disable-next-line complexity
	function useColors() {
		// NB: In an Electron preload script, document will be defined but not fully
		// initialized. Since we know we're in Chrome, we'll just detect this case
		// explicitly
		if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {
			return true;
		}

		// Internet Explorer and Edge do not support colors.
		if (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/)) {
			return false;
		}

		// Is webkit? http://stackoverflow.com/a/16459606/376773
		// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632
		return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||
			// Is firebug? http://stackoverflow.com/a/398120/376773
			(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||
			// Is firefox >= v31?
			// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages
			(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||
			// Double check webkit in userAgent just in case we are in a worker
			(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/));
	}

	/**
	 * Colorize log arguments if enabled.
	 *
	 * @api public
	 */

	function formatArgs(args) {
		args[0] = (this.useColors ? '%c' : '') +
			this.namespace +
			(this.useColors ? ' %c' : ' ') +
			args[0] +
			(this.useColors ? '%c ' : ' ') +
			'+' + module.exports.humanize(this.diff);

		if (!this.useColors) {
			return;
		}

		const c = 'color: ' + this.color;
		args.splice(1, 0, c, 'color: inherit');

		// The final "%c" is somewhat tricky, because there could be other
		// arguments passed either before or after the %c, so we need to
		// figure out the correct index to insert the CSS into
		let index = 0;
		let lastC = 0;
		args[0].replace(/%[a-zA-Z%]/g, match => {
			if (match === '%%') {
				return;
			}
			index++;
			if (match === '%c') {
				// We only are interested in the *last* %c
				// (the user may have provided their own)
				lastC = index;
			}
		});

		args.splice(lastC, 0, c);
	}

	/**
	 * Invokes `console.debug()` when available.
	 * No-op when `console.debug` is not a "function".
	 * If `console.debug` is not available, falls back
	 * to `console.log`.
	 *
	 * @api public
	 */
	exports.log = console.debug || console.log || (() => {});

	/**
	 * Save `namespaces`.
	 *
	 * @param {String} namespaces
	 * @api private
	 */
	function save(namespaces) {
		try {
			if (namespaces) {
				exports.storage.setItem('debug', namespaces);
			} else {
				exports.storage.removeItem('debug');
			}
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	/**
	 * Load `namespaces`.
	 *
	 * @return {String} returns the previously persisted debug modes
	 * @api private
	 */
	function load() {
		let r;
		try {
			r = exports.storage.getItem('debug');
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}

		// If debug isn't set in LS, and we're in Electron, try to load $DEBUG
		if (!r && typeof process !== 'undefined' && 'env' in process) {
			r = process.env.DEBUG;
		}

		return r;
	}

	/**
	 * Localstorage attempts to return the localstorage.
	 *
	 * This is necessary because safari throws
	 * when a user disables cookies/localstorage
	 * and you attempt to access it.
	 *
	 * @return {LocalStorage}
	 * @api private
	 */

	function localstorage() {
		try {
			// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context
			// The Browser also has localStorage in the global context.
			return localStorage;
		} catch (error) {
			// Swallow
			// XXX (@Qix-) should we be logging these?
		}
	}

	module.exports = common(exports);

	const {formatters} = module.exports;

	/**
	 * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.
	 */

	formatters.j = function (v) {
		try {
			return JSON.stringify(v);
		} catch (error) {
			return '[UnexpectedJSONParseError]: ' + error.message;
		}
	}; 
} (browser$2, browser$2.exports));

var browserExports = browser$2.exports;
var debug = /*@__PURE__*/getDefaultExportFromCjs(browserExports);

/**
 * Adds types to the EventTarget class. Hopefully this won't be necessary forever.
 *
 * https://github.com/microsoft/TypeScript/issues/28357
 * https://github.com/microsoft/TypeScript/issues/43477
 * https://github.com/microsoft/TypeScript/issues/299
 * etc
 */
let EventEmitter$3 = class EventEmitter extends EventTarget {
    #listeners = new Map();
    listenerCount(type) {
        const listeners = this.#listeners.get(type);
        if (listeners == null) {
            return 0;
        }
        return listeners.length;
    }
    addEventListener(type, listener, options) {
        super.addEventListener(type, listener, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            list = [];
            this.#listeners.set(type, list);
        }
        list.push({
            callback: listener,
            once: (options !== true && options !== false && options?.once) ?? false
        });
    }
    removeEventListener(type, listener, options) {
        super.removeEventListener(type.toString(), listener ?? null, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            return;
        }
        list = list.filter(({ callback }) => callback !== listener);
        this.#listeners.set(type, list);
    }
    dispatchEvent(event) {
        const result = super.dispatchEvent(event);
        let list = this.#listeners.get(event.type);
        if (list == null) {
            return result;
        }
        list = list.filter(({ once }) => !once);
        this.#listeners.set(event.type, list);
        return result;
    }
    safeDispatchEvent(type, detail) {
        return this.dispatchEvent(new CustomEvent$1(type, detail));
    }
};
/**
 * CustomEvent is a standard event but it's not supported by node.
 *
 * Remove this when https://github.com/nodejs/node/issues/40678 is closed.
 *
 * Ref: https://developer.mozilla.org/en-US/docs/Web/API/CustomEvent
 */
let CustomEventPolyfill$1 = class CustomEventPolyfill extends Event {
    /** Returns any custom data event was created with. Typically used for synthetic events. */
    detail;
    constructor(message, data) {
        super(message, data);
        // @ts-expect-error could be undefined
        this.detail = data?.detail;
    }
};
const CustomEvent$1 = globalThis.CustomEvent ?? CustomEventPolyfill$1;

/**
 * Convert input to a byte array.
 *
 * Handles both `0x` prefixed and non-prefixed strings.
 */
function hexToBytes$3(hex) {
    if (typeof hex === "string") {
        const _hex = hex.replace(/^0x/i, "");
        return fromString$3(_hex.toLowerCase(), "base16");
    }
    return hex;
}
/**
 * Convert byte array to hex string (no `0x` prefix).
 */
const bytesToHex$3 = (bytes) => toString$9(bytes, "base16");
/**
 * Decode byte array to utf-8 string.
 */
const bytesToUtf8 = (b) => toString$9(b, "utf8");
/**
 * Encode utf-8 string to byte array.
 */
const utf8ToBytes$4 = (s) => fromString$3(s, "utf8");
/**
 * Concatenate using Uint8Arrays as `Buffer` has a different behavior with `DataView`
 */
function concat(byteArrays, totalLength) {
    const len = totalLength ?? byteArrays.reduce((acc, curr) => acc + curr.length, 0);
    const res = new Uint8Array(len);
    let offset = 0;
    for (const bytes of byteArrays) {
        res.set(bytes, offset);
        offset += bytes.length;
    }
    return res;
}

var minimal$1 = {};

var aspromise;
var hasRequiredAspromise;

function requireAspromise () {
	if (hasRequiredAspromise) return aspromise;
	hasRequiredAspromise = 1;
	aspromise = asPromise;

	/**
	 * Callback as used by {@link util.asPromise}.
	 * @typedef asPromiseCallback
	 * @type {function}
	 * @param {Error|null} error Error, if any
	 * @param {...*} params Additional arguments
	 * @returns {undefined}
	 */

	/**
	 * Returns a promise from a node-style callback function.
	 * @memberof util
	 * @param {asPromiseCallback} fn Function to call
	 * @param {*} ctx Function context
	 * @param {...*} params Function arguments
	 * @returns {Promise<*>} Promisified function
	 */
	function asPromise(fn, ctx/*, varargs */) {
	    var params  = new Array(arguments.length - 1),
	        offset  = 0,
	        index   = 2,
	        pending = true;
	    while (index < arguments.length)
	        params[offset++] = arguments[index++];
	    return new Promise(function executor(resolve, reject) {
	        params[offset] = function callback(err/*, varargs */) {
	            if (pending) {
	                pending = false;
	                if (err)
	                    reject(err);
	                else {
	                    var params = new Array(arguments.length - 1),
	                        offset = 0;
	                    while (offset < params.length)
	                        params[offset++] = arguments[offset];
	                    resolve.apply(null, params);
	                }
	            }
	        };
	        try {
	            fn.apply(ctx || null, params);
	        } catch (err) {
	            if (pending) {
	                pending = false;
	                reject(err);
	            }
	        }
	    });
	}
	return aspromise;
}

var base64$f = {};

var hasRequiredBase64;

function requireBase64 () {
	if (hasRequiredBase64) return base64$f;
	hasRequiredBase64 = 1;
	(function (exports) {

		/**
		 * A minimal base64 implementation for number arrays.
		 * @memberof util
		 * @namespace
		 */
		var base64 = exports;

		/**
		 * Calculates the byte length of a base64 encoded string.
		 * @param {string} string Base64 encoded string
		 * @returns {number} Byte length
		 */
		base64.length = function length(string) {
		    var p = string.length;
		    if (!p)
		        return 0;
		    var n = 0;
		    while (--p % 4 > 1 && string.charAt(p) === "=")
		        ++n;
		    return Math.ceil(string.length * 3) / 4 - n;
		};

		// Base64 encoding table
		var b64 = new Array(64);

		// Base64 decoding table
		var s64 = new Array(123);

		// 65..90, 97..122, 48..57, 43, 47
		for (var i = 0; i < 64;)
		    s64[b64[i] = i < 26 ? i + 65 : i < 52 ? i + 71 : i < 62 ? i - 4 : i - 59 | 43] = i++;

		/**
		 * Encodes a buffer to a base64 encoded string.
		 * @param {Uint8Array} buffer Source buffer
		 * @param {number} start Source start
		 * @param {number} end Source end
		 * @returns {string} Base64 encoded string
		 */
		base64.encode = function encode(buffer, start, end) {
		    var parts = null,
		        chunk = [];
		    var i = 0, // output index
		        j = 0, // goto index
		        t;     // temporary
		    while (start < end) {
		        var b = buffer[start++];
		        switch (j) {
		            case 0:
		                chunk[i++] = b64[b >> 2];
		                t = (b & 3) << 4;
		                j = 1;
		                break;
		            case 1:
		                chunk[i++] = b64[t | b >> 4];
		                t = (b & 15) << 2;
		                j = 2;
		                break;
		            case 2:
		                chunk[i++] = b64[t | b >> 6];
		                chunk[i++] = b64[b & 63];
		                j = 0;
		                break;
		        }
		        if (i > 8191) {
		            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));
		            i = 0;
		        }
		    }
		    if (j) {
		        chunk[i++] = b64[t];
		        chunk[i++] = 61;
		        if (j === 1)
		            chunk[i++] = 61;
		    }
		    if (parts) {
		        if (i)
		            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));
		        return parts.join("");
		    }
		    return String.fromCharCode.apply(String, chunk.slice(0, i));
		};

		var invalidEncoding = "invalid encoding";

		/**
		 * Decodes a base64 encoded string to a buffer.
		 * @param {string} string Source string
		 * @param {Uint8Array} buffer Destination buffer
		 * @param {number} offset Destination offset
		 * @returns {number} Number of bytes written
		 * @throws {Error} If encoding is invalid
		 */
		base64.decode = function decode(string, buffer, offset) {
		    var start = offset;
		    var j = 0, // goto index
		        t;     // temporary
		    for (var i = 0; i < string.length;) {
		        var c = string.charCodeAt(i++);
		        if (c === 61 && j > 1)
		            break;
		        if ((c = s64[c]) === undefined)
		            throw Error(invalidEncoding);
		        switch (j) {
		            case 0:
		                t = c;
		                j = 1;
		                break;
		            case 1:
		                buffer[offset++] = t << 2 | (c & 48) >> 4;
		                t = c;
		                j = 2;
		                break;
		            case 2:
		                buffer[offset++] = (t & 15) << 4 | (c & 60) >> 2;
		                t = c;
		                j = 3;
		                break;
		            case 3:
		                buffer[offset++] = (t & 3) << 6 | c;
		                j = 0;
		                break;
		        }
		    }
		    if (j === 1)
		        throw Error(invalidEncoding);
		    return offset - start;
		};

		/**
		 * Tests if the specified string appears to be base64 encoded.
		 * @param {string} string String to test
		 * @returns {boolean} `true` if probably base64 encoded, otherwise false
		 */
		base64.test = function test(string) {
		    return /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/.test(string);
		}; 
	} (base64$f));
	return base64$f;
}

var eventemitter;
var hasRequiredEventemitter;

function requireEventemitter () {
	if (hasRequiredEventemitter) return eventemitter;
	hasRequiredEventemitter = 1;
	eventemitter = EventEmitter;

	/**
	 * Constructs a new event emitter instance.
	 * @classdesc A minimal event emitter.
	 * @memberof util
	 * @constructor
	 */
	function EventEmitter() {

	    /**
	     * Registered listeners.
	     * @type {Object.<string,*>}
	     * @private
	     */
	    this._listeners = {};
	}

	/**
	 * Registers an event listener.
	 * @param {string} evt Event name
	 * @param {function} fn Listener
	 * @param {*} [ctx] Listener context
	 * @returns {util.EventEmitter} `this`
	 */
	EventEmitter.prototype.on = function on(evt, fn, ctx) {
	    (this._listeners[evt] || (this._listeners[evt] = [])).push({
	        fn  : fn,
	        ctx : ctx || this
	    });
	    return this;
	};

	/**
	 * Removes an event listener or any matching listeners if arguments are omitted.
	 * @param {string} [evt] Event name. Removes all listeners if omitted.
	 * @param {function} [fn] Listener to remove. Removes all listeners of `evt` if omitted.
	 * @returns {util.EventEmitter} `this`
	 */
	EventEmitter.prototype.off = function off(evt, fn) {
	    if (evt === undefined)
	        this._listeners = {};
	    else {
	        if (fn === undefined)
	            this._listeners[evt] = [];
	        else {
	            var listeners = this._listeners[evt];
	            for (var i = 0; i < listeners.length;)
	                if (listeners[i].fn === fn)
	                    listeners.splice(i, 1);
	                else
	                    ++i;
	        }
	    }
	    return this;
	};

	/**
	 * Emits an event by calling its listeners with the specified arguments.
	 * @param {string} evt Event name
	 * @param {...*} args Arguments
	 * @returns {util.EventEmitter} `this`
	 */
	EventEmitter.prototype.emit = function emit(evt) {
	    var listeners = this._listeners[evt];
	    if (listeners) {
	        var args = [],
	            i = 1;
	        for (; i < arguments.length;)
	            args.push(arguments[i++]);
	        for (i = 0; i < listeners.length;)
	            listeners[i].fn.apply(listeners[i++].ctx, args);
	    }
	    return this;
	};
	return eventemitter;
}

var float;
var hasRequiredFloat;

function requireFloat () {
	if (hasRequiredFloat) return float;
	hasRequiredFloat = 1;

	float = factory(factory);

	/**
	 * Reads / writes floats / doubles from / to buffers.
	 * @name util.float
	 * @namespace
	 */

	/**
	 * Writes a 32 bit float to a buffer using little endian byte order.
	 * @name util.float.writeFloatLE
	 * @function
	 * @param {number} val Value to write
	 * @param {Uint8Array} buf Target buffer
	 * @param {number} pos Target buffer offset
	 * @returns {undefined}
	 */

	/**
	 * Writes a 32 bit float to a buffer using big endian byte order.
	 * @name util.float.writeFloatBE
	 * @function
	 * @param {number} val Value to write
	 * @param {Uint8Array} buf Target buffer
	 * @param {number} pos Target buffer offset
	 * @returns {undefined}
	 */

	/**
	 * Reads a 32 bit float from a buffer using little endian byte order.
	 * @name util.float.readFloatLE
	 * @function
	 * @param {Uint8Array} buf Source buffer
	 * @param {number} pos Source buffer offset
	 * @returns {number} Value read
	 */

	/**
	 * Reads a 32 bit float from a buffer using big endian byte order.
	 * @name util.float.readFloatBE
	 * @function
	 * @param {Uint8Array} buf Source buffer
	 * @param {number} pos Source buffer offset
	 * @returns {number} Value read
	 */

	/**
	 * Writes a 64 bit double to a buffer using little endian byte order.
	 * @name util.float.writeDoubleLE
	 * @function
	 * @param {number} val Value to write
	 * @param {Uint8Array} buf Target buffer
	 * @param {number} pos Target buffer offset
	 * @returns {undefined}
	 */

	/**
	 * Writes a 64 bit double to a buffer using big endian byte order.
	 * @name util.float.writeDoubleBE
	 * @function
	 * @param {number} val Value to write
	 * @param {Uint8Array} buf Target buffer
	 * @param {number} pos Target buffer offset
	 * @returns {undefined}
	 */

	/**
	 * Reads a 64 bit double from a buffer using little endian byte order.
	 * @name util.float.readDoubleLE
	 * @function
	 * @param {Uint8Array} buf Source buffer
	 * @param {number} pos Source buffer offset
	 * @returns {number} Value read
	 */

	/**
	 * Reads a 64 bit double from a buffer using big endian byte order.
	 * @name util.float.readDoubleBE
	 * @function
	 * @param {Uint8Array} buf Source buffer
	 * @param {number} pos Source buffer offset
	 * @returns {number} Value read
	 */

	// Factory function for the purpose of node-based testing in modified global environments
	function factory(exports) {

	    // float: typed array
	    if (typeof Float32Array !== "undefined") (function() {

	        var f32 = new Float32Array([ -0 ]),
	            f8b = new Uint8Array(f32.buffer),
	            le  = f8b[3] === 128;

	        function writeFloat_f32_cpy(val, buf, pos) {
	            f32[0] = val;
	            buf[pos    ] = f8b[0];
	            buf[pos + 1] = f8b[1];
	            buf[pos + 2] = f8b[2];
	            buf[pos + 3] = f8b[3];
	        }

	        function writeFloat_f32_rev(val, buf, pos) {
	            f32[0] = val;
	            buf[pos    ] = f8b[3];
	            buf[pos + 1] = f8b[2];
	            buf[pos + 2] = f8b[1];
	            buf[pos + 3] = f8b[0];
	        }

	        /* istanbul ignore next */
	        exports.writeFloatLE = le ? writeFloat_f32_cpy : writeFloat_f32_rev;
	        /* istanbul ignore next */
	        exports.writeFloatBE = le ? writeFloat_f32_rev : writeFloat_f32_cpy;

	        function readFloat_f32_cpy(buf, pos) {
	            f8b[0] = buf[pos    ];
	            f8b[1] = buf[pos + 1];
	            f8b[2] = buf[pos + 2];
	            f8b[3] = buf[pos + 3];
	            return f32[0];
	        }

	        function readFloat_f32_rev(buf, pos) {
	            f8b[3] = buf[pos    ];
	            f8b[2] = buf[pos + 1];
	            f8b[1] = buf[pos + 2];
	            f8b[0] = buf[pos + 3];
	            return f32[0];
	        }

	        /* istanbul ignore next */
	        exports.readFloatLE = le ? readFloat_f32_cpy : readFloat_f32_rev;
	        /* istanbul ignore next */
	        exports.readFloatBE = le ? readFloat_f32_rev : readFloat_f32_cpy;

	    // float: ieee754
	    })(); else (function() {

	        function writeFloat_ieee754(writeUint, val, buf, pos) {
	            var sign = val < 0 ? 1 : 0;
	            if (sign)
	                val = -val;
	            if (val === 0)
	                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos);
	            else if (isNaN(val))
	                writeUint(2143289344, buf, pos);
	            else if (val > 3.4028234663852886e+38) // +-Infinity
	                writeUint((sign << 31 | 2139095040) >>> 0, buf, pos);
	            else if (val < 1.1754943508222875e-38) // denormal
	                writeUint((sign << 31 | Math.round(val / 1.401298464324817e-45)) >>> 0, buf, pos);
	            else {
	                var exponent = Math.floor(Math.log(val) / Math.LN2),
	                    mantissa = Math.round(val * Math.pow(2, -exponent) * 8388608) & 8388607;
	                writeUint((sign << 31 | exponent + 127 << 23 | mantissa) >>> 0, buf, pos);
	            }
	        }

	        exports.writeFloatLE = writeFloat_ieee754.bind(null, writeUintLE);
	        exports.writeFloatBE = writeFloat_ieee754.bind(null, writeUintBE);

	        function readFloat_ieee754(readUint, buf, pos) {
	            var uint = readUint(buf, pos),
	                sign = (uint >> 31) * 2 + 1,
	                exponent = uint >>> 23 & 255,
	                mantissa = uint & 8388607;
	            return exponent === 255
	                ? mantissa
	                ? NaN
	                : sign * Infinity
	                : exponent === 0 // denormal
	                ? sign * 1.401298464324817e-45 * mantissa
	                : sign * Math.pow(2, exponent - 150) * (mantissa + 8388608);
	        }

	        exports.readFloatLE = readFloat_ieee754.bind(null, readUintLE);
	        exports.readFloatBE = readFloat_ieee754.bind(null, readUintBE);

	    })();

	    // double: typed array
	    if (typeof Float64Array !== "undefined") (function() {

	        var f64 = new Float64Array([-0]),
	            f8b = new Uint8Array(f64.buffer),
	            le  = f8b[7] === 128;

	        function writeDouble_f64_cpy(val, buf, pos) {
	            f64[0] = val;
	            buf[pos    ] = f8b[0];
	            buf[pos + 1] = f8b[1];
	            buf[pos + 2] = f8b[2];
	            buf[pos + 3] = f8b[3];
	            buf[pos + 4] = f8b[4];
	            buf[pos + 5] = f8b[5];
	            buf[pos + 6] = f8b[6];
	            buf[pos + 7] = f8b[7];
	        }

	        function writeDouble_f64_rev(val, buf, pos) {
	            f64[0] = val;
	            buf[pos    ] = f8b[7];
	            buf[pos + 1] = f8b[6];
	            buf[pos + 2] = f8b[5];
	            buf[pos + 3] = f8b[4];
	            buf[pos + 4] = f8b[3];
	            buf[pos + 5] = f8b[2];
	            buf[pos + 6] = f8b[1];
	            buf[pos + 7] = f8b[0];
	        }

	        /* istanbul ignore next */
	        exports.writeDoubleLE = le ? writeDouble_f64_cpy : writeDouble_f64_rev;
	        /* istanbul ignore next */
	        exports.writeDoubleBE = le ? writeDouble_f64_rev : writeDouble_f64_cpy;

	        function readDouble_f64_cpy(buf, pos) {
	            f8b[0] = buf[pos    ];
	            f8b[1] = buf[pos + 1];
	            f8b[2] = buf[pos + 2];
	            f8b[3] = buf[pos + 3];
	            f8b[4] = buf[pos + 4];
	            f8b[5] = buf[pos + 5];
	            f8b[6] = buf[pos + 6];
	            f8b[7] = buf[pos + 7];
	            return f64[0];
	        }

	        function readDouble_f64_rev(buf, pos) {
	            f8b[7] = buf[pos    ];
	            f8b[6] = buf[pos + 1];
	            f8b[5] = buf[pos + 2];
	            f8b[4] = buf[pos + 3];
	            f8b[3] = buf[pos + 4];
	            f8b[2] = buf[pos + 5];
	            f8b[1] = buf[pos + 6];
	            f8b[0] = buf[pos + 7];
	            return f64[0];
	        }

	        /* istanbul ignore next */
	        exports.readDoubleLE = le ? readDouble_f64_cpy : readDouble_f64_rev;
	        /* istanbul ignore next */
	        exports.readDoubleBE = le ? readDouble_f64_rev : readDouble_f64_cpy;

	    // double: ieee754
	    })(); else (function() {

	        function writeDouble_ieee754(writeUint, off0, off1, val, buf, pos) {
	            var sign = val < 0 ? 1 : 0;
	            if (sign)
	                val = -val;
	            if (val === 0) {
	                writeUint(0, buf, pos + off0);
	                writeUint(1 / val > 0 ? /* positive */ 0 : /* negative 0 */ 2147483648, buf, pos + off1);
	            } else if (isNaN(val)) {
	                writeUint(0, buf, pos + off0);
	                writeUint(2146959360, buf, pos + off1);
	            } else if (val > 1.7976931348623157e+308) { // +-Infinity
	                writeUint(0, buf, pos + off0);
	                writeUint((sign << 31 | 2146435072) >>> 0, buf, pos + off1);
	            } else {
	                var mantissa;
	                if (val < 2.2250738585072014e-308) { // denormal
	                    mantissa = val / 5e-324;
	                    writeUint(mantissa >>> 0, buf, pos + off0);
	                    writeUint((sign << 31 | mantissa / 4294967296) >>> 0, buf, pos + off1);
	                } else {
	                    var exponent = Math.floor(Math.log(val) / Math.LN2);
	                    if (exponent === 1024)
	                        exponent = 1023;
	                    mantissa = val * Math.pow(2, -exponent);
	                    writeUint(mantissa * 4503599627370496 >>> 0, buf, pos + off0);
	                    writeUint((sign << 31 | exponent + 1023 << 20 | mantissa * 1048576 & 1048575) >>> 0, buf, pos + off1);
	                }
	            }
	        }

	        exports.writeDoubleLE = writeDouble_ieee754.bind(null, writeUintLE, 0, 4);
	        exports.writeDoubleBE = writeDouble_ieee754.bind(null, writeUintBE, 4, 0);

	        function readDouble_ieee754(readUint, off0, off1, buf, pos) {
	            var lo = readUint(buf, pos + off0),
	                hi = readUint(buf, pos + off1);
	            var sign = (hi >> 31) * 2 + 1,
	                exponent = hi >>> 20 & 2047,
	                mantissa = 4294967296 * (hi & 1048575) + lo;
	            return exponent === 2047
	                ? mantissa
	                ? NaN
	                : sign * Infinity
	                : exponent === 0 // denormal
	                ? sign * 5e-324 * mantissa
	                : sign * Math.pow(2, exponent - 1075) * (mantissa + 4503599627370496);
	        }

	        exports.readDoubleLE = readDouble_ieee754.bind(null, readUintLE, 0, 4);
	        exports.readDoubleBE = readDouble_ieee754.bind(null, readUintBE, 4, 0);

	    })();

	    return exports;
	}

	// uint helpers

	function writeUintLE(val, buf, pos) {
	    buf[pos    ] =  val        & 255;
	    buf[pos + 1] =  val >>> 8  & 255;
	    buf[pos + 2] =  val >>> 16 & 255;
	    buf[pos + 3] =  val >>> 24;
	}

	function writeUintBE(val, buf, pos) {
	    buf[pos    ] =  val >>> 24;
	    buf[pos + 1] =  val >>> 16 & 255;
	    buf[pos + 2] =  val >>> 8  & 255;
	    buf[pos + 3] =  val        & 255;
	}

	function readUintLE(buf, pos) {
	    return (buf[pos    ]
	          | buf[pos + 1] << 8
	          | buf[pos + 2] << 16
	          | buf[pos + 3] << 24) >>> 0;
	}

	function readUintBE(buf, pos) {
	    return (buf[pos    ] << 24
	          | buf[pos + 1] << 16
	          | buf[pos + 2] << 8
	          | buf[pos + 3]) >>> 0;
	}
	return float;
}

var inquire_1;
var hasRequiredInquire;

function requireInquire () {
	if (hasRequiredInquire) return inquire_1;
	hasRequiredInquire = 1;
	inquire_1 = inquire;

	/**
	 * Requires a module only if available.
	 * @memberof util
	 * @param {string} moduleName Module to require
	 * @returns {?Object} Required module if available and not empty, otherwise `null`
	 */
	function inquire(moduleName) {
	    try {
	        var mod = eval("quire".replace(/^/,"re"))(moduleName); // eslint-disable-line no-eval
	        if (mod && (mod.length || Object.keys(mod).length))
	            return mod;
	    } catch (e) {} // eslint-disable-line no-empty
	    return null;
	}
	return inquire_1;
}

var utf8$2 = {};

var hasRequiredUtf8;

function requireUtf8 () {
	if (hasRequiredUtf8) return utf8$2;
	hasRequiredUtf8 = 1;
	(function (exports) {

		/**
		 * A minimal UTF8 implementation for number arrays.
		 * @memberof util
		 * @namespace
		 */
		var utf8 = exports;

		/**
		 * Calculates the UTF8 byte length of a string.
		 * @param {string} string String
		 * @returns {number} Byte length
		 */
		utf8.length = function utf8_length(string) {
		    var len = 0,
		        c = 0;
		    for (var i = 0; i < string.length; ++i) {
		        c = string.charCodeAt(i);
		        if (c < 128)
		            len += 1;
		        else if (c < 2048)
		            len += 2;
		        else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {
		            ++i;
		            len += 4;
		        } else
		            len += 3;
		    }
		    return len;
		};

		/**
		 * Reads UTF8 bytes as a string.
		 * @param {Uint8Array} buffer Source buffer
		 * @param {number} start Source start
		 * @param {number} end Source end
		 * @returns {string} String read
		 */
		utf8.read = function utf8_read(buffer, start, end) {
		    var len = end - start;
		    if (len < 1)
		        return "";
		    var parts = null,
		        chunk = [],
		        i = 0, // char offset
		        t;     // temporary
		    while (start < end) {
		        t = buffer[start++];
		        if (t < 128)
		            chunk[i++] = t;
		        else if (t > 191 && t < 224)
		            chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;
		        else if (t > 239 && t < 365) {
		            t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;
		            chunk[i++] = 0xD800 + (t >> 10);
		            chunk[i++] = 0xDC00 + (t & 1023);
		        } else
		            chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;
		        if (i > 8191) {
		            (parts || (parts = [])).push(String.fromCharCode.apply(String, chunk));
		            i = 0;
		        }
		    }
		    if (parts) {
		        if (i)
		            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));
		        return parts.join("");
		    }
		    return String.fromCharCode.apply(String, chunk.slice(0, i));
		};

		/**
		 * Writes a string as UTF8 bytes.
		 * @param {string} string Source string
		 * @param {Uint8Array} buffer Destination buffer
		 * @param {number} offset Destination offset
		 * @returns {number} Bytes written
		 */
		utf8.write = function utf8_write(string, buffer, offset) {
		    var start = offset,
		        c1, // character 1
		        c2; // character 2
		    for (var i = 0; i < string.length; ++i) {
		        c1 = string.charCodeAt(i);
		        if (c1 < 128) {
		            buffer[offset++] = c1;
		        } else if (c1 < 2048) {
		            buffer[offset++] = c1 >> 6       | 192;
		            buffer[offset++] = c1       & 63 | 128;
		        } else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {
		            c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);
		            ++i;
		            buffer[offset++] = c1 >> 18      | 240;
		            buffer[offset++] = c1 >> 12 & 63 | 128;
		            buffer[offset++] = c1 >> 6  & 63 | 128;
		            buffer[offset++] = c1       & 63 | 128;
		        } else {
		            buffer[offset++] = c1 >> 12      | 224;
		            buffer[offset++] = c1 >> 6  & 63 | 128;
		            buffer[offset++] = c1       & 63 | 128;
		        }
		    }
		    return offset - start;
		}; 
	} (utf8$2));
	return utf8$2;
}

var pool_1;
var hasRequiredPool;

function requirePool () {
	if (hasRequiredPool) return pool_1;
	hasRequiredPool = 1;
	pool_1 = pool;

	/**
	 * An allocator as used by {@link util.pool}.
	 * @typedef PoolAllocator
	 * @type {function}
	 * @param {number} size Buffer size
	 * @returns {Uint8Array} Buffer
	 */

	/**
	 * A slicer as used by {@link util.pool}.
	 * @typedef PoolSlicer
	 * @type {function}
	 * @param {number} start Start offset
	 * @param {number} end End offset
	 * @returns {Uint8Array} Buffer slice
	 * @this {Uint8Array}
	 */

	/**
	 * A general purpose buffer pool.
	 * @memberof util
	 * @function
	 * @param {PoolAllocator} alloc Allocator
	 * @param {PoolSlicer} slice Slicer
	 * @param {number} [size=8192] Slab size
	 * @returns {PoolAllocator} Pooled allocator
	 */
	function pool(alloc, slice, size) {
	    var SIZE   = size || 8192;
	    var MAX    = SIZE >>> 1;
	    var slab   = null;
	    var offset = SIZE;
	    return function pool_alloc(size) {
	        if (size < 1 || size > MAX)
	            return alloc(size);
	        if (offset + size > SIZE) {
	            slab = alloc(SIZE);
	            offset = 0;
	        }
	        var buf = slice.call(slab, offset, offset += size);
	        if (offset & 7) // align to 32 bit
	            offset = (offset | 7) + 1;
	        return buf;
	    };
	}
	return pool_1;
}

var longbits;
var hasRequiredLongbits;

function requireLongbits () {
	if (hasRequiredLongbits) return longbits;
	hasRequiredLongbits = 1;
	longbits = LongBits;

	var util = requireMinimal();

	/**
	 * Constructs new long bits.
	 * @classdesc Helper class for working with the low and high bits of a 64 bit value.
	 * @memberof util
	 * @constructor
	 * @param {number} lo Low 32 bits, unsigned
	 * @param {number} hi High 32 bits, unsigned
	 */
	function LongBits(lo, hi) {

	    // note that the casts below are theoretically unnecessary as of today, but older statically
	    // generated converter code might still call the ctor with signed 32bits. kept for compat.

	    /**
	     * Low bits.
	     * @type {number}
	     */
	    this.lo = lo >>> 0;

	    /**
	     * High bits.
	     * @type {number}
	     */
	    this.hi = hi >>> 0;
	}

	/**
	 * Zero bits.
	 * @memberof util.LongBits
	 * @type {util.LongBits}
	 */
	var zero = LongBits.zero = new LongBits(0, 0);

	zero.toNumber = function() { return 0; };
	zero.zzEncode = zero.zzDecode = function() { return this; };
	zero.length = function() { return 1; };

	/**
	 * Zero hash.
	 * @memberof util.LongBits
	 * @type {string}
	 */
	var zeroHash = LongBits.zeroHash = "\0\0\0\0\0\0\0\0";

	/**
	 * Constructs new long bits from the specified number.
	 * @param {number} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.fromNumber = function fromNumber(value) {
	    if (value === 0)
	        return zero;
	    var sign = value < 0;
	    if (sign)
	        value = -value;
	    var lo = value >>> 0,
	        hi = (value - lo) / 4294967296 >>> 0;
	    if (sign) {
	        hi = ~hi >>> 0;
	        lo = ~lo >>> 0;
	        if (++lo > 4294967295) {
	            lo = 0;
	            if (++hi > 4294967295)
	                hi = 0;
	        }
	    }
	    return new LongBits(lo, hi);
	};

	/**
	 * Constructs new long bits from a number, long or string.
	 * @param {Long|number|string} value Value
	 * @returns {util.LongBits} Instance
	 */
	LongBits.from = function from(value) {
	    if (typeof value === "number")
	        return LongBits.fromNumber(value);
	    if (util.isString(value)) {
	        /* istanbul ignore else */
	        if (util.Long)
	            value = util.Long.fromString(value);
	        else
	            return LongBits.fromNumber(parseInt(value, 10));
	    }
	    return value.low || value.high ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;
	};

	/**
	 * Converts this long bits to a possibly unsafe JavaScript number.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {number} Possibly unsafe number
	 */
	LongBits.prototype.toNumber = function toNumber(unsigned) {
	    if (!unsigned && this.hi >>> 31) {
	        var lo = ~this.lo + 1 >>> 0,
	            hi = ~this.hi     >>> 0;
	        if (!lo)
	            hi = hi + 1 >>> 0;
	        return -(lo + hi * 4294967296);
	    }
	    return this.lo + this.hi * 4294967296;
	};

	/**
	 * Converts this long bits to a long.
	 * @param {boolean} [unsigned=false] Whether unsigned or not
	 * @returns {Long} Long
	 */
	LongBits.prototype.toLong = function toLong(unsigned) {
	    return util.Long
	        ? new util.Long(this.lo | 0, this.hi | 0, Boolean(unsigned))
	        /* istanbul ignore next */
	        : { low: this.lo | 0, high: this.hi | 0, unsigned: Boolean(unsigned) };
	};

	var charCodeAt = String.prototype.charCodeAt;

	/**
	 * Constructs new long bits from the specified 8 characters long hash.
	 * @param {string} hash Hash
	 * @returns {util.LongBits} Bits
	 */
	LongBits.fromHash = function fromHash(hash) {
	    if (hash === zeroHash)
	        return zero;
	    return new LongBits(
	        ( charCodeAt.call(hash, 0)
	        | charCodeAt.call(hash, 1) << 8
	        | charCodeAt.call(hash, 2) << 16
	        | charCodeAt.call(hash, 3) << 24) >>> 0
	    ,
	        ( charCodeAt.call(hash, 4)
	        | charCodeAt.call(hash, 5) << 8
	        | charCodeAt.call(hash, 6) << 16
	        | charCodeAt.call(hash, 7) << 24) >>> 0
	    );
	};

	/**
	 * Converts this long bits to a 8 characters long hash.
	 * @returns {string} Hash
	 */
	LongBits.prototype.toHash = function toHash() {
	    return String.fromCharCode(
	        this.lo        & 255,
	        this.lo >>> 8  & 255,
	        this.lo >>> 16 & 255,
	        this.lo >>> 24      ,
	        this.hi        & 255,
	        this.hi >>> 8  & 255,
	        this.hi >>> 16 & 255,
	        this.hi >>> 24
	    );
	};

	/**
	 * Zig-zag encodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzEncode = function zzEncode() {
	    var mask =   this.hi >> 31;
	    this.hi  = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
	    this.lo  = ( this.lo << 1                   ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Zig-zag decodes this long bits.
	 * @returns {util.LongBits} `this`
	 */
	LongBits.prototype.zzDecode = function zzDecode() {
	    var mask = -(this.lo & 1);
	    this.lo  = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
	    this.hi  = ( this.hi >>> 1                  ^ mask) >>> 0;
	    return this;
	};

	/**
	 * Calculates the length of this longbits when encoded as a varint.
	 * @returns {number} Length
	 */
	LongBits.prototype.length = function length() {
	    var part0 =  this.lo,
	        part1 = (this.lo >>> 28 | this.hi << 4) >>> 0,
	        part2 =  this.hi >>> 24;
	    return part2 === 0
	         ? part1 === 0
	           ? part0 < 16384
	             ? part0 < 128 ? 1 : 2
	             : part0 < 2097152 ? 3 : 4
	           : part1 < 16384
	             ? part1 < 128 ? 5 : 6
	             : part1 < 2097152 ? 7 : 8
	         : part2 < 128 ? 9 : 10;
	};
	return longbits;
}

var hasRequiredMinimal;

function requireMinimal () {
	if (hasRequiredMinimal) return minimal$1;
	hasRequiredMinimal = 1;
	(function (exports) {
		var util = exports;

		// used to return a Promise where callback is omitted
		util.asPromise = requireAspromise();

		// converts to / from base64 encoded strings
		util.base64 = requireBase64();

		// base class of rpc.Service
		util.EventEmitter = requireEventemitter();

		// float handling accross browsers
		util.float = requireFloat();

		// requires modules optionally and hides the call from bundlers
		util.inquire = requireInquire();

		// converts to / from utf8 encoded strings
		util.utf8 = requireUtf8();

		// provides a node-like buffer pool in the browser
		util.pool = requirePool();

		// utility to work with the low and high bits of a 64 bit value
		util.LongBits = requireLongbits();

		/**
		 * Whether running within node or not.
		 * @memberof util
		 * @type {boolean}
		 */
		util.isNode = Boolean(typeof commonjsGlobal !== "undefined"
		                   && commonjsGlobal
		                   && commonjsGlobal.process
		                   && commonjsGlobal.process.versions
		                   && commonjsGlobal.process.versions.node);

		/**
		 * Global object reference.
		 * @memberof util
		 * @type {Object}
		 */
		util.global = util.isNode && commonjsGlobal
		           || typeof window !== "undefined" && window
		           || typeof self   !== "undefined" && self
		           || commonjsGlobal; // eslint-disable-line no-invalid-this

		/**
		 * An immuable empty array.
		 * @memberof util
		 * @type {Array.<*>}
		 * @const
		 */
		util.emptyArray = Object.freeze ? Object.freeze([]) : /* istanbul ignore next */ []; // used on prototypes

		/**
		 * An immutable empty object.
		 * @type {Object}
		 * @const
		 */
		util.emptyObject = Object.freeze ? Object.freeze({}) : /* istanbul ignore next */ {}; // used on prototypes

		/**
		 * Tests if the specified value is an integer.
		 * @function
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is an integer
		 */
		util.isInteger = Number.isInteger || /* istanbul ignore next */ function isInteger(value) {
		    return typeof value === "number" && isFinite(value) && Math.floor(value) === value;
		};

		/**
		 * Tests if the specified value is a string.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a string
		 */
		util.isString = function isString(value) {
		    return typeof value === "string" || value instanceof String;
		};

		/**
		 * Tests if the specified value is a non-null object.
		 * @param {*} value Value to test
		 * @returns {boolean} `true` if the value is a non-null object
		 */
		util.isObject = function isObject(value) {
		    return value && typeof value === "object";
		};

		/**
		 * Checks if a property on a message is considered to be present.
		 * This is an alias of {@link util.isSet}.
		 * @function
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isset =

		/**
		 * Checks if a property on a message is considered to be present.
		 * @param {Object} obj Plain object or message instance
		 * @param {string} prop Property name
		 * @returns {boolean} `true` if considered to be present, otherwise `false`
		 */
		util.isSet = function isSet(obj, prop) {
		    var value = obj[prop];
		    if (value != null && obj.hasOwnProperty(prop)) // eslint-disable-line eqeqeq, no-prototype-builtins
		        return typeof value !== "object" || (Array.isArray(value) ? value.length : Object.keys(value).length) > 0;
		    return false;
		};

		/**
		 * Any compatible Buffer instance.
		 * This is a minimal stand-alone definition of a Buffer instance. The actual type is that exported by node's typings.
		 * @interface Buffer
		 * @extends Uint8Array
		 */

		/**
		 * Node's Buffer class if available.
		 * @type {Constructor<Buffer>}
		 */
		util.Buffer = (function() {
		    try {
		        var Buffer = util.inquire("buffer").Buffer;
		        // refuse to use non-node buffers if not explicitly assigned (perf reasons):
		        return Buffer.prototype.utf8Write ? Buffer : /* istanbul ignore next */ null;
		    } catch (e) {
		        /* istanbul ignore next */
		        return null;
		    }
		})();

		// Internal alias of or polyfull for Buffer.from.
		util._Buffer_from = null;

		// Internal alias of or polyfill for Buffer.allocUnsafe.
		util._Buffer_allocUnsafe = null;

		/**
		 * Creates a new buffer of whatever type supported by the environment.
		 * @param {number|number[]} [sizeOrArray=0] Buffer size or number array
		 * @returns {Uint8Array|Buffer} Buffer
		 */
		util.newBuffer = function newBuffer(sizeOrArray) {
		    /* istanbul ignore next */
		    return typeof sizeOrArray === "number"
		        ? util.Buffer
		            ? util._Buffer_allocUnsafe(sizeOrArray)
		            : new util.Array(sizeOrArray)
		        : util.Buffer
		            ? util._Buffer_from(sizeOrArray)
		            : typeof Uint8Array === "undefined"
		                ? sizeOrArray
		                : new Uint8Array(sizeOrArray);
		};

		/**
		 * Array implementation used in the browser. `Uint8Array` if supported, otherwise `Array`.
		 * @type {Constructor<Uint8Array>}
		 */
		util.Array = typeof Uint8Array !== "undefined" ? Uint8Array /* istanbul ignore next */ : Array;

		/**
		 * Any compatible Long instance.
		 * This is a minimal stand-alone definition of a Long instance. The actual type is that exported by long.js.
		 * @interface Long
		 * @property {number} low Low bits
		 * @property {number} high High bits
		 * @property {boolean} unsigned Whether unsigned or not
		 */

		/**
		 * Long.js's Long class if available.
		 * @type {Constructor<Long>}
		 */
		util.Long = /* istanbul ignore next */ util.global.dcodeIO && /* istanbul ignore next */ util.global.dcodeIO.Long
		         || /* istanbul ignore next */ util.global.Long
		         || util.inquire("long");

		/**
		 * Regular expression used to verify 2 bit (`bool`) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key2Re = /^true|false|0|1$/;

		/**
		 * Regular expression used to verify 32 bit (`int32` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key32Re = /^-?(?:0|[1-9][0-9]*)$/;

		/**
		 * Regular expression used to verify 64 bit (`int64` etc.) map keys.
		 * @type {RegExp}
		 * @const
		 */
		util.key64Re = /^(?:[\\x00-\\xff]{8}|-?(?:0|[1-9][0-9]*))$/;

		/**
		 * Converts a number or long to an 8 characters long hash string.
		 * @param {Long|number} value Value to convert
		 * @returns {string} Hash
		 */
		util.longToHash = function longToHash(value) {
		    return value
		        ? util.LongBits.from(value).toHash()
		        : util.LongBits.zeroHash;
		};

		/**
		 * Converts an 8 characters long hash string to a long or number.
		 * @param {string} hash Hash
		 * @param {boolean} [unsigned=false] Whether unsigned or not
		 * @returns {Long|number} Original value
		 */
		util.longFromHash = function longFromHash(hash, unsigned) {
		    var bits = util.LongBits.fromHash(hash);
		    if (util.Long)
		        return util.Long.fromBits(bits.lo, bits.hi, unsigned);
		    return bits.toNumber(Boolean(unsigned));
		};

		/**
		 * Merges the properties of the source object into the destination object.
		 * @memberof util
		 * @param {Object.<string,*>} dst Destination object
		 * @param {Object.<string,*>} src Source object
		 * @param {boolean} [ifNotSet=false] Merges only if the key is not already set
		 * @returns {Object.<string,*>} Destination object
		 */
		function merge(dst, src, ifNotSet) { // used by converters
		    for (var keys = Object.keys(src), i = 0; i < keys.length; ++i)
		        if (dst[keys[i]] === undefined || !ifNotSet)
		            dst[keys[i]] = src[keys[i]];
		    return dst;
		}

		util.merge = merge;

		/**
		 * Converts the first character of a string to lower case.
		 * @param {string} str String to convert
		 * @returns {string} Converted string
		 */
		util.lcFirst = function lcFirst(str) {
		    return str.charAt(0).toLowerCase() + str.substring(1);
		};

		/**
		 * Creates a custom error constructor.
		 * @memberof util
		 * @param {string} name Error name
		 * @returns {Constructor<Error>} Custom error constructor
		 */
		function newError(name) {

		    function CustomError(message, properties) {

		        if (!(this instanceof CustomError))
		            return new CustomError(message, properties);

		        // Error.call(this, message);
		        // ^ just returns a new error instance because the ctor can be called as a function

		        Object.defineProperty(this, "message", { get: function() { return message; } });

		        /* istanbul ignore next */
		        if (Error.captureStackTrace) // node
		            Error.captureStackTrace(this, CustomError);
		        else
		            Object.defineProperty(this, "stack", { value: new Error().stack || "" });

		        if (properties)
		            merge(this, properties);
		    }

		    CustomError.prototype = Object.create(Error.prototype, {
		        constructor: {
		            value: CustomError,
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		        name: {
		            get: function get() { return name; },
		            set: undefined,
		            enumerable: false,
		            // configurable: false would accurately preserve the behavior of
		            // the original, but I'm guessing that was not intentional.
		            // For an actual error subclass, this property would
		            // be configurable.
		            configurable: true,
		        },
		        toString: {
		            value: function value() { return this.name + ": " + this.message; },
		            writable: true,
		            enumerable: false,
		            configurable: true,
		        },
		    });

		    return CustomError;
		}

		util.newError = newError;

		/**
		 * Constructs a new protocol error.
		 * @classdesc Error subclass indicating a protocol specifc error.
		 * @memberof util
		 * @extends Error
		 * @template T extends Message<T>
		 * @constructor
		 * @param {string} message Error message
		 * @param {Object.<string,*>} [properties] Additional properties
		 * @example
		 * try {
		 *     MyMessage.decode(someBuffer); // throws if required fields are missing
		 * } catch (e) {
		 *     if (e instanceof ProtocolError && e.instance)
		 *         console.log("decoded so far: " + JSON.stringify(e.instance));
		 * }
		 */
		util.ProtocolError = newError("ProtocolError");

		/**
		 * So far decoded message instance.
		 * @name util.ProtocolError#instance
		 * @type {Message<T>}
		 */

		/**
		 * A OneOf getter as returned by {@link util.oneOfGetter}.
		 * @typedef OneOfGetter
		 * @type {function}
		 * @returns {string|undefined} Set field name, if any
		 */

		/**
		 * Builds a getter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfGetter} Unbound getter
		 */
		util.oneOfGetter = function getOneOf(fieldNames) {
		    var fieldMap = {};
		    for (var i = 0; i < fieldNames.length; ++i)
		        fieldMap[fieldNames[i]] = 1;

		    /**
		     * @returns {string|undefined} Set field name, if any
		     * @this Object
		     * @ignore
		     */
		    return function() { // eslint-disable-line consistent-return
		        for (var keys = Object.keys(this), i = keys.length - 1; i > -1; --i)
		            if (fieldMap[keys[i]] === 1 && this[keys[i]] !== undefined && this[keys[i]] !== null)
		                return keys[i];
		    };
		};

		/**
		 * A OneOf setter as returned by {@link util.oneOfSetter}.
		 * @typedef OneOfSetter
		 * @type {function}
		 * @param {string|undefined} value Field name
		 * @returns {undefined}
		 */

		/**
		 * Builds a setter for a oneof's present field name.
		 * @param {string[]} fieldNames Field names
		 * @returns {OneOfSetter} Unbound setter
		 */
		util.oneOfSetter = function setOneOf(fieldNames) {

		    /**
		     * @param {string} name Field name
		     * @returns {undefined}
		     * @this Object
		     * @ignore
		     */
		    return function(name) {
		        for (var i = 0; i < fieldNames.length; ++i)
		            if (fieldNames[i] !== name)
		                delete this[fieldNames[i]];
		    };
		};

		/**
		 * Default conversion options used for {@link Message#toJSON} implementations.
		 *
		 * These options are close to proto3's JSON mapping with the exception that internal types like Any are handled just like messages. More precisely:
		 *
		 * - Longs become strings
		 * - Enums become string keys
		 * - Bytes become base64 encoded strings
		 * - (Sub-)Messages become plain objects
		 * - Maps become plain objects with all string keys
		 * - Repeated fields become arrays
		 * - NaN and Infinity for float and double fields become strings
		 *
		 * @type {IConversionOptions}
		 * @see https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json
		 */
		util.toJSONOptions = {
		    longs: String,
		    enums: String,
		    bytes: String,
		    json: true
		};

		// Sets up buffer utility according to the environment (called in index-minimal)
		util._configure = function() {
		    var Buffer = util.Buffer;
		    /* istanbul ignore if */
		    if (!Buffer) {
		        util._Buffer_from = util._Buffer_allocUnsafe = null;
		        return;
		    }
		    // because node 4.x buffers are incompatible & immutable
		    // see: https://github.com/dcodeIO/protobuf.js/pull/665
		    util._Buffer_from = Buffer.from !== Uint8Array.from && Buffer.from ||
		        /* istanbul ignore next */
		        function Buffer_from(value, encoding) {
		            return new Buffer(value, encoding);
		        };
		    util._Buffer_allocUnsafe = Buffer.allocUnsafe ||
		        /* istanbul ignore next */
		        function Buffer_allocUnsafe(size) {
		            return new Buffer(size);
		        };
		}; 
	} (minimal$1));
	return minimal$1;
}

var reader$2 = Reader$1;

var util$8      = requireMinimal();

var BufferReader$1; // cyclic

var LongBits$2  = util$8.LongBits,
    utf8$1      = util$8.utf8;

/* istanbul ignore next */
function indexOutOfRange(reader, writeLength) {
    return RangeError("index out of range: " + reader.pos + " + " + (writeLength || 1) + " > " + reader.len);
}

/**
 * Constructs a new reader instance using the specified buffer.
 * @classdesc Wire format reader using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 * @param {Uint8Array} buffer Buffer to read from
 */
function Reader$1(buffer) {

    /**
     * Read buffer.
     * @type {Uint8Array}
     */
    this.buf = buffer;

    /**
     * Read buffer position.
     * @type {number}
     */
    this.pos = 0;

    /**
     * Read buffer length.
     * @type {number}
     */
    this.len = buffer.length;
}

var create_array = typeof Uint8Array !== "undefined"
    ? function create_typed_array(buffer) {
        if (buffer instanceof Uint8Array || Array.isArray(buffer))
            return new Reader$1(buffer);
        throw Error("illegal buffer");
    }
    /* istanbul ignore next */
    : function create_array(buffer) {
        if (Array.isArray(buffer))
            return new Reader$1(buffer);
        throw Error("illegal buffer");
    };

var create$g = function create() {
    return util$8.Buffer
        ? function create_buffer_setup(buffer) {
            return (Reader$1.create = function create_buffer(buffer) {
                return util$8.Buffer.isBuffer(buffer)
                    ? new BufferReader$1(buffer)
                    /* istanbul ignore next */
                    : create_array(buffer);
            })(buffer);
        }
        /* istanbul ignore next */
        : create_array;
};

/**
 * Creates a new reader using the specified buffer.
 * @function
 * @param {Uint8Array|Buffer} buffer Buffer to read from
 * @returns {Reader|BufferReader} A {@link BufferReader} if `buffer` is a Buffer, otherwise a {@link Reader}
 * @throws {Error} If `buffer` is not a valid buffer
 */
Reader$1.create = create$g();

Reader$1.prototype._slice = util$8.Array.prototype.subarray || /* istanbul ignore next */ util$8.Array.prototype.slice;

/**
 * Reads a varint as an unsigned 32 bit value.
 * @function
 * @returns {number} Value read
 */
Reader$1.prototype.uint32 = (function read_uint32_setup() {
    var value = 4294967295; // optimizer type-hint, tends to deopt otherwise (?!)
    return function read_uint32() {
        value = (         this.buf[this.pos] & 127       ) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) <<  7) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0; if (this.buf[this.pos++] < 128) return value;
        value = (value | (this.buf[this.pos] &  15) << 28) >>> 0; if (this.buf[this.pos++] < 128) return value;

        /* istanbul ignore if */
        if ((this.pos += 5) > this.len) {
            this.pos = this.len;
            throw indexOutOfRange(this, 10);
        }
        return value;
    };
})();

/**
 * Reads a varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$1.prototype.int32 = function read_int32() {
    return this.uint32() | 0;
};

/**
 * Reads a zig-zag encoded varint as a signed 32 bit value.
 * @returns {number} Value read
 */
Reader$1.prototype.sint32 = function read_sint32() {
    var value = this.uint32();
    return value >>> 1 ^ -(value & 1) | 0;
};

/* eslint-disable no-invalid-this */

function readLongVarint() {
    // tends to deopt with local vars for octet etc.
    var bits = new LongBits$2(0, 0);
    var i = 0;
    if (this.len - this.pos > 4) { // fast route (lo)
        for (; i < 4; ++i) {
            // 1st..4th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 5th
        bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;
        bits.hi = (bits.hi | (this.buf[this.pos] & 127) >>  4) >>> 0;
        if (this.buf[this.pos++] < 128)
            return bits;
        i = 0;
    } else {
        for (; i < 3; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
            // 1st..3th
            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
        // 4th
        bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;
        return bits;
    }
    if (this.len - this.pos > 4) { // fast route (hi)
        for (; i < 5; ++i) {
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    } else {
        for (; i < 5; ++i) {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
            // 6th..10th
            bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;
            if (this.buf[this.pos++] < 128)
                return bits;
        }
    }
    /* istanbul ignore next */
    throw Error("invalid varint encoding");
}

/* eslint-enable no-invalid-this */

/**
 * Reads a varint as a signed 64 bit value.
 * @name Reader#int64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as an unsigned 64 bit value.
 * @name Reader#uint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a zig-zag encoded varint as a signed 64 bit value.
 * @name Reader#sint64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a varint as a boolean.
 * @returns {boolean} Value read
 */
Reader$1.prototype.bool = function read_bool() {
    return this.uint32() !== 0;
};

function readFixed32_end(buf, end) { // note that this uses `end`, not `pos`
    return (buf[end - 4]
          | buf[end - 3] << 8
          | buf[end - 2] << 16
          | buf[end - 1] << 24) >>> 0;
}

/**
 * Reads fixed 32 bits as an unsigned 32 bit integer.
 * @returns {number} Value read
 */
Reader$1.prototype.fixed32 = function read_fixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    return readFixed32_end(this.buf, this.pos += 4);
};

/**
 * Reads fixed 32 bits as a signed 32 bit integer.
 * @returns {number} Value read
 */
Reader$1.prototype.sfixed32 = function read_sfixed32() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    return readFixed32_end(this.buf, this.pos += 4) | 0;
};

/* eslint-disable no-invalid-this */

function readFixed64(/* this: Reader */) {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange(this, 8);

    return new LongBits$2(readFixed32_end(this.buf, this.pos += 4), readFixed32_end(this.buf, this.pos += 4));
}

/* eslint-enable no-invalid-this */

/**
 * Reads fixed 64 bits.
 * @name Reader#fixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads zig-zag encoded fixed 64 bits.
 * @name Reader#sfixed64
 * @function
 * @returns {Long} Value read
 */

/**
 * Reads a float (32 bit) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$1.prototype.float = function read_float() {

    /* istanbul ignore if */
    if (this.pos + 4 > this.len)
        throw indexOutOfRange(this, 4);

    var value = util$8.float.readFloatLE(this.buf, this.pos);
    this.pos += 4;
    return value;
};

/**
 * Reads a double (64 bit float) as a number.
 * @function
 * @returns {number} Value read
 */
Reader$1.prototype.double = function read_double() {

    /* istanbul ignore if */
    if (this.pos + 8 > this.len)
        throw indexOutOfRange(this, 4);

    var value = util$8.float.readDoubleLE(this.buf, this.pos);
    this.pos += 8;
    return value;
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @returns {Uint8Array} Value read
 */
Reader$1.prototype.bytes = function read_bytes() {
    var length = this.uint32(),
        start  = this.pos,
        end    = this.pos + length;

    /* istanbul ignore if */
    if (end > this.len)
        throw indexOutOfRange(this, length);

    this.pos += length;
    if (Array.isArray(this.buf)) // plain array
        return this.buf.slice(start, end);
    return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1
        ? new this.buf.constructor(0)
        : this._slice.call(this.buf, start, end);
};

/**
 * Reads a string preceeded by its byte length as a varint.
 * @returns {string} Value read
 */
Reader$1.prototype.string = function read_string() {
    var bytes = this.bytes();
    return utf8$1.read(bytes, 0, bytes.length);
};

/**
 * Skips the specified number of bytes if specified, otherwise skips a varint.
 * @param {number} [length] Length if known, otherwise a varint is assumed
 * @returns {Reader} `this`
 */
Reader$1.prototype.skip = function skip(length) {
    if (typeof length === "number") {
        /* istanbul ignore if */
        if (this.pos + length > this.len)
            throw indexOutOfRange(this, length);
        this.pos += length;
    } else {
        do {
            /* istanbul ignore if */
            if (this.pos >= this.len)
                throw indexOutOfRange(this);
        } while (this.buf[this.pos++] & 128);
    }
    return this;
};

/**
 * Skips the next element of the specified wire type.
 * @param {number} wireType Wire type received
 * @returns {Reader} `this`
 */
Reader$1.prototype.skipType = function(wireType) {
    switch (wireType) {
        case 0:
            this.skip();
            break;
        case 1:
            this.skip(8);
            break;
        case 2:
            this.skip(this.uint32());
            break;
        case 3:
            while ((wireType = this.uint32() & 7) !== 4) {
                this.skipType(wireType);
            }
            break;
        case 5:
            this.skip(4);
            break;

        /* istanbul ignore next */
        default:
            throw Error("invalid wire type " + wireType + " at offset " + this.pos);
    }
    return this;
};

Reader$1._configure = function(BufferReader_) {
    BufferReader$1 = BufferReader_;
    Reader$1.create = create$g();
    BufferReader$1._configure();

    var fn = util$8.Long ? "toLong" : /* istanbul ignore next */ "toNumber";
    util$8.merge(Reader$1.prototype, {

        int64: function read_int64() {
            return readLongVarint.call(this)[fn](false);
        },

        uint64: function read_uint64() {
            return readLongVarint.call(this)[fn](true);
        },

        sint64: function read_sint64() {
            return readLongVarint.call(this).zzDecode()[fn](false);
        },

        fixed64: function read_fixed64() {
            return readFixed64.call(this)[fn](true);
        },

        sfixed64: function read_sfixed64() {
            return readFixed64.call(this)[fn](false);
        }

    });
};

var ReaderClass = /*@__PURE__*/getDefaultExportFromCjs(reader$2);

var reader_buffer = BufferReader;

// extends Reader
var Reader = reader$2;
(BufferReader.prototype = Object.create(Reader.prototype)).constructor = BufferReader;

var util$7 = requireMinimal();

/**
 * Constructs a new buffer reader instance.
 * @classdesc Wire format reader using node buffers.
 * @extends Reader
 * @constructor
 * @param {Buffer} buffer Buffer to read from
 */
function BufferReader(buffer) {
    Reader.call(this, buffer);

    /**
     * Read buffer.
     * @name BufferReader#buf
     * @type {Buffer}
     */
}

BufferReader._configure = function () {
    /* istanbul ignore else */
    if (util$7.Buffer)
        BufferReader.prototype._slice = util$7.Buffer.prototype.slice;
};


/**
 * @override
 */
BufferReader.prototype.string = function read_string_buffer() {
    var len = this.uint32(); // modifies pos
    return this.buf.utf8Slice
        ? this.buf.utf8Slice(this.pos, this.pos = Math.min(this.pos + len, this.len))
        : this.buf.toString("utf-8", this.pos, this.pos = Math.min(this.pos + len, this.len));
};

/**
 * Reads a sequence of bytes preceeded by its length as a varint.
 * @name BufferReader#bytes
 * @function
 * @returns {Buffer} Value read
 */

BufferReader._configure();

var ReaderBufferClass = /*@__PURE__*/getDefaultExportFromCjs(reader_buffer);

var minimalExports = requireMinimal();
var util$6 = /*@__PURE__*/getDefaultExportFromCjs(minimalExports);

var writer$1 = Writer$1;

var util$5      = requireMinimal();

var BufferWriter$1; // cyclic

var LongBits$1  = util$5.LongBits,
    base64$e    = util$5.base64,
    utf8      = util$5.utf8;

/**
 * Constructs a new writer operation instance.
 * @classdesc Scheduled writer operation.
 * @constructor
 * @param {function(*, Uint8Array, number)} fn Function to call
 * @param {number} len Value byte length
 * @param {*} val Value to write
 * @ignore
 */
function Op(fn, len, val) {

    /**
     * Function to call.
     * @type {function(Uint8Array, number, *)}
     */
    this.fn = fn;

    /**
     * Value byte length.
     * @type {number}
     */
    this.len = len;

    /**
     * Next operation.
     * @type {Writer.Op|undefined}
     */
    this.next = undefined;

    /**
     * Value to write.
     * @type {*}
     */
    this.val = val; // type varies
}

/* istanbul ignore next */
function noop$1() {} // eslint-disable-line no-empty-function

/**
 * Constructs a new writer state instance.
 * @classdesc Copied writer state.
 * @memberof Writer
 * @constructor
 * @param {Writer} writer Writer to copy state from
 * @ignore
 */
function State(writer) {

    /**
     * Current head.
     * @type {Writer.Op}
     */
    this.head = writer.head;

    /**
     * Current tail.
     * @type {Writer.Op}
     */
    this.tail = writer.tail;

    /**
     * Current buffer length.
     * @type {number}
     */
    this.len = writer.len;

    /**
     * Next state.
     * @type {State|null}
     */
    this.next = writer.states;
}

/**
 * Constructs a new writer instance.
 * @classdesc Wire format writer using `Uint8Array` if available, otherwise `Array`.
 * @constructor
 */
function Writer$1() {

    /**
     * Current length.
     * @type {number}
     */
    this.len = 0;

    /**
     * Operations head.
     * @type {Object}
     */
    this.head = new Op(noop$1, 0, 0);

    /**
     * Operations tail
     * @type {Object}
     */
    this.tail = this.head;

    /**
     * Linked forked states.
     * @type {Object|null}
     */
    this.states = null;

    // When a value is written, the writer calculates its byte length and puts it into a linked
    // list of operations to perform when finish() is called. This both allows us to allocate
    // buffers of the exact required size and reduces the amount of work we have to do compared
    // to first calculating over objects and then encoding over objects. In our case, the encoding
    // part is just a linked list walk calling operations with already prepared values.
}

var create$f = function create() {
    return util$5.Buffer
        ? function create_buffer_setup() {
            return (Writer$1.create = function create_buffer() {
                return new BufferWriter$1();
            })();
        }
        /* istanbul ignore next */
        : function create_array() {
            return new Writer$1();
        };
};

/**
 * Creates a new writer.
 * @function
 * @returns {BufferWriter|Writer} A {@link BufferWriter} when Buffers are supported, otherwise a {@link Writer}
 */
Writer$1.create = create$f();

/**
 * Allocates a buffer of the specified size.
 * @param {number} size Buffer size
 * @returns {Uint8Array} Buffer
 */
Writer$1.alloc = function alloc(size) {
    return new util$5.Array(size);
};

// Use Uint8Array buffer pool in the browser, just like node does with buffers
/* istanbul ignore else */
if (util$5.Array !== Array)
    Writer$1.alloc = util$5.pool(Writer$1.alloc, util$5.Array.prototype.subarray);

/**
 * Pushes a new operation to the queue.
 * @param {function(Uint8Array, number, *)} fn Function to call
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @returns {Writer} `this`
 * @private
 */
Writer$1.prototype._push = function push(fn, len, val) {
    this.tail = this.tail.next = new Op(fn, len, val);
    this.len += len;
    return this;
};

function writeByte(val, buf, pos) {
    buf[pos] = val & 255;
}

function writeVarint32(val, buf, pos) {
    while (val > 127) {
        buf[pos++] = val & 127 | 128;
        val >>>= 7;
    }
    buf[pos] = val;
}

/**
 * Constructs a new varint writer operation instance.
 * @classdesc Scheduled varint writer operation.
 * @extends Op
 * @constructor
 * @param {number} len Value byte length
 * @param {number} val Value to write
 * @ignore
 */
function VarintOp(len, val) {
    this.len = len;
    this.next = undefined;
    this.val = val;
}

VarintOp.prototype = Object.create(Op.prototype);
VarintOp.prototype.fn = writeVarint32;

/**
 * Writes an unsigned 32 bit value as a varint.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.uint32 = function write_uint32(value) {
    // here, the call to this.push has been inlined and a varint specific Op subclass is used.
    // uint32 is by far the most frequently used operation and benefits significantly from this.
    this.len += (this.tail = this.tail.next = new VarintOp(
        (value = value >>> 0)
                < 128       ? 1
        : value < 16384     ? 2
        : value < 2097152   ? 3
        : value < 268435456 ? 4
        :                     5,
    value)).len;
    return this;
};

/**
 * Writes a signed 32 bit value as a varint.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.int32 = function write_int32(value) {
    return value < 0
        ? this._push(writeVarint64, 10, LongBits$1.fromNumber(value)) // 10 bytes per spec
        : this.uint32(value);
};

/**
 * Writes a 32 bit value as a varint, zig-zag encoded.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.sint32 = function write_sint32(value) {
    return this.uint32((value << 1 ^ value >> 31) >>> 0);
};

function writeVarint64(val, buf, pos) {
    while (val.hi) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;
        val.hi >>>= 7;
    }
    while (val.lo > 127) {
        buf[pos++] = val.lo & 127 | 128;
        val.lo = val.lo >>> 7;
    }
    buf[pos++] = val.lo;
}

/**
 * Writes an unsigned 64 bit value as a varint.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.uint64 = function write_uint64(value) {
    var bits = LongBits$1.from(value);
    return this._push(writeVarint64, bits.length(), bits);
};

/**
 * Writes a signed 64 bit value as a varint.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.int64 = Writer$1.prototype.uint64;

/**
 * Writes a signed 64 bit value as a varint, zig-zag encoded.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.sint64 = function write_sint64(value) {
    var bits = LongBits$1.from(value).zzEncode();
    return this._push(writeVarint64, bits.length(), bits);
};

/**
 * Writes a boolish value as a varint.
 * @param {boolean} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.bool = function write_bool(value) {
    return this._push(writeByte, 1, value ? 1 : 0);
};

function writeFixed32(val, buf, pos) {
    buf[pos    ] =  val         & 255;
    buf[pos + 1] =  val >>> 8   & 255;
    buf[pos + 2] =  val >>> 16  & 255;
    buf[pos + 3] =  val >>> 24;
}

/**
 * Writes an unsigned 32 bit value as fixed 32 bits.
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.fixed32 = function write_fixed32(value) {
    return this._push(writeFixed32, 4, value >>> 0);
};

/**
 * Writes a signed 32 bit value as fixed 32 bits.
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.sfixed32 = Writer$1.prototype.fixed32;

/**
 * Writes an unsigned 64 bit value as fixed 64 bits.
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.fixed64 = function write_fixed64(value) {
    var bits = LongBits$1.from(value);
    return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);
};

/**
 * Writes a signed 64 bit value as fixed 64 bits.
 * @function
 * @param {Long|number|string} value Value to write
 * @returns {Writer} `this`
 * @throws {TypeError} If `value` is a string and no long library is present.
 */
Writer$1.prototype.sfixed64 = Writer$1.prototype.fixed64;

/**
 * Writes a float (32 bit).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.float = function write_float(value) {
    return this._push(util$5.float.writeFloatLE, 4, value);
};

/**
 * Writes a double (64 bit float).
 * @function
 * @param {number} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.double = function write_double(value) {
    return this._push(util$5.float.writeDoubleLE, 8, value);
};

var writeBytes = util$5.Array.prototype.set
    ? function writeBytes_set(val, buf, pos) {
        buf.set(val, pos); // also works for plain array values
    }
    /* istanbul ignore next */
    : function writeBytes_for(val, buf, pos) {
        for (var i = 0; i < val.length; ++i)
            buf[pos + i] = val[i];
    };

/**
 * Writes a sequence of bytes.
 * @param {Uint8Array|string} value Buffer or base64 encoded string to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.bytes = function write_bytes(value) {
    var len = value.length >>> 0;
    if (!len)
        return this._push(writeByte, 1, 0);
    if (util$5.isString(value)) {
        var buf = Writer$1.alloc(len = base64$e.length(value));
        base64$e.decode(value, buf, 0);
        value = buf;
    }
    return this.uint32(len)._push(writeBytes, len, value);
};

/**
 * Writes a string.
 * @param {string} value Value to write
 * @returns {Writer} `this`
 */
Writer$1.prototype.string = function write_string(value) {
    var len = utf8.length(value);
    return len
        ? this.uint32(len)._push(utf8.write, len, value)
        : this._push(writeByte, 1, 0);
};

/**
 * Forks this writer's state by pushing it to a stack.
 * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.
 * @returns {Writer} `this`
 */
Writer$1.prototype.fork = function fork() {
    this.states = new State(this);
    this.head = this.tail = new Op(noop$1, 0, 0);
    this.len = 0;
    return this;
};

/**
 * Resets this instance to the last state.
 * @returns {Writer} `this`
 */
Writer$1.prototype.reset = function reset() {
    if (this.states) {
        this.head   = this.states.head;
        this.tail   = this.states.tail;
        this.len    = this.states.len;
        this.states = this.states.next;
    } else {
        this.head = this.tail = new Op(noop$1, 0, 0);
        this.len  = 0;
    }
    return this;
};

/**
 * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.
 * @returns {Writer} `this`
 */
Writer$1.prototype.ldelim = function ldelim() {
    var head = this.head,
        tail = this.tail,
        len  = this.len;
    this.reset().uint32(len);
    if (len) {
        this.tail.next = head.next; // skip noop
        this.tail = tail;
        this.len += len;
    }
    return this;
};

/**
 * Finishes the write operation.
 * @returns {Uint8Array} Finished buffer
 */
Writer$1.prototype.finish = function finish() {
    var head = this.head.next, // skip noop
        buf  = this.constructor.alloc(this.len),
        pos  = 0;
    while (head) {
        head.fn(head.val, buf, pos);
        pos += head.len;
        head = head.next;
    }
    // this.head = this.tail = null;
    return buf;
};

Writer$1._configure = function(BufferWriter_) {
    BufferWriter$1 = BufferWriter_;
    Writer$1.create = create$f();
    BufferWriter$1._configure();
};

var WriterClass = /*@__PURE__*/getDefaultExportFromCjs(writer$1);

var writer_buffer = BufferWriter;

// extends Writer
var Writer = writer$1;
(BufferWriter.prototype = Object.create(Writer.prototype)).constructor = BufferWriter;

var util$4 = requireMinimal();

/**
 * Constructs a new buffer writer instance.
 * @classdesc Wire format writer using node buffers.
 * @extends Writer
 * @constructor
 */
function BufferWriter() {
    Writer.call(this);
}

BufferWriter._configure = function () {
    /**
     * Allocates a buffer of the specified size.
     * @function
     * @param {number} size Buffer size
     * @returns {Buffer} Buffer
     */
    BufferWriter.alloc = util$4._Buffer_allocUnsafe;

    BufferWriter.writeBytesBuffer = util$4.Buffer && util$4.Buffer.prototype instanceof Uint8Array && util$4.Buffer.prototype.set.name === "set"
        ? function writeBytesBuffer_set(val, buf, pos) {
          buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)
          // also works for plain array values
        }
        /* istanbul ignore next */
        : function writeBytesBuffer_copy(val, buf, pos) {
          if (val.copy) // Buffer values
            val.copy(buf, pos, 0, val.length);
          else for (var i = 0; i < val.length;) // plain array values
            buf[pos++] = val[i++];
        };
};


/**
 * @override
 */
BufferWriter.prototype.bytes = function write_bytes_buffer(value) {
    if (util$4.isString(value))
        value = util$4._Buffer_from(value, "base64");
    var len = value.length >>> 0;
    this.uint32(len);
    if (len)
        this._push(BufferWriter.writeBytesBuffer, len, value);
    return this;
};

function writeStringBuffer(val, buf, pos) {
    if (val.length < 40) // plain js is faster for short strings (probably due to redundant assertions)
        util$4.utf8.write(val, buf, pos);
    else if (buf.utf8Write)
        buf.utf8Write(val, pos);
    else
        buf.write(val, pos);
}

/**
 * @override
 */
BufferWriter.prototype.string = function write_string_buffer(value) {
    var len = util$4.Buffer.byteLength(value);
    this.uint32(len);
    if (len)
        this._push(writeStringBuffer, len, value);
    return this;
};


/**
 * Finishes the write operation.
 * @name BufferWriter#finish
 * @function
 * @returns {Buffer} Finished buffer
 */

BufferWriter._configure();

var WriterBufferClass = /*@__PURE__*/getDefaultExportFromCjs(writer_buffer);

// @ts-expect-error no types
function configure() {
    util$6._configure();
    ReaderClass._configure(ReaderBufferClass);
    WriterClass._configure(WriterBufferClass);
}
// Set up buffer utility according to the environment
configure();
// monkey patch the reader to add native bigint support
const methods = [
    'uint64', 'int64', 'sint64', 'fixed64', 'sfixed64'
];
function patchReader(obj) {
    for (const method of methods) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function () {
            return BigInt(original.call(this).toString());
        };
    }
    return obj;
}
function reader$1(buf) {
    return patchReader(new ReaderClass(buf));
}
function patchWriter(obj) {
    for (const method of methods) {
        if (obj[method] == null) {
            continue;
        }
        const original = obj[method];
        obj[method] = function (val) {
            return original.call(this, val.toString());
        };
    }
    return obj;
}
function writer() {
    return patchWriter(WriterClass.create());
}

function decodeMessage$1(buf, codec) {
    const r = reader$1(buf instanceof Uint8Array ? buf : buf.subarray());
    return codec.decode(r);
}

function encodeMessage(message, codec) {
    const w = writer();
    codec.encode(message, w, {
        lengthDelimited: false
    });
    return w.finish();
}

// https://developers.google.com/protocol-buffers/docs/encoding#structure
var CODEC_TYPES;
(function (CODEC_TYPES) {
    CODEC_TYPES[CODEC_TYPES["VARINT"] = 0] = "VARINT";
    CODEC_TYPES[CODEC_TYPES["BIT64"] = 1] = "BIT64";
    CODEC_TYPES[CODEC_TYPES["LENGTH_DELIMITED"] = 2] = "LENGTH_DELIMITED";
    CODEC_TYPES[CODEC_TYPES["START_GROUP"] = 3] = "START_GROUP";
    CODEC_TYPES[CODEC_TYPES["END_GROUP"] = 4] = "END_GROUP";
    CODEC_TYPES[CODEC_TYPES["BIT32"] = 5] = "BIT32";
})(CODEC_TYPES || (CODEC_TYPES = {}));
function createCodec(name, type, encode, decode) {
    return {
        name,
        type,
        encode,
        decode
    };
}

function enumeration(v) {
    function findValue(val) {
        // Use the reverse mapping to look up the enum key for the stored value
        // https://www.typescriptlang.org/docs/handbook/enums.html#reverse-mappings
        if (v[val.toString()] == null) {
            throw new Error('Invalid enum value');
        }
        return v[val];
    }
    const encode = function enumEncode(val, writer) {
        const enumValue = findValue(val);
        writer.int32(enumValue);
    };
    const decode = function enumDecode(reader) {
        const val = reader.int32();
        return findValue(val);
    };
    // @ts-expect-error yeah yeah
    return createCodec('enum', CODEC_TYPES.VARINT, encode, decode);
}

function message$1(encode, decode) {
    return createCodec('message', CODEC_TYPES.LENGTH_DELIMITED, encode, decode);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var RateLimitProof$4;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$1(buf, RateLimitProof.codec());
    };
})(RateLimitProof$4 || (RateLimitProof$4 = {}));
var WakuMessage$4;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$4.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof$4.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$1(buf, WakuMessage.codec());
    };
})(WakuMessage$4 || (WakuMessage$4 = {}));

var message = /*#__PURE__*/Object.freeze({
    __proto__: null,
    get RateLimitProof () { return RateLimitProof$4; },
    get WakuMessage () { return WakuMessage$4; }
});

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var FilterRequest;
(function (FilterRequest) {
    (function (ContentFilter) {
        let _codec;
        ContentFilter.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                        w.uint32(10);
                        w.string(obj.contentTopic);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        contentTopic: ''
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.contentTopic = reader.string();
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        ContentFilter.encode = (obj) => {
            return encodeMessage(obj, ContentFilter.codec());
        };
        ContentFilter.decode = (buf) => {
            return decodeMessage$1(buf, ContentFilter.codec());
        };
    })(FilterRequest.ContentFilter || (FilterRequest.ContentFilter = {}));
    let _codec;
    FilterRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.subscribe != null && obj.subscribe !== false)) {
                    w.uint32(8);
                    w.bool(obj.subscribe);
                }
                if ((obj.topic != null && obj.topic !== '')) {
                    w.uint32(18);
                    w.string(obj.topic);
                }
                if (obj.contentFilters != null) {
                    for (const value of obj.contentFilters) {
                        w.uint32(26);
                        FilterRequest.ContentFilter.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    subscribe: false,
                    topic: '',
                    contentFilters: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.subscribe = reader.bool();
                            break;
                        case 2:
                            obj.topic = reader.string();
                            break;
                        case 3:
                            obj.contentFilters.push(FilterRequest.ContentFilter.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterRequest.encode = (obj) => {
        return encodeMessage(obj, FilterRequest.codec());
    };
    FilterRequest.decode = (buf) => {
        return decodeMessage$1(buf, FilterRequest.codec());
    };
})(FilterRequest || (FilterRequest = {}));
var MessagePush$1;
(function (MessagePush) {
    let _codec;
    MessagePush.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.messages != null) {
                    for (const value of obj.messages) {
                        w.uint32(10);
                        WakuMessage$3.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    messages: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.messages.push(WakuMessage$3.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    MessagePush.encode = (obj) => {
        return encodeMessage(obj, MessagePush.codec());
    };
    MessagePush.decode = (buf) => {
        return decodeMessage$1(buf, MessagePush.codec());
    };
})(MessagePush$1 || (MessagePush$1 = {}));
var FilterRpc;
(function (FilterRpc) {
    let _codec;
    FilterRpc.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.request != null) {
                    w.uint32(18);
                    FilterRequest.codec().encode(obj.request, w);
                }
                if (obj.push != null) {
                    w.uint32(26);
                    MessagePush$1.codec().encode(obj.push, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    requestId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.requestId = reader.string();
                            break;
                        case 2:
                            obj.request = FilterRequest.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.push = MessagePush$1.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterRpc.encode = (obj) => {
        return encodeMessage(obj, FilterRpc.codec());
    };
    FilterRpc.decode = (buf) => {
        return decodeMessage$1(buf, FilterRpc.codec());
    };
})(FilterRpc || (FilterRpc = {}));
var RateLimitProof$3;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$1(buf, RateLimitProof.codec());
    };
})(RateLimitProof$3 || (RateLimitProof$3 = {}));
var WakuMessage$3;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$3.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof$3.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$1(buf, WakuMessage.codec());
    };
})(WakuMessage$3 || (WakuMessage$3 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var TopicOnlyMessage$1;
(function (TopicOnlyMessage) {
    let _codec;
    TopicOnlyMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    TopicOnlyMessage.encode = (obj) => {
        return encodeMessage(obj, TopicOnlyMessage.codec());
    };
    TopicOnlyMessage.decode = (buf) => {
        return decodeMessage$1(buf, TopicOnlyMessage.codec());
    };
})(TopicOnlyMessage$1 || (TopicOnlyMessage$1 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var FilterSubscribeRequest;
(function (FilterSubscribeRequest) {
    let FilterSubscribeType;
    (function (FilterSubscribeType) {
        FilterSubscribeType["SUBSCRIBER_PING"] = "SUBSCRIBER_PING";
        FilterSubscribeType["SUBSCRIBE"] = "SUBSCRIBE";
        FilterSubscribeType["UNSUBSCRIBE"] = "UNSUBSCRIBE";
        FilterSubscribeType["UNSUBSCRIBE_ALL"] = "UNSUBSCRIBE_ALL";
    })(FilterSubscribeType = FilterSubscribeRequest.FilterSubscribeType || (FilterSubscribeRequest.FilterSubscribeType = {}));
    let __FilterSubscribeTypeValues;
    (function (__FilterSubscribeTypeValues) {
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["SUBSCRIBER_PING"] = 0] = "SUBSCRIBER_PING";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["SUBSCRIBE"] = 1] = "SUBSCRIBE";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["UNSUBSCRIBE"] = 2] = "UNSUBSCRIBE";
        __FilterSubscribeTypeValues[__FilterSubscribeTypeValues["UNSUBSCRIBE_ALL"] = 3] = "UNSUBSCRIBE_ALL";
    })(__FilterSubscribeTypeValues || (__FilterSubscribeTypeValues = {}));
    (function (FilterSubscribeType) {
        FilterSubscribeType.codec = () => {
            return enumeration(__FilterSubscribeTypeValues);
        };
    })(FilterSubscribeType = FilterSubscribeRequest.FilterSubscribeType || (FilterSubscribeRequest.FilterSubscribeType = {}));
    let _codec;
    FilterSubscribeRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.filterSubscribeType != null && __FilterSubscribeTypeValues[obj.filterSubscribeType] !== 0) {
                    w.uint32(16);
                    FilterSubscribeRequest.FilterSubscribeType.codec().encode(obj.filterSubscribeType, w);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(82);
                    w.string(obj.pubsubTopic);
                }
                if (obj.contentTopics != null) {
                    for (const value of obj.contentTopics) {
                        w.uint32(90);
                        w.string(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    requestId: '',
                    filterSubscribeType: FilterSubscribeType.SUBSCRIBER_PING,
                    contentTopics: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.requestId = reader.string();
                            break;
                        case 2:
                            obj.filterSubscribeType = FilterSubscribeRequest.FilterSubscribeType.codec().decode(reader);
                            break;
                        case 10:
                            obj.pubsubTopic = reader.string();
                            break;
                        case 11:
                            obj.contentTopics.push(reader.string());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterSubscribeRequest.encode = (obj) => {
        return encodeMessage(obj, FilterSubscribeRequest.codec());
    };
    FilterSubscribeRequest.decode = (buf) => {
        return decodeMessage$1(buf, FilterSubscribeRequest.codec());
    };
})(FilterSubscribeRequest || (FilterSubscribeRequest = {}));
var FilterSubscribeResponse$1;
(function (FilterSubscribeResponse) {
    let _codec;
    FilterSubscribeResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if ((obj.statusCode != null && obj.statusCode !== 0)) {
                    w.uint32(80);
                    w.uint32(obj.statusCode);
                }
                if (obj.statusDesc != null) {
                    w.uint32(90);
                    w.string(obj.statusDesc);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    requestId: '',
                    statusCode: 0
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.requestId = reader.string();
                            break;
                        case 10:
                            obj.statusCode = reader.uint32();
                            break;
                        case 11:
                            obj.statusDesc = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    FilterSubscribeResponse.encode = (obj) => {
        return encodeMessage(obj, FilterSubscribeResponse.codec());
    };
    FilterSubscribeResponse.decode = (buf) => {
        return decodeMessage$1(buf, FilterSubscribeResponse.codec());
    };
})(FilterSubscribeResponse$1 || (FilterSubscribeResponse$1 = {}));
var MessagePush;
(function (MessagePush) {
    let _codec;
    MessagePush.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.wakuMessage != null) {
                    w.uint32(10);
                    WakuMessage$2.codec().encode(obj.wakuMessage, w);
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(18);
                    w.string(obj.pubsubTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.wakuMessage = WakuMessage$2.codec().decode(reader, reader.uint32());
                            break;
                        case 2:
                            obj.pubsubTopic = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    MessagePush.encode = (obj) => {
        return encodeMessage(obj, MessagePush.codec());
    };
    MessagePush.decode = (buf) => {
        return decodeMessage$1(buf, MessagePush.codec());
    };
})(MessagePush || (MessagePush = {}));
var RateLimitProof$2;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$1(buf, RateLimitProof.codec());
    };
})(RateLimitProof$2 || (RateLimitProof$2 = {}));
var WakuMessage$2;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$2.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof$2.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$1(buf, WakuMessage.codec());
    };
})(WakuMessage$2 || (WakuMessage$2 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var PushRequest;
(function (PushRequest) {
    let _codec;
    PushRequest.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.pubsubTopic != null && obj.pubsubTopic !== '')) {
                    w.uint32(10);
                    w.string(obj.pubsubTopic);
                }
                if (obj.message != null) {
                    w.uint32(18);
                    WakuMessage$1.codec().encode(obj.message, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    pubsubTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.pubsubTopic = reader.string();
                            break;
                        case 2:
                            obj.message = WakuMessage$1.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushRequest.encode = (obj) => {
        return encodeMessage(obj, PushRequest.codec());
    };
    PushRequest.decode = (buf) => {
        return decodeMessage$1(buf, PushRequest.codec());
    };
})(PushRequest || (PushRequest = {}));
var PushResponse;
(function (PushResponse) {
    let _codec;
    PushResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.isSuccess != null && obj.isSuccess !== false)) {
                    w.uint32(8);
                    w.bool(obj.isSuccess);
                }
                if (obj.info != null) {
                    w.uint32(18);
                    w.string(obj.info);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    isSuccess: false
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.isSuccess = reader.bool();
                            break;
                        case 2:
                            obj.info = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushResponse.encode = (obj) => {
        return encodeMessage(obj, PushResponse.codec());
    };
    PushResponse.decode = (buf) => {
        return decodeMessage$1(buf, PushResponse.codec());
    };
})(PushResponse || (PushResponse = {}));
var PushRpc$1;
(function (PushRpc) {
    let _codec;
    PushRpc.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.request != null) {
                    w.uint32(18);
                    PushRequest.codec().encode(obj.request, w);
                }
                if (obj.response != null) {
                    w.uint32(26);
                    PushResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    requestId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.requestId = reader.string();
                            break;
                        case 2:
                            obj.request = PushRequest.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.response = PushResponse.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PushRpc.encode = (obj) => {
        return encodeMessage(obj, PushRpc.codec());
    };
    PushRpc.decode = (buf) => {
        return decodeMessage$1(buf, PushRpc.codec());
    };
})(PushRpc$1 || (PushRpc$1 = {}));
var RateLimitProof$1;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$1(buf, RateLimitProof.codec());
    };
})(RateLimitProof$1 || (RateLimitProof$1 = {}));
var WakuMessage$1;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof$1.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof$1.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$1(buf, WakuMessage.codec());
    };
})(WakuMessage$1 || (WakuMessage$1 = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var Index;
(function (Index) {
    let _codec;
    Index.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.digest != null && obj.digest.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.digest);
                }
                if ((obj.receiverTime != null && obj.receiverTime !== 0n)) {
                    w.uint32(16);
                    w.sint64(obj.receiverTime);
                }
                if ((obj.senderTime != null && obj.senderTime !== 0n)) {
                    w.uint32(24);
                    w.sint64(obj.senderTime);
                }
                if ((obj.pubsubTopic != null && obj.pubsubTopic !== '')) {
                    w.uint32(34);
                    w.string(obj.pubsubTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    digest: new Uint8Array(0),
                    receiverTime: 0n,
                    senderTime: 0n,
                    pubsubTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.digest = reader.bytes();
                            break;
                        case 2:
                            obj.receiverTime = reader.sint64();
                            break;
                        case 3:
                            obj.senderTime = reader.sint64();
                            break;
                        case 4:
                            obj.pubsubTopic = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Index.encode = (obj) => {
        return encodeMessage(obj, Index.codec());
    };
    Index.decode = (buf) => {
        return decodeMessage$1(buf, Index.codec());
    };
})(Index || (Index = {}));
var PagingInfo;
(function (PagingInfo) {
    (function (Direction) {
        Direction["BACKWARD"] = "BACKWARD";
        Direction["FORWARD"] = "FORWARD";
    })(PagingInfo.Direction || (PagingInfo.Direction = {}));
    let __DirectionValues;
    (function (__DirectionValues) {
        __DirectionValues[__DirectionValues["BACKWARD"] = 0] = "BACKWARD";
        __DirectionValues[__DirectionValues["FORWARD"] = 1] = "FORWARD";
    })(__DirectionValues || (__DirectionValues = {}));
    (function (Direction) {
        Direction.codec = () => {
            return enumeration(__DirectionValues);
        };
    })(PagingInfo.Direction || (PagingInfo.Direction = {}));
    let _codec;
    PagingInfo.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.pageSize != null) {
                    w.uint32(8);
                    w.uint64(obj.pageSize);
                }
                if (obj.cursor != null) {
                    w.uint32(18);
                    Index.codec().encode(obj.cursor, w);
                }
                if (obj.direction != null) {
                    w.uint32(24);
                    PagingInfo.Direction.codec().encode(obj.direction, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.pageSize = reader.uint64();
                            break;
                        case 2:
                            obj.cursor = Index.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.direction = PagingInfo.Direction.codec().decode(reader);
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PagingInfo.encode = (obj) => {
        return encodeMessage(obj, PagingInfo.codec());
    };
    PagingInfo.decode = (buf) => {
        return decodeMessage$1(buf, PagingInfo.codec());
    };
})(PagingInfo || (PagingInfo = {}));
var ContentFilter;
(function (ContentFilter) {
    let _codec;
    ContentFilter.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(10);
                    w.string(obj.contentTopic);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.contentTopic = reader.string();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    ContentFilter.encode = (obj) => {
        return encodeMessage(obj, ContentFilter.codec());
    };
    ContentFilter.decode = (buf) => {
        return decodeMessage$1(buf, ContentFilter.codec());
    };
})(ContentFilter || (ContentFilter = {}));
var HistoryQuery;
(function (HistoryQuery) {
    let _codec;
    HistoryQuery.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.pubsubTopic != null) {
                    w.uint32(18);
                    w.string(obj.pubsubTopic);
                }
                if (obj.contentFilters != null) {
                    for (const value of obj.contentFilters) {
                        w.uint32(26);
                        ContentFilter.codec().encode(value, w);
                    }
                }
                if (obj.pagingInfo != null) {
                    w.uint32(34);
                    PagingInfo.codec().encode(obj.pagingInfo, w);
                }
                if (obj.startTime != null) {
                    w.uint32(40);
                    w.sint64(obj.startTime);
                }
                if (obj.endTime != null) {
                    w.uint32(48);
                    w.sint64(obj.endTime);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    contentFilters: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2:
                            obj.pubsubTopic = reader.string();
                            break;
                        case 3:
                            obj.contentFilters.push(ContentFilter.codec().decode(reader, reader.uint32()));
                            break;
                        case 4:
                            obj.pagingInfo = PagingInfo.codec().decode(reader, reader.uint32());
                            break;
                        case 5:
                            obj.startTime = reader.sint64();
                            break;
                        case 6:
                            obj.endTime = reader.sint64();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    HistoryQuery.encode = (obj) => {
        return encodeMessage(obj, HistoryQuery.codec());
    };
    HistoryQuery.decode = (buf) => {
        return decodeMessage$1(buf, HistoryQuery.codec());
    };
})(HistoryQuery || (HistoryQuery = {}));
var HistoryResponse;
(function (HistoryResponse) {
    let HistoryError;
    (function (HistoryError) {
        HistoryError["NONE"] = "NONE";
        HistoryError["INVALID_CURSOR"] = "INVALID_CURSOR";
    })(HistoryError = HistoryResponse.HistoryError || (HistoryResponse.HistoryError = {}));
    let __HistoryErrorValues;
    (function (__HistoryErrorValues) {
        __HistoryErrorValues[__HistoryErrorValues["NONE"] = 0] = "NONE";
        __HistoryErrorValues[__HistoryErrorValues["INVALID_CURSOR"] = 1] = "INVALID_CURSOR";
    })(__HistoryErrorValues || (__HistoryErrorValues = {}));
    (function (HistoryError) {
        HistoryError.codec = () => {
            return enumeration(__HistoryErrorValues);
        };
    })(HistoryError = HistoryResponse.HistoryError || (HistoryResponse.HistoryError = {}));
    let _codec;
    HistoryResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.messages != null) {
                    for (const value of obj.messages) {
                        w.uint32(18);
                        WakuMessage.codec().encode(value, w);
                    }
                }
                if (obj.pagingInfo != null) {
                    w.uint32(26);
                    PagingInfo.codec().encode(obj.pagingInfo, w);
                }
                if (obj.error != null && __HistoryErrorValues[obj.error] !== 0) {
                    w.uint32(32);
                    HistoryResponse.HistoryError.codec().encode(obj.error, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    messages: [],
                    error: HistoryError.NONE
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 2:
                            obj.messages.push(WakuMessage.codec().decode(reader, reader.uint32()));
                            break;
                        case 3:
                            obj.pagingInfo = PagingInfo.codec().decode(reader, reader.uint32());
                            break;
                        case 4:
                            obj.error = HistoryResponse.HistoryError.codec().decode(reader);
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    HistoryResponse.encode = (obj) => {
        return encodeMessage(obj, HistoryResponse.codec());
    };
    HistoryResponse.decode = (buf) => {
        return decodeMessage$1(buf, HistoryResponse.codec());
    };
})(HistoryResponse || (HistoryResponse = {}));
var HistoryRpc$1;
(function (HistoryRpc) {
    let _codec;
    HistoryRpc.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.requestId != null && obj.requestId !== '')) {
                    w.uint32(10);
                    w.string(obj.requestId);
                }
                if (obj.query != null) {
                    w.uint32(18);
                    HistoryQuery.codec().encode(obj.query, w);
                }
                if (obj.response != null) {
                    w.uint32(26);
                    HistoryResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    requestId: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.requestId = reader.string();
                            break;
                        case 2:
                            obj.query = HistoryQuery.codec().decode(reader, reader.uint32());
                            break;
                        case 3:
                            obj.response = HistoryResponse.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    HistoryRpc.encode = (obj) => {
        return encodeMessage(obj, HistoryRpc.codec());
    };
    HistoryRpc.decode = (buf) => {
        return decodeMessage$1(buf, HistoryRpc.codec());
    };
})(HistoryRpc$1 || (HistoryRpc$1 = {}));
var RateLimitProof;
(function (RateLimitProof) {
    let _codec;
    RateLimitProof.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.proof != null && obj.proof.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.proof);
                }
                if ((obj.merkleRoot != null && obj.merkleRoot.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.merkleRoot);
                }
                if ((obj.epoch != null && obj.epoch.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.epoch);
                }
                if ((obj.shareX != null && obj.shareX.byteLength > 0)) {
                    w.uint32(34);
                    w.bytes(obj.shareX);
                }
                if ((obj.shareY != null && obj.shareY.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.shareY);
                }
                if ((obj.nullifier != null && obj.nullifier.byteLength > 0)) {
                    w.uint32(50);
                    w.bytes(obj.nullifier);
                }
                if ((obj.rlnIdentifier != null && obj.rlnIdentifier.byteLength > 0)) {
                    w.uint32(58);
                    w.bytes(obj.rlnIdentifier);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    proof: new Uint8Array(0),
                    merkleRoot: new Uint8Array(0),
                    epoch: new Uint8Array(0),
                    shareX: new Uint8Array(0),
                    shareY: new Uint8Array(0),
                    nullifier: new Uint8Array(0),
                    rlnIdentifier: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.proof = reader.bytes();
                            break;
                        case 2:
                            obj.merkleRoot = reader.bytes();
                            break;
                        case 3:
                            obj.epoch = reader.bytes();
                            break;
                        case 4:
                            obj.shareX = reader.bytes();
                            break;
                        case 5:
                            obj.shareY = reader.bytes();
                            break;
                        case 6:
                            obj.nullifier = reader.bytes();
                            break;
                        case 7:
                            obj.rlnIdentifier = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    RateLimitProof.encode = (obj) => {
        return encodeMessage(obj, RateLimitProof.codec());
    };
    RateLimitProof.decode = (buf) => {
        return decodeMessage$1(buf, RateLimitProof.codec());
    };
})(RateLimitProof || (RateLimitProof = {}));
var WakuMessage;
(function (WakuMessage) {
    let _codec;
    WakuMessage.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.payload);
                }
                if ((obj.contentTopic != null && obj.contentTopic !== '')) {
                    w.uint32(18);
                    w.string(obj.contentTopic);
                }
                if (obj.version != null) {
                    w.uint32(24);
                    w.uint32(obj.version);
                }
                if (obj.timestamp != null) {
                    w.uint32(80);
                    w.sint64(obj.timestamp);
                }
                if (obj.meta != null) {
                    w.uint32(90);
                    w.bytes(obj.meta);
                }
                if (obj.rateLimitProof != null) {
                    w.uint32(170);
                    RateLimitProof.codec().encode(obj.rateLimitProof, w);
                }
                if (obj.ephemeral != null) {
                    w.uint32(248);
                    w.bool(obj.ephemeral);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    payload: new Uint8Array(0),
                    contentTopic: ''
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.payload = reader.bytes();
                            break;
                        case 2:
                            obj.contentTopic = reader.string();
                            break;
                        case 3:
                            obj.version = reader.uint32();
                            break;
                        case 10:
                            obj.timestamp = reader.sint64();
                            break;
                        case 11:
                            obj.meta = reader.bytes();
                            break;
                        case 21:
                            obj.rateLimitProof = RateLimitProof.codec().decode(reader, reader.uint32());
                            break;
                        case 31:
                            obj.ephemeral = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    WakuMessage.encode = (obj) => {
        return encodeMessage(obj, WakuMessage.codec());
    };
    WakuMessage.decode = (buf) => {
        return decodeMessage$1(buf, WakuMessage.codec());
    };
})(WakuMessage || (WakuMessage = {}));

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var PeerInfo;
(function (PeerInfo) {
    let _codec;
    PeerInfo.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.enr != null) {
                    w.uint32(10);
                    w.bytes(obj.enr);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.enr = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerInfo.encode = (obj) => {
        return encodeMessage(obj, PeerInfo.codec());
    };
    PeerInfo.decode = (buf) => {
        return decodeMessage$1(buf, PeerInfo.codec());
    };
})(PeerInfo || (PeerInfo = {}));
var PeerExchangeQuery;
(function (PeerExchangeQuery) {
    let _codec;
    PeerExchangeQuery.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.numPeers != null) {
                    w.uint32(8);
                    w.uint64(obj.numPeers);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.numPeers = reader.uint64();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeQuery.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeQuery.codec());
    };
    PeerExchangeQuery.decode = (buf) => {
        return decodeMessage$1(buf, PeerExchangeQuery.codec());
    };
})(PeerExchangeQuery || (PeerExchangeQuery = {}));
var PeerExchangeResponse;
(function (PeerExchangeResponse) {
    let _codec;
    PeerExchangeResponse.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.peerInfos != null) {
                    for (const value of obj.peerInfos) {
                        w.uint32(10);
                        PeerInfo.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    peerInfos: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.peerInfos.push(PeerInfo.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeResponse.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeResponse.codec());
    };
    PeerExchangeResponse.decode = (buf) => {
        return decodeMessage$1(buf, PeerExchangeResponse.codec());
    };
})(PeerExchangeResponse || (PeerExchangeResponse = {}));
var PeerExchangeRPC$1;
(function (PeerExchangeRPC) {
    let _codec;
    PeerExchangeRPC.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.query != null) {
                    w.uint32(10);
                    PeerExchangeQuery.codec().encode(obj.query, w);
                }
                if (obj.response != null) {
                    w.uint32(18);
                    PeerExchangeResponse.codec().encode(obj.response, w);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.query = PeerExchangeQuery.codec().decode(reader, reader.uint32());
                            break;
                        case 2:
                            obj.response = PeerExchangeResponse.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerExchangeRPC.encode = (obj) => {
        return encodeMessage(obj, PeerExchangeRPC.codec());
    };
    PeerExchangeRPC.decode = (buf) => {
        return decodeMessage$1(buf, PeerExchangeRPC.codec());
    };
})(PeerExchangeRPC$1 || (PeerExchangeRPC$1 = {}));

const log$I = debug("waku:message:version-0");
const OneMillion$1 = BigInt(1000000);
const Version = 0;
class DecodedMessage {
    pubSubTopic;
    proto;
    constructor(pubSubTopic, proto) {
        this.pubSubTopic = pubSubTopic;
        this.proto = proto;
    }
    get ephemeral() {
        return Boolean(this.proto.ephemeral);
    }
    get payload() {
        return this.proto.payload;
    }
    get contentTopic() {
        return this.proto.contentTopic;
    }
    get _rawTimestamp() {
        return this.proto.timestamp;
    }
    get timestamp() {
        // In the case we receive a value that is bigger than JS's max number,
        // we catch the error and return undefined.
        try {
            if (this.proto.timestamp) {
                // nanoseconds 10^-9 to milliseconds 10^-3
                const timestamp = this.proto.timestamp / OneMillion$1;
                return new Date(Number(timestamp));
            }
            return;
        }
        catch (e) {
            return;
        }
    }
    get meta() {
        return this.proto.meta;
    }
    get version() {
        // https://rfc.vac.dev/spec/14/
        // > If omitted, the value SHOULD be interpreted as version 0.
        return this.proto.version ?? 0;
    }
    get rateLimitProof() {
        return this.proto.rateLimitProof;
    }
}
let Encoder$e = class Encoder {
    contentTopic;
    ephemeral;
    metaSetter;
    constructor(contentTopic, ephemeral = false, metaSetter) {
        this.contentTopic = contentTopic;
        this.ephemeral = ephemeral;
        this.metaSetter = metaSetter;
        if (!contentTopic || contentTopic === "") {
            throw new Error("Content topic must be specified");
        }
    }
    async toWire(message$1) {
        return WakuMessage$4.encode(await this.toProtoObj(message$1));
    }
    async toProtoObj(message) {
        const timestamp = message.timestamp ?? new Date();
        const protoMessage = {
            payload: message.payload,
            version: Version,
            contentTopic: this.contentTopic,
            timestamp: BigInt(timestamp.valueOf()) * OneMillion$1,
            meta: undefined,
            rateLimitProof: message.rateLimitProof,
            ephemeral: this.ephemeral
        };
        if (this.metaSetter) {
            const meta = this.metaSetter(protoMessage);
            return { ...protoMessage, meta };
        }
        return protoMessage;
    }
};
/**
 * Creates an encoder that encode messages without Waku level encryption or signature.
 *
 * An encoder is used to encode messages in the [`14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/)
 * format to be sent over the Waku network. The resulting encoder can then be
 * pass to { @link @waku/interfaces.LightPush.push } or
 * { @link @waku/interfaces.Relay.send } to automatically encode outgoing
 * messages.
 */
function createEncoder({ contentTopic, ephemeral, metaSetter }) {
    return new Encoder$e(contentTopic, ephemeral, metaSetter);
}
let Decoder$e = class Decoder {
    contentTopic;
    constructor(contentTopic) {
        this.contentTopic = contentTopic;
        if (!contentTopic || contentTopic === "") {
            throw new Error("Content topic must be specified");
        }
    }
    fromWireToProtoObj(bytes) {
        const protoMessage = WakuMessage$4.decode(bytes);
        log$I("Message decoded", protoMessage);
        return Promise.resolve({
            payload: protoMessage.payload,
            contentTopic: protoMessage.contentTopic,
            version: protoMessage.version ?? undefined,
            timestamp: protoMessage.timestamp ?? undefined,
            meta: protoMessage.meta ?? undefined,
            rateLimitProof: protoMessage.rateLimitProof ?? undefined,
            ephemeral: protoMessage.ephemeral ?? false
        });
    }
    async fromProtoObj(pubSubTopic, proto) {
        // https://rfc.vac.dev/spec/14/
        // > If omitted, the value SHOULD be interpreted as version 0.
        if (proto.version ?? 0 !== Version) {
            log$I("Failed to decode due to incorrect version, expected:", Version, ", actual:", proto.version);
            return Promise.resolve(undefined);
        }
        return new DecodedMessage(pubSubTopic, proto);
    }
};
/**
 * Creates a decoder that decode messages without Waku level encryption.
 *
 * A decoder is used to decode messages from the [14/WAKU2-MESSAGE](https://rfc.vac.dev/spec/14/)
 * format when received from the Waku network. The resulting decoder can then be
 * pass to { @link @waku/interfaces.Filter.subscribe } or
 * { @link @waku/interfaces.Relay.subscribe } to automatically decode incoming
 * messages.
 *
 * @param contentTopic The resulting decoder will only decode messages with this content topic.
 */
function createDecoder(contentTopic) {
    return new Decoder$e(contentTopic);
}

var version_0 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    DecodedMessage: DecodedMessage,
    Decoder: Decoder$e,
    Encoder: Encoder$e,
    Version: Version,
    createDecoder: createDecoder,
    createEncoder: createEncoder,
    proto: message
});

const RelayPingContentTopic = "/relay-ping/1/ping/null";
const log$H = debug("waku:keep-alive");
class KeepAliveManager {
    pingKeepAliveTimers;
    relayKeepAliveTimers;
    options;
    relay;
    constructor(options, relay) {
        this.pingKeepAliveTimers = new Map();
        this.relayKeepAliveTimers = new Map();
        this.options = options;
        this.relay = relay;
    }
    start(peerId, libp2pPing, peerStore) {
        // Just in case a timer already exists for this peer
        this.stop(peerId);
        const { pingKeepAlive: pingPeriodSecs, relayKeepAlive: relayPeriodSecs } = this.options;
        const peerIdStr = peerId.toString();
        if (pingPeriodSecs !== 0) {
            const interval = setInterval(() => {
                void (async () => {
                    try {
                        // ping the peer for keep alive
                        // also update the peer store with the latency
                        const ping = await libp2pPing.ping(peerId);
                        log$H(`Ping succeeded (${peerIdStr})`, ping);
                        try {
                            await peerStore.patch(peerId, {
                                metadata: {
                                    ping: utf8ToBytes$4(ping.toString())
                                }
                            });
                        }
                        catch (e) {
                            log$H("Failed to update ping", e);
                        }
                    }
                    catch (e) {
                        log$H(`Ping failed (${peerIdStr})`, e);
                    }
                })();
            }, pingPeriodSecs * 1000);
            this.pingKeepAliveTimers.set(peerIdStr, interval);
        }
        const relay = this.relay;
        if (relay && relayPeriodSecs !== 0) {
            const encoder = createEncoder({
                contentTopic: RelayPingContentTopic,
                ephemeral: true
            });
            const interval = setInterval(() => {
                log$H("Sending Waku Relay ping message");
                relay
                    .send(encoder, { payload: new Uint8Array([1]) })
                    .catch((e) => log$H("Failed to send relay ping", e));
            }, relayPeriodSecs * 1000);
            this.relayKeepAliveTimers.set(peerId, interval);
        }
    }
    stop(peerId) {
        const peerIdStr = peerId.toString();
        if (this.pingKeepAliveTimers.has(peerIdStr)) {
            clearInterval(this.pingKeepAliveTimers.get(peerIdStr));
            this.pingKeepAliveTimers.delete(peerIdStr);
        }
        if (this.relayKeepAliveTimers.has(peerId)) {
            clearInterval(this.relayKeepAliveTimers.get(peerId));
            this.relayKeepAliveTimers.delete(peerId);
        }
    }
    stopAll() {
        for (const timer of [
            ...Object.values(this.pingKeepAliveTimers),
            ...Object.values(this.relayKeepAliveTimers)
        ]) {
            clearInterval(timer);
        }
        this.pingKeepAliveTimers.clear();
        this.relayKeepAliveTimers.clear();
    }
}

const log$G = debug("waku:connection-manager");
const DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED = 1;
const DEFAULT_MAX_DIAL_ATTEMPTS_FOR_PEER = 3;
const DEFAULT_MAX_PARALLEL_DIALS = 3;
class ConnectionManager extends EventEmitter$3 {
    static instances = new Map();
    keepAliveManager;
    options;
    libp2p;
    dialAttemptsForPeer = new Map();
    dialErrorsForPeer = new Map();
    currentActiveDialCount = 0;
    pendingPeerDialQueue = [];
    static create(peerId, libp2p, keepAliveOptions, relay, options) {
        let instance = ConnectionManager.instances.get(peerId);
        if (!instance) {
            instance = new ConnectionManager(libp2p, keepAliveOptions, relay, options);
            ConnectionManager.instances.set(peerId, instance);
        }
        return instance;
    }
    async getPeersByDiscovery() {
        const peersDiscovered = await this.libp2p.peerStore.all();
        const peersConnected = this.libp2p
            .getConnections()
            .map((conn) => conn.remotePeer);
        const peersDiscoveredByBootstrap = [];
        const peersDiscoveredByPeerExchange = [];
        const peersConnectedByBootstrap = [];
        const peersConnectedByPeerExchange = [];
        for (const peer of peersDiscovered) {
            const tags = await this.getTagNamesForPeer(peer.id);
            if (tags.includes(Tags.BOOTSTRAP)) {
                peersDiscoveredByBootstrap.push(peer);
            }
            else if (tags.includes(Tags.PEER_EXCHANGE)) {
                peersDiscoveredByPeerExchange.push(peer);
            }
        }
        for (const peerId of peersConnected) {
            const peer = await this.libp2p.peerStore.get(peerId);
            const tags = await this.getTagNamesForPeer(peerId);
            if (tags.includes(Tags.BOOTSTRAP)) {
                peersConnectedByBootstrap.push(peer);
            }
            else if (tags.includes(Tags.PEER_EXCHANGE)) {
                peersConnectedByPeerExchange.push(peer);
            }
        }
        return {
            DISCOVERED: {
                [Tags.BOOTSTRAP]: peersDiscoveredByBootstrap,
                [Tags.PEER_EXCHANGE]: peersDiscoveredByPeerExchange
            },
            CONNECTED: {
                [Tags.BOOTSTRAP]: peersConnectedByBootstrap,
                [Tags.PEER_EXCHANGE]: peersConnectedByPeerExchange
            }
        };
    }
    constructor(libp2p, keepAliveOptions, relay, options) {
        super();
        this.libp2p = libp2p;
        this.options = {
            maxDialAttemptsForPeer: DEFAULT_MAX_DIAL_ATTEMPTS_FOR_PEER,
            maxBootstrapPeersAllowed: DEFAULT_MAX_BOOTSTRAP_PEERS_ALLOWED,
            maxParallelDials: DEFAULT_MAX_PARALLEL_DIALS,
            ...options
        };
        this.keepAliveManager = new KeepAliveManager(keepAliveOptions, relay);
        this.run()
            .then(() => log$G(`Connection Manager is now running`))
            .catch((error) => log$G(`Unexpected error while running service`, error));
        // libp2p emits `peer:discovery` events during its initialization
        // which means that before the ConnectionManager is initialized, some peers may have been discovered
        // we will dial the peers in peerStore ONCE before we start to listen to the `peer:discovery` events within the ConnectionManager
        this.dialPeerStorePeers().catch((error) => log$G(`Unexpected error while dialing peer store peers`, error));
    }
    async dialPeerStorePeers() {
        const peerInfos = await this.libp2p.peerStore.all();
        const dialPromises = [];
        for (const peerInfo of peerInfos) {
            if (this.libp2p.getConnections().find((c) => c.remotePeer === peerInfo.id))
                continue;
            dialPromises.push(this.attemptDial(peerInfo.id));
        }
        try {
            await Promise.all(dialPromises);
        }
        catch (error) {
            log$G(`Unexpected error while dialing peer store peers`, error);
        }
    }
    async run() {
        // start event listeners
        this.startPeerDiscoveryListener();
        this.startPeerConnectionListener();
        this.startPeerDisconnectionListener();
    }
    stop() {
        this.keepAliveManager.stopAll();
        this.libp2p.removeEventListener("peer:connect", this.onEventHandlers["peer:connect"]);
        this.libp2p.removeEventListener("peer:disconnect", this.onEventHandlers["peer:disconnect"]);
        this.libp2p.removeEventListener("peer:discovery", this.onEventHandlers["peer:discovery"]);
    }
    async dialPeer(peerId) {
        this.currentActiveDialCount += 1;
        let dialAttempt = 0;
        while (dialAttempt < this.options.maxDialAttemptsForPeer) {
            try {
                log$G(`Dialing peer ${peerId.toString()} on attempt ${dialAttempt + 1}`);
                await this.libp2p.dial(peerId);
                const tags = await this.getTagNamesForPeer(peerId);
                // add tag to connection describing discovery mechanism
                // don't add duplicate tags
                this.libp2p.getConnections(peerId).forEach((conn) => {
                    conn.tags = Array.from(new Set([...conn.tags, ...tags]));
                });
                this.dialAttemptsForPeer.delete(peerId.toString());
                // Dialing succeeded, break the loop
                break;
            }
            catch (error) {
                if (error instanceof AggregateError) {
                    // Handle AggregateError
                    log$G(`Error dialing peer ${peerId.toString()} - ${error.errors}`);
                }
                else {
                    // Handle generic error
                    log$G(`Error dialing peer ${peerId.toString()} - ${error.message}`);
                }
                this.dialErrorsForPeer.set(peerId.toString(), error);
                dialAttempt++;
                this.dialAttemptsForPeer.set(peerId.toString(), dialAttempt);
            }
        }
        // Always decrease the active dial count and process the dial queue
        this.currentActiveDialCount--;
        this.processDialQueue();
        // If max dial attempts reached and dialing failed, delete the peer
        if (dialAttempt === this.options.maxDialAttemptsForPeer) {
            try {
                const error = this.dialErrorsForPeer.get(peerId.toString());
                let errorMessage;
                if (error instanceof AggregateError) {
                    errorMessage = JSON.stringify(error.errors[0]);
                }
                else {
                    errorMessage = error.message;
                }
                log$G(`Deleting undialable peer ${peerId.toString()} from peer store. Error: ${errorMessage}`);
                this.dialErrorsForPeer.delete(peerId.toString());
                await this.libp2p.peerStore.delete(peerId);
            }
            catch (error) {
                throw new Error(`Error deleting undialable peer ${peerId.toString()} from peer store - ${error}`);
            }
        }
    }
    async dropConnection(peerId) {
        try {
            this.keepAliveManager.stop(peerId);
            await this.libp2p.hangUp(peerId);
            log$G(`Dropped connection with peer ${peerId.toString()}`);
        }
        catch (error) {
            log$G(`Error dropping connection with peer ${peerId.toString()} - ${error}`);
        }
    }
    processDialQueue() {
        if (this.pendingPeerDialQueue.length > 0 &&
            this.currentActiveDialCount < this.options.maxParallelDials) {
            const peerId = this.pendingPeerDialQueue.shift();
            if (!peerId)
                return;
            this.attemptDial(peerId).catch((error) => {
                log$G(error);
            });
        }
    }
    startPeerDiscoveryListener() {
        this.libp2p.addEventListener("peer:discovery", this.onEventHandlers["peer:discovery"]);
    }
    startPeerConnectionListener() {
        this.libp2p.addEventListener("peer:connect", this.onEventHandlers["peer:connect"]);
    }
    startPeerDisconnectionListener() {
        // TODO: ensure that these following issues are updated and confirmed
        /**
         * NOTE: Event is not being emitted on closing nor losing a connection.
         * @see https://github.com/libp2p/js-libp2p/issues/939
         * @see https://github.com/status-im/js-waku/issues/252
         *
         * >This event will be triggered anytime we are disconnected from another peer,
         * >regardless of the circumstances of that disconnection.
         * >If we happen to have multiple connections to a peer,
         * >this event will **only** be triggered when the last connection is closed.
         * @see https://github.com/libp2p/js-libp2p/blob/bad9e8c0ff58d60a78314077720c82ae331cc55b/doc/API.md?plain=1#L2100
         */
        this.libp2p.addEventListener("peer:disconnect", this.onEventHandlers["peer:disconnect"]);
    }
    async attemptDial(peerId) {
        if (this.currentActiveDialCount >= this.options.maxParallelDials) {
            this.pendingPeerDialQueue.push(peerId);
            return;
        }
        if (!(await this.shouldDialPeer(peerId)))
            return;
        this.dialPeer(peerId).catch((err) => {
            throw `Error dialing peer ${peerId.toString()} : ${err}`;
        });
    }
    onEventHandlers = {
        "peer:discovery": (evt) => {
            void (async () => {
                const { id: peerId } = evt.detail;
                const isBootstrap = (await this.getTagNamesForPeer(peerId)).includes(Tags.BOOTSTRAP);
                this.dispatchEvent(new CustomEvent$1(isBootstrap
                    ? EPeersByDiscoveryEvents.PEER_DISCOVERY_BOOTSTRAP
                    : EPeersByDiscoveryEvents.PEER_DISCOVERY_PEER_EXCHANGE, {
                    detail: peerId
                }));
                try {
                    await this.attemptDial(peerId);
                }
                catch (error) {
                    log$G(`Error dialing peer ${peerId.toString()} : ${error}`);
                }
            })();
        },
        "peer:connect": (evt) => {
            void (async () => {
                const peerId = evt.detail;
                this.keepAliveManager.start(peerId, this.libp2p.services.ping, this.libp2p.peerStore);
                const isBootstrap = (await this.getTagNamesForPeer(peerId)).includes(Tags.BOOTSTRAP);
                if (isBootstrap) {
                    const bootstrapConnections = this.libp2p
                        .getConnections()
                        .filter((conn) => conn.tags.includes(Tags.BOOTSTRAP));
                    // If we have too many bootstrap connections, drop one
                    if (bootstrapConnections.length > this.options.maxBootstrapPeersAllowed) {
                        await this.dropConnection(peerId);
                    }
                    else {
                        this.dispatchEvent(new CustomEvent$1(EPeersByDiscoveryEvents.PEER_CONNECT_BOOTSTRAP, {
                            detail: peerId
                        }));
                    }
                }
                else {
                    this.dispatchEvent(new CustomEvent$1(EPeersByDiscoveryEvents.PEER_CONNECT_PEER_EXCHANGE, {
                        detail: peerId
                    }));
                }
            })();
        },
        "peer:disconnect": () => {
            return (evt) => {
                this.keepAliveManager.stop(evt.detail);
            };
        }
    };
    /**
     * Checks if the peer is dialable based on the following conditions:
     * 1. If the peer is a bootstrap peer, it is only dialable if the number of current bootstrap connections is less than the max allowed.
     * 2. If the peer is not a bootstrap peer
     */
    async shouldDialPeer(peerId) {
        const isConnected = this.libp2p.getConnections(peerId).length > 0;
        if (isConnected)
            return false;
        const tagNames = await this.getTagNamesForPeer(peerId);
        const isBootstrap = tagNames.some((tagName) => tagName === Tags.BOOTSTRAP);
        if (isBootstrap) {
            const currentBootstrapConnections = this.libp2p
                .getConnections()
                .filter((conn) => {
                return conn.tags.find((name) => name === Tags.BOOTSTRAP);
            }).length;
            if (currentBootstrapConnections < this.options.maxBootstrapPeersAllowed)
                return true;
        }
        else {
            return true;
        }
        return false;
    }
    /**
     * Fetches the tag names for a given peer
     */
    async getTagNamesForPeer(peerId) {
        try {
            const peer = await this.libp2p.peerStore.get(peerId);
            return Array.from(peer.tags.keys());
        }
        catch (error) {
            log$G(`Failed to get peer ${peerId}, error: ${error}`);
            return [];
        }
    }
}

const DefaultPingKeepAliveValueSecs = 0;
const DefaultRelayKeepAliveValueSecs = 5 * 60;
const DefaultUserAgent = "js-waku";
const log$F = debug("waku:waku");
class WakuNode {
    libp2p;
    relay;
    store;
    filter;
    lightPush;
    connectionManager;
    constructor(options, libp2p, store, lightPush, filter, relay) {
        this.libp2p = libp2p;
        if (store) {
            this.store = store(libp2p);
        }
        if (filter) {
            this.filter = filter(libp2p);
        }
        if (lightPush) {
            this.lightPush = lightPush(libp2p);
        }
        if (relay) {
            this.relay = relay(libp2p);
        }
        const pingKeepAlive = options.pingKeepAlive || DefaultPingKeepAliveValueSecs;
        const relayKeepAlive = this.relay
            ? options.relayKeepAlive || DefaultRelayKeepAliveValueSecs
            : 0;
        const peerId = this.libp2p.peerId.toString();
        this.connectionManager = ConnectionManager.create(peerId, libp2p, { pingKeepAlive, relayKeepAlive }, this.relay);
        log$F("Waku node created", peerId, `relay: ${!!this.relay}, store: ${!!this.store}, light push: ${!!this
            .lightPush}, filter: ${!!this.filter}`);
    }
    /**
     * Dials to the provided peer.
     *
     * @param peer The peer to dial
     * @param protocols Waku protocols we expect from the peer; Defaults to mounted protocols
     */
    async dial(peer, protocols) {
        const _protocols = protocols ?? [];
        const peerId = mapToPeerIdOrMultiaddr(peer);
        if (typeof protocols === "undefined") {
            this.relay && _protocols.push(Protocols.Relay);
            this.store && _protocols.push(Protocols.Store);
            this.filter && _protocols.push(Protocols.Filter);
            this.lightPush && _protocols.push(Protocols.LightPush);
        }
        const codecs = [];
        if (_protocols.includes(Protocols.Relay)) {
            if (this.relay) {
                this.relay.gossipSub.multicodecs.forEach((codec) => codecs.push(codec));
            }
            else {
                log$F("Relay codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.Store)) {
            if (this.store) {
                codecs.push(this.store.multicodec);
            }
            else {
                log$F("Store codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.LightPush)) {
            if (this.lightPush) {
                codecs.push(this.lightPush.multicodec);
            }
            else {
                log$F("Light Push codec not included in dial codec: protocol not mounted locally");
            }
        }
        if (_protocols.includes(Protocols.Filter)) {
            if (this.filter) {
                codecs.push(this.filter.multicodec);
            }
            else {
                log$F("Filter codec not included in dial codec: protocol not mounted locally");
            }
        }
        log$F(`Dialing to ${peerId.toString()} with protocols ${_protocols}`);
        return this.libp2p.dialProtocol(peerId, codecs);
    }
    async start() {
        await this.libp2p.start();
    }
    async stop() {
        this.connectionManager.stop();
        await this.libp2p.stop();
    }
    isStarted() {
        return this.libp2p.isStarted();
    }
    /**
     * Return the local multiaddr with peer id on which libp2p is listening.
     *
     * @throws if libp2p is not listening on localhost.
     */
    getLocalMultiaddrWithID() {
        const localMultiaddr = this.libp2p
            .getMultiaddrs()
            .find((addr) => addr.toString().match(/127\.0\.0\.1/));
        if (!localMultiaddr || localMultiaddr.toString() === "") {
            throw "Not listening on localhost";
        }
        return localMultiaddr + "/p2p/" + this.libp2p.peerId.toString();
    }
}
function mapToPeerIdOrMultiaddr(peerId) {
    return isPeerId(peerId) ? peerId : multiaddr$1(peerId);
}

var waku = /*#__PURE__*/Object.freeze({
    __proto__: null,
    DefaultPingKeepAliveValueSecs: DefaultPingKeepAliveValueSecs,
    DefaultRelayKeepAliveValueSecs: DefaultRelayKeepAliveValueSecs,
    DefaultUserAgent: DefaultUserAgent,
    WakuNode: WakuNode
});

/**
 * DefaultPubSubTopic is the default gossipsub topic to use for Waku.
 */
const DefaultPubSubTopic = "/waku/2/default-waku/proto";

var index$6 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    version_0: version_0
});

function isDefined(value) {
    return Boolean(value);
}

/**
 * Return pseudo random subset of the input.
 */
function getPseudoRandomSubset(values, wantedNumber) {
    if (values.length <= wantedNumber || values.length <= 1) {
        return values;
    }
    return shuffle$1(values).slice(0, wantedNumber);
}
function shuffle$1(arr) {
    if (arr.length <= 1) {
        return arr;
    }
    const randInt = () => {
        return Math.floor(Math.random() * Math.floor(arr.length));
    };
    for (let i = 0; i < arr.length; i++) {
        const j = randInt();
        const tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
    return arr;
}

function groupByContentTopic(values) {
    const groupedDecoders = new Map();
    values.forEach((value) => {
        let decs = groupedDecoders.get(value.contentTopic);
        if (!decs) {
            groupedDecoders.set(value.contentTopic, []);
            decs = groupedDecoders.get(value.contentTopic);
        }
        decs.push(value);
    });
    return groupedDecoders;
}

const FRAME_RATE = 60;
/**
 * Function that transforms IReceiver subscription to iterable stream of data.
 * @param receiver - object that allows to be subscribed to;
 * @param decoder - parameter to be passed to receiver for subscription;
 * @param options - options for receiver for subscription;
 * @param iteratorOptions - optional configuration for iterator;
 * @returns iterator and stop function to terminate it.
 */
async function toAsyncIterator(receiver, decoder, iteratorOptions) {
    const iteratorDelay = iteratorOptions?.iteratorDelay ?? FRAME_RATE;
    const messages = [];
    let unsubscribe;
    unsubscribe = await receiver.subscribe(decoder, (message) => {
        messages.push(message);
    });
    const isWithTimeout = Number.isInteger(iteratorOptions?.timeoutMs);
    const timeoutMs = iteratorOptions?.timeoutMs ?? 0;
    const startTime = Date.now();
    async function* iterator() {
        while (true) {
            if (isWithTimeout && Date.now() - startTime >= timeoutMs) {
                return;
            }
            await wait(iteratorDelay);
            const message = messages.shift();
            if (!unsubscribe && messages.length === 0) {
                return message;
            }
            if (!message && unsubscribe) {
                continue;
            }
            yield message;
        }
    }
    return {
        iterator: iterator(),
        async stop() {
            if (unsubscribe) {
                await unsubscribe();
                unsubscribe = undefined;
            }
        }
    };
}
function wait(ms) {
    return new Promise((resolve) => {
        setTimeout(resolve, ms);
    });
}

const MB = 1024 ** 2;
const SIZE_CAP = 1; // 1 MB
const isSizeValid = (payload) => {
    if (payload.length / MB > SIZE_CAP) {
        return false;
    }
    return true;
};

function removeItemFromArray(arr, value) {
    const index = arr.indexOf(value);
    if (index > -1) {
        arr.splice(index, 1);
    }
    return arr;
}

var index$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getPseudoRandomSubset: getPseudoRandomSubset,
    groupByContentTopic: groupByContentTopic,
    isDefined: isDefined,
    isSizeValid: isSizeValid,
    removeItemFromArray: removeItemFromArray,
    toAsyncIterator: toAsyncIterator
});

function isAsyncIterable$b(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function all$1(source) {
    if (isAsyncIterable$b(source)) {
        return (async () => {
            const arr = [];
            for await (const entry of source) {
                arr.push(entry);
            }
            return arr;
        })();
    }
    const arr = [];
    for (const entry of source) {
        arr.push(entry);
    }
    return arr;
}

const symbol$3 = Symbol.for('@achingbrain/uint8arraylist');
function findBufAndOffset(bufs, index) {
    if (index == null || index < 0) {
        throw new RangeError('index is out of bounds');
    }
    let offset = 0;
    for (const buf of bufs) {
        const bufEnd = offset + buf.byteLength;
        if (index < bufEnd) {
            return {
                buf,
                index: index - offset
            };
        }
        offset = bufEnd;
    }
    throw new RangeError('index is out of bounds');
}
/**
 * Check if object is a CID instance
 *
 * @example
 *
 * ```js
 * import { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist'
 *
 * isUint8ArrayList(true) // false
 * isUint8ArrayList([]) // false
 * isUint8ArrayList(new Uint8ArrayList()) // true
 * ```
 */
function isUint8ArrayList(value) {
    return Boolean(value?.[symbol$3]);
}
class Uint8ArrayList {
    constructor(...data) {
        // Define symbol
        Object.defineProperty(this, symbol$3, { value: true });
        this.bufs = [];
        this.length = 0;
        if (data.length > 0) {
            this.appendAll(data);
        }
    }
    *[Symbol.iterator]() {
        yield* this.bufs;
    }
    get byteLength() {
        return this.length;
    }
    /**
     * Add one or more `bufs` to the end of this Uint8ArrayList
     */
    append(...bufs) {
        this.appendAll(bufs);
    }
    /**
     * Add all `bufs` to the end of this Uint8ArrayList
     */
    appendAll(bufs) {
        let length = 0;
        for (const buf of bufs) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.push(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.push(...buf.bufs);
            }
            else {
                throw new Error('Could not append value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Add one or more `bufs` to the start of this Uint8ArrayList
     */
    prepend(...bufs) {
        this.prependAll(bufs);
    }
    /**
     * Add all `bufs` to the start of this Uint8ArrayList
     */
    prependAll(bufs) {
        let length = 0;
        for (const buf of bufs.reverse()) {
            if (buf instanceof Uint8Array) {
                length += buf.byteLength;
                this.bufs.unshift(buf);
            }
            else if (isUint8ArrayList(buf)) {
                length += buf.byteLength;
                this.bufs.unshift(...buf.bufs);
            }
            else {
                throw new Error('Could not prepend value, must be an Uint8Array or a Uint8ArrayList');
            }
        }
        this.length += length;
    }
    /**
     * Read the value at `index`
     */
    get(index) {
        const res = findBufAndOffset(this.bufs, index);
        return res.buf[res.index];
    }
    /**
     * Set the value at `index` to `value`
     */
    set(index, value) {
        const res = findBufAndOffset(this.bufs, index);
        res.buf[res.index] = value;
    }
    /**
     * Copy bytes from `buf` to the index specified by `offset`
     */
    write(buf, offset = 0) {
        if (buf instanceof Uint8Array) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf[i]);
            }
        }
        else if (isUint8ArrayList(buf)) {
            for (let i = 0; i < buf.length; i++) {
                this.set(offset + i, buf.get(i));
            }
        }
        else {
            throw new Error('Could not write value, must be an Uint8Array or a Uint8ArrayList');
        }
    }
    /**
     * Remove bytes from the front of the pool
     */
    consume(bytes) {
        // first, normalize the argument, in accordance with how Buffer does it
        bytes = Math.trunc(bytes);
        // do nothing if not a positive number
        if (Number.isNaN(bytes) || bytes <= 0) {
            return;
        }
        // if consuming all bytes, skip iterating
        if (bytes === this.byteLength) {
            this.bufs = [];
            this.length = 0;
            return;
        }
        while (this.bufs.length > 0) {
            if (bytes >= this.bufs[0].byteLength) {
                bytes -= this.bufs[0].byteLength;
                this.length -= this.bufs[0].byteLength;
                this.bufs.shift();
            }
            else {
                this.bufs[0] = this.bufs[0].subarray(bytes);
                this.length -= bytes;
                break;
            }
        }
    }
    /**
     * Extracts a section of an array and returns a new array.
     *
     * This is a copy operation as it is with Uint8Arrays and Arrays
     * - note this is different to the behaviour of Node Buffers.
     */
    slice(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        return concat$1(bufs, length);
    }
    /**
     * Returns a alloc from the given start and end element index.
     *
     * In the best case where the data extracted comes from a single Uint8Array
     * internally this is a no-copy operation otherwise it is a copy operation.
     */
    subarray(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        if (bufs.length === 1) {
            return bufs[0];
        }
        return concat$1(bufs, length);
    }
    /**
     * Returns a allocList from the given start and end element index.
     *
     * This is a no-copy operation.
     */
    sublist(beginInclusive, endExclusive) {
        const { bufs, length } = this._subList(beginInclusive, endExclusive);
        const list = new Uint8ArrayList();
        list.length = length;
        // don't loop, just set the bufs
        list.bufs = bufs;
        return list;
    }
    _subList(beginInclusive, endExclusive) {
        beginInclusive = beginInclusive ?? 0;
        endExclusive = endExclusive ?? this.length;
        if (beginInclusive < 0) {
            beginInclusive = this.length + beginInclusive;
        }
        if (endExclusive < 0) {
            endExclusive = this.length + endExclusive;
        }
        if (beginInclusive < 0 || endExclusive > this.length) {
            throw new RangeError('index is out of bounds');
        }
        if (beginInclusive === endExclusive) {
            return { bufs: [], length: 0 };
        }
        if (beginInclusive === 0 && endExclusive === this.length) {
            return { bufs: [...this.bufs], length: this.length };
        }
        const bufs = [];
        let offset = 0;
        for (let i = 0; i < this.bufs.length; i++) {
            const buf = this.bufs[i];
            const bufStart = offset;
            const bufEnd = bufStart + buf.byteLength;
            // for next loop
            offset = bufEnd;
            if (beginInclusive >= bufEnd) {
                // start after this buf
                continue;
            }
            const sliceStartInBuf = beginInclusive >= bufStart && beginInclusive < bufEnd;
            const sliceEndsInBuf = endExclusive > bufStart && endExclusive <= bufEnd;
            if (sliceStartInBuf && sliceEndsInBuf) {
                // slice is wholly contained within this buffer
                if (beginInclusive === bufStart && endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                const start = beginInclusive - bufStart;
                bufs.push(buf.subarray(start, start + (endExclusive - beginInclusive)));
                break;
            }
            if (sliceStartInBuf) {
                // slice starts in this buffer
                if (beginInclusive === 0) {
                    // requested whole buffer
                    bufs.push(buf);
                    continue;
                }
                // requested part of buffer
                bufs.push(buf.subarray(beginInclusive - bufStart));
                continue;
            }
            if (sliceEndsInBuf) {
                if (endExclusive === bufEnd) {
                    // requested whole buffer
                    bufs.push(buf);
                    break;
                }
                // requested part of buffer
                bufs.push(buf.subarray(0, endExclusive - bufStart));
                break;
            }
            // slice started before this buffer and ends after it
            bufs.push(buf);
        }
        return { bufs, length: endExclusive - beginInclusive };
    }
    indexOf(search, offset = 0) {
        if (!isUint8ArrayList(search) && !(search instanceof Uint8Array)) {
            throw new TypeError('The "value" argument must be a Uint8ArrayList or Uint8Array');
        }
        const needle = search instanceof Uint8Array ? search : search.subarray();
        offset = Number(offset ?? 0);
        if (isNaN(offset)) {
            offset = 0;
        }
        if (offset < 0) {
            offset = this.length + offset;
        }
        if (offset < 0) {
            offset = 0;
        }
        if (search.length === 0) {
            return offset > this.length ? this.length : offset;
        }
        // https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm
        const M = needle.byteLength;
        if (M === 0) {
            throw new TypeError('search must be at least 1 byte long');
        }
        // radix
        const radix = 256;
        const rightmostPositions = new Int32Array(radix);
        // position of the rightmost occurrence of the byte c in the pattern
        for (let c = 0; c < radix; c++) {
            // -1 for bytes not in pattern
            rightmostPositions[c] = -1;
        }
        for (let j = 0; j < M; j++) {
            // rightmost position for bytes in pattern
            rightmostPositions[needle[j]] = j;
        }
        // Return offset of first match, -1 if no match
        const right = rightmostPositions;
        const lastIndex = this.byteLength - needle.byteLength;
        const lastPatIndex = needle.byteLength - 1;
        let skip;
        for (let i = offset; i <= lastIndex; i += skip) {
            skip = 0;
            for (let j = lastPatIndex; j >= 0; j--) {
                const char = this.get(i + j);
                if (needle[j] !== char) {
                    skip = Math.max(1, j - right[char]);
                    break;
                }
            }
            if (skip === 0) {
                return i;
            }
        }
        return -1;
    }
    getInt8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt8(0);
    }
    setInt8(byteOffset, value) {
        const buf = allocUnsafe$2(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt8(0, value);
        this.write(buf, byteOffset);
    }
    getInt16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt16(0, littleEndian);
    }
    setInt16(byteOffset, value, littleEndian) {
        const buf = alloc$1(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getInt32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getInt32(0, littleEndian);
    }
    setInt32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setInt32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigInt64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigInt64(0, littleEndian);
    }
    setBigInt64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigInt64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint8(byteOffset) {
        const buf = this.subarray(byteOffset, byteOffset + 1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint8(0);
    }
    setUint8(byteOffset, value) {
        const buf = allocUnsafe$2(1);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint8(0, value);
        this.write(buf, byteOffset);
    }
    getUint16(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint16(0, littleEndian);
    }
    setUint16(byteOffset, value, littleEndian) {
        const buf = alloc$1(2);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint16(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getUint32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getUint32(0, littleEndian);
    }
    setUint32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setUint32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getBigUint64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getBigUint64(0, littleEndian);
    }
    setBigUint64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setBigUint64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat32(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat32(0, littleEndian);
    }
    setFloat32(byteOffset, value, littleEndian) {
        const buf = alloc$1(4);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat32(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    getFloat64(byteOffset, littleEndian) {
        const buf = this.subarray(byteOffset, byteOffset + 8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        return view.getFloat64(0, littleEndian);
    }
    setFloat64(byteOffset, value, littleEndian) {
        const buf = alloc$1(8);
        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);
        view.setFloat64(0, value, littleEndian);
        this.write(buf, byteOffset);
    }
    equals(other) {
        if (other == null) {
            return false;
        }
        if (!(other instanceof Uint8ArrayList)) {
            return false;
        }
        if (other.bufs.length !== this.bufs.length) {
            return false;
        }
        for (let i = 0; i < this.bufs.length; i++) {
            if (!equals$4(this.bufs[i], other.bufs[i])) {
                return false;
            }
        }
        return true;
    }
    /**
     * Create a Uint8ArrayList from a pre-existing list of Uint8Arrays.  Use this
     * method if you know the total size of all the Uint8Arrays ahead of time.
     */
    static fromUint8Arrays(bufs, length) {
        const list = new Uint8ArrayList();
        list.bufs = bufs;
        if (length == null) {
            length = bufs.reduce((acc, curr) => acc + curr.byteLength, 0);
        }
        list.length = length;
        return list;
    }
}
/*
function indexOf (needle: Uint8Array, haystack: Uint8Array, offset = 0) {
  for (let i = offset; i < haystack.byteLength; i++) {
    for (let j = 0; j < needle.length; j++) {
      if (haystack[i + j] !== needle[j]) {
        break
      }

      if (j === needle.byteLength -1) {
        return i
      }
    }

    if (haystack.byteLength - i < needle.byteLength) {
      break
    }
  }

  return -1
}
*/

function accessor(buf) {
    if (buf instanceof Uint8Array) {
        return {
            get(index) {
                return buf[index];
            },
            set(index, value) {
                buf[index] = value;
            }
        };
    }
    return {
        get(index) {
            return buf.get(index);
        },
        set(index, value) {
            buf.set(index, value);
        }
    };
}

const TWO_32 = 4294967296;
class LongBits {
    constructor(hi = 0, lo = 0) {
        this.hi = hi;
        this.lo = lo;
    }
    /**
     * Returns these hi/lo bits as a BigInt
     */
    toBigInt(unsigned) {
        if (unsigned === true) {
            return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);
        }
        if ((this.hi >>> 31) !== 0) {
            const lo = ~this.lo + 1 >>> 0;
            let hi = ~this.hi >>> 0;
            if (lo === 0) {
                hi = hi + 1 >>> 0;
            }
            return -(BigInt(lo) + (BigInt(hi) << 32n));
        }
        return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);
    }
    /**
     * Returns these hi/lo bits as a Number - this may overflow, toBigInt
     * should be preferred
     */
    toNumber(unsigned) {
        return Number(this.toBigInt(unsigned));
    }
    /**
     * ZigZag decode a LongBits object
     */
    zzDecode() {
        const mask = -(this.lo & 1);
        const lo = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;
        const hi = (this.hi >>> 1 ^ mask) >>> 0;
        return new LongBits(hi, lo);
    }
    /**
     * ZigZag encode a LongBits object
     */
    zzEncode() {
        const mask = this.hi >> 31;
        const hi = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;
        const lo = (this.lo << 1 ^ mask) >>> 0;
        return new LongBits(hi, lo);
    }
    /**
     * Encode a LongBits object as a varint byte array
     */
    toBytes(buf, offset = 0) {
        const access = accessor(buf);
        while (this.hi > 0) {
            access.set(offset++, this.lo & 127 | 128);
            this.lo = (this.lo >>> 7 | this.hi << 25) >>> 0;
            this.hi >>>= 7;
        }
        while (this.lo > 127) {
            access.set(offset++, this.lo & 127 | 128);
            this.lo = this.lo >>> 7;
        }
        access.set(offset++, this.lo);
    }
    /**
     * Parse a LongBits object from a BigInt
     */
    static fromBigInt(value) {
        if (value === 0n) {
            return new LongBits();
        }
        const negative = value < 0;
        if (negative) {
            value = -value;
        }
        let hi = Number(value >> 32n) | 0;
        let lo = Number(value - (BigInt(hi) << 32n)) | 0;
        if (negative) {
            hi = ~hi >>> 0;
            lo = ~lo >>> 0;
            if (++lo > TWO_32) {
                lo = 0;
                if (++hi > TWO_32) {
                    hi = 0;
                }
            }
        }
        return new LongBits(hi, lo);
    }
    /**
     * Parse a LongBits object from a Number
     */
    static fromNumber(value) {
        if (value === 0) {
            return new LongBits();
        }
        const sign = value < 0;
        if (sign) {
            value = -value;
        }
        let lo = value >>> 0;
        let hi = (value - lo) / 4294967296 >>> 0;
        if (sign) {
            hi = ~hi >>> 0;
            lo = ~lo >>> 0;
            if (++lo > 4294967295) {
                lo = 0;
                if (++hi > 4294967295) {
                    hi = 0;
                }
            }
        }
        return new LongBits(hi, lo);
    }
    /**
     * Parse a LongBits object from a varint byte array
     */
    static fromBytes(buf, offset = 0) {
        const access = accessor(buf);
        // tends to deopt with local vars for octet etc.
        const bits = new LongBits();
        let i = 0;
        if (buf.length - offset > 4) { // fast route (lo)
            for (; i < 4; ++i) {
                // 1st..4th
                bits.lo = (bits.lo | (access.get(offset) & 127) << i * 7) >>> 0;
                if (access.get(offset++) < 128) {
                    return bits;
                }
            }
            // 5th
            bits.lo = (bits.lo | (access.get(offset) & 127) << 28) >>> 0;
            bits.hi = (bits.hi | (access.get(offset) & 127) >> 4) >>> 0;
            if (access.get(offset++) < 128) {
                return bits;
            }
            i = 0;
        }
        else {
            for (; i < 4; ++i) {
                /* istanbul ignore if */
                if (offset >= buf.length) {
                    throw RangeError(`index out of range: ${offset} > ${buf.length}`);
                }
                // 1st..4th
                bits.lo = (bits.lo | (access.get(offset) & 127) << i * 7) >>> 0;
                if (access.get(offset++) < 128) {
                    return bits;
                }
            }
        }
        if (buf.length - offset > 4) { // fast route (hi)
            for (; i < 5; ++i) {
                // 6th..10th
                bits.hi = (bits.hi | (access.get(offset) & 127) << i * 7 + 3) >>> 0;
                if (access.get(offset++) < 128) {
                    return bits;
                }
            }
        }
        else if (offset < buf.byteLength) {
            for (; i < 5; ++i) {
                /* istanbul ignore if */
                if (offset >= buf.length) {
                    throw RangeError(`index out of range: ${offset} > ${buf.length}`);
                }
                // 6th..10th
                bits.hi = (bits.hi | (access.get(offset) & 127) << i * 7 + 3) >>> 0;
                if (access.get(offset++) < 128) {
                    return bits;
                }
            }
        }
        /* istanbul ignore next */
        throw RangeError('invalid varint encoding');
    }
}

const N1$8 = Math.pow(2, 7);
const N2$8 = Math.pow(2, 14);
const N3$8 = Math.pow(2, 21);
const N4$8 = Math.pow(2, 28);
const N5$8 = Math.pow(2, 35);
const N6$8 = Math.pow(2, 42);
const N7$8 = Math.pow(2, 49);
const N8$8 = Math.pow(2, 56);
const N9$8 = Math.pow(2, 63);
const unsigned = {
    encodingLength(value) {
        if (value < N1$8) {
            return 1;
        }
        if (value < N2$8) {
            return 2;
        }
        if (value < N3$8) {
            return 3;
        }
        if (value < N4$8) {
            return 4;
        }
        if (value < N5$8) {
            return 5;
        }
        if (value < N6$8) {
            return 6;
        }
        if (value < N7$8) {
            return 7;
        }
        if (value < N8$8) {
            return 8;
        }
        if (value < N9$8) {
            return 9;
        }
        return 10;
    },
    encode(value, buf, offset = 0) {
        if (Number.MAX_SAFE_INTEGER != null && value > Number.MAX_SAFE_INTEGER) {
            throw new RangeError('Could not encode varint');
        }
        if (buf == null) {
            buf = allocUnsafe$2(unsigned.encodingLength(value));
        }
        LongBits.fromNumber(value).toBytes(buf, offset);
        return buf;
    },
    decode(buf, offset = 0) {
        return LongBits.fromBytes(buf, offset).toNumber(true);
    }
};

function isAsyncIterable$a(thing) {
    return thing[Symbol.asyncIterator] != null;
}

const defaultEncoder = (length) => {
    const lengthLength = unsigned.encodingLength(length);
    const lengthBuf = allocUnsafe$2(lengthLength);
    unsigned.encode(length, lengthBuf);
    defaultEncoder.bytes = lengthLength;
    return lengthBuf;
};
defaultEncoder.bytes = 0;
function encode$B(source, options) {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    function* maybeYield(chunk) {
        // length + data
        const length = encodeLength(chunk.byteLength);
        // yield only Uint8Arrays
        if (length instanceof Uint8Array) {
            yield length;
        }
        else {
            yield* length;
        }
        // yield only Uint8Arrays
        if (chunk instanceof Uint8Array) {
            yield chunk;
        }
        else {
            yield* chunk;
        }
    }
    if (isAsyncIterable$a(source)) {
        return (async function* () {
            for await (const chunk of source) {
                yield* maybeYield(chunk);
            }
        })();
    }
    return (function* () {
        for (const chunk of source) {
            yield* maybeYield(chunk);
        }
    })();
}
encode$B.single = (chunk, options) => {
    options = options ?? {};
    const encodeLength = options.lengthEncoder ?? defaultEncoder;
    return new Uint8ArrayList(encodeLength(chunk.byteLength), chunk);
};

/**
 * @typedef {{ [key: string]: any }} Extensions
 * @typedef {Error} Err
 * @property {string} message
 */

/**
 *
 * @param {Error} obj
 * @param {Extensions} props
 * @returns {Error & Extensions}
 */
function assign(obj, props) {
    for (const key in props) {
        Object.defineProperty(obj, key, {
            value: props[key],
            enumerable: true,
            configurable: true,
        });
    }

    return obj;
}

/**
 *
 * @param {any} err - An Error
 * @param {string|Extensions} code - A string code or props to set on the error
 * @param {Extensions} [props] - Props to set on the error
 * @returns {Error & Extensions}
 */
function createError(err, code, props) {
    if (!err || typeof err === 'string') {
        throw new TypeError('Please pass an Error to err-code');
    }

    if (!props) {
        props = {};
    }

    if (typeof code === 'object') {
        props = code;
        code = '';
    }

    if (code) {
        props.code = code;
    }

    try {
        return assign(err, props);
    } catch (_) {
        props.message = err.message;
        props.stack = err.stack;

        const ErrClass = function () {};

        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));

        // @ts-ignore
        const output = assign(new ErrClass(), props);

        return output;
    }
}

var errCode = createError;

var errCode$1 = /*@__PURE__*/getDefaultExportFromCjs(errCode);

/* eslint max-depth: ["error", 6] */
// Maximum length of the length section of the message
const MAX_LENGTH_LENGTH = 8; // Varint.encode(Number.MAX_SAFE_INTEGER).length
// Maximum length of the data section of the message
const MAX_DATA_LENGTH = 1024 * 1024 * 4;
var ReadMode;
(function (ReadMode) {
    ReadMode[ReadMode["LENGTH"] = 0] = "LENGTH";
    ReadMode[ReadMode["DATA"] = 1] = "DATA";
})(ReadMode || (ReadMode = {}));
const defaultDecoder = (buf) => {
    const length = unsigned.decode(buf);
    defaultDecoder.bytes = unsigned.encodingLength(length);
    return length;
};
defaultDecoder.bytes = 0;
function decode$v(source, options) {
    const buffer = new Uint8ArrayList();
    let mode = ReadMode.LENGTH;
    let dataLength = -1;
    const lengthDecoder = options?.lengthDecoder ?? defaultDecoder;
    const maxLengthLength = options?.maxLengthLength ?? MAX_LENGTH_LENGTH;
    const maxDataLength = options?.maxDataLength ?? MAX_DATA_LENGTH;
    function* maybeYield() {
        while (buffer.byteLength > 0) {
            if (mode === ReadMode.LENGTH) {
                // read length, ignore errors for short reads
                try {
                    dataLength = lengthDecoder(buffer);
                    if (dataLength < 0) {
                        throw errCode$1(new Error('invalid message length'), 'ERR_INVALID_MSG_LENGTH');
                    }
                    if (dataLength > maxDataLength) {
                        throw errCode$1(new Error('message length too long'), 'ERR_MSG_DATA_TOO_LONG');
                    }
                    const dataLengthLength = lengthDecoder.bytes;
                    buffer.consume(dataLengthLength);
                    if (options?.onLength != null) {
                        options.onLength(dataLength);
                    }
                    mode = ReadMode.DATA;
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        if (buffer.byteLength > maxLengthLength) {
                            throw errCode$1(new Error('message length length too long'), 'ERR_MSG_LENGTH_TOO_LONG');
                        }
                        break;
                    }
                    throw err;
                }
            }
            if (mode === ReadMode.DATA) {
                if (buffer.byteLength < dataLength) {
                    // not enough data, wait for more
                    break;
                }
                const data = buffer.sublist(0, dataLength);
                buffer.consume(dataLength);
                if (options?.onData != null) {
                    options.onData(data);
                }
                yield data;
                mode = ReadMode.LENGTH;
            }
        }
    }
    if (isAsyncIterable$a(source)) {
        return (async function* () {
            for await (const buf of source) {
                buffer.append(buf);
                yield* maybeYield();
            }
            if (buffer.byteLength > 0) {
                throw errCode$1(new Error('unexpected end of input'), 'ERR_UNEXPECTED_EOF');
            }
        })();
    }
    return (function* () {
        for (const buf of source) {
            buffer.append(buf);
            yield* maybeYield();
        }
        if (buffer.byteLength > 0) {
            throw errCode$1(new Error('unexpected end of input'), 'ERR_UNEXPECTED_EOF');
        }
    })();
}
decode$v.fromReader = (reader, options) => {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = (async function* () {
        while (true) {
            try {
                const { done, value } = await reader.next(byteLength);
                if (done === true) {
                    return;
                }
                if (value != null) {
                    yield value;
                }
            }
            catch (err) {
                if (err.code === 'ERR_UNDER_READ') {
                    return { done: true, value: null };
                }
                throw err;
            }
            finally {
                // Reset the byteLength so we continue to check for varints
                byteLength = 1;
            }
        }
    }());
    /**
     * Once the length has been parsed, read chunk for that length
     */
    const onLength = (l) => { byteLength = l; };
    return decode$v(varByteSource, {
        ...(options ?? {}),
        onLength
    });
};

function pDefer() {
	const deferred = {};

	deferred.promise = new Promise((resolve, reject) => {
		deferred.resolve = resolve;
		deferred.reject = reject;
	});

	return deferred;
}

// ported from https://www.npmjs.com/package/fast-fifo
class FixedFIFO {
    buffer;
    mask;
    top;
    btm;
    next;
    constructor(hwm) {
        if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) {
            throw new Error('Max size for a FixedFIFO should be a power of two');
        }
        this.buffer = new Array(hwm);
        this.mask = hwm - 1;
        this.top = 0;
        this.btm = 0;
        this.next = null;
    }
    push(data) {
        if (this.buffer[this.top] !== undefined) {
            return false;
        }
        this.buffer[this.top] = data;
        this.top = (this.top + 1) & this.mask;
        return true;
    }
    shift() {
        const last = this.buffer[this.btm];
        if (last === undefined) {
            return undefined;
        }
        this.buffer[this.btm] = undefined;
        this.btm = (this.btm + 1) & this.mask;
        return last;
    }
    isEmpty() {
        return this.buffer[this.btm] === undefined;
    }
}
class FIFO {
    size;
    hwm;
    head;
    tail;
    constructor(options = {}) {
        this.hwm = options.splitLimit ?? 16;
        this.head = new FixedFIFO(this.hwm);
        this.tail = this.head;
        this.size = 0;
    }
    calculateSize(obj) {
        if (obj?.byteLength != null) {
            return obj.byteLength;
        }
        return 1;
    }
    push(val) {
        if (val?.value != null) {
            this.size += this.calculateSize(val.value);
        }
        if (!this.head.push(val)) {
            const prev = this.head;
            this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length);
            this.head.push(val);
        }
    }
    shift() {
        let val = this.tail.shift();
        if (val === undefined && (this.tail.next != null)) {
            const next = this.tail.next;
            this.tail.next = null;
            this.tail = next;
            val = this.tail.shift();
        }
        if (val?.value != null) {
            this.size -= this.calculateSize(val.value);
        }
        return val;
    }
    isEmpty() {
        return this.head.isEmpty();
    }
}

/**
 * @packageDocumentation
 *
 * An iterable that you can push values into.
 *
 * @example
 *
 * ```js
 * import { pushable } from 'it-pushable'
 *
 * const source = pushable()
 *
 * setTimeout(() => source.push('hello'), 100)
 * setTimeout(() => source.push('world'), 200)
 * setTimeout(() => source.end(), 300)
 *
 * const start = Date.now()
 *
 * for await (const value of source) {
 *   console.log(`got "${value}" after ${Date.now() - start}ms`)
 * }
 * console.log(`done after ${Date.now() - start}ms`)
 *
 * // Output:
 * // got "hello" after 105ms
 * // got "world" after 207ms
 * // done after 309ms
 * ```
 *
 * @example
 *
 * ```js
 * import { pushableV } from 'it-pushable'
 * import all from 'it-all'
 *
 * const source = pushableV()
 *
 * source.push(1)
 * source.push(2)
 * source.push(3)
 * source.end()
 *
 * console.info(await all(source))
 *
 * // Output:
 * // [ [1, 2, 3] ]
 * ```
 */
let AbortError$7 = class AbortError extends Error {
    type;
    code;
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.code = code ?? 'ABORT_ERR';
    }
};
function pushable(options = {}) {
    const getNext = (buffer) => {
        const next = buffer.shift();
        if (next == null) {
            return { done: true };
        }
        if (next.error != null) {
            throw next.error;
        }
        return {
            done: next.done === true,
            // @ts-expect-error if done is false, value will be present
            value: next.value
        };
    };
    return _pushable(getNext, options);
}
function pushableV(options = {}) {
    const getNext = (buffer) => {
        let next;
        const values = [];
        while (!buffer.isEmpty()) {
            next = buffer.shift();
            if (next == null) {
                break;
            }
            if (next.error != null) {
                throw next.error;
            }
            if (next.done === false) {
                // @ts-expect-error if done is false value should be pushed
                values.push(next.value);
            }
        }
        if (next == null) {
            return { done: true };
        }
        return {
            done: next.done === true,
            value: values
        };
    };
    return _pushable(getNext, options);
}
function _pushable(getNext, options) {
    options = options ?? {};
    let onEnd = options.onEnd;
    let buffer = new FIFO();
    let pushable;
    let onNext;
    let ended;
    let drain = pDefer();
    const waitNext = async () => {
        try {
            if (!buffer.isEmpty()) {
                return getNext(buffer);
            }
            if (ended) {
                return { done: true };
            }
            return await new Promise((resolve, reject) => {
                onNext = (next) => {
                    onNext = null;
                    buffer.push(next);
                    try {
                        resolve(getNext(buffer));
                    }
                    catch (err) {
                        reject(err);
                    }
                    return pushable;
                };
            });
        }
        finally {
            if (buffer.isEmpty()) {
                // settle promise in the microtask queue to give consumers a chance to
                // await after calling .push
                queueMicrotask(() => {
                    drain.resolve();
                    drain = pDefer();
                });
            }
        }
    };
    const bufferNext = (next) => {
        if (onNext != null) {
            return onNext(next);
        }
        buffer.push(next);
        return pushable;
    };
    const bufferError = (err) => {
        buffer = new FIFO();
        if (onNext != null) {
            return onNext({ error: err });
        }
        buffer.push({ error: err });
        return pushable;
    };
    const push = (value) => {
        if (ended) {
            return pushable;
        }
        // @ts-expect-error `byteLength` is not declared on PushType
        if (options?.objectMode !== true && value?.byteLength == null) {
            throw new Error('objectMode was not true but tried to push non-Uint8Array value');
        }
        return bufferNext({ done: false, value });
    };
    const end = (err) => {
        if (ended)
            return pushable;
        ended = true;
        return (err != null) ? bufferError(err) : bufferNext({ done: true });
    };
    const _return = () => {
        buffer = new FIFO();
        end();
        return { done: true };
    };
    const _throw = (err) => {
        end(err);
        return { done: true };
    };
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next: waitNext,
        return: _return,
        throw: _throw,
        push,
        end,
        get readableLength() {
            return buffer.size;
        },
        onEmpty: async (options) => {
            const signal = options?.signal;
            signal?.throwIfAborted();
            if (buffer.isEmpty()) {
                return;
            }
            let cancel;
            let listener;
            if (signal != null) {
                cancel = new Promise((resolve, reject) => {
                    listener = () => {
                        reject(new AbortError$7());
                    };
                    signal.addEventListener('abort', listener);
                });
            }
            try {
                await Promise.race([
                    drain.promise,
                    cancel
                ]);
            }
            finally {
                if (listener != null && signal != null) {
                    signal?.removeEventListener('abort', listener);
                }
            }
        }
    };
    if (onEnd == null) {
        return pushable;
    }
    const _pushable = pushable;
    pushable = {
        [Symbol.asyncIterator]() { return this; },
        next() {
            return _pushable.next();
        },
        throw(err) {
            _pushable.throw(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return { done: true };
        },
        return() {
            _pushable.return();
            if (onEnd != null) {
                onEnd();
                onEnd = undefined;
            }
            return { done: true };
        },
        push,
        end(err) {
            _pushable.end(err);
            if (onEnd != null) {
                onEnd(err);
                onEnd = undefined;
            }
            return pushable;
        },
        get readableLength() {
            return _pushable.readableLength;
        }
    };
    return pushable;
}

function isAsyncIterable$9(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function merge$1(...sources) {
    const syncSources = [];
    for (const source of sources) {
        if (!isAsyncIterable$9(source)) {
            syncSources.push(source);
        }
    }
    if (syncSources.length === sources.length) {
        // all sources are synchronous
        return (function* () {
            for (const source of syncSources) {
                yield* source;
            }
        })();
    }
    return (async function* () {
        const output = pushable({
            objectMode: true
        });
        void Promise.resolve().then(async () => {
            try {
                await Promise.all(sources.map(async (source) => {
                    for await (const item of source) {
                        output.push(item);
                    }
                }));
                output.end();
            }
            catch (err) {
                output.end(err);
            }
        });
        yield* output;
    })();
}

function pipe(first, ...rest) {
    if (first == null) {
        throw new Error('Empty pipeline');
    }
    // Duplex at start: wrap in function and return duplex source
    if (isDuplex(first)) {
        const duplex = first;
        first = () => duplex.source;
        // Iterable at start: wrap in function
    }
    else if (isIterable(first) || isAsyncIterable$8(first)) {
        const source = first;
        first = () => source;
    }
    const fns = [first, ...rest];
    if (fns.length > 1) {
        // Duplex at end: use duplex sink
        if (isDuplex(fns[fns.length - 1])) {
            fns[fns.length - 1] = fns[fns.length - 1].sink;
        }
    }
    if (fns.length > 2) {
        // Duplex in the middle, consume source with duplex sink and return duplex source
        for (let i = 1; i < fns.length - 1; i++) {
            if (isDuplex(fns[i])) {
                fns[i] = duplexPipelineFn(fns[i]);
            }
        }
    }
    return rawPipe(...fns);
}
const rawPipe = (...fns) => {
    let res;
    while (fns.length > 0) {
        res = fns.shift()(res);
    }
    return res;
};
const isAsyncIterable$8 = (obj) => {
    return obj?.[Symbol.asyncIterator] != null;
};
const isIterable = (obj) => {
    return obj?.[Symbol.iterator] != null;
};
const isDuplex = (obj) => {
    if (obj == null) {
        return false;
    }
    return obj.sink != null && obj.source != null;
};
const duplexPipelineFn = (duplex) => {
    return (source) => {
        const p = duplex.sink(source);
        if (p?.then != null) {
            const stream = pushable({
                objectMode: true
            });
            p.then(() => {
                stream.end();
            }, (err) => {
                stream.end(err);
            });
            let sourceWrap;
            const source = duplex.source;
            if (isAsyncIterable$8(source)) {
                sourceWrap = async function* () {
                    yield* source;
                    stream.end();
                };
            }
            else if (isIterable(source)) {
                sourceWrap = function* () {
                    yield* source;
                    stream.end();
                };
            }
            else {
                throw new Error('Unknown duplex source type - must be Iterable or AsyncIterable');
            }
            return merge$1(stream, sourceWrap());
        }
        return duplex.source;
    };
};

const log$E = debug("waku:libp2p-utils");
/**
 * Returns a pseudo-random peer that supports the given protocol.
 * Useful for protocols such as store and light push
 */
function selectRandomPeer(peers) {
    if (peers.length === 0)
        return;
    const index = Math.round(Math.random() * (peers.length - 1));
    return peers[index];
}
/**
 * Returns the peer with the lowest latency.
 * @param peerStore - The Libp2p PeerStore
 * @param peers - The list of peers to choose from
 * @returns The peer with the lowest latency, or undefined if no peer could be reached
 */
async function selectLowestLatencyPeer(peerStore, peers) {
    if (peers.length === 0)
        return;
    const results = await Promise.all(peers.map(async (peer) => {
        const pingBytes = (await peerStore.get(peer.id)).metadata.get("ping");
        if (!pingBytes)
            return { peer, ping: Infinity };
        const ping = Number(bytesToUtf8(pingBytes)) ?? Infinity;
        return { peer, ping };
    }));
    const lowestLatencyResult = results.sort((a, b) => a.ping - b.ping)[0];
    if (!lowestLatencyResult) {
        return undefined;
    }
    return lowestLatencyResult.ping !== Infinity
        ? lowestLatencyResult.peer
        : undefined;
}
/**
 * Returns the list of peers that supports the given protocol.
 */
async function getPeersForProtocol(peerStore, protocols) {
    const peers = [];
    await peerStore.forEach((peer) => {
        for (let i = 0; i < protocols.length; i++) {
            if (peer.protocols.includes(protocols[i])) {
                peers.push(peer);
                break;
            }
        }
    });
    return peers;
}
/**
 * Returns a peer that supports the given protocol.
 * If peerId is provided, the peer with that id is returned.
 * Otherwise, the peer with the lowest latency is returned.
 * If no peer is found from the above criteria, a random peer is returned.
 */
async function selectPeerForProtocol(peerStore, protocols, peerId) {
    let peer;
    if (peerId) {
        peer = await peerStore.get(peerId);
        if (!peer) {
            throw new Error(`Failed to retrieve connection details for provided peer in peer store: ${peerId.toString()}`);
        }
    }
    else {
        const peers = await getPeersForProtocol(peerStore, protocols);
        peer = await selectLowestLatencyPeer(peerStore, peers);
        if (!peer) {
            peer = selectRandomPeer(peers);
            if (!peer)
                throw new Error(`Failed to find known peer that registers protocols: ${protocols}`);
        }
    }
    let protocol;
    for (const codec of protocols) {
        if (peer.protocols.includes(codec)) {
            protocol = codec;
            // Do not break as we want to keep the last value
        }
    }
    log$E(`Using codec ${protocol}`);
    if (!protocol) {
        throw new Error(`Peer does not register required protocols (${peer.id.toString()}): ${protocols}`);
    }
    return { peer, protocol };
}
function selectConnection(connections) {
    if (!connections.length)
        return;
    if (connections.length === 1)
        return connections[0];
    let latestConnection;
    connections.forEach((connection) => {
        if (connection.status === "open") {
            if (!latestConnection) {
                latestConnection = connection;
            }
            else if (connection.timeline.open > latestConnection.timeline.open) {
                latestConnection = connection;
            }
        }
    });
    return latestConnection;
}

/**
 * Retrieves a list of peers based on the specified criteria.
 *
 * @param peers - The list of peers to filter from.
 * @param numPeers - The total number of peers to retrieve. If 0, all peers are returned.
 * @param maxBootstrapPeers - The maximum number of bootstrap peers to retrieve.
 * @returns A Promise that resolves to an array of peers based on the specified criteria.
 */
async function filterPeers(peers, numPeers, maxBootstrapPeers) {
    // Collect the bootstrap peers up to the specified maximum
    const bootstrapPeers = peers
        .filter((peer) => peer.tags.has(Tags.BOOTSTRAP))
        .slice(0, maxBootstrapPeers);
    // Collect non-bootstrap peers
    const nonBootstrapPeers = peers.filter((peer) => !peer.tags.has(Tags.BOOTSTRAP));
    // If numPeers is 0, return all peers
    if (numPeers === 0) {
        return [...bootstrapPeers, ...nonBootstrapPeers];
    }
    // Initialize the list of selected peers with the bootstrap peers
    const selectedPeers = [...bootstrapPeers];
    // Fill up to numPeers with remaining random peers if needed
    while (selectedPeers.length < numPeers && nonBootstrapPeers.length > 0) {
        const randomIndex = Math.floor(Math.random() * nonBootstrapPeers.length);
        const randomPeer = nonBootstrapPeers.splice(randomIndex, 1)[0];
        selectedPeers.push(randomPeer);
    }
    return selectedPeers;
}

class StreamManager {
    multicodec;
    getConnections;
    addEventListener;
    streamPool;
    log;
    constructor(multicodec, getConnections, addEventListener) {
        this.multicodec = multicodec;
        this.getConnections = getConnections;
        this.addEventListener = addEventListener;
        this.log = debug(`waku:stream-manager:${multicodec}`);
        this.addEventListener("peer:update", this.handlePeerUpdateStreamPool.bind(this));
        this.getStream = this.getStream.bind(this);
        this.streamPool = new Map();
    }
    async getStream(peer) {
        const peerIdStr = peer.id.toString();
        const streamPromise = this.streamPool.get(peerIdStr);
        if (!streamPromise) {
            return this.newStream(peer); // fallback by creating a new stream on the spot
        }
        // We have the stream, let's remove it from the map
        this.streamPool.delete(peerIdStr);
        this.prepareNewStream(peer);
        const stream = await streamPromise;
        if (stream.status === "closed") {
            return this.newStream(peer); // fallback by creating a new stream on the spot
        }
        return stream;
    }
    async newStream(peer) {
        const connections = this.getConnections(peer.id);
        const connection = selectConnection(connections);
        if (!connection) {
            throw new Error("Failed to get a connection to the peer");
        }
        return connection.newStream(this.multicodec);
    }
    prepareNewStream(peer) {
        const streamPromise = this.newStream(peer);
        this.streamPool.set(peer.id.toString(), streamPromise);
    }
    handlePeerUpdateStreamPool = (evt) => {
        const peer = evt.detail.peer;
        if (peer.protocols.includes(this.multicodec)) {
            this.log(`Preemptively opening a stream to ${peer.id.toString()}`);
            this.prepareNewStream(peer);
        }
    };
}

/**
 * A class with predefined helpers, to be used as a base to implement Waku
 * Protocols.
 */
class BaseProtocol {
    multicodec;
    components;
    addLibp2pEventListener;
    removeLibp2pEventListener;
    streamManager;
    constructor(multicodec, components) {
        this.multicodec = multicodec;
        this.components = components;
        this.addLibp2pEventListener = components.events.addEventListener.bind(components.events);
        this.removeLibp2pEventListener = components.events.removeEventListener.bind(components.events);
        this.streamManager = new StreamManager(multicodec, components.connectionManager.getConnections.bind(components.connectionManager), this.addLibp2pEventListener);
    }
    async getStream(peer) {
        return this.streamManager.getStream(peer);
    }
    get peerStore() {
        return this.components.peerStore;
    }
    /**
     * Returns known peers from the address book (`libp2p.peerStore`) that support
     * the class protocol. Waku may or may not be currently connected to these
     * peers.
     */
    async peers() {
        return getPeersForProtocol(this.peerStore, [this.multicodec]);
    }
    async getPeer(peerId) {
        const { peer } = await selectPeerForProtocol(this.peerStore, [this.multicodec], peerId);
        return peer;
    }
    /**
     * Retrieves a list of peers based on the specified criteria.
     *
     * @param numPeers - The total number of peers to retrieve. If 0, all peers are returned.
     * @param maxBootstrapPeers - The maximum number of bootstrap peers to retrieve.
     * @returns A Promise that resolves to an array of peers based on the specified criteria.
     */
    async getPeers({ numPeers, maxBootstrapPeers } = {
        maxBootstrapPeers: 1,
        numPeers: 0
    }) {
        // Retrieve all peers that support the protocol
        const allPeersForProtocol = await getPeersForProtocol(this.peerStore, [
            this.multicodec
        ]);
        // Filter the peers based on the specified criteria
        return filterPeers(allPeersForProtocol, numPeers, maxBootstrapPeers);
    }
}

// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
let getRandomValues;
const rnds8 = new Uint8Array(16);
function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);

    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }

  return getRandomValues(rnds8);
}

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */

const byteToHex = [];

for (let i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).slice(1));
}

function unsafeStringify(arr, offset = 0) {
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  return (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase();
}

const randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);
var native = {
  randomUUID
};

function v4$2(options, buf, offset) {
  if (native.randomUUID && !buf && !options) {
    return native.randomUUID();
  }

  options = options || {};
  const rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`

  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  if (buf) {
    offset = offset || 0;

    for (let i = 0; i < 16; ++i) {
      buf[offset + i] = rnds[i];
    }

    return buf;
  }

  return unsafeStringify(rnds);
}

/**
 * FilterPushRPC represents a message conforming to the Waku FilterPush protocol.
 * Protocol documentation: https://rfc.vac.dev/spec/12/
 */
class FilterPushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = MessagePush.decode(bytes);
        return new FilterPushRpc(res);
    }
    encode() {
        return MessagePush.encode(this.proto);
    }
    get wakuMessage() {
        return this.proto.wakuMessage;
    }
    /**
     * Get the pubsub topic from the FilterPushRpc object.
     * @returns string
     */
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
}
class FilterSubscribeRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createSubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4$2(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeRequest(pubsubTopic, contentTopics) {
        return new FilterSubscribeRpc({
            requestId: v4$2(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE,
            pubsubTopic,
            contentTopics
        });
    }
    static createUnsubscribeAllRequest(pubsubTopic) {
        return new FilterSubscribeRpc({
            requestId: v4$2(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.UNSUBSCRIBE_ALL,
            pubsubTopic,
            contentTopics: []
        });
    }
    static createSubscriberPingRequest() {
        return new FilterSubscribeRpc({
            requestId: v4$2(),
            filterSubscribeType: FilterSubscribeRequest.FilterSubscribeType.SUBSCRIBER_PING,
            pubsubTopic: "",
            contentTopics: []
        });
    }
    static decode(bytes) {
        const res = FilterSubscribeRequest.decode(bytes);
        return new FilterSubscribeRpc(res);
    }
    encode() {
        return FilterSubscribeRequest.encode(this.proto);
    }
    get filterSubscribeType() {
        return this.proto.filterSubscribeType;
    }
    get requestId() {
        return this.proto.requestId;
    }
    get pubsubTopic() {
        return this.proto.pubsubTopic;
    }
    get contentTopics() {
        return this.proto.contentTopics;
    }
}
class FilterSubscribeResponse {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static decode(bytes) {
        const res = FilterSubscribeResponse$1.decode(bytes);
        return new FilterSubscribeResponse(res);
    }
    encode() {
        return FilterSubscribeResponse$1.encode(this.proto);
    }
    get statusCode() {
        return this.proto.statusCode;
    }
    get statusDesc() {
        return this.proto.statusDesc;
    }
    get requestId() {
        return this.proto.requestId;
    }
}

const log$D = debug("waku:filter:v2");
const FilterCodecs = {
    SUBSCRIBE: "/vac/waku/filter-subscribe/2.0.0-beta1",
    PUSH: "/vac/waku/filter-push/2.0.0-beta1"
};
class Subscription {
    peer;
    pubSubTopic;
    newStream;
    subscriptionCallbacks;
    constructor(pubSubTopic, remotePeer, newStream) {
        this.peer = remotePeer;
        this.pubSubTopic = pubSubTopic;
        this.newStream = newStream;
        this.subscriptionCallbacks = new Map();
    }
    async subscribe(decoders, callback) {
        const decodersArray = Array.isArray(decoders) ? decoders : [decoders];
        const decodersGroupedByCT = groupByContentTopic(decodersArray);
        const contentTopics = Array.from(decodersGroupedByCT.keys());
        const stream = await this.newStream(this.peer);
        const request = FilterSubscribeRpc.createSubscribeRequest(this.pubSubTopic, contentTopics);
        try {
            const res = await pipe([request.encode()], encode$B, stream, decode$v, async (source) => await all$1(source));
            const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
            if (statusCode < 200 || statusCode >= 300) {
                throw new Error(`Filter subscribe request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            }
            log$D("Subscribed to peer ", this.peer.id.toString(), "for content topics", contentTopics);
        }
        catch (e) {
            throw new Error("Error subscribing to peer: " +
                this.peer.id.toString() +
                " for content topics: " +
                contentTopics +
                ": " +
                e);
        }
        // Save the callback functions by content topics so they
        // can easily be removed (reciprocally replaced) if `unsubscribe` (reciprocally `subscribe`)
        // is called for those content topics
        decodersGroupedByCT.forEach((decoders, contentTopic) => {
            // Cast the type because a given `subscriptionCallbacks` map may hold
            // Decoder that decode to different implementations of `IDecodedMessage`
            const subscriptionCallback = {
                decoders,
                callback
            };
            // The callback and decoder may override previous values, this is on
            // purpose as the user may call `subscribe` to refresh the subscription
            this.subscriptionCallbacks.set(contentTopic, subscriptionCallback);
        });
    }
    async unsubscribe(contentTopics) {
        const stream = await this.newStream(this.peer);
        const unsubscribeRequest = FilterSubscribeRpc.createUnsubscribeRequest(this.pubSubTopic, contentTopics);
        try {
            await pipe([unsubscribeRequest.encode()], encode$B, stream.sink);
        }
        catch (error) {
            throw new Error("Error subscribing: " + error);
        }
        contentTopics.forEach((contentTopic) => {
            this.subscriptionCallbacks.delete(contentTopic);
        });
    }
    async ping() {
        const stream = await this.newStream(this.peer);
        const request = FilterSubscribeRpc.createSubscriberPingRequest();
        try {
            const res = await pipe([request.encode()], encode$B, stream, decode$v, async (source) => await all$1(source));
            const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
            if (statusCode < 200 || statusCode >= 300) {
                throw new Error(`Filter ping request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            }
            log$D("Ping successful");
        }
        catch (error) {
            log$D("Error pinging: ", error);
            throw new Error("Error pinging: " + error);
        }
    }
    async unsubscribeAll() {
        const stream = await this.newStream(this.peer);
        const request = FilterSubscribeRpc.createUnsubscribeAllRequest(this.pubSubTopic);
        try {
            const res = await pipe([request.encode()], encode$B, stream, decode$v, async (source) => await all$1(source));
            const { statusCode, requestId, statusDesc } = FilterSubscribeResponse.decode(res[0].slice());
            if (statusCode < 200 || statusCode >= 300) {
                throw new Error(`Filter unsubscribe all request ${requestId} failed with status code ${statusCode}: ${statusDesc}`);
            }
            this.subscriptionCallbacks.clear();
            log$D("Unsubscribed from all content topics");
        }
        catch (error) {
            throw new Error("Error unsubscribing from all content topics: " + error);
        }
    }
    async processMessage(message) {
        const contentTopic = message.contentTopic;
        const subscriptionCallback = this.subscriptionCallbacks.get(contentTopic);
        if (!subscriptionCallback) {
            log$D("No subscription callback available for ", contentTopic);
            return;
        }
        await pushMessage(subscriptionCallback, this.pubSubTopic, message);
    }
}
class Filter extends BaseProtocol {
    options;
    activeSubscriptions = new Map();
    NUM_PEERS_PROTOCOL = 1;
    getActiveSubscription(pubSubTopic, peerIdStr) {
        return this.activeSubscriptions.get(`${pubSubTopic}_${peerIdStr}`);
    }
    setActiveSubscription(pubSubTopic, peerIdStr, subscription) {
        this.activeSubscriptions.set(`${pubSubTopic}_${peerIdStr}`, subscription);
        return subscription;
    }
    constructor(libp2p, options) {
        super(FilterCodecs.SUBSCRIBE, libp2p.components);
        libp2p.handle(FilterCodecs.PUSH, this.onRequest.bind(this)).catch((e) => {
            log$D("Failed to register ", FilterCodecs.PUSH, e);
        });
        this.activeSubscriptions = new Map();
        this.options = options ?? {};
    }
    async createSubscription(pubSubTopic) {
        const _pubSubTopic = pubSubTopic ?? this.options.pubSubTopic ?? DefaultPubSubTopic;
        const peer = (await this.getPeers({
            maxBootstrapPeers: 1,
            numPeers: this.NUM_PEERS_PROTOCOL
        }))[0];
        const subscription = this.getActiveSubscription(_pubSubTopic, peer.id.toString()) ??
            this.setActiveSubscription(_pubSubTopic, peer.id.toString(), new Subscription(_pubSubTopic, peer, this.getStream.bind(this, peer)));
        return subscription;
    }
    toSubscriptionIterator(decoders) {
        return toAsyncIterator(this, decoders);
    }
    /**
     * This method is used to satisfy the `IReceiver` interface.
     *
     * @hidden
     *
     * @param decoders The decoders to use for the subscription.
     * @param callback The callback function to use for the subscription.
     * @param opts Optional protocol options for the subscription.
     *
     * @returns A Promise that resolves to a function that unsubscribes from the subscription.
     *
     * @remarks
     * This method should not be used directly.
     * Instead, use `createSubscription` to create a new subscription.
     */
    async subscribe(decoders, callback) {
        const subscription = await this.createSubscription();
        await subscription.subscribe(decoders, callback);
        const contentTopics = Array.from(groupByContentTopic(Array.isArray(decoders) ? decoders : [decoders]).keys());
        return async () => {
            await subscription.unsubscribe(contentTopics);
        };
    }
    onRequest(streamData) {
        log$D("Receiving message push");
        try {
            pipe(streamData.stream, decode$v, async (source) => {
                for await (const bytes of source) {
                    const response = FilterPushRpc.decode(bytes.slice());
                    const { pubsubTopic, wakuMessage } = response;
                    if (!wakuMessage) {
                        log$D("Received empty message");
                        return;
                    }
                    if (!pubsubTopic) {
                        log$D("PubSub topic missing from push message");
                        return;
                    }
                    const peerIdStr = streamData.connection.remotePeer.toString();
                    const subscription = this.getActiveSubscription(pubsubTopic, peerIdStr);
                    if (!subscription) {
                        log$D(`No subscription locally registered for topic ${pubsubTopic}`);
                        return;
                    }
                    await subscription.processMessage(wakuMessage);
                }
            }).then(() => {
                log$D("Receiving pipe closed.");
            }, (e) => {
                log$D("Error with receiving pipe", e);
            });
        }
        catch (e) {
            log$D("Error decoding message", e);
        }
    }
}
function wakuFilter(init = {}) {
    return (libp2p) => new Filter(libp2p, init);
}
async function pushMessage(subscriptionCallback, pubSubTopic, message) {
    const { decoders, callback } = subscriptionCallback;
    const { contentTopic } = message;
    if (!contentTopic) {
        log$D("Message has no content topic, skipping");
        return;
    }
    try {
        const decodePromises = decoders.map((dec) => dec
            .fromProtoObj(pubSubTopic, message)
            .then((decoded) => decoded || Promise.reject("Decoding failed")));
        const decodedMessage = await Promise.any(decodePromises);
        await callback(decodedMessage);
    }
    catch (e) {
        log$D("Error decoding message", e);
    }
}

var index$4 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    FilterCodecs: FilterCodecs,
    wakuFilter: wakuFilter
});

class PushRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(message, pubSubTopic) {
        return new PushRpc({
            requestId: v4$2(),
            request: {
                message: message,
                pubsubTopic: pubSubTopic
            },
            response: undefined
        });
    }
    static decode(bytes) {
        const res = PushRpc$1.decode(bytes);
        return new PushRpc(res);
    }
    encode() {
        return PushRpc$1.encode(this.proto);
    }
    get query() {
        return this.proto.request;
    }
    get response() {
        return this.proto.response;
    }
}

const log$C = debug("waku:light-push");
const LightPushCodec = "/vac/waku/lightpush/2.0.0-beta1";
/**
 * Implements the [Waku v2 Light Push protocol](https://rfc.vac.dev/spec/19/).
 */
class LightPush extends BaseProtocol {
    options;
    NUM_PEERS_PROTOCOL = 1;
    constructor(libp2p, options) {
        super(LightPushCodec, libp2p.components);
        this.options = options || {};
    }
    async preparePushMessage(encoder, message, pubSubTopic) {
        try {
            if (!isSizeValid(message.payload)) {
                log$C("Failed to send waku light push: message is bigger than 1MB");
                return { query: null, error: SendError.SIZE_TOO_BIG };
            }
            const protoMessage = await encoder.toProtoObj(message);
            if (!protoMessage) {
                log$C("Failed to encode to protoMessage, aborting push");
                return {
                    query: null,
                    error: SendError.ENCODE_FAILED
                };
            }
            const query = PushRpc.createRequest(protoMessage, pubSubTopic);
            return { query, error: null };
        }
        catch (error) {
            log$C("Failed to prepare push message", error);
            return {
                query: null,
                error: SendError.GENERIC_FAIL
            };
        }
    }
    async send(encoder, message) {
        const { pubSubTopic = DefaultPubSubTopic } = this.options;
        const recipients = [];
        const { query, error: preparationError } = await this.preparePushMessage(encoder, message, pubSubTopic);
        if (preparationError || !query) {
            return {
                recipients,
                errors: [preparationError]
            };
        }
        const peers = await this.getPeers({
            maxBootstrapPeers: 1,
            numPeers: this.NUM_PEERS_PROTOCOL
        });
        const promises = peers.map(async (peer) => {
            let error;
            const stream = await this.getStream(peer);
            try {
                const res = await pipe([query.encode()], encode$B, stream, decode$v, async (source) => await all$1(source));
                try {
                    const bytes = new Uint8ArrayList();
                    res.forEach((chunk) => {
                        bytes.append(chunk);
                    });
                    const response = PushRpc.decode(bytes).response;
                    if (response?.isSuccess) {
                        recipients.some((recipient) => recipient.equals(peer.id)) ||
                            recipients.push(peer.id);
                    }
                    else {
                        log$C("No response in PushRPC");
                        error = SendError.NO_RPC_RESPONSE;
                    }
                }
                catch (err) {
                    log$C("Failed to decode push reply", err);
                    error = SendError.DECODE_FAILED;
                }
            }
            catch (err) {
                log$C("Failed to send waku light push request", err);
                error = SendError.GENERIC_FAIL;
            }
            return { recipients, error };
        });
        const results = await Promise.allSettled(promises);
        const errors = results
            .filter((result) => result.status === "fulfilled")
            .map((result) => result.value.error)
            .filter((error) => error !== undefined);
        return {
            recipients,
            errors
        };
    }
}
function wakuLightPush(init = {}) {
    return (libp2p) => new LightPush(libp2p, init);
}

var index$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    LightPushCodec: LightPushCodec,
    get PushResponse () { return PushResponse; },
    wakuLightPush: wakuLightPush
});

function number$2(n) {
    if (!Number.isSafeInteger(n) || n < 0)
        throw new Error(`Wrong positive integer: ${n}`);
}
function bytes$2(b, ...lengths) {
    if (!(b instanceof Uint8Array))
        throw new Error('Expected Uint8Array');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new Error(`Expected Uint8Array of length ${lengths}, not of length=${b.length}`);
}
function hash$3(hash) {
    if (typeof hash !== 'function' || typeof hash.create !== 'function')
        throw new Error('Hash should be wrapped by utils.wrapConstructor');
    number$2(hash.outputLen);
    number$2(hash.blockLen);
}
function exists$2(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
function output$2(out, instance) {
    bytes$2(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error(`digestInto() expects output buffer of length at least ${min}`);
    }
}

const crypto$7 = typeof globalThis === 'object' && 'crypto' in globalThis ? globalThis.crypto : undefined;

/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.
// node.js versions earlier than v19 don't declare it in global scope.
// For node.js, package.json#exports field mapping rewrites import
// from `crypto` to `cryptoNode`, which imports native module.
// Makes the utils un-importable in browsers without a bundler.
// Once node.js 18 is deprecated, we can just drop the import.
const u8a$3 = (a) => a instanceof Uint8Array;
// Cast array to view
const createView$2 = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
// The rotate right (circular right shift) operation for uint32
const rotr$1 = (word, shift) => (word << (32 - shift)) | (word >>> shift);
// big-endian hardware is rare. Just in case someone still decides to run hashes:
// early-throw an error because we don't support BE yet.
const isLE$2 = new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;
if (!isLE$2)
    throw new Error('Non little-endian hardware is not supported');
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes$3(str) {
    if (typeof str !== 'string')
        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes$3(data) {
    if (typeof data === 'string')
        data = utf8ToBytes$3(data);
    if (!u8a$3(data))
        throw new Error(`expected Uint8Array, got ${typeof data}`);
    return data;
}
// For runtime check if class implements interface
let Hash$1 = class Hash {
    // Safe version that clones internal state
    clone() {
        return this._cloneInto();
    }
};
function wrapConstructor$1(hashCons) {
    const hashC = (msg) => hashCons().update(toBytes$3(msg)).digest();
    const tmp = hashCons();
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = () => hashCons();
    return hashC;
}
/**
 * Secure PRNG. Uses `crypto.getRandomValues`, which defers to OS.
 */
function randomBytes$8(bytesLength = 32) {
    if (crypto$7 && typeof crypto$7.getRandomValues === 'function') {
        return crypto$7.getRandomValues(new Uint8Array(bytesLength));
    }
    throw new Error('crypto.getRandomValues must be defined');
}

// Polyfill for Safari 14
function setBigUint64$2(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = isLE ? 4 : 0;
    const l = isLE ? 0 : 4;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}
// Base SHA2 class (RFC 6234)
let SHA2$1 = class SHA2 extends Hash$1 {
    constructor(blockLen, outputLen, padOffset, isLE) {
        super();
        this.blockLen = blockLen;
        this.outputLen = outputLen;
        this.padOffset = padOffset;
        this.isLE = isLE;
        this.finished = false;
        this.length = 0;
        this.pos = 0;
        this.destroyed = false;
        this.buffer = new Uint8Array(blockLen);
        this.view = createView$2(this.buffer);
    }
    update(data) {
        exists$2(this);
        const { view, buffer, blockLen } = this;
        data = toBytes$3(data);
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input, cast it to view and process
            if (take === blockLen) {
                const dataView = createView$2(data);
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(dataView, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(view, 0);
                this.pos = 0;
            }
        }
        this.length += data.length;
        this.roundClean();
        return this;
    }
    digestInto(out) {
        exists$2(this);
        output$2(out, this);
        this.finished = true;
        // Padding
        // We can avoid allocation of buffer for padding completely if it
        // was previously not allocated here. But it won't change performance.
        const { buffer, view, blockLen, isLE } = this;
        let { pos } = this;
        // append the bit '1' to the message
        buffer[pos++] = 0b10000000;
        this.buffer.subarray(pos).fill(0);
        // we have less than padOffset left in buffer, so we cannot put length in current block, need process it and pad again
        if (this.padOffset > blockLen - pos) {
            this.process(view, 0);
            pos = 0;
        }
        // Pad until full block byte with zeros
        for (let i = pos; i < blockLen; i++)
            buffer[i] = 0;
        // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that
        // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.
        // So we just write lowest 64 bits of that value.
        setBigUint64$2(view, blockLen - 8, BigInt(this.length * 8), isLE);
        this.process(view, 0);
        const oview = createView$2(out);
        const len = this.outputLen;
        // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT
        if (len % 4)
            throw new Error('_sha2: outputLen should be aligned to 32bit');
        const outLen = len / 4;
        const state = this.get();
        if (outLen > state.length)
            throw new Error('_sha2: outputLen bigger than state');
        for (let i = 0; i < outLen; i++)
            oview.setUint32(4 * i, state[i], isLE);
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
    _cloneInto(to) {
        to || (to = new this.constructor());
        to.set(...this.get());
        const { blockLen, buffer, length, finished, destroyed, pos } = this;
        to.length = length;
        to.pos = pos;
        to.finished = finished;
        to.destroyed = destroyed;
        if (length % blockLen)
            to.buffer.set(buffer);
        return to;
    }
};

// SHA2-256 need to try 2^128 hashes to execute birthday attack.
// BTC network is doing 2^67 hashes/sec as per early 2023.
// Choice: a ? b : c
const Chi$1 = (a, b, c) => (a & b) ^ (~a & c);
// Majority function, true if any two inpust is true
const Maj$1 = (a, b, c) => (a & b) ^ (a & c) ^ (b & c);
// Round constants:
// first 32 bits of the fractional parts of the cube roots of the first 64 primes 2..311)
// prettier-ignore
const SHA256_K$1 = /* @__PURE__ */ new Uint32Array([
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
]);
// Initial state (first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19):
// prettier-ignore
const IV$1 = /* @__PURE__ */ new Uint32Array([
    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
]);
// Temporary buffer, not used to store anything between runs
// Named this way because it matches specification.
const SHA256_W$1 = /* @__PURE__ */ new Uint32Array(64);
let SHA256$1 = class SHA256 extends SHA2$1 {
    constructor() {
        super(64, 32, 8, false);
        // We cannot use array here since array allows indexing by variable
        // which means optimizer/compiler cannot use registers.
        this.A = IV$1[0] | 0;
        this.B = IV$1[1] | 0;
        this.C = IV$1[2] | 0;
        this.D = IV$1[3] | 0;
        this.E = IV$1[4] | 0;
        this.F = IV$1[5] | 0;
        this.G = IV$1[6] | 0;
        this.H = IV$1[7] | 0;
    }
    get() {
        const { A, B, C, D, E, F, G, H } = this;
        return [A, B, C, D, E, F, G, H];
    }
    // prettier-ignore
    set(A, B, C, D, E, F, G, H) {
        this.A = A | 0;
        this.B = B | 0;
        this.C = C | 0;
        this.D = D | 0;
        this.E = E | 0;
        this.F = F | 0;
        this.G = G | 0;
        this.H = H | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4)
            SHA256_W$1[i] = view.getUint32(offset, false);
        for (let i = 16; i < 64; i++) {
            const W15 = SHA256_W$1[i - 15];
            const W2 = SHA256_W$1[i - 2];
            const s0 = rotr$1(W15, 7) ^ rotr$1(W15, 18) ^ (W15 >>> 3);
            const s1 = rotr$1(W2, 17) ^ rotr$1(W2, 19) ^ (W2 >>> 10);
            SHA256_W$1[i] = (s1 + SHA256_W$1[i - 7] + s0 + SHA256_W$1[i - 16]) | 0;
        }
        // Compression function main loop, 64 rounds
        let { A, B, C, D, E, F, G, H } = this;
        for (let i = 0; i < 64; i++) {
            const sigma1 = rotr$1(E, 6) ^ rotr$1(E, 11) ^ rotr$1(E, 25);
            const T1 = (H + sigma1 + Chi$1(E, F, G) + SHA256_K$1[i] + SHA256_W$1[i]) | 0;
            const sigma0 = rotr$1(A, 2) ^ rotr$1(A, 13) ^ rotr$1(A, 22);
            const T2 = (sigma0 + Maj$1(A, B, C)) | 0;
            H = G;
            G = F;
            F = E;
            E = (D + T1) | 0;
            D = C;
            C = B;
            B = A;
            A = (T1 + T2) | 0;
        }
        // Add the compressed chunk to the current hash value
        A = (A + this.A) | 0;
        B = (B + this.B) | 0;
        C = (C + this.C) | 0;
        D = (D + this.D) | 0;
        E = (E + this.E) | 0;
        F = (F + this.F) | 0;
        G = (G + this.G) | 0;
        H = (H + this.H) | 0;
        this.set(A, B, C, D, E, F, G, H);
    }
    roundClean() {
        SHA256_W$1.fill(0);
    }
    destroy() {
        this.set(0, 0, 0, 0, 0, 0, 0, 0);
        this.buffer.fill(0);
    }
};
/**
 * SHA2-256 hash function
 * @param message - data that would be hashed
 */
const sha256$a = /* @__PURE__ */ wrapConstructor$1(() => new SHA256$1());

const EmptyMessage = {
    payload: new Uint8Array(),
    contentTopic: "",
    version: undefined,
    timestamp: undefined,
    meta: undefined,
    rateLimitProof: undefined,
    ephemeral: undefined
};
function toProtoMessage(wire) {
    return { ...EmptyMessage, ...wire };
}

const OneMillion = BigInt(1000000);
var PageDirection;
(function (PageDirection) {
    PageDirection["BACKWARD"] = "backward";
    PageDirection["FORWARD"] = "forward";
})(PageDirection || (PageDirection = {}));
class HistoryRpc {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    get query() {
        return this.proto.query;
    }
    get response() {
        return this.proto.response;
    }
    /**
     * Create History Query.
     */
    static createQuery(params) {
        const contentFilters = params.contentTopics.map((contentTopic) => {
            return { contentTopic };
        });
        const direction = directionToProto(params.pageDirection);
        const pagingInfo = {
            pageSize: BigInt(params.pageSize),
            cursor: params.cursor,
            direction
        };
        let startTime, endTime;
        if (params.startTime) {
            // milliseconds 10^-3 to nanoseconds 10^-9
            startTime = BigInt(params.startTime.valueOf()) * OneMillion;
        }
        if (params.endTime) {
            // milliseconds 10^-3 to nanoseconds 10^-9
            endTime = BigInt(params.endTime.valueOf()) * OneMillion;
        }
        return new HistoryRpc({
            requestId: v4$2(),
            query: {
                pubsubTopic: params.pubSubTopic,
                contentFilters,
                pagingInfo,
                startTime,
                endTime
            },
            response: undefined
        });
    }
    decode(bytes) {
        const res = HistoryRpc$1.decode(bytes);
        return new HistoryRpc(res);
    }
    encode() {
        return HistoryRpc$1.encode(this.proto);
    }
}
function directionToProto(pageDirection) {
    switch (pageDirection) {
        case PageDirection.BACKWARD:
            return PagingInfo.Direction.BACKWARD;
        case PageDirection.FORWARD:
            return PagingInfo.Direction.FORWARD;
        default:
            return PagingInfo.Direction.BACKWARD;
    }
}

var HistoryError = HistoryResponse.HistoryError;
const log$B = debug("waku:store");
const StoreCodec = "/vac/waku/store/2.0.0-beta4";
const DefaultPageSize = 10;
/**
 * Implements the [Waku v2 Store protocol](https://rfc.vac.dev/spec/13/).
 *
 * The Waku Store protocol can be used to retrieved historical messages.
 */
class Store extends BaseProtocol {
    options;
    NUM_PEERS_PROTOCOL = 1;
    constructor(libp2p, options) {
        super(StoreCodec, libp2p.components);
        this.options = options ?? {};
    }
    /**
     * Processes messages based on the provided callback and options.
     * @private
     */
    async processMessages(messages, callback, options) {
        let abort = false;
        const messagesOrUndef = await Promise.all(messages);
        let processedMessages = messagesOrUndef.filter(isDefined);
        if (this.shouldReverseOrder(options)) {
            processedMessages = processedMessages.reverse();
        }
        await Promise.all(processedMessages.map(async (msg) => {
            if (msg && !abort) {
                abort = Boolean(await callback(msg));
            }
        }));
        return abort;
    }
    /**
     * Determines whether to reverse the order of messages based on the provided options.
     *
     * Messages in pages are ordered from oldest (first) to most recent (last).
     * https://github.com/vacp2p/rfc/issues/533
     *
     * @private
     */
    shouldReverseOrder(options) {
        return (typeof options?.pageDirection === "undefined" ||
            options?.pageDirection === PageDirection.BACKWARD);
    }
    /**
     * @deprecated Use `queryWithOrderedCallback` instead
     **/
    queryOrderedCallback = this.queryWithOrderedCallback;
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     *
     * The callback function takes a `WakuMessage` in input,
     * messages are processed in order:
     * - oldest to latest if `options.pageDirection` == { @link PageDirection.FORWARD }
     * - latest to oldest if `options.pageDirection` == { @link PageDirection.BACKWARD }
     *
     * The ordering may affect performance.
     * The ordering depends on the behavior of the remote store node.
     * If strong ordering is needed, you may need to handle this at application level
     * and set your own timestamps too (the WakuMessage timestamps are not certified).
     *
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     */
    async queryWithOrderedCallback(decoders, callback, options) {
        for await (const promises of this.queryGenerator(decoders, options)) {
            if (await this.processMessages(promises, callback, options))
                break;
        }
    }
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     * The callback function takes a `Promise<WakuMessage>` in input,
     * useful if messages need to be decrypted and performance matters.
     *
     * The order of the messages passed to the callback is as follows:
     * - within a page, messages are expected to be ordered from oldest to most recent
     * - pages direction depends on { @link QueryOptions.pageDirection }
     *
     * Do note that the resolution of the `Promise<WakuMessage | undefined` may
     * break the order as it may rely on the browser decryption API, which in turn,
     * may have a different speed depending on the type of decryption.
     *
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     */
    async queryWithPromiseCallback(decoders, callback, options) {
        let abort = false;
        for await (const page of this.queryGenerator(decoders, options)) {
            const _promises = page.map(async (msgPromise) => {
                if (abort)
                    return;
                abort = Boolean(await callback(msgPromise));
            });
            await Promise.all(_promises);
            if (abort)
                break;
        }
    }
    /**
     * Do a query to a Waku Store to retrieve historical/missed messages.
     *
     * This is a generator, useful if you want most control on how messages
     * are processed.
     *
     * The order of the messages returned by the remote Waku node SHOULD BE
     * as follows:
     * - within a page, messages SHOULD be ordered from oldest to most recent
     * - pages direction depends on { @link QueryOptions.pageDirection }
     * @throws If not able to reach a Waku Store peer to query,
     * or if an error is encountered when processing the reply,
     * or if two decoders with the same content topic are passed.
     */
    async *queryGenerator(decoders, options) {
        const { pubSubTopic = DefaultPubSubTopic } = this.options;
        let startTime, endTime;
        if (options?.timeFilter) {
            startTime = options.timeFilter.startTime;
            endTime = options.timeFilter.endTime;
        }
        const decodersAsMap = new Map();
        decoders.forEach((dec) => {
            if (decodersAsMap.has(dec.contentTopic)) {
                throw new Error("API does not support different decoder per content topic");
            }
            decodersAsMap.set(dec.contentTopic, dec);
        });
        const contentTopics = decoders.map((dec) => dec.contentTopic);
        const queryOpts = Object.assign({
            pubSubTopic: pubSubTopic,
            pageDirection: PageDirection.BACKWARD,
            pageSize: DefaultPageSize
        }, options, { contentTopics, startTime, endTime });
        log$B("Querying history with the following options", options);
        const peer = (await this.getPeers({
            numPeers: this.NUM_PEERS_PROTOCOL,
            maxBootstrapPeers: 1
        }))[0];
        for await (const messages of paginate(this.getStream.bind(this, peer), queryOpts, decodersAsMap, options?.cursor)) {
            yield messages;
        }
    }
}
async function* paginate(streamFactory, queryOpts, decoders, cursor) {
    if (queryOpts.contentTopics.toString() !==
        Array.from(decoders.keys()).toString()) {
        throw new Error("Internal error, the decoders should match the query's content topics");
    }
    let currentCursor = cursor;
    while (true) {
        queryOpts.cursor = currentCursor;
        const historyRpcQuery = HistoryRpc.createQuery(queryOpts);
        log$B("Querying store peer", `for (${queryOpts.pubSubTopic})`, queryOpts.contentTopics);
        const stream = await streamFactory();
        const res = await pipe([historyRpcQuery.encode()], encode$B, stream, decode$v, async (source) => await all$1(source));
        const bytes = new Uint8ArrayList();
        res.forEach((chunk) => {
            bytes.append(chunk);
        });
        const reply = historyRpcQuery.decode(bytes);
        if (!reply.response) {
            log$B("Stopping pagination due to store `response` field missing");
            break;
        }
        const response = reply.response;
        if (response.error && response.error !== HistoryError.NONE) {
            throw "History response contains an Error: " + response.error;
        }
        if (!response.messages || !response.messages.length) {
            log$B("Stopping pagination due to store `response.messages` field missing or empty");
            break;
        }
        log$B(`${response.messages.length} messages retrieved from store`);
        yield response.messages.map((protoMsg) => {
            const contentTopic = protoMsg.contentTopic;
            if (typeof contentTopic !== "undefined") {
                const decoder = decoders.get(contentTopic);
                if (decoder) {
                    return decoder.fromProtoObj(queryOpts.pubSubTopic, toProtoMessage(protoMsg));
                }
            }
            return Promise.resolve(undefined);
        });
        const nextCursor = response.pagingInfo?.cursor;
        if (typeof nextCursor === "undefined") {
            // If the server does not return cursor then there is an issue,
            // Need to abort, or we end up in an infinite loop
            log$B("Stopping pagination due to `response.pagingInfo.cursor` missing from store response");
            break;
        }
        currentCursor = nextCursor;
        const responsePageSize = response.pagingInfo?.pageSize;
        const queryPageSize = historyRpcQuery.query?.pagingInfo?.pageSize;
        if (
        // Response page size smaller than query, meaning this is the last page
        responsePageSize &&
            queryPageSize &&
            responsePageSize < queryPageSize) {
            break;
        }
    }
}
async function createCursor(message, pubsubTopic = DefaultPubSubTopic) {
    if (!message ||
        !message.timestamp ||
        !message.payload ||
        !message.contentTopic) {
        throw new Error("Message is missing required fields");
    }
    const contentTopicBytes = utf8ToBytes$4(message.contentTopic);
    const digest = sha256$a(concat([contentTopicBytes, message.payload]));
    const messageTime = BigInt(message.timestamp.getTime()) * BigInt(1000000);
    return {
        digest,
        pubsubTopic,
        senderTime: messageTime,
        receiverTime: messageTime
    };
}
function wakuStore(init = {}) {
    return (libp2p) => new Store(libp2p, init);
}

var index$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    DefaultPageSize: DefaultPageSize,
    get PageDirection () { return PageDirection; },
    StoreCodec: StoreCodec,
    createCursor: createCursor,
    wakuStore: wakuStore
});

let TimeoutError$3 = class TimeoutError extends Error {
	constructor(message) {
		super(message);
		this.name = 'TimeoutError';
	}
};

/**
An error to be thrown when the request is aborted by AbortController.
DOMException is thrown instead of this Error when DOMException is available.
*/
let AbortError$6 = class AbortError extends Error {
	constructor(message) {
		super();
		this.name = 'AbortError';
		this.message = message;
	}
};

/**
TODO: Remove AbortError and just throw DOMException when targeting Node 18.
*/
const getDOMException$2 = errorMessage => globalThis.DOMException === undefined ?
	new AbortError$6(errorMessage) :
	new DOMException(errorMessage);

/**
TODO: Remove below function and just 'reject(signal.reason)' when targeting Node 18.
*/
const getAbortedReason$2 = signal => {
	const reason = signal.reason === undefined ?
		getDOMException$2('This operation was aborted.') :
		signal.reason;

	return reason instanceof Error ? reason : getDOMException$2(reason);
};

function pTimeout$2(promise, milliseconds, fallback, options) {
	let timer;

	const cancelablePromise = new Promise((resolve, reject) => {
		if (typeof milliseconds !== 'number' || Math.sign(milliseconds) !== 1) {
			throw new TypeError(`Expected \`milliseconds\` to be a positive number, got \`${milliseconds}\``);
		}

		if (milliseconds === Number.POSITIVE_INFINITY) {
			resolve(promise);
			return;
		}

		options = {
			customTimers: {setTimeout, clearTimeout},
			...options
		};

		if (options.signal) {
			const {signal} = options;
			if (signal.aborted) {
				reject(getAbortedReason$2(signal));
			}

			signal.addEventListener('abort', () => {
				reject(getAbortedReason$2(signal));
			});
		}

		timer = options.customTimers.setTimeout.call(undefined, () => {
			if (typeof fallback === 'function') {
				try {
					resolve(fallback());
				} catch (error) {
					reject(error);
				}

				return;
			}

			const message = typeof fallback === 'string' ? fallback : `Promise timed out after ${milliseconds} milliseconds`;
			const timeoutError = fallback instanceof Error ? fallback : new TimeoutError$3(message);

			if (typeof promise.cancel === 'function') {
				promise.cancel();
			}

			reject(timeoutError);
		}, milliseconds);

		(async () => {
			try {
				resolve(await promise);
			} catch (error) {
				reject(error);
			} finally {
				options.customTimers.clearTimeout.call(undefined, timer);
			}
		})();
	});

	cancelablePromise.clear = () => {
		clearTimeout(timer);
		timer = undefined;
	};

	return cancelablePromise;
}

const normalizeEmitter = emitter => {
	const addListener = emitter.on || emitter.addListener || emitter.addEventListener;
	const removeListener = emitter.off || emitter.removeListener || emitter.removeEventListener;

	if (!addListener || !removeListener) {
		throw new TypeError('Emitter is not compatible');
	}

	return {
		addListener: addListener.bind(emitter),
		removeListener: removeListener.bind(emitter),
	};
};

function pEventMultiple(emitter, event, options) {
	let cancel;
	const returnValue = new Promise((resolve, reject) => {
		options = {
			rejectionEvents: ['error'],
			multiArgs: false,
			resolveImmediately: false,
			...options,
		};

		if (!(options.count >= 0 && (options.count === Number.POSITIVE_INFINITY || Number.isInteger(options.count)))) {
			throw new TypeError('The `count` option should be at least 0 or more');
		}

		// Allow multiple events
		const events = [event].flat();

		const items = [];
		const {addListener, removeListener} = normalizeEmitter(emitter);

		const onItem = (...arguments_) => {
			const value = options.multiArgs ? arguments_ : arguments_[0];

			// eslint-disable-next-line unicorn/no-array-callback-reference
			if (options.filter && !options.filter(value)) {
				return;
			}

			items.push(value);

			if (options.count === items.length) {
				cancel();
				resolve(items);
			}
		};

		const rejectHandler = error => {
			cancel();
			reject(error);
		};

		cancel = () => {
			for (const event of events) {
				removeListener(event, onItem);
			}

			for (const rejectionEvent of options.rejectionEvents) {
				removeListener(rejectionEvent, rejectHandler);
			}
		};

		for (const event of events) {
			addListener(event, onItem);
		}

		for (const rejectionEvent of options.rejectionEvents) {
			addListener(rejectionEvent, rejectHandler);
		}

		if (options.resolveImmediately) {
			resolve(items);
		}
	});

	returnValue.cancel = cancel;

	if (typeof options.timeout === 'number') {
		const timeout = pTimeout$2(returnValue, options.timeout);
		timeout.cancel = cancel;
		return timeout;
	}

	return returnValue;
}

function pEvent(emitter, event, options) {
	if (typeof options === 'function') {
		options = {filter: options};
	}

	options = {
		...options,
		count: 1,
		resolveImmediately: false,
	};

	const arrayPromise = pEventMultiple(emitter, event, options);
	const promise = arrayPromise.then(array => array[0]); // eslint-disable-line promise/prefer-await-to-then
	promise.cancel = arrayPromise.cancel;

	return promise;
}

const log$A = debug("waku:wait-for-remote-peer");
/**
 * Wait for a remote peer to be ready given the passed protocols.
 * Must be used after attempting to connect to nodes, using
 * {@link @waku/core.WakuNode.dial} or a bootstrap method with
 * {@link @waku/sdk.createLightNode}.
 *
 * If the passed protocols is a GossipSub protocol, then it resolves only once
 * a peer is in a mesh, to help ensure that other peers will send and receive
 * message to us.
 *
 * @param waku The Waku Node
 * @param protocols The protocols that need to be enabled by remote peers.
 * @param timeoutMs A timeout value in milliseconds..
 *
 * @returns A promise that **resolves** if all desired protocols are fulfilled by
 * remote nodes, **rejects** if the timeoutMs is reached.
 * @throws If passing a protocol that is not mounted
 * @default Wait for remote peers with protocols enabled locally and no time out is applied.
 */
async function waitForRemotePeer(waku, protocols, timeoutMs) {
    protocols = protocols ?? getEnabledProtocols(waku);
    if (!waku.isStarted())
        return Promise.reject("Waku node is not started");
    const promises = [];
    if (protocols.includes(Protocols.Relay)) {
        if (!waku.relay)
            throw new Error("Cannot wait for Relay peer: protocol not mounted");
        promises.push(waitForGossipSubPeerInMesh(waku.relay));
    }
    if (protocols.includes(Protocols.Store)) {
        if (!waku.store)
            throw new Error("Cannot wait for Store peer: protocol not mounted");
        promises.push(waitForConnectedPeer(waku.store));
    }
    if (protocols.includes(Protocols.LightPush)) {
        if (!waku.lightPush)
            throw new Error("Cannot wait for LightPush peer: protocol not mounted");
        promises.push(waitForConnectedPeer(waku.lightPush));
    }
    if (protocols.includes(Protocols.Filter)) {
        if (!waku.filter)
            throw new Error("Cannot wait for Filter peer: protocol not mounted");
        promises.push(waitForConnectedPeer(waku.filter));
    }
    if (timeoutMs) {
        await rejectOnTimeout(Promise.all(promises), timeoutMs, "Timed out waiting for a remote peer.");
    }
    else {
        await Promise.all(promises);
    }
}
/**
 * Wait for a peer with the given protocol to be connected.
 */
async function waitForConnectedPeer(protocol) {
    const codec = protocol.multicodec;
    const peers = await protocol.peers();
    if (peers.length) {
        log$A(`${codec} peer found: `, peers[0].id.toString());
        return;
    }
    await new Promise((resolve) => {
        const cb = (evt) => {
            if (evt.detail?.protocols?.includes(codec)) {
                log$A("Resolving for", codec, evt.detail.protocols);
                protocol.removeLibp2pEventListener("peer:identify", cb);
                resolve();
            }
        };
        protocol.addLibp2pEventListener("peer:identify", cb);
    });
}
/**
 * Wait for a peer with the given protocol to be connected and in the gossipsub
 * mesh.
 */
async function waitForGossipSubPeerInMesh(waku) {
    let peers = waku.getMeshPeers();
    while (peers.length == 0) {
        await pEvent(waku.gossipSub, "gossipsub:heartbeat");
        peers = waku.getMeshPeers();
    }
}
const awaitTimeout = (ms, rejectReason) => new Promise((_resolve, reject) => setTimeout(() => reject(rejectReason), ms));
async function rejectOnTimeout(promise, timeoutMs, rejectReason) {
    await Promise.race([promise, awaitTimeout(timeoutMs, rejectReason)]);
}
function getEnabledProtocols(waku) {
    const protocols = [];
    if (waku.relay) {
        protocols.push(Protocols.Relay);
    }
    if (waku.filter) {
        protocols.push(Protocols.Filter);
    }
    if (waku.store) {
        protocols.push(Protocols.Store);
    }
    if (waku.lightPush) {
        protocols.push(Protocols.LightPush);
    }
    return protocols;
}

var index$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    ConnectionManager: ConnectionManager,
    DefaultPubSubTopic: DefaultPubSubTopic,
    DefaultUserAgent: DefaultUserAgent,
    FilterCodecs: FilterCodecs,
    KeepAliveManager: KeepAliveManager,
    get PageDirection () { return PageDirection; },
    StreamManager: StreamManager,
    WakuNode: WakuNode,
    createCursor: createCursor,
    createDecoder: createDecoder,
    createEncoder: createEncoder,
    message: index$6,
    waitForRemotePeer: waitForRemotePeer,
    waku: waku,
    wakuFilter: wakuFilter,
    wakuLightPush: wakuLightPush,
    wakuStore: wakuStore,
    waku_filter: index$4,
    waku_light_push: index$3,
    waku_store: index$2
});

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive bytes over streams.
 *
 * @example
 *
 * ```typescript
 * import { byteStream } from 'it-byte-stream'
 *
 * const stream = byteStream(duplex)
 *
 * // read the next chunk
 * const bytes = await stream.read()
 *
 * // read the next five bytes
 * const fiveBytes = await stream.read(5)
 *
 * // write bytes into the stream
 * await stream.write(Uint8Array.from([0, 1, 2, 3, 4]))
 * ```
 */
let CodeError$2 = class CodeError extends Error {
    code;
    constructor(message, code) {
        super(message);
        this.code = code;
    }
};
let AbortError$5 = class AbortError extends CodeError$2 {
    type;
    constructor(message) {
        super(message, 'ABORT_ERR');
        this.type = 'aborted';
    }
};
function byteStream(duplex) {
    const write = pushable();
    duplex.sink(write).catch((err) => {
        write.end(err);
    });
    duplex.sink = async (source) => {
        for await (const buf of source) {
            write.push(buf);
        }
        write.end();
    };
    let source = duplex.source;
    if (duplex.source[Symbol.iterator] != null) {
        source = duplex.source[Symbol.iterator]();
    }
    else if (duplex.source[Symbol.asyncIterator] != null) {
        source = duplex.source[Symbol.asyncIterator]();
    }
    const readBuffer = new Uint8ArrayList();
    const W = {
        read: async (bytes, options) => {
            options?.signal?.throwIfAborted();
            let listener;
            const abortPromise = new Promise((resolve, reject) => {
                listener = () => {
                    reject(new AbortError$5('Read aborted'));
                };
                options?.signal?.addEventListener('abort', listener);
            });
            try {
                if (bytes == null) {
                    // just read whatever arrives
                    const { done, value } = await Promise.race([
                        source.next(),
                        abortPromise
                    ]);
                    if (done === true) {
                        return new Uint8ArrayList();
                    }
                    return value;
                }
                while (readBuffer.byteLength < bytes) {
                    const { value, done } = await Promise.race([
                        source.next(),
                        abortPromise
                    ]);
                    if (done === true) {
                        throw new CodeError$2('unexpected end of input', 'ERR_UNEXPECTED_EOF');
                    }
                    readBuffer.append(value);
                }
                const buf = readBuffer.sublist(0, bytes);
                readBuffer.consume(bytes);
                return buf;
            }
            finally {
                if (listener != null) {
                    options?.signal?.removeEventListener('abort', listener);
                }
            }
        },
        write: async (data, options) => {
            options?.signal?.throwIfAborted();
            // just write
            if (data instanceof Uint8Array) {
                write.push(data);
            }
            else {
                write.push(data.subarray());
            }
            await write.onEmpty(options);
        },
        unwrap: () => {
            const originalStream = duplex.source;
            duplex.source = (async function* () {
                yield* readBuffer;
                yield* originalStream;
            }());
            return duplex;
        }
    };
    return W;
}

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive length-prefixed byte arrays over
 * streams.
 *
 * @example
 *
 * ```typescript
 * import { lpStream } from 'it-length-prefixed-stream'
 *
 * const stream = lpStream(duplex)
 *
 * // read the next length-prefixed chunk
 * const bytes = await stream.read()
 *
 * // write a length-prefixed chunk
 * await stream.write(Uint8Array.from([0, 1, 2, 3, 4]))
 * ```
 */
let CodeError$1 = class CodeError extends Error {
    code;
    constructor(message, code) {
        super(message);
        this.code = code;
    }
};
const defaultLengthDecoder = (buf) => {
    return unsigned.decode(buf);
};
defaultLengthDecoder.bytes = 0;
function lpStream(duplex, opts) {
    const bytes = byteStream(duplex);
    const W = {
        read: async (options) => {
            let dataLength = -1;
            const lengthBuffer = new Uint8ArrayList();
            const decodeLength = opts?.lengthDecoder ?? defaultLengthDecoder;
            while (true) {
                // read one byte at a time until we can decode a varint
                lengthBuffer.append(await bytes.read(1, options));
                try {
                    dataLength = decodeLength(lengthBuffer);
                }
                catch (err) {
                    if (err instanceof RangeError) {
                        continue;
                    }
                    throw err;
                }
                if (dataLength > -1) {
                    break;
                }
                if (opts?.maxLengthLength != null && lengthBuffer.byteLength > opts.maxLengthLength) {
                    throw new CodeError$1('message length length too long', 'ERR_MSG_LENGTH_TOO_LONG');
                }
            }
            if (opts?.maxDataLength != null && dataLength > opts.maxDataLength) {
                throw new CodeError$1('message length too long', 'ERR_MSG_DATA_TOO_LONG');
            }
            return bytes.read(dataLength, options);
        },
        write: async (data, options) => {
            // encode, write
            await bytes.write(encode$B.single(data, opts), options);
        },
        unwrap: () => {
            return bytes.unwrap();
        }
    };
    return W;
}

/**
 * A pair of streams where one drains from the other
 */
function pair() {
    const deferred = pDefer();
    let piped = false;
    return {
        sink: async (source) => {
            if (piped) {
                throw new Error('already piped');
            }
            piped = true;
            deferred.resolve(source);
        },
        source: (async function* () {
            const source = await deferred.promise;
            yield* source;
        }())
    };
}

/**
 * Two duplex streams that are attached to each other
 */
function duplexPair() {
    const a = pair();
    const b = pair();
    return [
        {
            source: a.source,
            sink: b.sink
        },
        {
            source: b.source,
            sink: a.sink
        }
    ];
}

const NOISE_MSG_MAX_LENGTH_BYTES = 65535;
const NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG = NOISE_MSG_MAX_LENGTH_BYTES - 16;
const DUMP_SESSION_KEYS = Boolean(globalThis.process?.env?.DUMP_SESSION_KEYS);

/*! noble-ciphers - MIT License (c) 2023 Paul Miller (paulmillr.com) */
const u8a$2 = (a) => a instanceof Uint8Array;
const u32 = (arr) => new Uint32Array(arr.buffer, arr.byteOffset, Math.floor(arr.byteLength / 4));
// Cast array to view
const createView$1 = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
// big-endian hardware is rare. Just in case someone still decides to run ciphers:
// early-throw an error because we don't support BE yet.
const isLE$1 = new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;
if (!isLE$1)
    throw new Error('Non little-endian hardware is not supported');
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes$2(str) {
    if (typeof str !== 'string')
        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes$2(data) {
    if (typeof data === 'string')
        data = utf8ToBytes$2(data);
    if (!u8a$2(data))
        throw new Error(`expected Uint8Array, got ${typeof data}`);
    return data;
}
// Check if object doens't have custom constructor (like Uint8Array/Array)
const isPlainObject = (obj) => Object.prototype.toString.call(obj) === '[object Object]' && obj.constructor === Object;
function checkOpts(defaults, opts) {
    if (opts !== undefined && (typeof opts !== 'object' || !isPlainObject(opts)))
        throw new Error('Options should be object or undefined');
    const merged = Object.assign(defaults, opts);
    return merged;
}
function ensureBytes$3(b, len) {
    if (!(b instanceof Uint8Array))
        throw new Error('Uint8Array expected');
    if (typeof len === 'number')
        if (b.length !== len)
            throw new Error(`Uint8Array length ${len} expected`);
}
// Constant-time equality
function equalBytes$2(a, b) {
    // Should not happen
    if (a.length !== b.length)
        throw new Error('equalBytes: Different size of Uint8Arrays');
    let isSame = true;
    for (let i = 0; i < a.length; i++)
        isSame && (isSame = a[i] === b[i]); // Lets hope JIT won't optimize away.
    return isSame;
}
// Polyfill for Safari 14
function setBigUint64$1(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = isLE ? 4 : 0;
    const l = isLE ? 0 : 4;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}

function number$1(n) {
    if (!Number.isSafeInteger(n) || n < 0)
        throw new Error(`Wrong positive integer: ${n}`);
}
function bool$1(b) {
    if (typeof b !== 'boolean')
        throw new Error(`Expected boolean, not ${b}`);
}
function bytes$1(b, ...lengths) {
    if (!(b instanceof Uint8Array))
        throw new Error('Expected Uint8Array');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new Error(`Expected Uint8Array of length ${lengths}, not of length=${b.length}`);
}
function hash$2(hash) {
    if (typeof hash !== 'function' || typeof hash.create !== 'function')
        throw new Error('Hash should be wrapped by utils.wrapConstructor');
    number$1(hash.outputLen);
    number$1(hash.blockLen);
}
function exists$1(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
function output$1(out, instance) {
    bytes$1(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error(`digestInto() expects output buffer of length at least ${min}`);
    }
}
const assert$1 = { number: number$1, bool: bool$1, bytes: bytes$1, hash: hash$2, exists: exists$1, output: output$1 };

// Poly1305 is a fast and parallel secret-key message-authentication code.
// https://cr.yp.to/mac.html, https://cr.yp.to/mac/poly1305-20050329.pdf
// https://datatracker.ietf.org/doc/html/rfc8439
// Based on Public Domain poly1305-donna https://github.com/floodyberry/poly1305-donna
const u8to16 = (a, i) => (a[i++] & 0xff) | ((a[i++] & 0xff) << 8);
class Poly1305 {
    constructor(key) {
        this.blockLen = 16;
        this.outputLen = 16;
        this.buffer = new Uint8Array(16);
        this.r = new Uint16Array(10);
        this.h = new Uint16Array(10);
        this.pad = new Uint16Array(8);
        this.pos = 0;
        this.finished = false;
        key = toBytes$2(key);
        ensureBytes$3(key, 32);
        const t0 = u8to16(key, 0);
        const t1 = u8to16(key, 2);
        const t2 = u8to16(key, 4);
        const t3 = u8to16(key, 6);
        const t4 = u8to16(key, 8);
        const t5 = u8to16(key, 10);
        const t6 = u8to16(key, 12);
        const t7 = u8to16(key, 14);
        // https://github.com/floodyberry/poly1305-donna/blob/e6ad6e091d30d7f4ec2d4f978be1fcfcbce72781/poly1305-donna-16.h#L47
        this.r[0] = t0 & 0x1fff;
        this.r[1] = ((t0 >>> 13) | (t1 << 3)) & 0x1fff;
        this.r[2] = ((t1 >>> 10) | (t2 << 6)) & 0x1f03;
        this.r[3] = ((t2 >>> 7) | (t3 << 9)) & 0x1fff;
        this.r[4] = ((t3 >>> 4) | (t4 << 12)) & 0x00ff;
        this.r[5] = (t4 >>> 1) & 0x1ffe;
        this.r[6] = ((t4 >>> 14) | (t5 << 2)) & 0x1fff;
        this.r[7] = ((t5 >>> 11) | (t6 << 5)) & 0x1f81;
        this.r[8] = ((t6 >>> 8) | (t7 << 8)) & 0x1fff;
        this.r[9] = (t7 >>> 5) & 0x007f;
        for (let i = 0; i < 8; i++)
            this.pad[i] = u8to16(key, 16 + 2 * i);
    }
    process(data, offset, isLast = false) {
        const hibit = isLast ? 0 : 1 << 11;
        const { h, r } = this;
        const r0 = r[0];
        const r1 = r[1];
        const r2 = r[2];
        const r3 = r[3];
        const r4 = r[4];
        const r5 = r[5];
        const r6 = r[6];
        const r7 = r[7];
        const r8 = r[8];
        const r9 = r[9];
        const t0 = u8to16(data, offset + 0);
        const t1 = u8to16(data, offset + 2);
        const t2 = u8to16(data, offset + 4);
        const t3 = u8to16(data, offset + 6);
        const t4 = u8to16(data, offset + 8);
        const t5 = u8to16(data, offset + 10);
        const t6 = u8to16(data, offset + 12);
        const t7 = u8to16(data, offset + 14);
        let h0 = h[0] + (t0 & 0x1fff);
        let h1 = h[1] + (((t0 >>> 13) | (t1 << 3)) & 0x1fff);
        let h2 = h[2] + (((t1 >>> 10) | (t2 << 6)) & 0x1fff);
        let h3 = h[3] + (((t2 >>> 7) | (t3 << 9)) & 0x1fff);
        let h4 = h[4] + (((t3 >>> 4) | (t4 << 12)) & 0x1fff);
        let h5 = h[5] + ((t4 >>> 1) & 0x1fff);
        let h6 = h[6] + (((t4 >>> 14) | (t5 << 2)) & 0x1fff);
        let h7 = h[7] + (((t5 >>> 11) | (t6 << 5)) & 0x1fff);
        let h8 = h[8] + (((t6 >>> 8) | (t7 << 8)) & 0x1fff);
        let h9 = h[9] + ((t7 >>> 5) | hibit);
        let c = 0;
        let d0 = c + h0 * r0 + h1 * (5 * r9) + h2 * (5 * r8) + h3 * (5 * r7) + h4 * (5 * r6);
        c = d0 >>> 13;
        d0 &= 0x1fff;
        d0 += h5 * (5 * r5) + h6 * (5 * r4) + h7 * (5 * r3) + h8 * (5 * r2) + h9 * (5 * r1);
        c += d0 >>> 13;
        d0 &= 0x1fff;
        let d1 = c + h0 * r1 + h1 * r0 + h2 * (5 * r9) + h3 * (5 * r8) + h4 * (5 * r7);
        c = d1 >>> 13;
        d1 &= 0x1fff;
        d1 += h5 * (5 * r6) + h6 * (5 * r5) + h7 * (5 * r4) + h8 * (5 * r3) + h9 * (5 * r2);
        c += d1 >>> 13;
        d1 &= 0x1fff;
        let d2 = c + h0 * r2 + h1 * r1 + h2 * r0 + h3 * (5 * r9) + h4 * (5 * r8);
        c = d2 >>> 13;
        d2 &= 0x1fff;
        d2 += h5 * (5 * r7) + h6 * (5 * r6) + h7 * (5 * r5) + h8 * (5 * r4) + h9 * (5 * r3);
        c += d2 >>> 13;
        d2 &= 0x1fff;
        let d3 = c + h0 * r3 + h1 * r2 + h2 * r1 + h3 * r0 + h4 * (5 * r9);
        c = d3 >>> 13;
        d3 &= 0x1fff;
        d3 += h5 * (5 * r8) + h6 * (5 * r7) + h7 * (5 * r6) + h8 * (5 * r5) + h9 * (5 * r4);
        c += d3 >>> 13;
        d3 &= 0x1fff;
        let d4 = c + h0 * r4 + h1 * r3 + h2 * r2 + h3 * r1 + h4 * r0;
        c = d4 >>> 13;
        d4 &= 0x1fff;
        d4 += h5 * (5 * r9) + h6 * (5 * r8) + h7 * (5 * r7) + h8 * (5 * r6) + h9 * (5 * r5);
        c += d4 >>> 13;
        d4 &= 0x1fff;
        let d5 = c + h0 * r5 + h1 * r4 + h2 * r3 + h3 * r2 + h4 * r1;
        c = d5 >>> 13;
        d5 &= 0x1fff;
        d5 += h5 * r0 + h6 * (5 * r9) + h7 * (5 * r8) + h8 * (5 * r7) + h9 * (5 * r6);
        c += d5 >>> 13;
        d5 &= 0x1fff;
        let d6 = c + h0 * r6 + h1 * r5 + h2 * r4 + h3 * r3 + h4 * r2;
        c = d6 >>> 13;
        d6 &= 0x1fff;
        d6 += h5 * r1 + h6 * r0 + h7 * (5 * r9) + h8 * (5 * r8) + h9 * (5 * r7);
        c += d6 >>> 13;
        d6 &= 0x1fff;
        let d7 = c + h0 * r7 + h1 * r6 + h2 * r5 + h3 * r4 + h4 * r3;
        c = d7 >>> 13;
        d7 &= 0x1fff;
        d7 += h5 * r2 + h6 * r1 + h7 * r0 + h8 * (5 * r9) + h9 * (5 * r8);
        c += d7 >>> 13;
        d7 &= 0x1fff;
        let d8 = c + h0 * r8 + h1 * r7 + h2 * r6 + h3 * r5 + h4 * r4;
        c = d8 >>> 13;
        d8 &= 0x1fff;
        d8 += h5 * r3 + h6 * r2 + h7 * r1 + h8 * r0 + h9 * (5 * r9);
        c += d8 >>> 13;
        d8 &= 0x1fff;
        let d9 = c + h0 * r9 + h1 * r8 + h2 * r7 + h3 * r6 + h4 * r5;
        c = d9 >>> 13;
        d9 &= 0x1fff;
        d9 += h5 * r4 + h6 * r3 + h7 * r2 + h8 * r1 + h9 * r0;
        c += d9 >>> 13;
        d9 &= 0x1fff;
        c = ((c << 2) + c) | 0;
        c = (c + d0) | 0;
        d0 = c & 0x1fff;
        c = c >>> 13;
        d1 += c;
        h[0] = d0;
        h[1] = d1;
        h[2] = d2;
        h[3] = d3;
        h[4] = d4;
        h[5] = d5;
        h[6] = d6;
        h[7] = d7;
        h[8] = d8;
        h[9] = d9;
    }
    finalize() {
        const { h, pad } = this;
        const g = new Uint16Array(10);
        let c = h[1] >>> 13;
        h[1] &= 0x1fff;
        for (let i = 2; i < 10; i++) {
            h[i] += c;
            c = h[i] >>> 13;
            h[i] &= 0x1fff;
        }
        h[0] += c * 5;
        c = h[0] >>> 13;
        h[0] &= 0x1fff;
        h[1] += c;
        c = h[1] >>> 13;
        h[1] &= 0x1fff;
        h[2] += c;
        g[0] = h[0] + 5;
        c = g[0] >>> 13;
        g[0] &= 0x1fff;
        for (let i = 1; i < 10; i++) {
            g[i] = h[i] + c;
            c = g[i] >>> 13;
            g[i] &= 0x1fff;
        }
        g[9] -= 1 << 13;
        let mask = (c ^ 1) - 1;
        for (let i = 0; i < 10; i++)
            g[i] &= mask;
        mask = ~mask;
        for (let i = 0; i < 10; i++)
            h[i] = (h[i] & mask) | g[i];
        h[0] = (h[0] | (h[1] << 13)) & 0xffff;
        h[1] = ((h[1] >>> 3) | (h[2] << 10)) & 0xffff;
        h[2] = ((h[2] >>> 6) | (h[3] << 7)) & 0xffff;
        h[3] = ((h[3] >>> 9) | (h[4] << 4)) & 0xffff;
        h[4] = ((h[4] >>> 12) | (h[5] << 1) | (h[6] << 14)) & 0xffff;
        h[5] = ((h[6] >>> 2) | (h[7] << 11)) & 0xffff;
        h[6] = ((h[7] >>> 5) | (h[8] << 8)) & 0xffff;
        h[7] = ((h[8] >>> 8) | (h[9] << 5)) & 0xffff;
        let f = h[0] + pad[0];
        h[0] = f & 0xffff;
        for (let i = 1; i < 8; i++) {
            f = (((h[i] + pad[i]) | 0) + (f >>> 16)) | 0;
            h[i] = f & 0xffff;
        }
    }
    update(data) {
        assert$1.exists(this);
        const { buffer, blockLen } = this;
        data = toBytes$2(data);
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input
            if (take === blockLen) {
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(data, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(buffer, 0, false);
                this.pos = 0;
            }
        }
        return this;
    }
    destroy() {
        this.h.fill(0);
        this.r.fill(0);
        this.buffer.fill(0);
        this.pad.fill(0);
    }
    digestInto(out) {
        assert$1.exists(this);
        assert$1.output(out, this);
        this.finished = true;
        const { buffer, h } = this;
        let { pos } = this;
        if (pos) {
            buffer[pos++] = 1;
            // buffer.subarray(pos).fill(0);
            for (; pos < 16; pos++)
                buffer[pos] = 0;
            this.process(buffer, 0, true);
        }
        this.finalize();
        let opos = 0;
        for (let i = 0; i < 8; i++) {
            out[opos++] = h[i] >>> 0;
            out[opos++] = h[i] >>> 8;
        }
        return out;
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
}
function wrapConstructorWithKey(hashCons) {
    const hashC = (msg, key) => hashCons(key).update(toBytes$2(msg)).digest();
    const tmp = hashCons(new Uint8Array(32));
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = (key) => hashCons(key);
    return hashC;
}
const poly1305 = wrapConstructorWithKey((key) => new Poly1305(key));

// Basic utils for salsa-like ciphers
// Check out _micro.ts for descriptive documentation.
/*
RFC8439 requires multi-step cipher stream, where
authKey starts with counter: 0, actual msg with counter: 1.

For this, we need a way to re-use nonce / counter:

    const counter = new Uint8Array(4);
    chacha(..., counter, ...); // counter is now 1
    chacha(..., counter, ...); // counter is now 2

This is complicated:

- Original papers don't allow mutating counters
- Counter overflow is undefined: https://mailarchive.ietf.org/arch/msg/cfrg/gsOnTJzcbgG6OqD8Sc0GO5aR_tU/
- 3rd-party library stablelib implementation uses an approach where you can provide
  nonce and counter instead of just nonce - and it will re-use it
- We could have did something similar, but ChaCha has different counter position
  (counter | nonce), which is not composable with XChaCha, because full counter
  is (nonce16 | counter | nonce16). Stablelib doesn't support in-place counter for XChaCha.
- We could separate nonce & counter and provide separate API for counter re-use, but
  there are different counter sizes depending on an algorithm.
- Salsa & ChaCha also differ in structures of key / sigma:

    salsa:     c0 | k(4) | c1 | nonce(2) | ctr(2) | c2 | k(4) | c4
    chacha:    c(4) | k(8) | ctr(1) | nonce(3)
    chachaDJB: c(4) | k(8) | ctr(2) | nonce(2)
- Creating function such as `setSalsaState(key, nonce, sigma, data)` won't work,
  because we can't re-use counter array
- 32-bit nonce is `2 ** 32 * 64` = 256GB with 32-bit counter
- JS does not allow UintArrays bigger than 4GB, so supporting 64-bit counters doesn't matter

Structure is as following:

key=16 -> sigma16, k=key|key
key=32 -> sigma32, k=key

nonces:
salsa20:      8   (8-byte counter)
chacha20djb:  8   (8-byte counter)
chacha20tls:  12  (4-byte counter)
xsalsa:       24  (16 -> hsalsa, 8 -> old nonce)
xchacha:      24  (16 -> hchacha, 8 -> old nonce)

https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-xchacha#appendix-A.2
Use the subkey and remaining 8 byte nonce with ChaCha20 as normal
(prefixed by 4 NUL bytes, since [RFC8439] specifies a 12-byte nonce).
*/
const sigma16 = utf8ToBytes$2('expand 16-byte k');
const sigma32 = utf8ToBytes$2('expand 32-byte k');
const sigma16_32 = u32(sigma16);
const sigma32_32 = u32(sigma32);
// Is byte array aligned to 4 byte offset (u32)?
const isAligned32 = (b) => !(b.byteOffset % 4);
const salsaBasic = (opts) => {
    const { core, rounds, counterRight, counterLen, allow128bitKeys, extendNonceFn, blockLen } = checkOpts({ rounds: 20, counterRight: false, counterLen: 8, allow128bitKeys: true, blockLen: 64 }, opts);
    assert$1.number(counterLen);
    assert$1.number(rounds);
    assert$1.number(blockLen);
    assert$1.bool(counterRight);
    assert$1.bool(allow128bitKeys);
    const blockLen32 = blockLen / 4;
    if (blockLen % 4 !== 0)
        throw new Error('Salsa/ChaCha: blockLen should be aligned to 4 bytes');
    return (key, nonce, data, output, counter = 0) => {
        assert$1.bytes(key);
        assert$1.bytes(nonce);
        assert$1.bytes(data);
        if (!output)
            output = new Uint8Array(data.length);
        assert$1.bytes(output);
        assert$1.number(counter);
        // > new Uint32Array([2**32])
        // Uint32Array(1) [ 0 ]
        // > new Uint32Array([2**32-1])
        // Uint32Array(1) [ 4294967295 ]
        if (counter < 0 || counter >= 2 ** 32 - 1)
            throw new Error('Salsa/ChaCha: counter overflow');
        if (output.length < data.length) {
            throw new Error(`Salsa/ChaCha: output (${output.length}) is shorter than data (${data.length})`);
        }
        const toClean = [];
        let k, sigma;
        // Handle 128 byte keys
        if (key.length === 32) {
            k = key;
            sigma = sigma32_32;
        }
        else if (key.length === 16 && allow128bitKeys) {
            k = new Uint8Array(32);
            k.set(key);
            k.set(key, 16);
            sigma = sigma16_32;
            toClean.push(k);
        }
        else
            throw new Error(`Salsa/ChaCha: wrong key length=${key.length}, expected`);
        // Handle extended nonce (HChaCha/HSalsa)
        if (extendNonceFn) {
            if (nonce.length <= 16)
                throw new Error(`Salsa/ChaCha: extended nonce should be bigger than 16 bytes`);
            k = extendNonceFn(sigma, k, nonce.subarray(0, 16), new Uint8Array(32));
            toClean.push(k);
            nonce = nonce.subarray(16);
        }
        // Handle nonce counter
        const nonceLen = 16 - counterLen;
        if (nonce.length !== nonceLen)
            throw new Error(`Salsa/ChaCha: nonce should be ${nonceLen} or 16 bytes`);
        // Pad counter when nonce is 64 bit
        if (nonceLen !== 12) {
            const nc = new Uint8Array(12);
            nc.set(nonce, counterRight ? 0 : 12 - nonce.length);
            toClean.push((nonce = nc));
        }
        // Counter positions
        const block = new Uint8Array(blockLen);
        // Cast to Uint32Array for speed
        const b32 = u32(block);
        const k32 = u32(k);
        const n32 = u32(nonce);
        // Make sure that buffers aligned to 4 bytes
        const d32 = isAligned32(data) && u32(data);
        const o32 = isAligned32(output) && u32(output);
        toClean.push(b32);
        const len = data.length;
        for (let pos = 0, ctr = counter; pos < len; ctr++) {
            core(sigma, k32, n32, b32, ctr, rounds);
            if (ctr >= 2 ** 32 - 1)
                throw new Error('Salsa/ChaCha: counter overflow');
            const take = Math.min(blockLen, len - pos);
            // full block && aligned to 4 bytes
            if (take === blockLen && o32 && d32) {
                const pos32 = pos / 4;
                if (pos % 4 !== 0)
                    throw new Error('Salsa/ChaCha: wrong block position');
                for (let j = 0; j < blockLen32; j++)
                    o32[pos32 + j] = d32[pos32 + j] ^ b32[j];
                pos += blockLen;
                continue;
            }
            for (let j = 0; j < take; j++)
                output[pos + j] = data[pos + j] ^ block[j];
            pos += take;
        }
        for (let i = 0; i < toClean.length; i++)
            toClean[i].fill(0);
        return output;
    };
};

// ChaCha20 stream cipher was released in 2008. ChaCha aims to increase
// the diffusion per round, but had slightly less cryptanalysis.
// https://cr.yp.to/chacha.html, http://cr.yp.to/chacha/chacha-20080128.pdf
// Left rotate for uint32
const rotl = (a, b) => (a << b) | (a >>> (32 - b));
/**
 * ChaCha core function.
 */
// prettier-ignore
function chachaCore(c, k, n, out, cnt, rounds = 20) {
    let y00 = c[0], y01 = c[1], y02 = c[2], y03 = c[3]; // "expa"   "nd 3"  "2-by"  "te k"
    let y04 = k[0], y05 = k[1], y06 = k[2], y07 = k[3]; // Key      Key     Key     Key
    let y08 = k[4], y09 = k[5], y10 = k[6], y11 = k[7]; // Key      Key     Key     Key
    let y12 = cnt, y13 = n[0], y14 = n[1], y15 = n[2]; // Counter  Counter	Nonce   Nonce
    // Save state to temporary variables
    let x00 = y00, x01 = y01, x02 = y02, x03 = y03, x04 = y04, x05 = y05, x06 = y06, x07 = y07, x08 = y08, x09 = y09, x10 = y10, x11 = y11, x12 = y12, x13 = y13, x14 = y14, x15 = y15;
    // Main loop
    for (let i = 0; i < rounds; i += 2) {
        x00 = (x00 + x04) | 0;
        x12 = rotl(x12 ^ x00, 16);
        x08 = (x08 + x12) | 0;
        x04 = rotl(x04 ^ x08, 12);
        x00 = (x00 + x04) | 0;
        x12 = rotl(x12 ^ x00, 8);
        x08 = (x08 + x12) | 0;
        x04 = rotl(x04 ^ x08, 7);
        x01 = (x01 + x05) | 0;
        x13 = rotl(x13 ^ x01, 16);
        x09 = (x09 + x13) | 0;
        x05 = rotl(x05 ^ x09, 12);
        x01 = (x01 + x05) | 0;
        x13 = rotl(x13 ^ x01, 8);
        x09 = (x09 + x13) | 0;
        x05 = rotl(x05 ^ x09, 7);
        x02 = (x02 + x06) | 0;
        x14 = rotl(x14 ^ x02, 16);
        x10 = (x10 + x14) | 0;
        x06 = rotl(x06 ^ x10, 12);
        x02 = (x02 + x06) | 0;
        x14 = rotl(x14 ^ x02, 8);
        x10 = (x10 + x14) | 0;
        x06 = rotl(x06 ^ x10, 7);
        x03 = (x03 + x07) | 0;
        x15 = rotl(x15 ^ x03, 16);
        x11 = (x11 + x15) | 0;
        x07 = rotl(x07 ^ x11, 12);
        x03 = (x03 + x07) | 0;
        x15 = rotl(x15 ^ x03, 8);
        x11 = (x11 + x15) | 0;
        x07 = rotl(x07 ^ x11, 7);
        x00 = (x00 + x05) | 0;
        x15 = rotl(x15 ^ x00, 16);
        x10 = (x10 + x15) | 0;
        x05 = rotl(x05 ^ x10, 12);
        x00 = (x00 + x05) | 0;
        x15 = rotl(x15 ^ x00, 8);
        x10 = (x10 + x15) | 0;
        x05 = rotl(x05 ^ x10, 7);
        x01 = (x01 + x06) | 0;
        x12 = rotl(x12 ^ x01, 16);
        x11 = (x11 + x12) | 0;
        x06 = rotl(x06 ^ x11, 12);
        x01 = (x01 + x06) | 0;
        x12 = rotl(x12 ^ x01, 8);
        x11 = (x11 + x12) | 0;
        x06 = rotl(x06 ^ x11, 7);
        x02 = (x02 + x07) | 0;
        x13 = rotl(x13 ^ x02, 16);
        x08 = (x08 + x13) | 0;
        x07 = rotl(x07 ^ x08, 12);
        x02 = (x02 + x07) | 0;
        x13 = rotl(x13 ^ x02, 8);
        x08 = (x08 + x13) | 0;
        x07 = rotl(x07 ^ x08, 7);
        x03 = (x03 + x04) | 0;
        x14 = rotl(x14 ^ x03, 16);
        x09 = (x09 + x14) | 0;
        x04 = rotl(x04 ^ x09, 12);
        x03 = (x03 + x04) | 0;
        x14 = rotl(x14 ^ x03, 8);
        x09 = (x09 + x14) | 0;
        x04 = rotl(x04 ^ x09, 7);
    }
    // Write output
    let oi = 0;
    out[oi++] = (y00 + x00) | 0;
    out[oi++] = (y01 + x01) | 0;
    out[oi++] = (y02 + x02) | 0;
    out[oi++] = (y03 + x03) | 0;
    out[oi++] = (y04 + x04) | 0;
    out[oi++] = (y05 + x05) | 0;
    out[oi++] = (y06 + x06) | 0;
    out[oi++] = (y07 + x07) | 0;
    out[oi++] = (y08 + x08) | 0;
    out[oi++] = (y09 + x09) | 0;
    out[oi++] = (y10 + x10) | 0;
    out[oi++] = (y11 + x11) | 0;
    out[oi++] = (y12 + x12) | 0;
    out[oi++] = (y13 + x13) | 0;
    out[oi++] = (y14 + x14) | 0;
    out[oi++] = (y15 + x15) | 0;
}
/**
 * hchacha helper method, used primarily in xchacha, to hash
 * key and nonce into key' and nonce'.
 * Same as chachaCore, but there doesn't seem to be a way to move the block
 * out without 25% performance hit.
 */
// prettier-ignore
function hchacha(c, key, src, out) {
    const k32 = u32(key);
    const i32 = u32(src);
    const o32 = u32(out);
    let x00 = c[0], x01 = c[1], x02 = c[2], x03 = c[3];
    let x04 = k32[0], x05 = k32[1], x06 = k32[2], x07 = k32[3];
    let x08 = k32[4], x09 = k32[5], x10 = k32[6], x11 = k32[7];
    let x12 = i32[0], x13 = i32[1], x14 = i32[2], x15 = i32[3];
    for (let i = 0; i < 20; i += 2) {
        x00 = (x00 + x04) | 0;
        x12 = rotl(x12 ^ x00, 16);
        x08 = (x08 + x12) | 0;
        x04 = rotl(x04 ^ x08, 12);
        x00 = (x00 + x04) | 0;
        x12 = rotl(x12 ^ x00, 8);
        x08 = (x08 + x12) | 0;
        x04 = rotl(x04 ^ x08, 7);
        x01 = (x01 + x05) | 0;
        x13 = rotl(x13 ^ x01, 16);
        x09 = (x09 + x13) | 0;
        x05 = rotl(x05 ^ x09, 12);
        x01 = (x01 + x05) | 0;
        x13 = rotl(x13 ^ x01, 8);
        x09 = (x09 + x13) | 0;
        x05 = rotl(x05 ^ x09, 7);
        x02 = (x02 + x06) | 0;
        x14 = rotl(x14 ^ x02, 16);
        x10 = (x10 + x14) | 0;
        x06 = rotl(x06 ^ x10, 12);
        x02 = (x02 + x06) | 0;
        x14 = rotl(x14 ^ x02, 8);
        x10 = (x10 + x14) | 0;
        x06 = rotl(x06 ^ x10, 7);
        x03 = (x03 + x07) | 0;
        x15 = rotl(x15 ^ x03, 16);
        x11 = (x11 + x15) | 0;
        x07 = rotl(x07 ^ x11, 12);
        x03 = (x03 + x07) | 0;
        x15 = rotl(x15 ^ x03, 8);
        x11 = (x11 + x15) | 0;
        x07 = rotl(x07 ^ x11, 7);
        x00 = (x00 + x05) | 0;
        x15 = rotl(x15 ^ x00, 16);
        x10 = (x10 + x15) | 0;
        x05 = rotl(x05 ^ x10, 12);
        x00 = (x00 + x05) | 0;
        x15 = rotl(x15 ^ x00, 8);
        x10 = (x10 + x15) | 0;
        x05 = rotl(x05 ^ x10, 7);
        x01 = (x01 + x06) | 0;
        x12 = rotl(x12 ^ x01, 16);
        x11 = (x11 + x12) | 0;
        x06 = rotl(x06 ^ x11, 12);
        x01 = (x01 + x06) | 0;
        x12 = rotl(x12 ^ x01, 8);
        x11 = (x11 + x12) | 0;
        x06 = rotl(x06 ^ x11, 7);
        x02 = (x02 + x07) | 0;
        x13 = rotl(x13 ^ x02, 16);
        x08 = (x08 + x13) | 0;
        x07 = rotl(x07 ^ x08, 12);
        x02 = (x02 + x07) | 0;
        x13 = rotl(x13 ^ x02, 8);
        x08 = (x08 + x13) | 0;
        x07 = rotl(x07 ^ x08, 7);
        x03 = (x03 + x04) | 0;
        x14 = rotl(x14 ^ x03, 16);
        x09 = (x09 + x14) | 0;
        x04 = rotl(x04 ^ x09, 12);
        x03 = (x03 + x04) | 0;
        x14 = rotl(x14 ^ x03, 8);
        x09 = (x09 + x14) | 0;
        x04 = rotl(x04 ^ x09, 7);
    }
    o32[0] = x00;
    o32[1] = x01;
    o32[2] = x02;
    o32[3] = x03;
    o32[4] = x12;
    o32[5] = x13;
    o32[6] = x14;
    o32[7] = x15;
    return out;
}
/**
 * Original, non-RFC chacha20 from DJB. 8-byte nonce, 8-byte counter.
 */
salsaBasic({ core: chachaCore, counterRight: false, counterLen: 8 });
/**
 * ChaCha stream cipher. Conforms to RFC 8439 (IETF, TLS). 12-byte nonce, 4-byte counter.
 * With 12-byte nonce, it's not safe to use fill it with random (CSPRNG), due to collision chance.
 */
const chacha20 = salsaBasic({
    core: chachaCore,
    counterRight: false,
    counterLen: 4,
    allow128bitKeys: false,
});
/**
 * XChaCha eXtended-nonce ChaCha. 24-byte nonce.
 * With 24-byte nonce, it's safe to use fill it with random (CSPRNG).
 * https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-xchacha
 */
salsaBasic({
    core: chachaCore,
    counterRight: false,
    counterLen: 8,
    extendNonceFn: hchacha,
    allow128bitKeys: false,
});
/**
 * Reduced 8-round chacha, described in original paper.
 */
salsaBasic({
    core: chachaCore,
    counterRight: false,
    counterLen: 4,
    rounds: 8,
});
/**
 * Reduced 12-round chacha, described in original paper.
 */
salsaBasic({
    core: chachaCore,
    counterRight: false,
    counterLen: 4,
    rounds: 12,
});
const ZERO = new Uint8Array(16);
// Pad to digest size with zeros
const updatePadded = (h, msg) => {
    h.update(msg);
    const left = msg.length % 16;
    if (left)
        h.update(ZERO.subarray(left));
};
const computeTag = (fn, key, nonce, data, AAD) => {
    const authKey = fn(key, nonce, new Uint8Array(32));
    const h = poly1305.create(authKey);
    if (AAD)
        updatePadded(h, AAD);
    updatePadded(h, data);
    const num = new Uint8Array(16);
    const view = createView$1(num);
    setBigUint64$1(view, 0, BigInt(AAD ? AAD.length : 0), true);
    setBigUint64$1(view, 8, BigInt(data.length), true);
    h.update(num);
    const res = h.digest();
    authKey.fill(0);
    return res;
};
/**
 * AEAD algorithm from RFC 8439.
 * Salsa20 and chacha (RFC 8439) use poly1305 differently.
 * We could have composed them similar to:
 * https://github.com/paulmillr/scure-base/blob/b266c73dde977b1dd7ef40ef7a23cc15aab526b3/index.ts#L250
 * But it's hard because of authKey:
 * In salsa20, authKey changes position in salsa stream.
 * In chacha, authKey can't be computed inside computeTag, it modifies the counter.
 */
const _poly1305_aead = (fn) => (key, nonce, AAD) => {
    const tagLength = 16;
    ensureBytes$3(key, 32);
    ensureBytes$3(nonce);
    return {
        tagLength,
        encrypt: (plaintext) => {
            const res = new Uint8Array(plaintext.length + tagLength);
            fn(key, nonce, plaintext, res, 1);
            const tag = computeTag(fn, key, nonce, res.subarray(0, -tagLength), AAD);
            res.set(tag, plaintext.length); // append tag
            return res;
        },
        decrypt: (ciphertext) => {
            if (ciphertext.length < tagLength)
                throw new Error(`Encrypted data should be at least ${tagLength}`);
            const realTag = ciphertext.subarray(-tagLength);
            const data = ciphertext.subarray(0, -tagLength);
            const tag = computeTag(fn, key, nonce, data, AAD);
            if (!equalBytes$2(realTag, tag))
                throw new Error('Wrong tag');
            return fn(key, nonce, data, undefined, 1);
        },
    };
};
/**
 * ChaCha20-Poly1305 from RFC 8439.
 * With 12-byte nonce, it's not safe to use fill it with random (CSPRNG), due to collision chance.
 */
const chacha20_poly1305 = _poly1305_aead(chacha20);

function number(n) {
    if (!Number.isSafeInteger(n) || n < 0)
        throw new Error(`Wrong positive integer: ${n}`);
}
function bool(b) {
    if (typeof b !== 'boolean')
        throw new Error(`Expected boolean, not ${b}`);
}
function bytes(b, ...lengths) {
    if (!(b instanceof Uint8Array))
        throw new Error('Expected Uint8Array');
    if (lengths.length > 0 && !lengths.includes(b.length))
        throw new Error(`Expected Uint8Array of length ${lengths}, not of length=${b.length}`);
}
function hash$1(hash) {
    if (typeof hash !== 'function' || typeof hash.create !== 'function')
        throw new Error('Hash should be wrapped by utils.wrapConstructor');
    number(hash.outputLen);
    number(hash.blockLen);
}
function exists(instance, checkFinished = true) {
    if (instance.destroyed)
        throw new Error('Hash instance has been destroyed');
    if (checkFinished && instance.finished)
        throw new Error('Hash#digest() has already been called');
}
function output(out, instance) {
    bytes(out);
    const min = instance.outputLen;
    if (out.length < min) {
        throw new Error(`digestInto() expects output buffer of length at least ${min}`);
    }
}
const assert = {
    number,
    bool,
    bytes,
    hash: hash$1,
    exists,
    output,
};

const crypto$6 = typeof globalThis === 'object' && 'crypto' in globalThis ? globalThis.crypto : undefined;

/*! noble-hashes - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// We use WebCrypto aka globalThis.crypto, which exists in browsers and node.js 16+.
// node.js versions earlier than v19 don't declare it in global scope.
// For node.js, package.json#exports field mapping rewrites import
// from `crypto` to `cryptoNode`, which imports native module.
// Makes the utils un-importable in browsers without a bundler.
// Once node.js 18 is deprecated, we can just drop the import.
const u8a$1 = (a) => a instanceof Uint8Array;
// Cast array to view
const createView = (arr) => new DataView(arr.buffer, arr.byteOffset, arr.byteLength);
// The rotate right (circular right shift) operation for uint32
const rotr = (word, shift) => (word << (32 - shift)) | (word >>> shift);
// big-endian hardware is rare. Just in case someone still decides to run hashes:
// early-throw an error because we don't support BE yet.
const isLE = new Uint8Array(new Uint32Array([0x11223344]).buffer)[0] === 0x44;
if (!isLE)
    throw new Error('Non little-endian hardware is not supported');
Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, '0'));
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes$1(str) {
    if (typeof str !== 'string')
        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
/**
 * Normalizes (non-hex) string or Uint8Array to Uint8Array.
 * Warning: when Uint8Array is passed, it would NOT get copied.
 * Keep in mind for future mutable operations.
 */
function toBytes$1(data) {
    if (typeof data === 'string')
        data = utf8ToBytes$1(data);
    if (!u8a$1(data))
        throw new Error(`expected Uint8Array, got ${typeof data}`);
    return data;
}
/**
 * Copies several Uint8Arrays into one.
 */
function concatBytes$3(...arrays) {
    const r = new Uint8Array(arrays.reduce((sum, a) => sum + a.length, 0));
    let pad = 0; // walk through each item, ensure they have proper type
    arrays.forEach((a) => {
        if (!u8a$1(a))
            throw new Error('Uint8Array expected');
        r.set(a, pad);
        pad += a.length;
    });
    return r;
}
// For runtime check if class implements interface
class Hash {
    // Safe version that clones internal state
    clone() {
        return this._cloneInto();
    }
}
function wrapConstructor(hashCons) {
    const hashC = (msg) => hashCons().update(toBytes$1(msg)).digest();
    const tmp = hashCons();
    hashC.outputLen = tmp.outputLen;
    hashC.blockLen = tmp.blockLen;
    hashC.create = () => hashCons();
    return hashC;
}
/**
 * Secure PRNG. Uses `crypto.getRandomValues`, which defers to OS.
 */
function randomBytes$7(bytesLength = 32) {
    if (crypto$6 && typeof crypto$6.getRandomValues === 'function') {
        return crypto$6.getRandomValues(new Uint8Array(bytesLength));
    }
    throw new Error('crypto.getRandomValues must be defined');
}

// Polyfill for Safari 14
function setBigUint64(view, byteOffset, value, isLE) {
    if (typeof view.setBigUint64 === 'function')
        return view.setBigUint64(byteOffset, value, isLE);
    const _32n = BigInt(32);
    const _u32_max = BigInt(0xffffffff);
    const wh = Number((value >> _32n) & _u32_max);
    const wl = Number(value & _u32_max);
    const h = isLE ? 4 : 0;
    const l = isLE ? 0 : 4;
    view.setUint32(byteOffset + h, wh, isLE);
    view.setUint32(byteOffset + l, wl, isLE);
}
// Base SHA2 class (RFC 6234)
class SHA2 extends Hash {
    constructor(blockLen, outputLen, padOffset, isLE) {
        super();
        this.blockLen = blockLen;
        this.outputLen = outputLen;
        this.padOffset = padOffset;
        this.isLE = isLE;
        this.finished = false;
        this.length = 0;
        this.pos = 0;
        this.destroyed = false;
        this.buffer = new Uint8Array(blockLen);
        this.view = createView(this.buffer);
    }
    update(data) {
        assert.exists(this);
        const { view, buffer, blockLen } = this;
        data = toBytes$1(data);
        const len = data.length;
        for (let pos = 0; pos < len;) {
            const take = Math.min(blockLen - this.pos, len - pos);
            // Fast path: we have at least one block in input, cast it to view and process
            if (take === blockLen) {
                const dataView = createView(data);
                for (; blockLen <= len - pos; pos += blockLen)
                    this.process(dataView, pos);
                continue;
            }
            buffer.set(data.subarray(pos, pos + take), this.pos);
            this.pos += take;
            pos += take;
            if (this.pos === blockLen) {
                this.process(view, 0);
                this.pos = 0;
            }
        }
        this.length += data.length;
        this.roundClean();
        return this;
    }
    digestInto(out) {
        assert.exists(this);
        assert.output(out, this);
        this.finished = true;
        // Padding
        // We can avoid allocation of buffer for padding completely if it
        // was previously not allocated here. But it won't change performance.
        const { buffer, view, blockLen, isLE } = this;
        let { pos } = this;
        // append the bit '1' to the message
        buffer[pos++] = 0b10000000;
        this.buffer.subarray(pos).fill(0);
        // we have less than padOffset left in buffer, so we cannot put length in current block, need process it and pad again
        if (this.padOffset > blockLen - pos) {
            this.process(view, 0);
            pos = 0;
        }
        // Pad until full block byte with zeros
        for (let i = pos; i < blockLen; i++)
            buffer[i] = 0;
        // Note: sha512 requires length to be 128bit integer, but length in JS will overflow before that
        // You need to write around 2 exabytes (u64_max / 8 / (1024**6)) for this to happen.
        // So we just write lowest 64 bits of that value.
        setBigUint64(view, blockLen - 8, BigInt(this.length * 8), isLE);
        this.process(view, 0);
        const oview = createView(out);
        const len = this.outputLen;
        // NOTE: we do division by 4 later, which should be fused in single op with modulo by JIT
        if (len % 4)
            throw new Error('_sha2: outputLen should be aligned to 32bit');
        const outLen = len / 4;
        const state = this.get();
        if (outLen > state.length)
            throw new Error('_sha2: outputLen bigger than state');
        for (let i = 0; i < outLen; i++)
            oview.setUint32(4 * i, state[i], isLE);
    }
    digest() {
        const { buffer, outputLen } = this;
        this.digestInto(buffer);
        const res = buffer.slice(0, outputLen);
        this.destroy();
        return res;
    }
    _cloneInto(to) {
        to || (to = new this.constructor());
        to.set(...this.get());
        const { blockLen, buffer, length, finished, destroyed, pos } = this;
        to.length = length;
        to.pos = pos;
        to.finished = finished;
        to.destroyed = destroyed;
        if (length % blockLen)
            to.buffer.set(buffer);
        return to;
    }
}

const U32_MASK64 = BigInt(2 ** 32 - 1);
const _32n = BigInt(32);
// We are not using BigUint64Array, because they are extremely slow as per 2022
function fromBig(n, le = false) {
    if (le)
        return { h: Number(n & U32_MASK64), l: Number((n >> _32n) & U32_MASK64) };
    return { h: Number((n >> _32n) & U32_MASK64) | 0, l: Number(n & U32_MASK64) | 0 };
}
function split(lst, le = false) {
    let Ah = new Uint32Array(lst.length);
    let Al = new Uint32Array(lst.length);
    for (let i = 0; i < lst.length; i++) {
        const { h, l } = fromBig(lst[i], le);
        [Ah[i], Al[i]] = [h, l];
    }
    return [Ah, Al];
}
const toBig = (h, l) => (BigInt(h >>> 0) << _32n) | BigInt(l >>> 0);
// for Shift in [0, 32)
const shrSH = (h, l, s) => h >>> s;
const shrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);
// Right rotate for Shift in [1, 32)
const rotrSH = (h, l, s) => (h >>> s) | (l << (32 - s));
const rotrSL = (h, l, s) => (h << (32 - s)) | (l >>> s);
// Right rotate for Shift in (32, 64), NOTE: 32 is special case.
const rotrBH = (h, l, s) => (h << (64 - s)) | (l >>> (s - 32));
const rotrBL = (h, l, s) => (h >>> (s - 32)) | (l << (64 - s));
// Right rotate for shift===32 (just swaps l&h)
const rotr32H = (h, l) => l;
const rotr32L = (h, l) => h;
// Left rotate for Shift in [1, 32)
const rotlSH = (h, l, s) => (h << s) | (l >>> (32 - s));
const rotlSL = (h, l, s) => (l << s) | (h >>> (32 - s));
// Left rotate for Shift in (32, 64), NOTE: 32 is special case.
const rotlBH = (h, l, s) => (l << (s - 32)) | (h >>> (64 - s));
const rotlBL = (h, l, s) => (h << (s - 32)) | (l >>> (64 - s));
// JS uses 32-bit signed integers for bitwise operations which means we cannot
// simple take carry out of low bit sum by shift, we need to use division.
// Removing "export" has 5% perf penalty -_-
function add(Ah, Al, Bh, Bl) {
    const l = (Al >>> 0) + (Bl >>> 0);
    return { h: (Ah + Bh + ((l / 2 ** 32) | 0)) | 0, l: l | 0 };
}
// Addition with more than 2 elements
const add3L = (Al, Bl, Cl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0);
const add3H = (low, Ah, Bh, Ch) => (Ah + Bh + Ch + ((low / 2 ** 32) | 0)) | 0;
const add4L = (Al, Bl, Cl, Dl) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0);
const add4H = (low, Ah, Bh, Ch, Dh) => (Ah + Bh + Ch + Dh + ((low / 2 ** 32) | 0)) | 0;
const add5L = (Al, Bl, Cl, Dl, El) => (Al >>> 0) + (Bl >>> 0) + (Cl >>> 0) + (Dl >>> 0) + (El >>> 0);
const add5H = (low, Ah, Bh, Ch, Dh, Eh) => (Ah + Bh + Ch + Dh + Eh + ((low / 2 ** 32) | 0)) | 0;
// prettier-ignore
const u64 = {
    fromBig, split, toBig,
    shrSH, shrSL,
    rotrSH, rotrSL, rotrBH, rotrBL,
    rotr32H, rotr32L,
    rotlSH, rotlSL, rotlBH, rotlBL,
    add, add3L, add3H, add4L, add4H, add5H, add5L,
};

// Round contants (first 32 bits of the fractional parts of the cube roots of the first 80 primes 2..409):
// prettier-ignore
const [SHA512_Kh, SHA512_Kl] = u64.split([
    '0x428a2f98d728ae22', '0x7137449123ef65cd', '0xb5c0fbcfec4d3b2f', '0xe9b5dba58189dbbc',
    '0x3956c25bf348b538', '0x59f111f1b605d019', '0x923f82a4af194f9b', '0xab1c5ed5da6d8118',
    '0xd807aa98a3030242', '0x12835b0145706fbe', '0x243185be4ee4b28c', '0x550c7dc3d5ffb4e2',
    '0x72be5d74f27b896f', '0x80deb1fe3b1696b1', '0x9bdc06a725c71235', '0xc19bf174cf692694',
    '0xe49b69c19ef14ad2', '0xefbe4786384f25e3', '0x0fc19dc68b8cd5b5', '0x240ca1cc77ac9c65',
    '0x2de92c6f592b0275', '0x4a7484aa6ea6e483', '0x5cb0a9dcbd41fbd4', '0x76f988da831153b5',
    '0x983e5152ee66dfab', '0xa831c66d2db43210', '0xb00327c898fb213f', '0xbf597fc7beef0ee4',
    '0xc6e00bf33da88fc2', '0xd5a79147930aa725', '0x06ca6351e003826f', '0x142929670a0e6e70',
    '0x27b70a8546d22ffc', '0x2e1b21385c26c926', '0x4d2c6dfc5ac42aed', '0x53380d139d95b3df',
    '0x650a73548baf63de', '0x766a0abb3c77b2a8', '0x81c2c92e47edaee6', '0x92722c851482353b',
    '0xa2bfe8a14cf10364', '0xa81a664bbc423001', '0xc24b8b70d0f89791', '0xc76c51a30654be30',
    '0xd192e819d6ef5218', '0xd69906245565a910', '0xf40e35855771202a', '0x106aa07032bbd1b8',
    '0x19a4c116b8d2d0c8', '0x1e376c085141ab53', '0x2748774cdf8eeb99', '0x34b0bcb5e19b48a8',
    '0x391c0cb3c5c95a63', '0x4ed8aa4ae3418acb', '0x5b9cca4f7763e373', '0x682e6ff3d6b2b8a3',
    '0x748f82ee5defb2fc', '0x78a5636f43172f60', '0x84c87814a1f0ab72', '0x8cc702081a6439ec',
    '0x90befffa23631e28', '0xa4506cebde82bde9', '0xbef9a3f7b2c67915', '0xc67178f2e372532b',
    '0xca273eceea26619c', '0xd186b8c721c0c207', '0xeada7dd6cde0eb1e', '0xf57d4f7fee6ed178',
    '0x06f067aa72176fba', '0x0a637dc5a2c898a6', '0x113f9804bef90dae', '0x1b710b35131c471b',
    '0x28db77f523047d84', '0x32caab7b40c72493', '0x3c9ebe0a15c9bebc', '0x431d67c49c100d4c',
    '0x4cc5d4becb3e42b6', '0x597f299cfc657e2a', '0x5fcb6fab3ad6faec', '0x6c44198c4a475817'
].map(n => BigInt(n)));
// Temporary buffer, not used to store anything between runs
const SHA512_W_H = new Uint32Array(80);
const SHA512_W_L = new Uint32Array(80);
class SHA512 extends SHA2 {
    constructor() {
        super(128, 64, 16, false);
        // We cannot use array here since array allows indexing by variable which means optimizer/compiler cannot use registers.
        // Also looks cleaner and easier to verify with spec.
        // Initial state (first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19):
        // h -- high 32 bits, l -- low 32 bits
        this.Ah = 0x6a09e667 | 0;
        this.Al = 0xf3bcc908 | 0;
        this.Bh = 0xbb67ae85 | 0;
        this.Bl = 0x84caa73b | 0;
        this.Ch = 0x3c6ef372 | 0;
        this.Cl = 0xfe94f82b | 0;
        this.Dh = 0xa54ff53a | 0;
        this.Dl = 0x5f1d36f1 | 0;
        this.Eh = 0x510e527f | 0;
        this.El = 0xade682d1 | 0;
        this.Fh = 0x9b05688c | 0;
        this.Fl = 0x2b3e6c1f | 0;
        this.Gh = 0x1f83d9ab | 0;
        this.Gl = 0xfb41bd6b | 0;
        this.Hh = 0x5be0cd19 | 0;
        this.Hl = 0x137e2179 | 0;
    }
    // prettier-ignore
    get() {
        const { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;
        return [Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl];
    }
    // prettier-ignore
    set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl) {
        this.Ah = Ah | 0;
        this.Al = Al | 0;
        this.Bh = Bh | 0;
        this.Bl = Bl | 0;
        this.Ch = Ch | 0;
        this.Cl = Cl | 0;
        this.Dh = Dh | 0;
        this.Dl = Dl | 0;
        this.Eh = Eh | 0;
        this.El = El | 0;
        this.Fh = Fh | 0;
        this.Fl = Fl | 0;
        this.Gh = Gh | 0;
        this.Gl = Gl | 0;
        this.Hh = Hh | 0;
        this.Hl = Hl | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 64 words w[16..79] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4) {
            SHA512_W_H[i] = view.getUint32(offset);
            SHA512_W_L[i] = view.getUint32((offset += 4));
        }
        for (let i = 16; i < 80; i++) {
            // s0 := (w[i-15] rightrotate 1) xor (w[i-15] rightrotate 8) xor (w[i-15] rightshift 7)
            const W15h = SHA512_W_H[i - 15] | 0;
            const W15l = SHA512_W_L[i - 15] | 0;
            const s0h = u64.rotrSH(W15h, W15l, 1) ^ u64.rotrSH(W15h, W15l, 8) ^ u64.shrSH(W15h, W15l, 7);
            const s0l = u64.rotrSL(W15h, W15l, 1) ^ u64.rotrSL(W15h, W15l, 8) ^ u64.shrSL(W15h, W15l, 7);
            // s1 := (w[i-2] rightrotate 19) xor (w[i-2] rightrotate 61) xor (w[i-2] rightshift 6)
            const W2h = SHA512_W_H[i - 2] | 0;
            const W2l = SHA512_W_L[i - 2] | 0;
            const s1h = u64.rotrSH(W2h, W2l, 19) ^ u64.rotrBH(W2h, W2l, 61) ^ u64.shrSH(W2h, W2l, 6);
            const s1l = u64.rotrSL(W2h, W2l, 19) ^ u64.rotrBL(W2h, W2l, 61) ^ u64.shrSL(W2h, W2l, 6);
            // SHA256_W[i] = s0 + s1 + SHA256_W[i - 7] + SHA256_W[i - 16];
            const SUMl = u64.add4L(s0l, s1l, SHA512_W_L[i - 7], SHA512_W_L[i - 16]);
            const SUMh = u64.add4H(SUMl, s0h, s1h, SHA512_W_H[i - 7], SHA512_W_H[i - 16]);
            SHA512_W_H[i] = SUMh | 0;
            SHA512_W_L[i] = SUMl | 0;
        }
        let { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;
        // Compression function main loop, 80 rounds
        for (let i = 0; i < 80; i++) {
            // S1 := (e rightrotate 14) xor (e rightrotate 18) xor (e rightrotate 41)
            const sigma1h = u64.rotrSH(Eh, El, 14) ^ u64.rotrSH(Eh, El, 18) ^ u64.rotrBH(Eh, El, 41);
            const sigma1l = u64.rotrSL(Eh, El, 14) ^ u64.rotrSL(Eh, El, 18) ^ u64.rotrBL(Eh, El, 41);
            //const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;
            const CHIh = (Eh & Fh) ^ (~Eh & Gh);
            const CHIl = (El & Fl) ^ (~El & Gl);
            // T1 = H + sigma1 + Chi(E, F, G) + SHA512_K[i] + SHA512_W[i]
            // prettier-ignore
            const T1ll = u64.add5L(Hl, sigma1l, CHIl, SHA512_Kl[i], SHA512_W_L[i]);
            const T1h = u64.add5H(T1ll, Hh, sigma1h, CHIh, SHA512_Kh[i], SHA512_W_H[i]);
            const T1l = T1ll | 0;
            // S0 := (a rightrotate 28) xor (a rightrotate 34) xor (a rightrotate 39)
            const sigma0h = u64.rotrSH(Ah, Al, 28) ^ u64.rotrBH(Ah, Al, 34) ^ u64.rotrBH(Ah, Al, 39);
            const sigma0l = u64.rotrSL(Ah, Al, 28) ^ u64.rotrBL(Ah, Al, 34) ^ u64.rotrBL(Ah, Al, 39);
            const MAJh = (Ah & Bh) ^ (Ah & Ch) ^ (Bh & Ch);
            const MAJl = (Al & Bl) ^ (Al & Cl) ^ (Bl & Cl);
            Hh = Gh | 0;
            Hl = Gl | 0;
            Gh = Fh | 0;
            Gl = Fl | 0;
            Fh = Eh | 0;
            Fl = El | 0;
            ({ h: Eh, l: El } = u64.add(Dh | 0, Dl | 0, T1h | 0, T1l | 0));
            Dh = Ch | 0;
            Dl = Cl | 0;
            Ch = Bh | 0;
            Cl = Bl | 0;
            Bh = Ah | 0;
            Bl = Al | 0;
            const All = u64.add3L(T1l, sigma0l, MAJl);
            Ah = u64.add3H(All, T1h, sigma0h, MAJh);
            Al = All | 0;
        }
        // Add the compressed chunk to the current hash value
        ({ h: Ah, l: Al } = u64.add(this.Ah | 0, this.Al | 0, Ah | 0, Al | 0));
        ({ h: Bh, l: Bl } = u64.add(this.Bh | 0, this.Bl | 0, Bh | 0, Bl | 0));
        ({ h: Ch, l: Cl } = u64.add(this.Ch | 0, this.Cl | 0, Ch | 0, Cl | 0));
        ({ h: Dh, l: Dl } = u64.add(this.Dh | 0, this.Dl | 0, Dh | 0, Dl | 0));
        ({ h: Eh, l: El } = u64.add(this.Eh | 0, this.El | 0, Eh | 0, El | 0));
        ({ h: Fh, l: Fl } = u64.add(this.Fh | 0, this.Fl | 0, Fh | 0, Fl | 0));
        ({ h: Gh, l: Gl } = u64.add(this.Gh | 0, this.Gl | 0, Gh | 0, Gl | 0));
        ({ h: Hh, l: Hl } = u64.add(this.Hh | 0, this.Hl | 0, Hh | 0, Hl | 0));
        this.set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl);
    }
    roundClean() {
        SHA512_W_H.fill(0);
        SHA512_W_L.fill(0);
    }
    destroy() {
        this.buffer.fill(0);
        this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
    }
}
class SHA512_224 extends SHA512 {
    constructor() {
        super();
        // h -- high 32 bits, l -- low 32 bits
        this.Ah = 0x8c3d37c8 | 0;
        this.Al = 0x19544da2 | 0;
        this.Bh = 0x73e19966 | 0;
        this.Bl = 0x89dcd4d6 | 0;
        this.Ch = 0x1dfab7ae | 0;
        this.Cl = 0x32ff9c82 | 0;
        this.Dh = 0x679dd514 | 0;
        this.Dl = 0x582f9fcf | 0;
        this.Eh = 0x0f6d2b69 | 0;
        this.El = 0x7bd44da8 | 0;
        this.Fh = 0x77e36f73 | 0;
        this.Fl = 0x04c48942 | 0;
        this.Gh = 0x3f9d85a8 | 0;
        this.Gl = 0x6a1d36c8 | 0;
        this.Hh = 0x1112e6ad | 0;
        this.Hl = 0x91d692a1 | 0;
        this.outputLen = 28;
    }
}
class SHA512_256 extends SHA512 {
    constructor() {
        super();
        // h -- high 32 bits, l -- low 32 bits
        this.Ah = 0x22312194 | 0;
        this.Al = 0xfc2bf72c | 0;
        this.Bh = 0x9f555fa3 | 0;
        this.Bl = 0xc84c64c2 | 0;
        this.Ch = 0x2393b86b | 0;
        this.Cl = 0x6f53b151 | 0;
        this.Dh = 0x96387719 | 0;
        this.Dl = 0x5940eabd | 0;
        this.Eh = 0x96283ee2 | 0;
        this.El = 0xa88effe3 | 0;
        this.Fh = 0xbe5e1e25 | 0;
        this.Fl = 0x53863992 | 0;
        this.Gh = 0x2b0199fc | 0;
        this.Gl = 0x2c85b8aa | 0;
        this.Hh = 0x0eb72ddc | 0;
        this.Hl = 0x81c52ca2 | 0;
        this.outputLen = 32;
    }
}
class SHA384 extends SHA512 {
    constructor() {
        super();
        // h -- high 32 bits, l -- low 32 bits
        this.Ah = 0xcbbb9d5d | 0;
        this.Al = 0xc1059ed8 | 0;
        this.Bh = 0x629a292a | 0;
        this.Bl = 0x367cd507 | 0;
        this.Ch = 0x9159015a | 0;
        this.Cl = 0x3070dd17 | 0;
        this.Dh = 0x152fecd8 | 0;
        this.Dl = 0xf70e5939 | 0;
        this.Eh = 0x67332667 | 0;
        this.El = 0xffc00b31 | 0;
        this.Fh = 0x8eb44a87 | 0;
        this.Fl = 0x68581511 | 0;
        this.Gh = 0xdb0c2e0d | 0;
        this.Gl = 0x64f98fa7 | 0;
        this.Hh = 0x47b5481d | 0;
        this.Hl = 0xbefa4fa4 | 0;
        this.outputLen = 48;
    }
}
const sha512$1 = wrapConstructor(() => new SHA512());
wrapConstructor(() => new SHA512_224());
wrapConstructor(() => new SHA512_256());
wrapConstructor(() => new SHA384());

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// 100 lines of code in the file are duplicated from noble-hashes (utils).
// This is OK: `abstract` directory does not use noble-hashes.
// User may opt-in into using different hashing library. This way, noble-hashes
// won't be included into their bundle.
const _0n$7 = BigInt(0);
const _1n$9 = BigInt(1);
const _2n$6 = BigInt(2);
const u8a = (a) => a instanceof Uint8Array;
const hexes$2 = Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, '0'));
/**
 * @example bytesToHex(Uint8Array.from([0xca, 0xfe, 0x01, 0x23])) // 'cafe0123'
 */
function bytesToHex$2(bytes) {
    if (!u8a(bytes))
        throw new Error('Uint8Array expected');
    // pre-caching improves the speed 6x
    let hex = '';
    for (let i = 0; i < bytes.length; i++) {
        hex += hexes$2[bytes[i]];
    }
    return hex;
}
function numberToHexUnpadded$1(num) {
    const hex = num.toString(16);
    return hex.length & 1 ? `0${hex}` : hex;
}
function hexToNumber$1(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    // Big Endian
    return BigInt(hex === '' ? '0' : `0x${hex}`);
}
/**
 * @example hexToBytes('cafe0123') // Uint8Array.from([0xca, 0xfe, 0x01, 0x23])
 */
function hexToBytes$2(hex) {
    if (typeof hex !== 'string')
        throw new Error('hex string expected, got ' + typeof hex);
    const len = hex.length;
    if (len % 2)
        throw new Error('padded hex string expected, got unpadded hex of length ' + len);
    const array = new Uint8Array(len / 2);
    for (let i = 0; i < array.length; i++) {
        const j = i * 2;
        const hexByte = hex.slice(j, j + 2);
        const byte = Number.parseInt(hexByte, 16);
        if (Number.isNaN(byte) || byte < 0)
            throw new Error('Invalid byte sequence');
        array[i] = byte;
    }
    return array;
}
// BE: Big Endian, LE: Little Endian
function bytesToNumberBE(bytes) {
    return hexToNumber$1(bytesToHex$2(bytes));
}
function bytesToNumberLE$1(bytes) {
    if (!u8a(bytes))
        throw new Error('Uint8Array expected');
    return hexToNumber$1(bytesToHex$2(Uint8Array.from(bytes).reverse()));
}
function numberToBytesBE(n, len) {
    return hexToBytes$2(n.toString(16).padStart(len * 2, '0'));
}
function numberToBytesLE(n, len) {
    return numberToBytesBE(n, len).reverse();
}
// Unpadded, rarely used
function numberToVarBytesBE(n) {
    return hexToBytes$2(numberToHexUnpadded$1(n));
}
/**
 * Takes hex string or Uint8Array, converts to Uint8Array.
 * Validates output length.
 * Will throw error for other types.
 * @param title descriptive title for an error e.g. 'private key'
 * @param hex hex string or Uint8Array
 * @param expectedLength optional, will compare to result array's length
 * @returns
 */
function ensureBytes$2(title, hex, expectedLength) {
    let res;
    if (typeof hex === 'string') {
        try {
            res = hexToBytes$2(hex);
        }
        catch (e) {
            throw new Error(`${title} must be valid hex string, got "${hex}". Cause: ${e}`);
        }
    }
    else if (u8a(hex)) {
        // Uint8Array.from() instead of hash.slice() because node.js Buffer
        // is instance of Uint8Array, and its slice() creates **mutable** copy
        res = Uint8Array.from(hex);
    }
    else {
        throw new Error(`${title} must be hex string or Uint8Array`);
    }
    const len = res.length;
    if (typeof expectedLength === 'number' && len !== expectedLength)
        throw new Error(`${title} expected ${expectedLength} bytes, got ${len}`);
    return res;
}
/**
 * Copies several Uint8Arrays into one.
 */
function concatBytes$2(...arrays) {
    const r = new Uint8Array(arrays.reduce((sum, a) => sum + a.length, 0));
    let pad = 0; // walk through each item, ensure they have proper type
    arrays.forEach((a) => {
        if (!u8a(a))
            throw new Error('Uint8Array expected');
        r.set(a, pad);
        pad += a.length;
    });
    return r;
}
function equalBytes$1(b1, b2) {
    // We don't care about timing attacks here
    if (b1.length !== b2.length)
        return false;
    for (let i = 0; i < b1.length; i++)
        if (b1[i] !== b2[i])
            return false;
    return true;
}
/**
 * @example utf8ToBytes('abc') // new Uint8Array([97, 98, 99])
 */
function utf8ToBytes(str) {
    if (typeof str !== 'string')
        throw new Error(`utf8ToBytes expected string, got ${typeof str}`);
    return new Uint8Array(new TextEncoder().encode(str)); // https://bugzil.la/1681809
}
// Bit operations
/**
 * Calculates amount of bits in a bigint.
 * Same as `n.toString(2).length`
 */
function bitLen(n) {
    let len;
    for (len = 0; n > _0n$7; n >>= _1n$9, len += 1)
        ;
    return len;
}
/**
 * Gets single bit at position.
 * NOTE: first bit position is 0 (same as arrays)
 * Same as `!!+Array.from(n.toString(2)).reverse()[pos]`
 */
function bitGet(n, pos) {
    return (n >> BigInt(pos)) & _1n$9;
}
/**
 * Sets single bit at position.
 */
const bitSet = (n, pos, value) => {
    return n | ((value ? _1n$9 : _0n$7) << BigInt(pos));
};
/**
 * Calculate mask for N bits. Not using ** operator with bigints because of old engines.
 * Same as BigInt(`0b${Array(i).fill('1').join('')}`)
 */
const bitMask = (n) => (_2n$6 << BigInt(n - 1)) - _1n$9;
// DRBG
const u8n = (data) => new Uint8Array(data); // creates Uint8Array
const u8fr = (arr) => Uint8Array.from(arr); // another shortcut
/**
 * Minimal HMAC-DRBG from NIST 800-90 for RFC6979 sigs.
 * @returns function that will call DRBG until 2nd arg returns something meaningful
 * @example
 *   const drbg = createHmacDRBG<Key>(32, 32, hmac);
 *   drbg(seed, bytesToKey); // bytesToKey must return Key or undefined
 */
function createHmacDrbg(hashLen, qByteLen, hmacFn) {
    if (typeof hashLen !== 'number' || hashLen < 2)
        throw new Error('hashLen must be a number');
    if (typeof qByteLen !== 'number' || qByteLen < 2)
        throw new Error('qByteLen must be a number');
    if (typeof hmacFn !== 'function')
        throw new Error('hmacFn must be a function');
    // Step B, Step C: set hashLen to 8*ceil(hlen/8)
    let v = u8n(hashLen); // Minimal non-full-spec HMAC-DRBG from NIST 800-90 for RFC6979 sigs.
    let k = u8n(hashLen); // Steps B and C of RFC6979 3.2: set hashLen, in our case always same
    let i = 0; // Iterations counter, will throw when over 1000
    const reset = () => {
        v.fill(1);
        k.fill(0);
        i = 0;
    };
    const h = (...b) => hmacFn(k, v, ...b); // hmac(k)(v, ...values)
    const reseed = (seed = u8n()) => {
        // HMAC-DRBG reseed() function. Steps D-G
        k = h(u8fr([0x00]), seed); // k = hmac(k || v || 0x00 || seed)
        v = h(); // v = hmac(k || v)
        if (seed.length === 0)
            return;
        k = h(u8fr([0x01]), seed); // k = hmac(k || v || 0x01 || seed)
        v = h(); // v = hmac(k || v)
    };
    const gen = () => {
        // HMAC-DRBG generate() function
        if (i++ >= 1000)
            throw new Error('drbg: tried 1000 values');
        let len = 0;
        const out = [];
        while (len < qByteLen) {
            v = h();
            const sl = v.slice();
            out.push(sl);
            len += v.length;
        }
        return concatBytes$2(...out);
    };
    const genUntil = (seed, pred) => {
        reset();
        reseed(seed); // Steps D-G
        let res = undefined; // Step H: grind until k is in [1..n-1]
        while (!(res = pred(gen())))
            reseed();
        reset();
        return res;
    };
    return genUntil;
}
// Validating curves and fields
const validatorFns = {
    bigint: (val) => typeof val === 'bigint',
    function: (val) => typeof val === 'function',
    boolean: (val) => typeof val === 'boolean',
    string: (val) => typeof val === 'string',
    isSafeInteger: (val) => Number.isSafeInteger(val),
    array: (val) => Array.isArray(val),
    field: (val, object) => object.Fp.isValid(val),
    hash: (val) => typeof val === 'function' && Number.isSafeInteger(val.outputLen),
};
// type Record<K extends string | number | symbol, T> = { [P in K]: T; }
function validateObject(object, validators, optValidators = {}) {
    const checkField = (fieldName, type, isOptional) => {
        const checkVal = validatorFns[type];
        if (typeof checkVal !== 'function')
            throw new Error(`Invalid validator "${type}", expected function`);
        const val = object[fieldName];
        if (isOptional && val === undefined)
            return;
        if (!checkVal(val, object)) {
            throw new Error(`Invalid param ${String(fieldName)}=${val} (${typeof val}), expected ${type}`);
        }
    };
    for (const [fieldName, type] of Object.entries(validators))
        checkField(fieldName, type, false);
    for (const [fieldName, type] of Object.entries(optValidators))
        checkField(fieldName, type, true);
    return object;
}
// validate type tests
// const o: { a: number; b: number; c: number } = { a: 1, b: 5, c: 6 };
// const z0 = validateObject(o, { a: 'isSafeInteger' }, { c: 'bigint' }); // Ok!
// // Should fail type-check
// const z1 = validateObject(o, { a: 'tmp' }, { c: 'zz' });
// const z2 = validateObject(o, { a: 'isSafeInteger' }, { c: 'zz' });
// const z3 = validateObject(o, { test: 'boolean', z: 'bug' });
// const z4 = validateObject(o, { a: 'boolean', z: 'bug' });

var ut = /*#__PURE__*/Object.freeze({
    __proto__: null,
    bitGet: bitGet,
    bitLen: bitLen,
    bitMask: bitMask,
    bitSet: bitSet,
    bytesToHex: bytesToHex$2,
    bytesToNumberBE: bytesToNumberBE,
    bytesToNumberLE: bytesToNumberLE$1,
    concatBytes: concatBytes$2,
    createHmacDrbg: createHmacDrbg,
    ensureBytes: ensureBytes$2,
    equalBytes: equalBytes$1,
    hexToBytes: hexToBytes$2,
    hexToNumber: hexToNumber$1,
    numberToBytesBE: numberToBytesBE,
    numberToBytesLE: numberToBytesLE,
    numberToHexUnpadded: numberToHexUnpadded$1,
    numberToVarBytesBE: numberToVarBytesBE,
    utf8ToBytes: utf8ToBytes,
    validateObject: validateObject
});

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Utilities for modular arithmetics and finite fields
// prettier-ignore
const _0n$6 = BigInt(0), _1n$8 = BigInt(1), _2n$5 = BigInt(2), _3n$2 = BigInt(3);
// prettier-ignore
const _4n = BigInt(4), _5n$1 = BigInt(5), _8n$3 = BigInt(8);
// prettier-ignore
BigInt(9); BigInt(16);
// Calculates a modulo b
function mod$2(a, b) {
    const result = a % b;
    return result >= _0n$6 ? result : b + result;
}
/**
 * Efficiently raise num to power and do modular division.
 * Unsafe in some contexts: uses ladder, so can expose bigint bits.
 * @example
 * pow(2n, 6n, 11n) // 64n % 11n == 9n
 */
// TODO: use field version && remove
function pow(num, power, modulo) {
    if (modulo <= _0n$6 || power < _0n$6)
        throw new Error('Expected power/modulo > 0');
    if (modulo === _1n$8)
        return _0n$6;
    let res = _1n$8;
    while (power > _0n$6) {
        if (power & _1n$8)
            res = (res * num) % modulo;
        num = (num * num) % modulo;
        power >>= _1n$8;
    }
    return res;
}
// Does x ^ (2 ^ power) mod p. pow2(30, 4) == 30 ^ (2 ^ 4)
function pow2$2(x, power, modulo) {
    let res = x;
    while (power-- > _0n$6) {
        res *= res;
        res %= modulo;
    }
    return res;
}
// Inverses number over modulo
function invert$2(number, modulo) {
    if (number === _0n$6 || modulo <= _0n$6) {
        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);
    }
    // Euclidean GCD https://brilliant.org/wiki/extended-euclidean-algorithm/
    // Fermat's little theorem "CT-like" version inv(n) = n^(m-2) mod m is 30x slower.
    let a = mod$2(number, modulo);
    let b = modulo;
    // prettier-ignore
    let x = _0n$6, u = _1n$8;
    while (a !== _0n$6) {
        // JIT applies optimization if those two lines follow each other
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        // prettier-ignore
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n$8)
        throw new Error('invert: does not exist');
    return mod$2(x, modulo);
}
// Tonelli-Shanks algorithm
// Paper 1: https://eprint.iacr.org/2012/685.pdf (page 12)
// Paper 2: Square Roots from 1; 24, 51, 10 to Dan Shanks
function tonelliShanks(P) {
    // Legendre constant: used to calculate Legendre symbol (a | p),
    // which denotes the value of a^((p-1)/2) (mod p).
    // (a | p) ≡ 1    if a is a square (mod p)
    // (a | p) ≡ -1   if a is not a square (mod p)
    // (a | p) ≡ 0    if a ≡ 0 (mod p)
    const legendreC = (P - _1n$8) / _2n$5;
    let Q, S, Z;
    // Step 1: By factoring out powers of 2 from p - 1,
    // find q and s such that p - 1 = q*(2^s) with q odd
    for (Q = P - _1n$8, S = 0; Q % _2n$5 === _0n$6; Q /= _2n$5, S++)
        ;
    // Step 2: Select a non-square z such that (z | p) ≡ -1 and set c ≡ zq
    for (Z = _2n$5; Z < P && pow(Z, legendreC, P) !== P - _1n$8; Z++)
        ;
    // Fast-path
    if (S === 1) {
        const p1div4 = (P + _1n$8) / _4n;
        return function tonelliFast(Fp, n) {
            const root = Fp.pow(n, p1div4);
            if (!Fp.eql(Fp.sqr(root), n))
                throw new Error('Cannot find square root');
            return root;
        };
    }
    // Slow-path
    const Q1div2 = (Q + _1n$8) / _2n$5;
    return function tonelliSlow(Fp, n) {
        // Step 0: Check that n is indeed a square: (n | p) should not be ≡ -1
        if (Fp.pow(n, legendreC) === Fp.neg(Fp.ONE))
            throw new Error('Cannot find square root');
        let r = S;
        // TODO: will fail at Fp2/etc
        let g = Fp.pow(Fp.mul(Fp.ONE, Z), Q); // will update both x and b
        let x = Fp.pow(n, Q1div2); // first guess at the square root
        let b = Fp.pow(n, Q); // first guess at the fudge factor
        while (!Fp.eql(b, Fp.ONE)) {
            if (Fp.eql(b, Fp.ZERO))
                return Fp.ZERO; // https://en.wikipedia.org/wiki/Tonelli%E2%80%93Shanks_algorithm (4. If t = 0, return r = 0)
            // Find m such b^(2^m)==1
            let m = 1;
            for (let t2 = Fp.sqr(b); m < r; m++) {
                if (Fp.eql(t2, Fp.ONE))
                    break;
                t2 = Fp.sqr(t2); // t2 *= t2
            }
            // NOTE: r-m-1 can be bigger than 32, need to convert to bigint before shift, otherwise there will be overflow
            const ge = Fp.pow(g, _1n$8 << BigInt(r - m - 1)); // ge = 2^(r-m-1)
            g = Fp.sqr(ge); // g = ge * ge
            x = Fp.mul(x, ge); // x *= ge
            b = Fp.mul(b, g); // b *= g
            r = m;
        }
        return x;
    };
}
function FpSqrt(P) {
    // NOTE: different algorithms can give different roots, it is up to user to decide which one they want.
    // For example there is FpSqrtOdd/FpSqrtEven to choice root based on oddness (used for hash-to-curve).
    // P ≡ 3 (mod 4)
    // √n = n^((P+1)/4)
    if (P % _4n === _3n$2) {
        // Not all roots possible!
        // const ORDER =
        //   0x1a0111ea397fe69a4b1ba7b6434bacd764774b84f38512bf6730d2a0f6b0f6241eabfffeb153ffffb9feffffffffaaabn;
        // const NUM = 72057594037927816n;
        const p1div4 = (P + _1n$8) / _4n;
        return function sqrt3mod4(Fp, n) {
            const root = Fp.pow(n, p1div4);
            // Throw if root**2 != n
            if (!Fp.eql(Fp.sqr(root), n))
                throw new Error('Cannot find square root');
            return root;
        };
    }
    // Atkin algorithm for q ≡ 5 (mod 8), https://eprint.iacr.org/2012/685.pdf (page 10)
    if (P % _8n$3 === _5n$1) {
        const c1 = (P - _5n$1) / _8n$3;
        return function sqrt5mod8(Fp, n) {
            const n2 = Fp.mul(n, _2n$5);
            const v = Fp.pow(n2, c1);
            const nv = Fp.mul(n, v);
            const i = Fp.mul(Fp.mul(nv, _2n$5), v);
            const root = Fp.mul(nv, Fp.sub(i, Fp.ONE));
            if (!Fp.eql(Fp.sqr(root), n))
                throw new Error('Cannot find square root');
            return root;
        };
    }
    // Other cases: Tonelli-Shanks algorithm
    return tonelliShanks(P);
}
// Little-endian check for first LE bit (last BE bit);
const isNegativeLE = (num, modulo) => (mod$2(num, modulo) & _1n$8) === _1n$8;
// prettier-ignore
const FIELD_FIELDS = [
    'create', 'isValid', 'is0', 'neg', 'inv', 'sqrt', 'sqr',
    'eql', 'add', 'sub', 'mul', 'pow', 'div',
    'addN', 'subN', 'mulN', 'sqrN'
];
function validateField(field) {
    const initial = {
        ORDER: 'bigint',
        MASK: 'bigint',
        BYTES: 'isSafeInteger',
        BITS: 'isSafeInteger',
    };
    const opts = FIELD_FIELDS.reduce((map, val) => {
        map[val] = 'function';
        return map;
    }, initial);
    return validateObject(field, opts);
}
// Generic field functions
function FpPow(f, num, power) {
    // Should have same speed as pow for bigints
    // TODO: benchmark!
    if (power < _0n$6)
        throw new Error('Expected power > 0');
    if (power === _0n$6)
        return f.ONE;
    if (power === _1n$8)
        return num;
    let p = f.ONE;
    let d = num;
    while (power > _0n$6) {
        if (power & _1n$8)
            p = f.mul(p, d);
        d = f.sqr(d);
        power >>= _1n$8;
    }
    return p;
}
// 0 is non-invertible: non-batched version will throw on 0
function FpInvertBatch(f, nums) {
    const tmp = new Array(nums.length);
    // Walk from first to last, multiply them by each other MOD p
    const lastMultiplied = nums.reduce((acc, num, i) => {
        if (f.is0(num))
            return acc;
        tmp[i] = acc;
        return f.mul(acc, num);
    }, f.ONE);
    // Invert last element
    const inverted = f.inv(lastMultiplied);
    // Walk from last to first, multiply them by inverted each other MOD p
    nums.reduceRight((acc, num, i) => {
        if (f.is0(num))
            return acc;
        tmp[i] = f.mul(acc, tmp[i]);
        return f.mul(acc, num);
    }, inverted);
    return tmp;
}
// CURVE.n lengths
function nLength(n, nBitLength) {
    // Bit size, byte size of CURVE.n
    const _nBitLength = nBitLength !== undefined ? nBitLength : n.toString(2).length;
    const nByteLength = Math.ceil(_nBitLength / 8);
    return { nBitLength: _nBitLength, nByteLength };
}
/**
 * Initializes a galois field over prime. Non-primes are not supported for now.
 * Do not init in loop: slow. Very fragile: always run a benchmark on change.
 * Major performance gains:
 * a) non-normalized operations like mulN instead of mul
 * b) `Object.freeze`
 * c) Same object shape: never add or remove keys
 * @param ORDER prime positive bigint
 * @param bitLen how many bits the field consumes
 * @param isLE (def: false) if encoding / decoding should be in little-endian
 * @param redef optional faster redefinitions of sqrt and other methods
 */
function Field(ORDER, bitLen, isLE = false, redef = {}) {
    if (ORDER <= _0n$6)
        throw new Error(`Expected Fp ORDER > 0, got ${ORDER}`);
    const { nBitLength: BITS, nByteLength: BYTES } = nLength(ORDER, bitLen);
    if (BYTES > 2048)
        throw new Error('Field lengths over 2048 bytes are not supported');
    const sqrtP = FpSqrt(ORDER);
    const f = Object.freeze({
        ORDER,
        BITS,
        BYTES,
        MASK: bitMask(BITS),
        ZERO: _0n$6,
        ONE: _1n$8,
        create: (num) => mod$2(num, ORDER),
        isValid: (num) => {
            if (typeof num !== 'bigint')
                throw new Error(`Invalid field element: expected bigint, got ${typeof num}`);
            return _0n$6 <= num && num < ORDER; // 0 is valid element, but it's not invertible
        },
        is0: (num) => num === _0n$6,
        isOdd: (num) => (num & _1n$8) === _1n$8,
        neg: (num) => mod$2(-num, ORDER),
        eql: (lhs, rhs) => lhs === rhs,
        sqr: (num) => mod$2(num * num, ORDER),
        add: (lhs, rhs) => mod$2(lhs + rhs, ORDER),
        sub: (lhs, rhs) => mod$2(lhs - rhs, ORDER),
        mul: (lhs, rhs) => mod$2(lhs * rhs, ORDER),
        pow: (num, power) => FpPow(f, num, power),
        div: (lhs, rhs) => mod$2(lhs * invert$2(rhs, ORDER), ORDER),
        // Same as above, but doesn't normalize
        sqrN: (num) => num * num,
        addN: (lhs, rhs) => lhs + rhs,
        subN: (lhs, rhs) => lhs - rhs,
        mulN: (lhs, rhs) => lhs * rhs,
        inv: (num) => invert$2(num, ORDER),
        sqrt: redef.sqrt || ((n) => sqrtP(f, n)),
        invertBatch: (lst) => FpInvertBatch(f, lst),
        // TODO: do we really need constant cmov?
        // We don't have const-time bigints anyway, so probably will be not very useful
        cmov: (a, b, c) => (c ? b : a),
        toBytes: (num) => (isLE ? numberToBytesLE(num, BYTES) : numberToBytesBE(num, BYTES)),
        fromBytes: (bytes) => {
            if (bytes.length !== BYTES)
                throw new Error(`Fp.fromBytes: expected ${BYTES}, got ${bytes.length}`);
            return isLE ? bytesToNumberLE$1(bytes) : bytesToNumberBE(bytes);
        },
    });
    return Object.freeze(f);
}
function FpSqrtEven(Fp, elm) {
    if (!Fp.isOdd)
        throw new Error(`Field doesn't have isOdd`);
    const root = Fp.sqrt(elm);
    return Fp.isOdd(root) ? Fp.neg(root) : root;
}
/**
 * FIPS 186 B.4.1-compliant "constant-time" private key generation utility.
 * Can take (n+8) or more bytes of uniform input e.g. from CSPRNG or KDF
 * and convert them into private scalar, with the modulo bias being negligible.
 * Needs at least 40 bytes of input for 32-byte private key.
 * https://research.kudelskisecurity.com/2020/07/28/the-definitive-guide-to-modulo-bias-and-how-to-avoid-it/
 * @param hash hash output from SHA3 or a similar function
 * @param groupOrder size of subgroup - (e.g. curveFn.CURVE.n)
 * @param isLE interpret hash bytes as LE num
 * @returns valid private scalar
 */
function hashToPrivateScalar(hash, groupOrder, isLE = false) {
    hash = ensureBytes$2('privateHash', hash);
    const hashLen = hash.length;
    const minLen = nLength(groupOrder).nByteLength + 8;
    if (minLen < 24 || hashLen < minLen || hashLen > 1024)
        throw new Error(`hashToPrivateScalar: expected ${minLen}-1024 bytes of input, got ${hashLen}`);
    const num = isLE ? bytesToNumberLE$1(hash) : bytesToNumberBE(hash);
    return mod$2(num, groupOrder - _1n$8) + _1n$8;
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Abelian group utilities
const _0n$5 = BigInt(0);
const _1n$7 = BigInt(1);
// Elliptic curve multiplication of Point by scalar. Fragile.
// Scalars should always be less than curve order: this should be checked inside of a curve itself.
// Creates precomputation tables for fast multiplication:
// - private scalar is split by fixed size windows of W bits
// - every window point is collected from window's table & added to accumulator
// - since windows are different, same point inside tables won't be accessed more than once per calc
// - each multiplication is 'Math.ceil(CURVE_ORDER / 𝑊) + 1' point additions (fixed for any scalar)
// - +1 window is neccessary for wNAF
// - wNAF reduces table size: 2x less memory + 2x faster generation, but 10% slower multiplication
// TODO: Research returning 2d JS array of windows, instead of a single window. This would allow
// windows to be in different memory locations
function wNAF(c, bits) {
    const constTimeNegate = (condition, item) => {
        const neg = item.negate();
        return condition ? neg : item;
    };
    const opts = (W) => {
        const windows = Math.ceil(bits / W) + 1; // +1, because
        const windowSize = 2 ** (W - 1); // -1 because we skip zero
        return { windows, windowSize };
    };
    return {
        constTimeNegate,
        // non-const time multiplication ladder
        unsafeLadder(elm, n) {
            let p = c.ZERO;
            let d = elm;
            while (n > _0n$5) {
                if (n & _1n$7)
                    p = p.add(d);
                d = d.double();
                n >>= _1n$7;
            }
            return p;
        },
        /**
         * Creates a wNAF precomputation window. Used for caching.
         * Default window size is set by `utils.precompute()` and is equal to 8.
         * Number of precomputed points depends on the curve size:
         * 2^(𝑊−1) * (Math.ceil(𝑛 / 𝑊) + 1), where:
         * - 𝑊 is the window size
         * - 𝑛 is the bitlength of the curve order.
         * For a 256-bit curve and window size 8, the number of precomputed points is 128 * 33 = 4224.
         * @returns precomputed point tables flattened to a single array
         */
        precomputeWindow(elm, W) {
            const { windows, windowSize } = opts(W);
            const points = [];
            let p = elm;
            let base = p;
            for (let window = 0; window < windows; window++) {
                base = p;
                points.push(base);
                // =1, because we skip zero
                for (let i = 1; i < windowSize; i++) {
                    base = base.add(p);
                    points.push(base);
                }
                p = base.double();
            }
            return points;
        },
        /**
         * Implements ec multiplication using precomputed tables and w-ary non-adjacent form.
         * @param W window size
         * @param precomputes precomputed tables
         * @param n scalar (we don't check here, but should be less than curve order)
         * @returns real and fake (for const-time) points
         */
        wNAF(W, precomputes, n) {
            // TODO: maybe check that scalar is less than group order? wNAF behavious is undefined otherwise
            // But need to carefully remove other checks before wNAF. ORDER == bits here
            const { windows, windowSize } = opts(W);
            let p = c.ZERO;
            let f = c.BASE;
            const mask = BigInt(2 ** W - 1); // Create mask with W ones: 0b1111 for W=4 etc.
            const maxNumber = 2 ** W;
            const shiftBy = BigInt(W);
            for (let window = 0; window < windows; window++) {
                const offset = window * windowSize;
                // Extract W bits.
                let wbits = Number(n & mask);
                // Shift number by W bits.
                n >>= shiftBy;
                // If the bits are bigger than max size, we'll split those.
                // +224 => 256 - 32
                if (wbits > windowSize) {
                    wbits -= maxNumber;
                    n += _1n$7;
                }
                // This code was first written with assumption that 'f' and 'p' will never be infinity point:
                // since each addition is multiplied by 2 ** W, it cannot cancel each other. However,
                // there is negate now: it is possible that negated element from low value
                // would be the same as high element, which will create carry into next window.
                // It's not obvious how this can fail, but still worth investigating later.
                // Check if we're onto Zero point.
                // Add random point inside current window to f.
                const offset1 = offset;
                const offset2 = offset + Math.abs(wbits) - 1; // -1 because we skip zero
                const cond1 = window % 2 !== 0;
                const cond2 = wbits < 0;
                if (wbits === 0) {
                    // The most important part for const-time getPublicKey
                    f = f.add(constTimeNegate(cond1, precomputes[offset1]));
                }
                else {
                    p = p.add(constTimeNegate(cond2, precomputes[offset2]));
                }
            }
            // JIT-compiler should not eliminate f here, since it will later be used in normalizeZ()
            // Even if the variable is still unused, there are some checks which will
            // throw an exception, so compiler needs to prove they won't happen, which is hard.
            // At this point there is a way to F be infinity-point even if p is not,
            // which makes it less const-time: around 1 bigint multiply.
            return { p, f };
        },
        wNAFCached(P, precomputesMap, n, transform) {
            // @ts-ignore
            const W = P._WINDOW_SIZE || 1;
            // Calculate precomputes on a first run, reuse them after
            let comp = precomputesMap.get(P);
            if (!comp) {
                comp = this.precomputeWindow(P, W);
                if (W !== 1) {
                    precomputesMap.set(P, transform(comp));
                }
            }
            return this.wNAF(W, comp, n);
        },
    };
}
function validateBasic(curve) {
    validateField(curve.Fp);
    validateObject(curve, {
        n: 'bigint',
        h: 'bigint',
        Gx: 'field',
        Gy: 'field',
    }, {
        nBitLength: 'isSafeInteger',
        nByteLength: 'isSafeInteger',
    });
    // Set defaults
    return Object.freeze({
        ...nLength(curve.n, curve.nBitLength),
        ...curve,
        ...{ p: curve.Fp.ORDER },
    });
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Twisted Edwards curve. The formula is: ax² + y² = 1 + dx²y²
// Be friendly to bad ECMAScript parsers by not using bigint literals
// prettier-ignore
const _0n$4 = BigInt(0), _1n$6 = BigInt(1), _2n$4 = BigInt(2), _8n$2 = BigInt(8);
// verification rule is either zip215 or rfc8032 / nist186-5. Consult fromHex:
const VERIFY_DEFAULT = { zip215: true };
function validateOpts$2(curve) {
    const opts = validateBasic(curve);
    validateObject(curve, {
        hash: 'function',
        a: 'bigint',
        d: 'bigint',
        randomBytes: 'function',
    }, {
        adjustScalarBytes: 'function',
        domain: 'function',
        uvRatio: 'function',
        mapToCurve: 'function',
    });
    // Set defaults
    return Object.freeze({ ...opts });
}
// It is not generic twisted curve for now, but ed25519/ed448 generic implementation
function twistedEdwards(curveDef) {
    const CURVE = validateOpts$2(curveDef);
    const { Fp, n: CURVE_ORDER, prehash: prehash, hash: cHash, randomBytes, nByteLength, h: cofactor, } = CURVE;
    const MASK = _2n$4 << (BigInt(nByteLength * 8) - _1n$6);
    const modP = Fp.create; // Function overrides
    // sqrt(u/v)
    const uvRatio = CURVE.uvRatio ||
        ((u, v) => {
            try {
                return { isValid: true, value: Fp.sqrt(u * Fp.inv(v)) };
            }
            catch (e) {
                return { isValid: false, value: _0n$4 };
            }
        });
    const adjustScalarBytes = CURVE.adjustScalarBytes || ((bytes) => bytes); // NOOP
    const domain = CURVE.domain ||
        ((data, ctx, phflag) => {
            if (ctx.length || phflag)
                throw new Error('Contexts/pre-hash are not supported');
            return data;
        }); // NOOP
    const inBig = (n) => typeof n === 'bigint' && _0n$4 < n; // n in [1..]
    const inRange = (n, max) => inBig(n) && inBig(max) && n < max; // n in [1..max-1]
    const in0MaskRange = (n) => n === _0n$4 || inRange(n, MASK); // n in [0..MASK-1]
    function assertInRange(n, max) {
        // n in [1..max-1]
        if (inRange(n, max))
            return n;
        throw new Error(`Expected valid scalar < ${max}, got ${typeof n} ${n}`);
    }
    function assertGE0(n) {
        // n in [0..CURVE_ORDER-1]
        return n === _0n$4 ? n : assertInRange(n, CURVE_ORDER); // GE = prime subgroup, not full group
    }
    const pointPrecomputes = new Map();
    function isPoint(other) {
        if (!(other instanceof Point))
            throw new Error('ExtendedPoint expected');
    }
    // Extended Point works in extended coordinates: (x, y, z, t) ∋ (x=x/z, y=y/z, t=xy).
    // https://en.wikipedia.org/wiki/Twisted_Edwards_curve#Extended_coordinates
    class Point {
        constructor(ex, ey, ez, et) {
            this.ex = ex;
            this.ey = ey;
            this.ez = ez;
            this.et = et;
            if (!in0MaskRange(ex))
                throw new Error('x required');
            if (!in0MaskRange(ey))
                throw new Error('y required');
            if (!in0MaskRange(ez))
                throw new Error('z required');
            if (!in0MaskRange(et))
                throw new Error('t required');
        }
        get x() {
            return this.toAffine().x;
        }
        get y() {
            return this.toAffine().y;
        }
        static fromAffine(p) {
            if (p instanceof Point)
                throw new Error('extended point not allowed');
            const { x, y } = p || {};
            if (!in0MaskRange(x) || !in0MaskRange(y))
                throw new Error('invalid affine point');
            return new Point(x, y, _1n$6, modP(x * y));
        }
        static normalizeZ(points) {
            const toInv = Fp.invertBatch(points.map((p) => p.ez));
            return points.map((p, i) => p.toAffine(toInv[i])).map(Point.fromAffine);
        }
        // "Private method", don't use it directly
        _setWindowSize(windowSize) {
            this._WINDOW_SIZE = windowSize;
            pointPrecomputes.delete(this);
        }
        // Not required for fromHex(), which always creates valid points.
        // Could be useful for fromAffine().
        assertValidity() {
            const { a, d } = CURVE;
            if (this.is0())
                throw new Error('bad point: ZERO'); // TODO: optimize, with vars below?
            // Equation in affine coordinates: ax² + y² = 1 + dx²y²
            // Equation in projective coordinates (X/Z, Y/Z, Z):  (aX² + Y²)Z² = Z⁴ + dX²Y²
            const { ex: X, ey: Y, ez: Z, et: T } = this;
            const X2 = modP(X * X); // X²
            const Y2 = modP(Y * Y); // Y²
            const Z2 = modP(Z * Z); // Z²
            const Z4 = modP(Z2 * Z2); // Z⁴
            const aX2 = modP(X2 * a); // aX²
            const left = modP(Z2 * modP(aX2 + Y2)); // (aX² + Y²)Z²
            const right = modP(Z4 + modP(d * modP(X2 * Y2))); // Z⁴ + dX²Y²
            if (left !== right)
                throw new Error('bad point: equation left != right (1)');
            // In Extended coordinates we also have T, which is x*y=T/Z: check X*Y == Z*T
            const XY = modP(X * Y);
            const ZT = modP(Z * T);
            if (XY !== ZT)
                throw new Error('bad point: equation left != right (2)');
        }
        // Compare one point to another.
        equals(other) {
            isPoint(other);
            const { ex: X1, ey: Y1, ez: Z1 } = this;
            const { ex: X2, ey: Y2, ez: Z2 } = other;
            const X1Z2 = modP(X1 * Z2);
            const X2Z1 = modP(X2 * Z1);
            const Y1Z2 = modP(Y1 * Z2);
            const Y2Z1 = modP(Y2 * Z1);
            return X1Z2 === X2Z1 && Y1Z2 === Y2Z1;
        }
        is0() {
            return this.equals(Point.ZERO);
        }
        negate() {
            // Flips point sign to a negative one (-x, y in affine coords)
            return new Point(modP(-this.ex), this.ey, this.ez, modP(-this.et));
        }
        // Fast algo for doubling Extended Point.
        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#doubling-dbl-2008-hwcd
        // Cost: 4M + 4S + 1*a + 6add + 1*2.
        double() {
            const { a } = CURVE;
            const { ex: X1, ey: Y1, ez: Z1 } = this;
            const A = modP(X1 * X1); // A = X12
            const B = modP(Y1 * Y1); // B = Y12
            const C = modP(_2n$4 * modP(Z1 * Z1)); // C = 2*Z12
            const D = modP(a * A); // D = a*A
            const x1y1 = X1 + Y1;
            const E = modP(modP(x1y1 * x1y1) - A - B); // E = (X1+Y1)2-A-B
            const G = D + B; // G = D+B
            const F = G - C; // F = G-C
            const H = D - B; // H = D-B
            const X3 = modP(E * F); // X3 = E*F
            const Y3 = modP(G * H); // Y3 = G*H
            const T3 = modP(E * H); // T3 = E*H
            const Z3 = modP(F * G); // Z3 = F*G
            return new Point(X3, Y3, Z3, T3);
        }
        // Fast algo for adding 2 Extended Points.
        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#addition-add-2008-hwcd
        // Cost: 9M + 1*a + 1*d + 7add.
        add(other) {
            isPoint(other);
            const { a, d } = CURVE;
            const { ex: X1, ey: Y1, ez: Z1, et: T1 } = this;
            const { ex: X2, ey: Y2, ez: Z2, et: T2 } = other;
            // Faster algo for adding 2 Extended Points when curve's a=-1.
            // http://hyperelliptic.org/EFD/g1p/auto-twisted-extended-1.html#addition-add-2008-hwcd-4
            // Cost: 8M + 8add + 2*2.
            // Note: It does not check whether the `other` point is valid.
            if (a === BigInt(-1)) {
                const A = modP((Y1 - X1) * (Y2 + X2));
                const B = modP((Y1 + X1) * (Y2 - X2));
                const F = modP(B - A);
                if (F === _0n$4)
                    return this.double(); // Same point. Tests say it doesn't affect timing
                const C = modP(Z1 * _2n$4 * T2);
                const D = modP(T1 * _2n$4 * Z2);
                const E = D + C;
                const G = B + A;
                const H = D - C;
                const X3 = modP(E * F);
                const Y3 = modP(G * H);
                const T3 = modP(E * H);
                const Z3 = modP(F * G);
                return new Point(X3, Y3, Z3, T3);
            }
            const A = modP(X1 * X2); // A = X1*X2
            const B = modP(Y1 * Y2); // B = Y1*Y2
            const C = modP(T1 * d * T2); // C = T1*d*T2
            const D = modP(Z1 * Z2); // D = Z1*Z2
            const E = modP((X1 + Y1) * (X2 + Y2) - A - B); // E = (X1+Y1)*(X2+Y2)-A-B
            const F = D - C; // F = D-C
            const G = D + C; // G = D+C
            const H = modP(B - a * A); // H = B-a*A
            const X3 = modP(E * F); // X3 = E*F
            const Y3 = modP(G * H); // Y3 = G*H
            const T3 = modP(E * H); // T3 = E*H
            const Z3 = modP(F * G); // Z3 = F*G
            return new Point(X3, Y3, Z3, T3);
        }
        subtract(other) {
            return this.add(other.negate());
        }
        wNAF(n) {
            return wnaf.wNAFCached(this, pointPrecomputes, n, Point.normalizeZ);
        }
        // Constant-time multiplication.
        multiply(scalar) {
            const { p, f } = this.wNAF(assertInRange(scalar, CURVE_ORDER));
            return Point.normalizeZ([p, f])[0];
        }
        // Non-constant-time multiplication. Uses double-and-add algorithm.
        // It's faster, but should only be used when you don't care about
        // an exposed private key e.g. sig verification.
        // Does NOT allow scalars higher than CURVE.n.
        multiplyUnsafe(scalar) {
            let n = assertGE0(scalar); // 0 <= scalar < CURVE.n
            if (n === _0n$4)
                return I;
            if (this.equals(I) || n === _1n$6)
                return this;
            if (this.equals(G))
                return this.wNAF(n).p;
            return wnaf.unsafeLadder(this, n);
        }
        // Checks if point is of small order.
        // If you add something to small order point, you will have "dirty"
        // point with torsion component.
        // Multiplies point by cofactor and checks if the result is 0.
        isSmallOrder() {
            return this.multiplyUnsafe(cofactor).is0();
        }
        // Multiplies point by curve order and checks if the result is 0.
        // Returns `false` is the point is dirty.
        isTorsionFree() {
            return wnaf.unsafeLadder(this, CURVE_ORDER).is0();
        }
        // Converts Extended point to default (x, y) coordinates.
        // Can accept precomputed Z^-1 - for example, from invertBatch.
        toAffine(iz) {
            const { ex: x, ey: y, ez: z } = this;
            const is0 = this.is0();
            if (iz == null)
                iz = is0 ? _8n$2 : Fp.inv(z); // 8 was chosen arbitrarily
            const ax = modP(x * iz);
            const ay = modP(y * iz);
            const zz = modP(z * iz);
            if (is0)
                return { x: _0n$4, y: _1n$6 };
            if (zz !== _1n$6)
                throw new Error('invZ was invalid');
            return { x: ax, y: ay };
        }
        clearCofactor() {
            const { h: cofactor } = CURVE;
            if (cofactor === _1n$6)
                return this;
            return this.multiplyUnsafe(cofactor);
        }
        // Converts hash string or Uint8Array to Point.
        // Uses algo from RFC8032 5.1.3.
        static fromHex(hex, zip215 = false) {
            const { d, a } = CURVE;
            const len = Fp.BYTES;
            hex = ensureBytes$2('pointHex', hex, len); // copy hex to a new array
            const normed = hex.slice(); // copy again, we'll manipulate it
            const lastByte = hex[len - 1]; // select last byte
            normed[len - 1] = lastByte & ~0x80; // clear last bit
            const y = bytesToNumberLE$1(normed);
            if (y === _0n$4) ;
            else {
                // RFC8032 prohibits >= p, but ZIP215 doesn't
                if (zip215)
                    assertInRange(y, MASK); // zip215=true [1..P-1] (2^255-19-1 for ed25519)
                else
                    assertInRange(y, Fp.ORDER); // zip215=false [1..MASK-1] (2^256-1 for ed25519)
            }
            // Ed25519: x² = (y²-1)/(dy²+1) mod p. Ed448: x² = (y²-1)/(dy²-1) mod p. Generic case:
            // ax²+y²=1+dx²y² => y²-1=dx²y²-ax² => y²-1=x²(dy²-a) => x²=(y²-1)/(dy²-a)
            const y2 = modP(y * y); // denominator is always non-0 mod p.
            const u = modP(y2 - _1n$6); // u = y² - 1
            const v = modP(d * y2 - a); // v = d y² + 1.
            let { isValid, value: x } = uvRatio(u, v); // √(u/v)
            if (!isValid)
                throw new Error('Point.fromHex: invalid y coordinate');
            const isXOdd = (x & _1n$6) === _1n$6; // There are 2 square roots. Use x_0 bit to select proper
            const isLastByteOdd = (lastByte & 0x80) !== 0; // x_0, last bit
            if (!zip215 && x === _0n$4 && isLastByteOdd)
                // if x=0 and x_0 = 1, fail
                throw new Error('Point.fromHex: x=0 and x_0=1');
            if (isLastByteOdd !== isXOdd)
                x = modP(-x); // if x_0 != x mod 2, set x = p-x
            return Point.fromAffine({ x, y });
        }
        static fromPrivateKey(privKey) {
            return getExtendedPublicKey(privKey).point;
        }
        toRawBytes() {
            const { x, y } = this.toAffine();
            const bytes = numberToBytesLE(y, Fp.BYTES); // each y has 2 x values (x, -y)
            bytes[bytes.length - 1] |= x & _1n$6 ? 0x80 : 0; // when compressing, it's enough to store y
            return bytes; // and use the last byte to encode sign of x
        }
        toHex() {
            return bytesToHex$2(this.toRawBytes()); // Same as toRawBytes, but returns string.
        }
    }
    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, _1n$6, modP(CURVE.Gx * CURVE.Gy));
    Point.ZERO = new Point(_0n$4, _1n$6, _1n$6, _0n$4); // 0, 1, 1, 0
    const { BASE: G, ZERO: I } = Point;
    const wnaf = wNAF(Point, nByteLength * 8);
    function modN(a) {
        return mod$2(a, CURVE_ORDER);
    }
    // Little-endian SHA512 with modulo n
    function modN_LE(hash) {
        return modN(bytesToNumberLE$1(hash));
    }
    /** Convenience method that creates public key and other stuff. RFC8032 5.1.5 */
    function getExtendedPublicKey(key) {
        const len = nByteLength;
        key = ensureBytes$2('private key', key, len);
        // Hash private key with curve's hash function to produce uniformingly random input
        // Check byte lengths: ensure(64, h(ensure(32, key)))
        const hashed = ensureBytes$2('hashed private key', cHash(key), 2 * len);
        const head = adjustScalarBytes(hashed.slice(0, len)); // clear first half bits, produce FE
        const prefix = hashed.slice(len, 2 * len); // second half is called key prefix (5.1.6)
        const scalar = modN_LE(head); // The actual private scalar
        const point = G.multiply(scalar); // Point on Edwards curve aka public key
        const pointBytes = point.toRawBytes(); // Uint8Array representation
        return { head, prefix, scalar, point, pointBytes };
    }
    // Calculates EdDSA pub key. RFC8032 5.1.5. Privkey is hashed. Use first half with 3 bits cleared
    function getPublicKey(privKey) {
        return getExtendedPublicKey(privKey).pointBytes;
    }
    // int('LE', SHA512(dom2(F, C) || msgs)) mod N
    function hashDomainToScalar(context = new Uint8Array(), ...msgs) {
        const msg = concatBytes$2(...msgs);
        return modN_LE(cHash(domain(msg, ensureBytes$2('context', context), !!prehash)));
    }
    /** Signs message with privateKey. RFC8032 5.1.6 */
    function sign(msg, privKey, options = {}) {
        msg = ensureBytes$2('message', msg);
        if (prehash)
            msg = prehash(msg); // for ed25519ph etc.
        const { prefix, scalar, pointBytes } = getExtendedPublicKey(privKey);
        const r = hashDomainToScalar(options.context, prefix, msg); // r = dom2(F, C) || prefix || PH(M)
        const R = G.multiply(r).toRawBytes(); // R = rG
        const k = hashDomainToScalar(options.context, R, pointBytes, msg); // R || A || PH(M)
        const s = modN(r + k * scalar); // S = (r + k * s) mod L
        assertGE0(s); // 0 <= s < l
        const res = concatBytes$2(R, numberToBytesLE(s, Fp.BYTES));
        return ensureBytes$2('result', res, nByteLength * 2); // 64-byte signature
    }
    const verifyOpts = VERIFY_DEFAULT;
    function verify(sig, msg, publicKey, options = verifyOpts) {
        const { context, zip215 } = options;
        const len = Fp.BYTES; // Verifies EdDSA signature against message and public key. RFC8032 5.1.7.
        sig = ensureBytes$2('signature', sig, 2 * len); // An extended group equation is checked.
        msg = ensureBytes$2('message', msg);
        if (prehash)
            msg = prehash(msg); // for ed25519ph, etc
        const s = bytesToNumberLE$1(sig.slice(len, 2 * len));
        // zip215: true is good for consensus-critical apps and allows points < 2^256
        // zip215: false follows RFC8032 / NIST186-5 and restricts points to CURVE.p
        let A, R, SB;
        try {
            A = Point.fromHex(publicKey, zip215);
            R = Point.fromHex(sig.slice(0, len), zip215);
            SB = G.multiplyUnsafe(s); // 0 <= s < l is done inside
        }
        catch (error) {
            return false;
        }
        if (!zip215 && A.isSmallOrder())
            return false;
        const k = hashDomainToScalar(context, R.toRawBytes(), A.toRawBytes(), msg);
        const RkA = R.add(A.multiplyUnsafe(k));
        // [8][S]B = [8]R + [8][k]A'
        return RkA.subtract(SB).clearCofactor().equals(Point.ZERO);
    }
    G._setWindowSize(8); // Enable precomputes. Slows down first publicKey computation by 20ms.
    const utils = {
        getExtendedPublicKey,
        // ed25519 private keys are uniform 32b. No need to check for modulo bias, like in secp256k1.
        randomPrivateKey: () => randomBytes(Fp.BYTES),
        /**
         * We're doing scalar multiplication (used in getPublicKey etc) with precomputed BASE_POINT
         * values. This slows down first getPublicKey() by milliseconds (see Speed section),
         * but allows to speed-up subsequent getPublicKey() calls up to 20x.
         * @param windowSize 2, 4, 8, 16
         */
        precompute(windowSize = 8, point = Point.BASE) {
            point._setWindowSize(windowSize);
            point.multiply(BigInt(3));
            return point;
        },
    };
    return {
        CURVE,
        getPublicKey,
        sign,
        verify,
        ExtendedPoint: Point,
        utils,
    };
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const _0n$3 = BigInt(0);
const _1n$5 = BigInt(1);
function validateOpts$1(curve) {
    validateObject(curve, {
        a: 'bigint',
    }, {
        montgomeryBits: 'isSafeInteger',
        nByteLength: 'isSafeInteger',
        adjustScalarBytes: 'function',
        domain: 'function',
        powPminus2: 'function',
        Gu: 'bigint',
    });
    // Set defaults
    return Object.freeze({ ...curve });
}
// NOTE: not really montgomery curve, just bunch of very specific methods for X25519/X448 (RFC 7748, https://www.rfc-editor.org/rfc/rfc7748)
// Uses only one coordinate instead of two
function montgomery(curveDef) {
    const CURVE = validateOpts$1(curveDef);
    const { P } = CURVE;
    const modP = (n) => mod$2(n, P);
    const montgomeryBits = CURVE.montgomeryBits;
    const montgomeryBytes = Math.ceil(montgomeryBits / 8);
    const fieldLen = CURVE.nByteLength;
    const adjustScalarBytes = CURVE.adjustScalarBytes || ((bytes) => bytes);
    const powPminus2 = CURVE.powPminus2 || ((x) => pow(x, P - BigInt(2), P));
    // cswap from RFC7748. But it is not from RFC7748!
    /*
      cswap(swap, x_2, x_3):
           dummy = mask(swap) AND (x_2 XOR x_3)
           x_2 = x_2 XOR dummy
           x_3 = x_3 XOR dummy
           Return (x_2, x_3)
    Where mask(swap) is the all-1 or all-0 word of the same length as x_2
     and x_3, computed, e.g., as mask(swap) = 0 - swap.
    */
    function cswap(swap, x_2, x_3) {
        const dummy = modP(swap * (x_2 - x_3));
        x_2 = modP(x_2 - dummy);
        x_3 = modP(x_3 + dummy);
        return [x_2, x_3];
    }
    // Accepts 0 as well
    function assertFieldElement(n) {
        if (typeof n === 'bigint' && _0n$3 <= n && n < P)
            return n;
        throw new Error('Expected valid scalar 0 < scalar < CURVE.P');
    }
    // x25519 from 4
    // The constant a24 is (486662 - 2) / 4 = 121665 for curve25519/X25519
    const a24 = (CURVE.a - BigInt(2)) / BigInt(4);
    /**
     *
     * @param pointU u coordinate (x) on Montgomery Curve 25519
     * @param scalar by which the point would be multiplied
     * @returns new Point on Montgomery curve
     */
    function montgomeryLadder(pointU, scalar) {
        const u = assertFieldElement(pointU);
        // Section 5: Implementations MUST accept non-canonical values and process them as
        // if they had been reduced modulo the field prime.
        const k = assertFieldElement(scalar);
        const x_1 = u;
        let x_2 = _1n$5;
        let z_2 = _0n$3;
        let x_3 = u;
        let z_3 = _1n$5;
        let swap = _0n$3;
        let sw;
        for (let t = BigInt(montgomeryBits - 1); t >= _0n$3; t--) {
            const k_t = (k >> t) & _1n$5;
            swap ^= k_t;
            sw = cswap(swap, x_2, x_3);
            x_2 = sw[0];
            x_3 = sw[1];
            sw = cswap(swap, z_2, z_3);
            z_2 = sw[0];
            z_3 = sw[1];
            swap = k_t;
            const A = x_2 + z_2;
            const AA = modP(A * A);
            const B = x_2 - z_2;
            const BB = modP(B * B);
            const E = AA - BB;
            const C = x_3 + z_3;
            const D = x_3 - z_3;
            const DA = modP(D * A);
            const CB = modP(C * B);
            const dacb = DA + CB;
            const da_cb = DA - CB;
            x_3 = modP(dacb * dacb);
            z_3 = modP(x_1 * modP(da_cb * da_cb));
            x_2 = modP(AA * BB);
            z_2 = modP(E * (AA + modP(a24 * E)));
        }
        // (x_2, x_3) = cswap(swap, x_2, x_3)
        sw = cswap(swap, x_2, x_3);
        x_2 = sw[0];
        x_3 = sw[1];
        // (z_2, z_3) = cswap(swap, z_2, z_3)
        sw = cswap(swap, z_2, z_3);
        z_2 = sw[0];
        z_3 = sw[1];
        // z_2^(p - 2)
        const z2 = powPminus2(z_2);
        // Return x_2 * (z_2^(p - 2))
        return modP(x_2 * z2);
    }
    function encodeUCoordinate(u) {
        return numberToBytesLE(modP(u), montgomeryBytes);
    }
    function decodeUCoordinate(uEnc) {
        // Section 5: When receiving such an array, implementations of X25519
        // MUST mask the most significant bit in the final byte.
        // This is very ugly way, but it works because fieldLen-1 is outside of bounds for X448, so this becomes NOOP
        // fieldLen - scalaryBytes = 1 for X448 and = 0 for X25519
        const u = ensureBytes$2('u coordinate', uEnc, montgomeryBytes);
        // u[fieldLen-1] crashes QuickJS (TypeError: out-of-bound numeric index)
        if (fieldLen === montgomeryBytes)
            u[fieldLen - 1] &= 127; // 0b0111_1111
        return bytesToNumberLE$1(u);
    }
    function decodeScalar(n) {
        const bytes = ensureBytes$2('scalar', n);
        if (bytes.length !== montgomeryBytes && bytes.length !== fieldLen)
            throw new Error(`Expected ${montgomeryBytes} or ${fieldLen} bytes, got ${bytes.length}`);
        return bytesToNumberLE$1(adjustScalarBytes(bytes));
    }
    function scalarMult(scalar, u) {
        const pointU = decodeUCoordinate(u);
        const _scalar = decodeScalar(scalar);
        const pu = montgomeryLadder(pointU, _scalar);
        // The result was not contributory
        // https://cr.yp.to/ecdh.html#validate
        if (pu === _0n$3)
            throw new Error('Invalid private or public key received');
        return encodeUCoordinate(pu);
    }
    // Computes public key from private. By doing scalar multiplication of base point.
    const GuBytes = encodeUCoordinate(CURVE.Gu);
    function scalarMultBase(scalar) {
        return scalarMult(scalar, GuBytes);
    }
    return {
        scalarMult,
        scalarMultBase,
        getSharedSecret: (privateKey, publicKey) => scalarMult(privateKey, publicKey),
        getPublicKey: (privateKey) => scalarMultBase(privateKey),
        utils: { randomPrivateKey: () => CURVE.randomBytes(CURVE.nByteLength) },
        GuBytes: GuBytes,
    };
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
/**
 * ed25519 Twisted Edwards curve with following addons:
 * - X25519 ECDH
 * - Ristretto cofactor elimination
 * - Elligator hash-to-group / point indistinguishability
 */
const ED25519_P = BigInt('57896044618658097711785492504343953926634992332820282019728792003956564819949');
// √(-1) aka √(a) aka 2^((p-1)/4)
const ED25519_SQRT_M1 = BigInt('19681161376707505956807079304988542015446066515923890162744021073123829784752');
// prettier-ignore
BigInt(0); const _1n$4 = BigInt(1), _2n$3 = BigInt(2), _5n = BigInt(5);
// prettier-ignore
const _10n = BigInt(10), _20n = BigInt(20), _40n = BigInt(40), _80n = BigInt(80);
function ed25519_pow_2_252_3(x) {
    const P = ED25519_P;
    const x2 = (x * x) % P;
    const b2 = (x2 * x) % P; // x^3, 11
    const b4 = (pow2$2(b2, _2n$3, P) * b2) % P; // x^15, 1111
    const b5 = (pow2$2(b4, _1n$4, P) * x) % P; // x^31
    const b10 = (pow2$2(b5, _5n, P) * b5) % P;
    const b20 = (pow2$2(b10, _10n, P) * b10) % P;
    const b40 = (pow2$2(b20, _20n, P) * b20) % P;
    const b80 = (pow2$2(b40, _40n, P) * b40) % P;
    const b160 = (pow2$2(b80, _80n, P) * b80) % P;
    const b240 = (pow2$2(b160, _80n, P) * b80) % P;
    const b250 = (pow2$2(b240, _10n, P) * b10) % P;
    const pow_p_5_8 = (pow2$2(b250, _2n$3, P) * x) % P;
    // ^ To pow to (p+3)/8, multiply it by x.
    return { pow_p_5_8, b2 };
}
function adjustScalarBytes(bytes) {
    // Section 5: For X25519, in order to decode 32 random bytes as an integer scalar,
    // set the three least significant bits of the first byte
    bytes[0] &= 248; // 0b1111_1000
    // and the most significant bit of the last to zero,
    bytes[31] &= 127; // 0b0111_1111
    // set the second most significant bit of the last byte to 1
    bytes[31] |= 64; // 0b0100_0000
    return bytes;
}
// sqrt(u/v)
function uvRatio$1(u, v) {
    const P = ED25519_P;
    const v3 = mod$2(v * v * v, P); // v³
    const v7 = mod$2(v3 * v3 * v, P); // v⁷
    // (p+3)/8 and (p-5)/8
    const pow = ed25519_pow_2_252_3(u * v7).pow_p_5_8;
    let x = mod$2(u * v3 * pow, P); // (uv³)(uv⁷)^(p-5)/8
    const vx2 = mod$2(v * x * x, P); // vx²
    const root1 = x; // First root candidate
    const root2 = mod$2(x * ED25519_SQRT_M1, P); // Second root candidate
    const useRoot1 = vx2 === u; // If vx² = u (mod p), x is a square root
    const useRoot2 = vx2 === mod$2(-u, P); // If vx² = -u, set x <-- x * 2^((p-1)/4)
    const noRoot = vx2 === mod$2(-u * ED25519_SQRT_M1, P); // There is no valid root, vx² = -u√(-1)
    if (useRoot1)
        x = root1;
    if (useRoot2 || noRoot)
        x = root2; // We return root2 anyway, for const-time
    if (isNegativeLE(x, P))
        x = mod$2(-x, P);
    return { isValid: useRoot1 || useRoot2, value: x };
}
const Fp$1 = Field(ED25519_P, undefined, true);
const ed25519Defaults = {
    // Param: a
    a: BigInt(-1),
    // d is equal to -121665/121666 over finite field.
    // Negative number is P - number, and division is invert(number, P)
    d: BigInt('37095705934669439343138083508754565189542113879843219016388785533085940283555'),
    // Finite field 𝔽p over which we'll do calculations; 2n**255n - 19n
    Fp: Fp$1,
    // Subgroup order: how many points curve has
    // 2n**252n + 27742317777372353535851937790883648493n;
    n: BigInt('7237005577332262213973186563042994240857116359379907606001950938285454250989'),
    // Cofactor
    h: BigInt(8),
    // Base point (x, y) aka generator point
    Gx: BigInt('15112221349535400772501151409588531511454012693041857206046113283949847762202'),
    Gy: BigInt('46316835694926478169428394003475163141307993866256225615783033603165251855960'),
    hash: sha512$1,
    randomBytes: randomBytes$7,
    adjustScalarBytes,
    // dom2
    // Ratio of u to v. Allows us to combine inversion and square root. Uses algo from RFC8032 5.1.3.
    // Constant-time, u/√v
    uvRatio: uvRatio$1,
};
const ed25519 = twistedEdwards(ed25519Defaults);
function ed25519_domain(data, ctx, phflag) {
    if (ctx.length > 255)
        throw new Error('Context is too big');
    return concatBytes$3(utf8ToBytes$1('SigEd25519 no Ed25519 collisions'), new Uint8Array([phflag ? 1 : 0, ctx.length]), ctx, data);
}
twistedEdwards({ ...ed25519Defaults, domain: ed25519_domain });
twistedEdwards({
    ...ed25519Defaults,
    domain: ed25519_domain,
    prehash: sha512$1,
});
const x25519 = /* @__PURE__ */ (() => montgomery({
    P: ED25519_P,
    a: BigInt(486662),
    montgomeryBits: 255,
    nByteLength: 32,
    Gu: BigInt(9),
    powPminus2: (x) => {
        const P = ED25519_P;
        // x^(p-2) aka x^(2^255-21)
        const { pow_p_5_8, b2 } = ed25519_pow_2_252_3(x);
        return mod$2(pow2$2(pow_p_5_8, BigInt(3), P) * b2, P);
    },
    adjustScalarBytes,
    randomBytes: randomBytes$7,
}))();
// Hash To Curve Elligator2 Map (NOTE: different from ristretto255 elligator)
// NOTE: very important part is usage of FpSqrtEven for ELL2_C1_EDWARDS, since
// SageMath returns different root first and everything falls apart
const ELL2_C1 = (Fp$1.ORDER + BigInt(3)) / BigInt(8); // 1. c1 = (q + 3) / 8       # Integer arithmetic
Fp$1.pow(_2n$3, ELL2_C1); // 2. c2 = 2^c1
Fp$1.sqrt(Fp$1.neg(Fp$1.ONE)); // 3. c3 = sqrt(-1)
(Fp$1.ORDER - BigInt(5)) / BigInt(8); // 4. c4 = (q - 5) / 8       # Integer arithmetic
BigInt(486662);
FpSqrtEven(Fp$1, Fp$1.neg(BigInt(486664))); // sgn0(c1) MUST equal 0
// √(ad - 1)
BigInt('25063068953384623474111414158702152701244531502492656460079210482610430750235');
// 1 / √(a-d)
BigInt('54469307008909316920995813868745141605393597292927456921205312896311721017578');
// 1-d²
BigInt('1159843021668779879193775521855586647937357759715417654439879720876111806838');
// (d-1)²
BigInt('40440834346308536858101042469323190826248399146238708352240133220865137265952');
BigInt('0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff');

// HMAC (RFC 2104)
let HMAC$1 = class HMAC extends Hash$1 {
    constructor(hash, _key) {
        super();
        this.finished = false;
        this.destroyed = false;
        hash$3(hash);
        const key = toBytes$3(_key);
        this.iHash = hash.create();
        if (typeof this.iHash.update !== 'function')
            throw new Error('Expected instance of class which extends utils.Hash');
        this.blockLen = this.iHash.blockLen;
        this.outputLen = this.iHash.outputLen;
        const blockLen = this.blockLen;
        const pad = new Uint8Array(blockLen);
        // blockLen can be bigger than outputLen
        pad.set(key.length > blockLen ? hash.create().update(key).digest() : key);
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36;
        this.iHash.update(pad);
        // By doing update (processing of first block) of outer hash here we can re-use it between multiple calls via clone
        this.oHash = hash.create();
        // Undo internal XOR && apply outer XOR
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36 ^ 0x5c;
        this.oHash.update(pad);
        pad.fill(0);
    }
    update(buf) {
        exists$2(this);
        this.iHash.update(buf);
        return this;
    }
    digestInto(out) {
        exists$2(this);
        bytes$2(out, this.outputLen);
        this.finished = true;
        this.iHash.digestInto(out);
        this.oHash.update(out);
        this.oHash.digestInto(out);
        this.destroy();
    }
    digest() {
        const out = new Uint8Array(this.oHash.outputLen);
        this.digestInto(out);
        return out;
    }
    _cloneInto(to) {
        // Create new instance without calling constructor since key already in state and we don't know it.
        to || (to = Object.create(Object.getPrototypeOf(this), {}));
        const { oHash, iHash, finished, destroyed, blockLen, outputLen } = this;
        to = to;
        to.finished = finished;
        to.destroyed = destroyed;
        to.blockLen = blockLen;
        to.outputLen = outputLen;
        to.oHash = oHash._cloneInto(to.oHash);
        to.iHash = iHash._cloneInto(to.iHash);
        return to;
    }
    destroy() {
        this.destroyed = true;
        this.oHash.destroy();
        this.iHash.destroy();
    }
};
/**
 * HMAC: RFC2104 message authentication code.
 * @param hash - function that would be used e.g. sha256
 * @param key - message key
 * @param message - message data
 */
const hmac$2 = (hash, key, message) => new HMAC$1(hash, key).update(message).digest();
hmac$2.create = (hash, key) => new HMAC$1(hash, key);

// HKDF (RFC 5869)
// https://soatok.blog/2021/11/17/understanding-hkdf/
/**
 * HKDF-Extract(IKM, salt) -> PRK
 * Arguments position differs from spec (IKM is first one, since it is not optional)
 * @param hash
 * @param ikm
 * @param salt
 * @returns
 */
function extract(hash, ikm, salt) {
    hash$3(hash);
    // NOTE: some libraries treat zero-length array as 'not provided';
    // we don't, since we have undefined as 'not provided'
    // https://github.com/RustCrypto/KDFs/issues/15
    if (salt === undefined)
        salt = new Uint8Array(hash.outputLen); // if not provided, it is set to a string of HashLen zeros
    return hmac$2(hash, toBytes$3(salt), toBytes$3(ikm));
}
// HKDF-Expand(PRK, info, L) -> OKM
const HKDF_COUNTER = /* @__PURE__ */ new Uint8Array([0]);
const EMPTY_BUFFER = /* @__PURE__ */ new Uint8Array();
/**
 * HKDF-expand from the spec.
 * @param prk - a pseudorandom key of at least HashLen octets (usually, the output from the extract step)
 * @param info - optional context and application specific information (can be a zero-length string)
 * @param length - length of output keying material in octets
 */
function expand(hash, prk, info, length = 32) {
    hash$3(hash);
    number$2(length);
    if (length > 255 * hash.outputLen)
        throw new Error('Length should be <= 255*HashLen');
    const blocks = Math.ceil(length / hash.outputLen);
    if (info === undefined)
        info = EMPTY_BUFFER;
    // first L(ength) octets of T
    const okm = new Uint8Array(blocks * hash.outputLen);
    // Re-use HMAC instance between blocks
    const HMAC = hmac$2.create(hash, prk);
    const HMACTmp = HMAC._cloneInto();
    const T = new Uint8Array(HMAC.outputLen);
    for (let counter = 0; counter < blocks; counter++) {
        HKDF_COUNTER[0] = counter + 1;
        // T(0) = empty string (zero length)
        // T(N) = HMAC-Hash(PRK, T(N-1) | info | N)
        HMACTmp.update(counter === 0 ? EMPTY_BUFFER : T)
            .update(info)
            .update(HKDF_COUNTER)
            .digestInto(T);
        okm.set(T, hash.outputLen * counter);
        HMAC._cloneInto(HMACTmp);
    }
    HMAC.destroy();
    HMACTmp.destroy();
    T.fill(0);
    HKDF_COUNTER.fill(0);
    return okm.slice(0, length);
}

const pureJsCrypto = {
    hashSHA256(data) {
        return sha256$a(data);
    },
    getHKDF(ck, ikm) {
        const prk = extract(sha256$a, ikm, ck);
        const okmU8Array = expand(sha256$a, prk, undefined, 96);
        const okm = okmU8Array;
        const k1 = okm.subarray(0, 32);
        const k2 = okm.subarray(32, 64);
        const k3 = okm.subarray(64, 96);
        return [k1, k2, k3];
    },
    generateX25519KeyPair() {
        const secretKey = x25519.utils.randomPrivateKey();
        const publicKey = x25519.getPublicKey(secretKey);
        return {
            publicKey,
            privateKey: secretKey
        };
    },
    generateX25519KeyPairFromSeed(seed) {
        const publicKey = x25519.getPublicKey(seed);
        return {
            publicKey,
            privateKey: seed
        };
    },
    generateX25519SharedKey(privateKey, publicKey) {
        return x25519.getSharedSecret(privateKey, publicKey);
    },
    chaCha20Poly1305Encrypt(plaintext, nonce, ad, k) {
        return chacha20_poly1305(k, nonce, ad).encrypt(plaintext);
    },
    chaCha20Poly1305Decrypt(ciphertext, nonce, ad, k, dst) {
        const result = chacha20_poly1305(k, nonce, ad).decrypt(ciphertext);
        if (dst) {
            dst.set(result);
            return result;
        }
        return result;
    }
};

const allocUnsafe$1 = (len) => {
    if (globalThis.Buffer) {
        return globalThis.Buffer.allocUnsafe(len);
    }
    return new Uint8Array(len);
};
const uint16BEEncode = (value) => {
    const target = allocUnsafe$1(2);
    new DataView(target.buffer, target.byteOffset, target.byteLength).setUint16(0, value, false);
    return target;
};
uint16BEEncode.bytes = 2;
const uint16BEDecode = (data) => {
    if (data.length < 2)
        throw RangeError('Could not decode int16BE');
    if (data instanceof Uint8Array) {
        return new DataView(data.buffer, data.byteOffset, data.byteLength).getUint16(0, false);
    }
    return data.getUint16(0);
};
uint16BEDecode.bytes = 2;
// Note: IK and XX encoder usage is opposite (XX uses in stages encode0 where IK uses encode1)
function encode0(message) {
    return concat$1([message.ne, message.ciphertext], message.ne.length + message.ciphertext.length);
}
function encode1(message) {
    return concat$1([message.ne, message.ns, message.ciphertext], message.ne.length + message.ns.length + message.ciphertext.length);
}
function encode2(message) {
    return concat$1([message.ns, message.ciphertext], message.ns.length + message.ciphertext.length);
}
function decode0(input) {
    if (input.length < 32) {
        throw new Error('Cannot decode stage 0 MessageBuffer: length less than 32 bytes.');
    }
    return {
        ne: input.subarray(0, 32),
        ciphertext: input.subarray(32, input.length),
        ns: new Uint8Array(0)
    };
}
function decode1(input) {
    if (input.length < 80) {
        throw new Error('Cannot decode stage 1 MessageBuffer: length less than 80 bytes.');
    }
    return {
        ne: input.subarray(0, 32),
        ns: input.subarray(32, 80),
        ciphertext: input.subarray(80, input.length)
    };
}
function decode2(input) {
    if (input.length < 48) {
        throw new Error('Cannot decode stage 2 MessageBuffer: length less than 48 bytes.');
    }
    return {
        ne: new Uint8Array(0),
        ns: input.subarray(0, 48),
        ciphertext: input.subarray(48, input.length)
    };
}

const CHACHA_TAG_LENGTH = 16;
// Returns generator that encrypts payload from the user
function encryptStream(handshake, metrics) {
    return async function* (source) {
        for await (const chunk of source) {
            for (let i = 0; i < chunk.length; i += NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG) {
                let end = i + NOISE_MSG_MAX_LENGTH_BYTES_WITHOUT_TAG;
                if (end > chunk.length) {
                    end = chunk.length;
                }
                const data = handshake.encrypt(chunk.subarray(i, end), handshake.session);
                metrics?.encryptedPackets.increment();
                yield uint16BEEncode(data.byteLength);
                yield data;
            }
        }
    };
}
// Decrypt received payload to the user
function decryptStream(handshake, metrics) {
    return async function* (source) {
        for await (const chunk of source) {
            for (let i = 0; i < chunk.length; i += NOISE_MSG_MAX_LENGTH_BYTES) {
                let end = i + NOISE_MSG_MAX_LENGTH_BYTES;
                if (end > chunk.length) {
                    end = chunk.length;
                }
                if (end - CHACHA_TAG_LENGTH < i) {
                    throw new Error('Invalid chunk');
                }
                const encrypted = chunk.subarray(i, end);
                // memory allocation is not cheap so reuse the encrypted Uint8Array
                // see https://github.com/ChainSafe/js-libp2p-noise/pull/242#issue-1422126164
                // this is ok because chacha20 reads bytes one by one and don't reread after that
                // it's also tested in https://github.com/ChainSafe/as-chacha20poly1305/pull/1/files#diff-25252846b58979dcaf4e41d47b3eadd7e4f335e7fb98da6c049b1f9cd011f381R48
                const dst = chunk.subarray(i, end - CHACHA_TAG_LENGTH);
                const { plaintext: decrypted, valid } = handshake.decrypt(encrypted, handshake.session, dst);
                if (!valid) {
                    metrics?.decryptErrors.increment();
                    throw new Error('Failed to validate decrypted chunk');
                }
                metrics?.decryptedPackets.increment();
                yield decrypted;
            }
        }
    };
}

/**
 * Node.js module for Forge.
 *
 * @author Dave Longley
 *
 * Copyright 2011-2016 Digital Bazaar, Inc.
 */

var forge$m = {
  // default options
  options: {
    usePureJavaScript: false
  }
};

var forge$n = /*@__PURE__*/getDefaultExportFromCjs(forge$m);

var util$3 = {exports: {}};

/**
 * Base-N/Base-X encoding/decoding functions.
 *
 * Original implementation from base-x:
 * https://github.com/cryptocoinjs/base-x
 *
 * Which is MIT licensed:
 *
 * The MIT License (MIT)
 *
 * Copyright base-x contributors (c) 2016
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */

var api = {};
var baseN$1 = api;

// baseN alphabet indexes
var _reverseAlphabets = {};

/**
 * BaseN-encodes a Uint8Array using the given alphabet.
 *
 * @param input the Uint8Array to encode.
 * @param maxline the maximum number of encoded characters per line to use,
 *          defaults to none.
 *
 * @return the baseN-encoded output string.
 */
api.encode = function(input, alphabet, maxline) {
  if(typeof alphabet !== 'string') {
    throw new TypeError('"alphabet" must be a string.');
  }
  if(maxline !== undefined && typeof maxline !== 'number') {
    throw new TypeError('"maxline" must be a number.');
  }

  var output = '';

  if(!(input instanceof Uint8Array)) {
    // assume forge byte buffer
    output = _encodeWithByteBuffer(input, alphabet);
  } else {
    var i = 0;
    var base = alphabet.length;
    var first = alphabet.charAt(0);
    var digits = [0];
    for(i = 0; i < input.length; ++i) {
      for(var j = 0, carry = input[i]; j < digits.length; ++j) {
        carry += digits[j] << 8;
        digits[j] = carry % base;
        carry = (carry / base) | 0;
      }

      while(carry > 0) {
        digits.push(carry % base);
        carry = (carry / base) | 0;
      }
    }

    // deal with leading zeros
    for(i = 0; input[i] === 0 && i < input.length - 1; ++i) {
      output += first;
    }
    // convert digits to a string
    for(i = digits.length - 1; i >= 0; --i) {
      output += alphabet[digits[i]];
    }
  }

  if(maxline) {
    var regex = new RegExp('.{1,' + maxline + '}', 'g');
    output = output.match(regex).join('\r\n');
  }

  return output;
};

/**
 * Decodes a baseN-encoded (using the given alphabet) string to a
 * Uint8Array.
 *
 * @param input the baseN-encoded input string.
 *
 * @return the Uint8Array.
 */
api.decode = function(input, alphabet) {
  if(typeof input !== 'string') {
    throw new TypeError('"input" must be a string.');
  }
  if(typeof alphabet !== 'string') {
    throw new TypeError('"alphabet" must be a string.');
  }

  var table = _reverseAlphabets[alphabet];
  if(!table) {
    // compute reverse alphabet
    table = _reverseAlphabets[alphabet] = [];
    for(var i = 0; i < alphabet.length; ++i) {
      table[alphabet.charCodeAt(i)] = i;
    }
  }

  // remove whitespace characters
  input = input.replace(/\s/g, '');

  var base = alphabet.length;
  var first = alphabet.charAt(0);
  var bytes = [0];
  for(var i = 0; i < input.length; i++) {
    var value = table[input.charCodeAt(i)];
    if(value === undefined) {
      return;
    }

    for(var j = 0, carry = value; j < bytes.length; ++j) {
      carry += bytes[j] * base;
      bytes[j] = carry & 0xff;
      carry >>= 8;
    }

    while(carry > 0) {
      bytes.push(carry & 0xff);
      carry >>= 8;
    }
  }

  // deal with leading zeros
  for(var k = 0; input[k] === first && k < input.length - 1; ++k) {
    bytes.push(0);
  }

  if(typeof Buffer !== 'undefined') {
    return Buffer.from(bytes.reverse());
  }

  return new Uint8Array(bytes.reverse());
};

function _encodeWithByteBuffer(input, alphabet) {
  var i = 0;
  var base = alphabet.length;
  var first = alphabet.charAt(0);
  var digits = [0];
  for(i = 0; i < input.length(); ++i) {
    for(var j = 0, carry = input.at(i); j < digits.length; ++j) {
      carry += digits[j] << 8;
      digits[j] = carry % base;
      carry = (carry / base) | 0;
    }

    while(carry > 0) {
      digits.push(carry % base);
      carry = (carry / base) | 0;
    }
  }

  var output = '';

  // deal with leading zeros
  for(i = 0; input.at(i) === 0 && i < input.length() - 1; ++i) {
    output += first;
  }
  // convert digits to a string
  for(i = digits.length - 1; i >= 0; --i) {
    output += alphabet[digits[i]];
  }

  return output;
}

/**
 * Utility functions for web applications.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2018 Digital Bazaar, Inc.
 */

var forge$l = forge$m;
var baseN = baseN$1;

/* Utilities API */
var util$2 = util$3.exports = forge$l.util = forge$l.util || {};

// define setImmediate and nextTick
(function() {
  // use native nextTick (unless we're in webpack)
  // webpack (or better node-libs-browser polyfill) sets process.browser.
  // this way we can detect webpack properly
  if(typeof process !== 'undefined' && process.nextTick && !process.browser) {
    util$2.nextTick = process.nextTick;
    if(typeof setImmediate === 'function') {
      util$2.setImmediate = setImmediate;
    } else {
      // polyfill setImmediate with nextTick, older versions of node
      // (those w/o setImmediate) won't totally starve IO
      util$2.setImmediate = util$2.nextTick;
    }
    return;
  }

  // polyfill nextTick with native setImmediate
  if(typeof setImmediate === 'function') {
    util$2.setImmediate = function() { return setImmediate.apply(undefined, arguments); };
    util$2.nextTick = function(callback) {
      return setImmediate(callback);
    };
    return;
  }

  /* Note: A polyfill upgrade pattern is used here to allow combining
  polyfills. For example, MutationObserver is fast, but blocks UI updates,
  so it needs to allow UI updates periodically, so it falls back on
  postMessage or setTimeout. */

  // polyfill with setTimeout
  util$2.setImmediate = function(callback) {
    setTimeout(callback, 0);
  };

  // upgrade polyfill to use postMessage
  if(typeof window !== 'undefined' &&
    typeof window.postMessage === 'function') {
    var msg = 'forge.setImmediate';
    var callbacks = [];
    util$2.setImmediate = function(callback) {
      callbacks.push(callback);
      // only send message when one hasn't been sent in
      // the current turn of the event loop
      if(callbacks.length === 1) {
        window.postMessage(msg, '*');
      }
    };
    function handler(event) {
      if(event.source === window && event.data === msg) {
        event.stopPropagation();
        var copy = callbacks.slice();
        callbacks.length = 0;
        copy.forEach(function(callback) {
          callback();
        });
      }
    }
    window.addEventListener('message', handler, true);
  }

  // upgrade polyfill to use MutationObserver
  if(typeof MutationObserver !== 'undefined') {
    // polyfill with MutationObserver
    var now = Date.now();
    var attr = true;
    var div = document.createElement('div');
    var callbacks = [];
    new MutationObserver(function() {
      var copy = callbacks.slice();
      callbacks.length = 0;
      copy.forEach(function(callback) {
        callback();
      });
    }).observe(div, {attributes: true});
    var oldSetImmediate = util$2.setImmediate;
    util$2.setImmediate = function(callback) {
      if(Date.now() - now > 15) {
        now = Date.now();
        oldSetImmediate(callback);
      } else {
        callbacks.push(callback);
        // only trigger observer when it hasn't been triggered in
        // the current turn of the event loop
        if(callbacks.length === 1) {
          div.setAttribute('a', attr = !attr);
        }
      }
    };
  }

  util$2.nextTick = util$2.setImmediate;
})();

// check if running under Node.js
util$2.isNodejs =
  typeof process !== 'undefined' && process.versions && process.versions.node;


// 'self' will also work in Web Workers (instance of WorkerGlobalScope) while
// it will point to `window` in the main thread.
// To remain compatible with older browsers, we fall back to 'window' if 'self'
// is not available.
util$2.globalScope = (function() {
  if(util$2.isNodejs) {
    return commonjsGlobal;
  }

  return typeof self === 'undefined' ? window : self;
})();

// define isArray
util$2.isArray = Array.isArray || function(x) {
  return Object.prototype.toString.call(x) === '[object Array]';
};

// define isArrayBuffer
util$2.isArrayBuffer = function(x) {
  return typeof ArrayBuffer !== 'undefined' && x instanceof ArrayBuffer;
};

// define isArrayBufferView
util$2.isArrayBufferView = function(x) {
  return x && util$2.isArrayBuffer(x.buffer) && x.byteLength !== undefined;
};

/**
 * Ensure a bits param is 8, 16, 24, or 32. Used to validate input for
 * algorithms where bit manipulation, JavaScript limitations, and/or algorithm
 * design only allow for byte operations of a limited size.
 *
 * @param n number of bits.
 *
 * Throw Error if n invalid.
 */
function _checkBitsParam(n) {
  if(!(n === 8 || n === 16 || n === 24 || n === 32)) {
    throw new Error('Only 8, 16, 24, or 32 bits supported: ' + n);
  }
}

// TODO: set ByteBuffer to best available backing
util$2.ByteBuffer = ByteStringBuffer;

/** Buffer w/BinaryString backing */

/**
 * Constructor for a binary string backed byte buffer.
 *
 * @param [b] the bytes to wrap (either encoded as string, one byte per
 *          character, or as an ArrayBuffer or Typed Array).
 */
function ByteStringBuffer(b) {
  // TODO: update to match DataBuffer API

  // the data in this buffer
  this.data = '';
  // the pointer for reading from this buffer
  this.read = 0;

  if(typeof b === 'string') {
    this.data = b;
  } else if(util$2.isArrayBuffer(b) || util$2.isArrayBufferView(b)) {
    if(typeof Buffer !== 'undefined' && b instanceof Buffer) {
      this.data = b.toString('binary');
    } else {
      // convert native buffer to forge buffer
      // FIXME: support native buffers internally instead
      var arr = new Uint8Array(b);
      try {
        this.data = String.fromCharCode.apply(null, arr);
      } catch(e) {
        for(var i = 0; i < arr.length; ++i) {
          this.putByte(arr[i]);
        }
      }
    }
  } else if(b instanceof ByteStringBuffer ||
    (typeof b === 'object' && typeof b.data === 'string' &&
    typeof b.read === 'number')) {
    // copy existing buffer
    this.data = b.data;
    this.read = b.read;
  }

  // used for v8 optimization
  this._constructedStringLength = 0;
}
util$2.ByteStringBuffer = ByteStringBuffer;

/* Note: This is an optimization for V8-based browsers. When V8 concatenates
  a string, the strings are only joined logically using a "cons string" or
  "constructed/concatenated string". These containers keep references to one
  another and can result in very large memory usage. For example, if a 2MB
  string is constructed by concatenating 4 bytes together at a time, the
  memory usage will be ~44MB; so ~22x increase. The strings are only joined
  together when an operation requiring their joining takes place, such as
  substr(). This function is called when adding data to this buffer to ensure
  these types of strings are periodically joined to reduce the memory
  footprint. */
var _MAX_CONSTRUCTED_STRING_LENGTH = 4096;
util$2.ByteStringBuffer.prototype._optimizeConstructedString = function(x) {
  this._constructedStringLength += x;
  if(this._constructedStringLength > _MAX_CONSTRUCTED_STRING_LENGTH) {
    // this substr() should cause the constructed string to join
    this.data.substr(0, 1);
    this._constructedStringLength = 0;
  }
};

/**
 * Gets the number of bytes in this buffer.
 *
 * @return the number of bytes in this buffer.
 */
util$2.ByteStringBuffer.prototype.length = function() {
  return this.data.length - this.read;
};

/**
 * Gets whether or not this buffer is empty.
 *
 * @return true if this buffer is empty, false if not.
 */
util$2.ByteStringBuffer.prototype.isEmpty = function() {
  return this.length() <= 0;
};

/**
 * Puts a byte in this buffer.
 *
 * @param b the byte to put.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putByte = function(b) {
  return this.putBytes(String.fromCharCode(b));
};

/**
 * Puts a byte in this buffer N times.
 *
 * @param b the byte to put.
 * @param n the number of bytes of value b to put.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.fillWithByte = function(b, n) {
  b = String.fromCharCode(b);
  var d = this.data;
  while(n > 0) {
    if(n & 1) {
      d += b;
    }
    n >>>= 1;
    if(n > 0) {
      b += b;
    }
  }
  this.data = d;
  this._optimizeConstructedString(n);
  return this;
};

/**
 * Puts bytes in this buffer.
 *
 * @param bytes the bytes (as a binary encoded string) to put.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putBytes = function(bytes) {
  this.data += bytes;
  this._optimizeConstructedString(bytes.length);
  return this;
};

/**
 * Puts a UTF-16 encoded string into this buffer.
 *
 * @param str the string to put.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putString = function(str) {
  return this.putBytes(util$2.encodeUtf8(str));
};

/**
 * Puts a 16-bit integer in this buffer in big-endian order.
 *
 * @param i the 16-bit integer.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putInt16 = function(i) {
  return this.putBytes(
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i & 0xFF));
};

/**
 * Puts a 24-bit integer in this buffer in big-endian order.
 *
 * @param i the 24-bit integer.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putInt24 = function(i) {
  return this.putBytes(
    String.fromCharCode(i >> 16 & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i & 0xFF));
};

/**
 * Puts a 32-bit integer in this buffer in big-endian order.
 *
 * @param i the 32-bit integer.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putInt32 = function(i) {
  return this.putBytes(
    String.fromCharCode(i >> 24 & 0xFF) +
    String.fromCharCode(i >> 16 & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i & 0xFF));
};

/**
 * Puts a 16-bit integer in this buffer in little-endian order.
 *
 * @param i the 16-bit integer.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putInt16Le = function(i) {
  return this.putBytes(
    String.fromCharCode(i & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF));
};

/**
 * Puts a 24-bit integer in this buffer in little-endian order.
 *
 * @param i the 24-bit integer.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putInt24Le = function(i) {
  return this.putBytes(
    String.fromCharCode(i & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i >> 16 & 0xFF));
};

/**
 * Puts a 32-bit integer in this buffer in little-endian order.
 *
 * @param i the 32-bit integer.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putInt32Le = function(i) {
  return this.putBytes(
    String.fromCharCode(i & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i >> 16 & 0xFF) +
    String.fromCharCode(i >> 24 & 0xFF));
};

/**
 * Puts an n-bit integer in this buffer in big-endian order.
 *
 * @param i the n-bit integer.
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putInt = function(i, n) {
  _checkBitsParam(n);
  var bytes = '';
  do {
    n -= 8;
    bytes += String.fromCharCode((i >> n) & 0xFF);
  } while(n > 0);
  return this.putBytes(bytes);
};

/**
 * Puts a signed n-bit integer in this buffer in big-endian order. Two's
 * complement representation is used.
 *
 * @param i the n-bit integer.
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putSignedInt = function(i, n) {
  // putInt checks n
  if(i < 0) {
    i += 2 << (n - 1);
  }
  return this.putInt(i, n);
};

/**
 * Puts the given buffer into this buffer.
 *
 * @param buffer the buffer to put into this one.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.putBuffer = function(buffer) {
  return this.putBytes(buffer.getBytes());
};

/**
 * Gets a byte from this buffer and advances the read pointer by 1.
 *
 * @return the byte.
 */
util$2.ByteStringBuffer.prototype.getByte = function() {
  return this.data.charCodeAt(this.read++);
};

/**
 * Gets a uint16 from this buffer in big-endian order and advances the read
 * pointer by 2.
 *
 * @return the uint16.
 */
util$2.ByteStringBuffer.prototype.getInt16 = function() {
  var rval = (
    this.data.charCodeAt(this.read) << 8 ^
    this.data.charCodeAt(this.read + 1));
  this.read += 2;
  return rval;
};

/**
 * Gets a uint24 from this buffer in big-endian order and advances the read
 * pointer by 3.
 *
 * @return the uint24.
 */
util$2.ByteStringBuffer.prototype.getInt24 = function() {
  var rval = (
    this.data.charCodeAt(this.read) << 16 ^
    this.data.charCodeAt(this.read + 1) << 8 ^
    this.data.charCodeAt(this.read + 2));
  this.read += 3;
  return rval;
};

/**
 * Gets a uint32 from this buffer in big-endian order and advances the read
 * pointer by 4.
 *
 * @return the word.
 */
util$2.ByteStringBuffer.prototype.getInt32 = function() {
  var rval = (
    this.data.charCodeAt(this.read) << 24 ^
    this.data.charCodeAt(this.read + 1) << 16 ^
    this.data.charCodeAt(this.read + 2) << 8 ^
    this.data.charCodeAt(this.read + 3));
  this.read += 4;
  return rval;
};

/**
 * Gets a uint16 from this buffer in little-endian order and advances the read
 * pointer by 2.
 *
 * @return the uint16.
 */
util$2.ByteStringBuffer.prototype.getInt16Le = function() {
  var rval = (
    this.data.charCodeAt(this.read) ^
    this.data.charCodeAt(this.read + 1) << 8);
  this.read += 2;
  return rval;
};

/**
 * Gets a uint24 from this buffer in little-endian order and advances the read
 * pointer by 3.
 *
 * @return the uint24.
 */
util$2.ByteStringBuffer.prototype.getInt24Le = function() {
  var rval = (
    this.data.charCodeAt(this.read) ^
    this.data.charCodeAt(this.read + 1) << 8 ^
    this.data.charCodeAt(this.read + 2) << 16);
  this.read += 3;
  return rval;
};

/**
 * Gets a uint32 from this buffer in little-endian order and advances the read
 * pointer by 4.
 *
 * @return the word.
 */
util$2.ByteStringBuffer.prototype.getInt32Le = function() {
  var rval = (
    this.data.charCodeAt(this.read) ^
    this.data.charCodeAt(this.read + 1) << 8 ^
    this.data.charCodeAt(this.read + 2) << 16 ^
    this.data.charCodeAt(this.read + 3) << 24);
  this.read += 4;
  return rval;
};

/**
 * Gets an n-bit integer from this buffer in big-endian order and advances the
 * read pointer by ceil(n/8).
 *
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return the integer.
 */
util$2.ByteStringBuffer.prototype.getInt = function(n) {
  _checkBitsParam(n);
  var rval = 0;
  do {
    // TODO: Use (rval * 0x100) if adding support for 33 to 53 bits.
    rval = (rval << 8) + this.data.charCodeAt(this.read++);
    n -= 8;
  } while(n > 0);
  return rval;
};

/**
 * Gets a signed n-bit integer from this buffer in big-endian order, using
 * two's complement, and advances the read pointer by n/8.
 *
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return the integer.
 */
util$2.ByteStringBuffer.prototype.getSignedInt = function(n) {
  // getInt checks n
  var x = this.getInt(n);
  var max = 2 << (n - 2);
  if(x >= max) {
    x -= max << 1;
  }
  return x;
};

/**
 * Reads bytes out as a binary encoded string and clears them from the
 * buffer. Note that the resulting string is binary encoded (in node.js this
 * encoding is referred to as `binary`, it is *not* `utf8`).
 *
 * @param count the number of bytes to read, undefined or null for all.
 *
 * @return a binary encoded string of bytes.
 */
util$2.ByteStringBuffer.prototype.getBytes = function(count) {
  var rval;
  if(count) {
    // read count bytes
    count = Math.min(this.length(), count);
    rval = this.data.slice(this.read, this.read + count);
    this.read += count;
  } else if(count === 0) {
    rval = '';
  } else {
    // read all bytes, optimize to only copy when needed
    rval = (this.read === 0) ? this.data : this.data.slice(this.read);
    this.clear();
  }
  return rval;
};

/**
 * Gets a binary encoded string of the bytes from this buffer without
 * modifying the read pointer.
 *
 * @param count the number of bytes to get, omit to get all.
 *
 * @return a string full of binary encoded characters.
 */
util$2.ByteStringBuffer.prototype.bytes = function(count) {
  return (typeof(count) === 'undefined' ?
    this.data.slice(this.read) :
    this.data.slice(this.read, this.read + count));
};

/**
 * Gets a byte at the given index without modifying the read pointer.
 *
 * @param i the byte index.
 *
 * @return the byte.
 */
util$2.ByteStringBuffer.prototype.at = function(i) {
  return this.data.charCodeAt(this.read + i);
};

/**
 * Puts a byte at the given index without modifying the read pointer.
 *
 * @param i the byte index.
 * @param b the byte to put.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.setAt = function(i, b) {
  this.data = this.data.substr(0, this.read + i) +
    String.fromCharCode(b) +
    this.data.substr(this.read + i + 1);
  return this;
};

/**
 * Gets the last byte without modifying the read pointer.
 *
 * @return the last byte.
 */
util$2.ByteStringBuffer.prototype.last = function() {
  return this.data.charCodeAt(this.data.length - 1);
};

/**
 * Creates a copy of this buffer.
 *
 * @return the copy.
 */
util$2.ByteStringBuffer.prototype.copy = function() {
  var c = util$2.createBuffer(this.data);
  c.read = this.read;
  return c;
};

/**
 * Compacts this buffer.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.compact = function() {
  if(this.read > 0) {
    this.data = this.data.slice(this.read);
    this.read = 0;
  }
  return this;
};

/**
 * Clears this buffer.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.clear = function() {
  this.data = '';
  this.read = 0;
  return this;
};

/**
 * Shortens this buffer by triming bytes off of the end of this buffer.
 *
 * @param count the number of bytes to trim off.
 *
 * @return this buffer.
 */
util$2.ByteStringBuffer.prototype.truncate = function(count) {
  var len = Math.max(0, this.length() - count);
  this.data = this.data.substr(this.read, len);
  this.read = 0;
  return this;
};

/**
 * Converts this buffer to a hexadecimal string.
 *
 * @return a hexadecimal string.
 */
util$2.ByteStringBuffer.prototype.toHex = function() {
  var rval = '';
  for(var i = this.read; i < this.data.length; ++i) {
    var b = this.data.charCodeAt(i);
    if(b < 16) {
      rval += '0';
    }
    rval += b.toString(16);
  }
  return rval;
};

/**
 * Converts this buffer to a UTF-16 string (standard JavaScript string).
 *
 * @return a UTF-16 string.
 */
util$2.ByteStringBuffer.prototype.toString = function() {
  return util$2.decodeUtf8(this.bytes());
};

/** End Buffer w/BinaryString backing */

/** Buffer w/UInt8Array backing */

/**
 * FIXME: Experimental. Do not use yet.
 *
 * Constructor for an ArrayBuffer-backed byte buffer.
 *
 * The buffer may be constructed from a string, an ArrayBuffer, DataView, or a
 * TypedArray.
 *
 * If a string is given, its encoding should be provided as an option,
 * otherwise it will default to 'binary'. A 'binary' string is encoded such
 * that each character is one byte in length and size.
 *
 * If an ArrayBuffer, DataView, or TypedArray is given, it will be used
 * *directly* without any copying. Note that, if a write to the buffer requires
 * more space, the buffer will allocate a new backing ArrayBuffer to
 * accommodate. The starting read and write offsets for the buffer may be
 * given as options.
 *
 * @param [b] the initial bytes for this buffer.
 * @param options the options to use:
 *          [readOffset] the starting read offset to use (default: 0).
 *          [writeOffset] the starting write offset to use (default: the
 *            length of the first parameter).
 *          [growSize] the minimum amount, in bytes, to grow the buffer by to
 *            accommodate writes (default: 1024).
 *          [encoding] the encoding ('binary', 'utf8', 'utf16', 'hex') for the
 *            first parameter, if it is a string (default: 'binary').
 */
function DataBuffer(b, options) {
  // default options
  options = options || {};

  // pointers for read from/write to buffer
  this.read = options.readOffset || 0;
  this.growSize = options.growSize || 1024;

  var isArrayBuffer = util$2.isArrayBuffer(b);
  var isArrayBufferView = util$2.isArrayBufferView(b);
  if(isArrayBuffer || isArrayBufferView) {
    // use ArrayBuffer directly
    if(isArrayBuffer) {
      this.data = new DataView(b);
    } else {
      // TODO: adjust read/write offset based on the type of view
      // or specify that this must be done in the options ... that the
      // offsets are byte-based
      this.data = new DataView(b.buffer, b.byteOffset, b.byteLength);
    }
    this.write = ('writeOffset' in options ?
      options.writeOffset : this.data.byteLength);
    return;
  }

  // initialize to empty array buffer and add any given bytes using putBytes
  this.data = new DataView(new ArrayBuffer(0));
  this.write = 0;

  if(b !== null && b !== undefined) {
    this.putBytes(b);
  }

  if('writeOffset' in options) {
    this.write = options.writeOffset;
  }
}
util$2.DataBuffer = DataBuffer;

/**
 * Gets the number of bytes in this buffer.
 *
 * @return the number of bytes in this buffer.
 */
util$2.DataBuffer.prototype.length = function() {
  return this.write - this.read;
};

/**
 * Gets whether or not this buffer is empty.
 *
 * @return true if this buffer is empty, false if not.
 */
util$2.DataBuffer.prototype.isEmpty = function() {
  return this.length() <= 0;
};

/**
 * Ensures this buffer has enough empty space to accommodate the given number
 * of bytes. An optional parameter may be given that indicates a minimum
 * amount to grow the buffer if necessary. If the parameter is not given,
 * the buffer will be grown by some previously-specified default amount
 * or heuristic.
 *
 * @param amount the number of bytes to accommodate.
 * @param [growSize] the minimum amount, in bytes, to grow the buffer by if
 *          necessary.
 */
util$2.DataBuffer.prototype.accommodate = function(amount, growSize) {
  if(this.length() >= amount) {
    return this;
  }
  growSize = Math.max(growSize || this.growSize, amount);

  // grow buffer
  var src = new Uint8Array(
    this.data.buffer, this.data.byteOffset, this.data.byteLength);
  var dst = new Uint8Array(this.length() + growSize);
  dst.set(src);
  this.data = new DataView(dst.buffer);

  return this;
};

/**
 * Puts a byte in this buffer.
 *
 * @param b the byte to put.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putByte = function(b) {
  this.accommodate(1);
  this.data.setUint8(this.write++, b);
  return this;
};

/**
 * Puts a byte in this buffer N times.
 *
 * @param b the byte to put.
 * @param n the number of bytes of value b to put.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.fillWithByte = function(b, n) {
  this.accommodate(n);
  for(var i = 0; i < n; ++i) {
    this.data.setUint8(b);
  }
  return this;
};

/**
 * Puts bytes in this buffer. The bytes may be given as a string, an
 * ArrayBuffer, a DataView, or a TypedArray.
 *
 * @param bytes the bytes to put.
 * @param [encoding] the encoding for the first parameter ('binary', 'utf8',
 *          'utf16', 'hex'), if it is a string (default: 'binary').
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putBytes = function(bytes, encoding) {
  if(util$2.isArrayBufferView(bytes)) {
    var src = new Uint8Array(bytes.buffer, bytes.byteOffset, bytes.byteLength);
    var len = src.byteLength - src.byteOffset;
    this.accommodate(len);
    var dst = new Uint8Array(this.data.buffer, this.write);
    dst.set(src);
    this.write += len;
    return this;
  }

  if(util$2.isArrayBuffer(bytes)) {
    var src = new Uint8Array(bytes);
    this.accommodate(src.byteLength);
    var dst = new Uint8Array(this.data.buffer);
    dst.set(src, this.write);
    this.write += src.byteLength;
    return this;
  }

  // bytes is a util.DataBuffer or equivalent
  if(bytes instanceof util$2.DataBuffer ||
    (typeof bytes === 'object' &&
    typeof bytes.read === 'number' && typeof bytes.write === 'number' &&
    util$2.isArrayBufferView(bytes.data))) {
    var src = new Uint8Array(bytes.data.byteLength, bytes.read, bytes.length());
    this.accommodate(src.byteLength);
    var dst = new Uint8Array(bytes.data.byteLength, this.write);
    dst.set(src);
    this.write += src.byteLength;
    return this;
  }

  if(bytes instanceof util$2.ByteStringBuffer) {
    // copy binary string and process as the same as a string parameter below
    bytes = bytes.data;
    encoding = 'binary';
  }

  // string conversion
  encoding = encoding || 'binary';
  if(typeof bytes === 'string') {
    var view;

    // decode from string
    if(encoding === 'hex') {
      this.accommodate(Math.ceil(bytes.length / 2));
      view = new Uint8Array(this.data.buffer, this.write);
      this.write += util$2.binary.hex.decode(bytes, view, this.write);
      return this;
    }
    if(encoding === 'base64') {
      this.accommodate(Math.ceil(bytes.length / 4) * 3);
      view = new Uint8Array(this.data.buffer, this.write);
      this.write += util$2.binary.base64.decode(bytes, view, this.write);
      return this;
    }

    // encode text as UTF-8 bytes
    if(encoding === 'utf8') {
      // encode as UTF-8 then decode string as raw binary
      bytes = util$2.encodeUtf8(bytes);
      encoding = 'binary';
    }

    // decode string as raw binary
    if(encoding === 'binary' || encoding === 'raw') {
      // one byte per character
      this.accommodate(bytes.length);
      view = new Uint8Array(this.data.buffer, this.write);
      this.write += util$2.binary.raw.decode(view);
      return this;
    }

    // encode text as UTF-16 bytes
    if(encoding === 'utf16') {
      // two bytes per character
      this.accommodate(bytes.length * 2);
      view = new Uint16Array(this.data.buffer, this.write);
      this.write += util$2.text.utf16.encode(view);
      return this;
    }

    throw new Error('Invalid encoding: ' + encoding);
  }

  throw Error('Invalid parameter: ' + bytes);
};

/**
 * Puts the given buffer into this buffer.
 *
 * @param buffer the buffer to put into this one.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putBuffer = function(buffer) {
  this.putBytes(buffer);
  buffer.clear();
  return this;
};

/**
 * Puts a string into this buffer.
 *
 * @param str the string to put.
 * @param [encoding] the encoding for the string (default: 'utf16').
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putString = function(str) {
  return this.putBytes(str, 'utf16');
};

/**
 * Puts a 16-bit integer in this buffer in big-endian order.
 *
 * @param i the 16-bit integer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putInt16 = function(i) {
  this.accommodate(2);
  this.data.setInt16(this.write, i);
  this.write += 2;
  return this;
};

/**
 * Puts a 24-bit integer in this buffer in big-endian order.
 *
 * @param i the 24-bit integer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putInt24 = function(i) {
  this.accommodate(3);
  this.data.setInt16(this.write, i >> 8 & 0xFFFF);
  this.data.setInt8(this.write, i >> 16 & 0xFF);
  this.write += 3;
  return this;
};

/**
 * Puts a 32-bit integer in this buffer in big-endian order.
 *
 * @param i the 32-bit integer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putInt32 = function(i) {
  this.accommodate(4);
  this.data.setInt32(this.write, i);
  this.write += 4;
  return this;
};

/**
 * Puts a 16-bit integer in this buffer in little-endian order.
 *
 * @param i the 16-bit integer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putInt16Le = function(i) {
  this.accommodate(2);
  this.data.setInt16(this.write, i, true);
  this.write += 2;
  return this;
};

/**
 * Puts a 24-bit integer in this buffer in little-endian order.
 *
 * @param i the 24-bit integer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putInt24Le = function(i) {
  this.accommodate(3);
  this.data.setInt8(this.write, i >> 16 & 0xFF);
  this.data.setInt16(this.write, i >> 8 & 0xFFFF, true);
  this.write += 3;
  return this;
};

/**
 * Puts a 32-bit integer in this buffer in little-endian order.
 *
 * @param i the 32-bit integer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putInt32Le = function(i) {
  this.accommodate(4);
  this.data.setInt32(this.write, i, true);
  this.write += 4;
  return this;
};

/**
 * Puts an n-bit integer in this buffer in big-endian order.
 *
 * @param i the n-bit integer.
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putInt = function(i, n) {
  _checkBitsParam(n);
  this.accommodate(n / 8);
  do {
    n -= 8;
    this.data.setInt8(this.write++, (i >> n) & 0xFF);
  } while(n > 0);
  return this;
};

/**
 * Puts a signed n-bit integer in this buffer in big-endian order. Two's
 * complement representation is used.
 *
 * @param i the n-bit integer.
 * @param n the number of bits in the integer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.putSignedInt = function(i, n) {
  _checkBitsParam(n);
  this.accommodate(n / 8);
  if(i < 0) {
    i += 2 << (n - 1);
  }
  return this.putInt(i, n);
};

/**
 * Gets a byte from this buffer and advances the read pointer by 1.
 *
 * @return the byte.
 */
util$2.DataBuffer.prototype.getByte = function() {
  return this.data.getInt8(this.read++);
};

/**
 * Gets a uint16 from this buffer in big-endian order and advances the read
 * pointer by 2.
 *
 * @return the uint16.
 */
util$2.DataBuffer.prototype.getInt16 = function() {
  var rval = this.data.getInt16(this.read);
  this.read += 2;
  return rval;
};

/**
 * Gets a uint24 from this buffer in big-endian order and advances the read
 * pointer by 3.
 *
 * @return the uint24.
 */
util$2.DataBuffer.prototype.getInt24 = function() {
  var rval = (
    this.data.getInt16(this.read) << 8 ^
    this.data.getInt8(this.read + 2));
  this.read += 3;
  return rval;
};

/**
 * Gets a uint32 from this buffer in big-endian order and advances the read
 * pointer by 4.
 *
 * @return the word.
 */
util$2.DataBuffer.prototype.getInt32 = function() {
  var rval = this.data.getInt32(this.read);
  this.read += 4;
  return rval;
};

/**
 * Gets a uint16 from this buffer in little-endian order and advances the read
 * pointer by 2.
 *
 * @return the uint16.
 */
util$2.DataBuffer.prototype.getInt16Le = function() {
  var rval = this.data.getInt16(this.read, true);
  this.read += 2;
  return rval;
};

/**
 * Gets a uint24 from this buffer in little-endian order and advances the read
 * pointer by 3.
 *
 * @return the uint24.
 */
util$2.DataBuffer.prototype.getInt24Le = function() {
  var rval = (
    this.data.getInt8(this.read) ^
    this.data.getInt16(this.read + 1, true) << 8);
  this.read += 3;
  return rval;
};

/**
 * Gets a uint32 from this buffer in little-endian order and advances the read
 * pointer by 4.
 *
 * @return the word.
 */
util$2.DataBuffer.prototype.getInt32Le = function() {
  var rval = this.data.getInt32(this.read, true);
  this.read += 4;
  return rval;
};

/**
 * Gets an n-bit integer from this buffer in big-endian order and advances the
 * read pointer by n/8.
 *
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return the integer.
 */
util$2.DataBuffer.prototype.getInt = function(n) {
  _checkBitsParam(n);
  var rval = 0;
  do {
    // TODO: Use (rval * 0x100) if adding support for 33 to 53 bits.
    rval = (rval << 8) + this.data.getInt8(this.read++);
    n -= 8;
  } while(n > 0);
  return rval;
};

/**
 * Gets a signed n-bit integer from this buffer in big-endian order, using
 * two's complement, and advances the read pointer by n/8.
 *
 * @param n the number of bits in the integer (8, 16, 24, or 32).
 *
 * @return the integer.
 */
util$2.DataBuffer.prototype.getSignedInt = function(n) {
  // getInt checks n
  var x = this.getInt(n);
  var max = 2 << (n - 2);
  if(x >= max) {
    x -= max << 1;
  }
  return x;
};

/**
 * Reads bytes out as a binary encoded string and clears them from the
 * buffer.
 *
 * @param count the number of bytes to read, undefined or null for all.
 *
 * @return a binary encoded string of bytes.
 */
util$2.DataBuffer.prototype.getBytes = function(count) {
  // TODO: deprecate this method, it is poorly named and
  // this.toString('binary') replaces it
  // add a toTypedArray()/toArrayBuffer() function
  var rval;
  if(count) {
    // read count bytes
    count = Math.min(this.length(), count);
    rval = this.data.slice(this.read, this.read + count);
    this.read += count;
  } else if(count === 0) {
    rval = '';
  } else {
    // read all bytes, optimize to only copy when needed
    rval = (this.read === 0) ? this.data : this.data.slice(this.read);
    this.clear();
  }
  return rval;
};

/**
 * Gets a binary encoded string of the bytes from this buffer without
 * modifying the read pointer.
 *
 * @param count the number of bytes to get, omit to get all.
 *
 * @return a string full of binary encoded characters.
 */
util$2.DataBuffer.prototype.bytes = function(count) {
  // TODO: deprecate this method, it is poorly named, add "getString()"
  return (typeof(count) === 'undefined' ?
    this.data.slice(this.read) :
    this.data.slice(this.read, this.read + count));
};

/**
 * Gets a byte at the given index without modifying the read pointer.
 *
 * @param i the byte index.
 *
 * @return the byte.
 */
util$2.DataBuffer.prototype.at = function(i) {
  return this.data.getUint8(this.read + i);
};

/**
 * Puts a byte at the given index without modifying the read pointer.
 *
 * @param i the byte index.
 * @param b the byte to put.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.setAt = function(i, b) {
  this.data.setUint8(i, b);
  return this;
};

/**
 * Gets the last byte without modifying the read pointer.
 *
 * @return the last byte.
 */
util$2.DataBuffer.prototype.last = function() {
  return this.data.getUint8(this.write - 1);
};

/**
 * Creates a copy of this buffer.
 *
 * @return the copy.
 */
util$2.DataBuffer.prototype.copy = function() {
  return new util$2.DataBuffer(this);
};

/**
 * Compacts this buffer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.compact = function() {
  if(this.read > 0) {
    var src = new Uint8Array(this.data.buffer, this.read);
    var dst = new Uint8Array(src.byteLength);
    dst.set(src);
    this.data = new DataView(dst);
    this.write -= this.read;
    this.read = 0;
  }
  return this;
};

/**
 * Clears this buffer.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.clear = function() {
  this.data = new DataView(new ArrayBuffer(0));
  this.read = this.write = 0;
  return this;
};

/**
 * Shortens this buffer by triming bytes off of the end of this buffer.
 *
 * @param count the number of bytes to trim off.
 *
 * @return this buffer.
 */
util$2.DataBuffer.prototype.truncate = function(count) {
  this.write = Math.max(0, this.length() - count);
  this.read = Math.min(this.read, this.write);
  return this;
};

/**
 * Converts this buffer to a hexadecimal string.
 *
 * @return a hexadecimal string.
 */
util$2.DataBuffer.prototype.toHex = function() {
  var rval = '';
  for(var i = this.read; i < this.data.byteLength; ++i) {
    var b = this.data.getUint8(i);
    if(b < 16) {
      rval += '0';
    }
    rval += b.toString(16);
  }
  return rval;
};

/**
 * Converts this buffer to a string, using the given encoding. If no
 * encoding is given, 'utf8' (UTF-8) is used.
 *
 * @param [encoding] the encoding to use: 'binary', 'utf8', 'utf16', 'hex',
 *          'base64' (default: 'utf8').
 *
 * @return a string representation of the bytes in this buffer.
 */
util$2.DataBuffer.prototype.toString = function(encoding) {
  var view = new Uint8Array(this.data, this.read, this.length());
  encoding = encoding || 'utf8';

  // encode to string
  if(encoding === 'binary' || encoding === 'raw') {
    return util$2.binary.raw.encode(view);
  }
  if(encoding === 'hex') {
    return util$2.binary.hex.encode(view);
  }
  if(encoding === 'base64') {
    return util$2.binary.base64.encode(view);
  }

  // decode to text
  if(encoding === 'utf8') {
    return util$2.text.utf8.decode(view);
  }
  if(encoding === 'utf16') {
    return util$2.text.utf16.decode(view);
  }

  throw new Error('Invalid encoding: ' + encoding);
};

/** End Buffer w/UInt8Array backing */

/**
 * Creates a buffer that stores bytes. A value may be given to populate the
 * buffer with data. This value can either be string of encoded bytes or a
 * regular string of characters. When passing a string of binary encoded
 * bytes, the encoding `raw` should be given. This is also the default. When
 * passing a string of characters, the encoding `utf8` should be given.
 *
 * @param [input] a string with encoded bytes to store in the buffer.
 * @param [encoding] (default: 'raw', other: 'utf8').
 */
util$2.createBuffer = function(input, encoding) {
  // TODO: deprecate, use new ByteBuffer() instead
  encoding = encoding || 'raw';
  if(input !== undefined && encoding === 'utf8') {
    input = util$2.encodeUtf8(input);
  }
  return new util$2.ByteBuffer(input);
};

/**
 * Fills a string with a particular value. If you want the string to be a byte
 * string, pass in String.fromCharCode(theByte).
 *
 * @param c the character to fill the string with, use String.fromCharCode
 *          to fill the string with a byte value.
 * @param n the number of characters of value c to fill with.
 *
 * @return the filled string.
 */
util$2.fillString = function(c, n) {
  var s = '';
  while(n > 0) {
    if(n & 1) {
      s += c;
    }
    n >>>= 1;
    if(n > 0) {
      c += c;
    }
  }
  return s;
};

/**
 * Performs a per byte XOR between two byte strings and returns the result as a
 * string of bytes.
 *
 * @param s1 first string of bytes.
 * @param s2 second string of bytes.
 * @param n the number of bytes to XOR.
 *
 * @return the XOR'd result.
 */
util$2.xorBytes = function(s1, s2, n) {
  var s3 = '';
  var b = '';
  var t = '';
  var i = 0;
  var c = 0;
  for(; n > 0; --n, ++i) {
    b = s1.charCodeAt(i) ^ s2.charCodeAt(i);
    if(c >= 10) {
      s3 += t;
      t = '';
      c = 0;
    }
    t += String.fromCharCode(b);
    ++c;
  }
  s3 += t;
  return s3;
};

/**
 * Converts a hex string into a 'binary' encoded string of bytes.
 *
 * @param hex the hexadecimal string to convert.
 *
 * @return the binary-encoded string of bytes.
 */
util$2.hexToBytes = function(hex) {
  // TODO: deprecate: "Deprecated. Use util.binary.hex.decode instead."
  var rval = '';
  var i = 0;
  if(hex.length & 1 == 1) {
    // odd number of characters, convert first character alone
    i = 1;
    rval += String.fromCharCode(parseInt(hex[0], 16));
  }
  // convert 2 characters (1 byte) at a time
  for(; i < hex.length; i += 2) {
    rval += String.fromCharCode(parseInt(hex.substr(i, 2), 16));
  }
  return rval;
};

/**
 * Converts a 'binary' encoded string of bytes to hex.
 *
 * @param bytes the byte string to convert.
 *
 * @return the string of hexadecimal characters.
 */
util$2.bytesToHex = function(bytes) {
  // TODO: deprecate: "Deprecated. Use util.binary.hex.encode instead."
  return util$2.createBuffer(bytes).toHex();
};

/**
 * Converts an 32-bit integer to 4-big-endian byte string.
 *
 * @param i the integer.
 *
 * @return the byte string.
 */
util$2.int32ToBytes = function(i) {
  return (
    String.fromCharCode(i >> 24 & 0xFF) +
    String.fromCharCode(i >> 16 & 0xFF) +
    String.fromCharCode(i >> 8 & 0xFF) +
    String.fromCharCode(i & 0xFF));
};

// base64 characters, reverse mapping
var _base64 =
  'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=';
var _base64Idx = [
/*43 -43 = 0*/
/*'+',  1,  2,  3,'/' */
   62, -1, -1, -1, 63,

/*'0','1','2','3','4','5','6','7','8','9' */
   52, 53, 54, 55, 56, 57, 58, 59, 60, 61,

/*15, 16, 17,'=', 19, 20, 21 */
  -1, -1, -1, 64, -1, -1, -1,

/*65 - 43 = 22*/
/*'A','B','C','D','E','F','G','H','I','J','K','L','M', */
   0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,

/*'N','O','P','Q','R','S','T','U','V','W','X','Y','Z' */
   13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,

/*91 - 43 = 48 */
/*48, 49, 50, 51, 52, 53 */
  -1, -1, -1, -1, -1, -1,

/*97 - 43 = 54*/
/*'a','b','c','d','e','f','g','h','i','j','k','l','m' */
   26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,

/*'n','o','p','q','r','s','t','u','v','w','x','y','z' */
   39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51
];

// base58 characters (Bitcoin alphabet)
var _base58 = '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz';

/**
 * Base64 encodes a 'binary' encoded string of bytes.
 *
 * @param input the binary encoded string of bytes to base64-encode.
 * @param maxline the maximum number of encoded characters per line to use,
 *          defaults to none.
 *
 * @return the base64-encoded output.
 */
util$2.encode64 = function(input, maxline) {
  // TODO: deprecate: "Deprecated. Use util.binary.base64.encode instead."
  var line = '';
  var output = '';
  var chr1, chr2, chr3;
  var i = 0;
  while(i < input.length) {
    chr1 = input.charCodeAt(i++);
    chr2 = input.charCodeAt(i++);
    chr3 = input.charCodeAt(i++);

    // encode 4 character group
    line += _base64.charAt(chr1 >> 2);
    line += _base64.charAt(((chr1 & 3) << 4) | (chr2 >> 4));
    if(isNaN(chr2)) {
      line += '==';
    } else {
      line += _base64.charAt(((chr2 & 15) << 2) | (chr3 >> 6));
      line += isNaN(chr3) ? '=' : _base64.charAt(chr3 & 63);
    }

    if(maxline && line.length > maxline) {
      output += line.substr(0, maxline) + '\r\n';
      line = line.substr(maxline);
    }
  }
  output += line;
  return output;
};

/**
 * Base64 decodes a string into a 'binary' encoded string of bytes.
 *
 * @param input the base64-encoded input.
 *
 * @return the binary encoded string.
 */
util$2.decode64 = function(input) {
  // TODO: deprecate: "Deprecated. Use util.binary.base64.decode instead."

  // remove all non-base64 characters
  input = input.replace(/[^A-Za-z0-9\+\/\=]/g, '');

  var output = '';
  var enc1, enc2, enc3, enc4;
  var i = 0;

  while(i < input.length) {
    enc1 = _base64Idx[input.charCodeAt(i++) - 43];
    enc2 = _base64Idx[input.charCodeAt(i++) - 43];
    enc3 = _base64Idx[input.charCodeAt(i++) - 43];
    enc4 = _base64Idx[input.charCodeAt(i++) - 43];

    output += String.fromCharCode((enc1 << 2) | (enc2 >> 4));
    if(enc3 !== 64) {
      // decoded at least 2 bytes
      output += String.fromCharCode(((enc2 & 15) << 4) | (enc3 >> 2));
      if(enc4 !== 64) {
        // decoded 3 bytes
        output += String.fromCharCode(((enc3 & 3) << 6) | enc4);
      }
    }
  }

  return output;
};

/**
 * Encodes the given string of characters (a standard JavaScript
 * string) as a binary encoded string where the bytes represent
 * a UTF-8 encoded string of characters. Non-ASCII characters will be
 * encoded as multiple bytes according to UTF-8.
 *
 * @param str a standard string of characters to encode.
 *
 * @return the binary encoded string.
 */
util$2.encodeUtf8 = function(str) {
  return unescape(encodeURIComponent(str));
};

/**
 * Decodes a binary encoded string that contains bytes that
 * represent a UTF-8 encoded string of characters -- into a
 * string of characters (a standard JavaScript string).
 *
 * @param str the binary encoded string to decode.
 *
 * @return the resulting standard string of characters.
 */
util$2.decodeUtf8 = function(str) {
  return decodeURIComponent(escape(str));
};

// binary encoding/decoding tools
// FIXME: Experimental. Do not use yet.
util$2.binary = {
  raw: {},
  hex: {},
  base64: {},
  base58: {},
  baseN : {
    encode: baseN.encode,
    decode: baseN.decode
  }
};

/**
 * Encodes a Uint8Array as a binary-encoded string. This encoding uses
 * a value between 0 and 255 for each character.
 *
 * @param bytes the Uint8Array to encode.
 *
 * @return the binary-encoded string.
 */
util$2.binary.raw.encode = function(bytes) {
  return String.fromCharCode.apply(null, bytes);
};

/**
 * Decodes a binary-encoded string to a Uint8Array. This encoding uses
 * a value between 0 and 255 for each character.
 *
 * @param str the binary-encoded string to decode.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$2.binary.raw.decode = function(str, output, offset) {
  var out = output;
  if(!out) {
    out = new Uint8Array(str.length);
  }
  offset = offset || 0;
  var j = offset;
  for(var i = 0; i < str.length; ++i) {
    out[j++] = str.charCodeAt(i);
  }
  return output ? (j - offset) : out;
};

/**
 * Encodes a 'binary' string, ArrayBuffer, DataView, TypedArray, or
 * ByteBuffer as a string of hexadecimal characters.
 *
 * @param bytes the bytes to convert.
 *
 * @return the string of hexadecimal characters.
 */
util$2.binary.hex.encode = util$2.bytesToHex;

/**
 * Decodes a hex-encoded string to a Uint8Array.
 *
 * @param hex the hexadecimal string to convert.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$2.binary.hex.decode = function(hex, output, offset) {
  var out = output;
  if(!out) {
    out = new Uint8Array(Math.ceil(hex.length / 2));
  }
  offset = offset || 0;
  var i = 0, j = offset;
  if(hex.length & 1) {
    // odd number of characters, convert first character alone
    i = 1;
    out[j++] = parseInt(hex[0], 16);
  }
  // convert 2 characters (1 byte) at a time
  for(; i < hex.length; i += 2) {
    out[j++] = parseInt(hex.substr(i, 2), 16);
  }
  return output ? (j - offset) : out;
};

/**
 * Base64-encodes a Uint8Array.
 *
 * @param input the Uint8Array to encode.
 * @param maxline the maximum number of encoded characters per line to use,
 *          defaults to none.
 *
 * @return the base64-encoded output string.
 */
util$2.binary.base64.encode = function(input, maxline) {
  var line = '';
  var output = '';
  var chr1, chr2, chr3;
  var i = 0;
  while(i < input.byteLength) {
    chr1 = input[i++];
    chr2 = input[i++];
    chr3 = input[i++];

    // encode 4 character group
    line += _base64.charAt(chr1 >> 2);
    line += _base64.charAt(((chr1 & 3) << 4) | (chr2 >> 4));
    if(isNaN(chr2)) {
      line += '==';
    } else {
      line += _base64.charAt(((chr2 & 15) << 2) | (chr3 >> 6));
      line += isNaN(chr3) ? '=' : _base64.charAt(chr3 & 63);
    }

    if(maxline && line.length > maxline) {
      output += line.substr(0, maxline) + '\r\n';
      line = line.substr(maxline);
    }
  }
  output += line;
  return output;
};

/**
 * Decodes a base64-encoded string to a Uint8Array.
 *
 * @param input the base64-encoded input string.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$2.binary.base64.decode = function(input, output, offset) {
  var out = output;
  if(!out) {
    out = new Uint8Array(Math.ceil(input.length / 4) * 3);
  }

  // remove all non-base64 characters
  input = input.replace(/[^A-Za-z0-9\+\/\=]/g, '');

  offset = offset || 0;
  var enc1, enc2, enc3, enc4;
  var i = 0, j = offset;

  while(i < input.length) {
    enc1 = _base64Idx[input.charCodeAt(i++) - 43];
    enc2 = _base64Idx[input.charCodeAt(i++) - 43];
    enc3 = _base64Idx[input.charCodeAt(i++) - 43];
    enc4 = _base64Idx[input.charCodeAt(i++) - 43];

    out[j++] = (enc1 << 2) | (enc2 >> 4);
    if(enc3 !== 64) {
      // decoded at least 2 bytes
      out[j++] = ((enc2 & 15) << 4) | (enc3 >> 2);
      if(enc4 !== 64) {
        // decoded 3 bytes
        out[j++] = ((enc3 & 3) << 6) | enc4;
      }
    }
  }

  // make sure result is the exact decoded length
  return output ? (j - offset) : out.subarray(0, j);
};

// add support for base58 encoding/decoding with Bitcoin alphabet
util$2.binary.base58.encode = function(input, maxline) {
  return util$2.binary.baseN.encode(input, _base58, maxline);
};
util$2.binary.base58.decode = function(input, maxline) {
  return util$2.binary.baseN.decode(input, _base58, maxline);
};

// text encoding/decoding tools
// FIXME: Experimental. Do not use yet.
util$2.text = {
  utf8: {},
  utf16: {}
};

/**
 * Encodes the given string as UTF-8 in a Uint8Array.
 *
 * @param str the string to encode.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$2.text.utf8.encode = function(str, output, offset) {
  str = util$2.encodeUtf8(str);
  var out = output;
  if(!out) {
    out = new Uint8Array(str.length);
  }
  offset = offset || 0;
  var j = offset;
  for(var i = 0; i < str.length; ++i) {
    out[j++] = str.charCodeAt(i);
  }
  return output ? (j - offset) : out;
};

/**
 * Decodes the UTF-8 contents from a Uint8Array.
 *
 * @param bytes the Uint8Array to decode.
 *
 * @return the resulting string.
 */
util$2.text.utf8.decode = function(bytes) {
  return util$2.decodeUtf8(String.fromCharCode.apply(null, bytes));
};

/**
 * Encodes the given string as UTF-16 in a Uint8Array.
 *
 * @param str the string to encode.
 * @param [output] an optional Uint8Array to write the output to; if it
 *          is too small, an exception will be thrown.
 * @param [offset] the start offset for writing to the output (default: 0).
 *
 * @return the Uint8Array or the number of bytes written if output was given.
 */
util$2.text.utf16.encode = function(str, output, offset) {
  var out = output;
  if(!out) {
    out = new Uint8Array(str.length * 2);
  }
  var view = new Uint16Array(out.buffer);
  offset = offset || 0;
  var j = offset;
  var k = offset;
  for(var i = 0; i < str.length; ++i) {
    view[k++] = str.charCodeAt(i);
    j += 2;
  }
  return output ? (j - offset) : out;
};

/**
 * Decodes the UTF-16 contents from a Uint8Array.
 *
 * @param bytes the Uint8Array to decode.
 *
 * @return the resulting string.
 */
util$2.text.utf16.decode = function(bytes) {
  return String.fromCharCode.apply(null, new Uint16Array(bytes.buffer));
};

/**
 * Deflates the given data using a flash interface.
 *
 * @param api the flash interface.
 * @param bytes the data.
 * @param raw true to return only raw deflate data, false to include zlib
 *          header and trailer.
 *
 * @return the deflated data as a string.
 */
util$2.deflate = function(api, bytes, raw) {
  bytes = util$2.decode64(api.deflate(util$2.encode64(bytes)).rval);

  // strip zlib header and trailer if necessary
  if(raw) {
    // zlib header is 2 bytes (CMF,FLG) where FLG indicates that
    // there is a 4-byte DICT (alder-32) block before the data if
    // its 5th bit is set
    var start = 2;
    var flg = bytes.charCodeAt(1);
    if(flg & 0x20) {
      start = 6;
    }
    // zlib trailer is 4 bytes of adler-32
    bytes = bytes.substring(start, bytes.length - 4);
  }

  return bytes;
};

/**
 * Inflates the given data using a flash interface.
 *
 * @param api the flash interface.
 * @param bytes the data.
 * @param raw true if the incoming data has no zlib header or trailer and is
 *          raw DEFLATE data.
 *
 * @return the inflated data as a string, null on error.
 */
util$2.inflate = function(api, bytes, raw) {
  // TODO: add zlib header and trailer if necessary/possible
  var rval = api.inflate(util$2.encode64(bytes)).rval;
  return (rval === null) ? null : util$2.decode64(rval);
};

/**
 * Sets a storage object.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 * @param obj the storage object, null to remove.
 */
var _setStorageObject = function(api, id, obj) {
  if(!api) {
    throw new Error('WebStorage not available.');
  }

  var rval;
  if(obj === null) {
    rval = api.removeItem(id);
  } else {
    // json-encode and base64-encode object
    obj = util$2.encode64(JSON.stringify(obj));
    rval = api.setItem(id, obj);
  }

  // handle potential flash error
  if(typeof(rval) !== 'undefined' && rval.rval !== true) {
    var error = new Error(rval.error.message);
    error.id = rval.error.id;
    error.name = rval.error.name;
    throw error;
  }
};

/**
 * Gets a storage object.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 *
 * @return the storage object entry or null if none exists.
 */
var _getStorageObject = function(api, id) {
  if(!api) {
    throw new Error('WebStorage not available.');
  }

  // get the existing entry
  var rval = api.getItem(id);

  /* Note: We check api.init because we can't do (api == localStorage)
    on IE because of "Class doesn't support Automation" exception. Only
    the flash api has an init method so this works too, but we need a
    better solution in the future. */

  // flash returns item wrapped in an object, handle special case
  if(api.init) {
    if(rval.rval === null) {
      if(rval.error) {
        var error = new Error(rval.error.message);
        error.id = rval.error.id;
        error.name = rval.error.name;
        throw error;
      }
      // no error, but also no item
      rval = null;
    } else {
      rval = rval.rval;
    }
  }

  // handle decoding
  if(rval !== null) {
    // base64-decode and json-decode data
    rval = JSON.parse(util$2.decode64(rval));
  }

  return rval;
};

/**
 * Stores an item in local storage.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 * @param key the key for the item.
 * @param data the data for the item (any javascript object/primitive).
 */
var _setItem = function(api, id, key, data) {
  // get storage object
  var obj = _getStorageObject(api, id);
  if(obj === null) {
    // create a new storage object
    obj = {};
  }
  // update key
  obj[key] = data;

  // set storage object
  _setStorageObject(api, id, obj);
};

/**
 * Gets an item from local storage.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 * @param key the key for the item.
 *
 * @return the item.
 */
var _getItem = function(api, id, key) {
  // get storage object
  var rval = _getStorageObject(api, id);
  if(rval !== null) {
    // return data at key
    rval = (key in rval) ? rval[key] : null;
  }

  return rval;
};

/**
 * Removes an item from local storage.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 * @param key the key for the item.
 */
var _removeItem = function(api, id, key) {
  // get storage object
  var obj = _getStorageObject(api, id);
  if(obj !== null && key in obj) {
    // remove key
    delete obj[key];

    // see if entry has no keys remaining
    var empty = true;
    for(var prop in obj) {
      empty = false;
      break;
    }
    if(empty) {
      // remove entry entirely if no keys are left
      obj = null;
    }

    // set storage object
    _setStorageObject(api, id, obj);
  }
};

/**
 * Clears the local disk storage identified by the given ID.
 *
 * @param api the storage interface.
 * @param id the storage ID to use.
 */
var _clearItems = function(api, id) {
  _setStorageObject(api, id, null);
};

/**
 * Calls a storage function.
 *
 * @param func the function to call.
 * @param args the arguments for the function.
 * @param location the location argument.
 *
 * @return the return value from the function.
 */
var _callStorageFunction = function(func, args, location) {
  var rval = null;

  // default storage types
  if(typeof(location) === 'undefined') {
    location = ['web', 'flash'];
  }

  // apply storage types in order of preference
  var type;
  var done = false;
  var exception = null;
  for(var idx in location) {
    type = location[idx];
    try {
      if(type === 'flash' || type === 'both') {
        if(args[0] === null) {
          throw new Error('Flash local storage not available.');
        }
        rval = func.apply(this, args);
        done = (type === 'flash');
      }
      if(type === 'web' || type === 'both') {
        args[0] = localStorage;
        rval = func.apply(this, args);
        done = true;
      }
    } catch(ex) {
      exception = ex;
    }
    if(done) {
      break;
    }
  }

  if(!done) {
    throw exception;
  }

  return rval;
};

/**
 * Stores an item on local disk.
 *
 * The available types of local storage include 'flash', 'web', and 'both'.
 *
 * The type 'flash' refers to flash local storage (SharedObject). In order
 * to use flash local storage, the 'api' parameter must be valid. The type
 * 'web' refers to WebStorage, if supported by the browser. The type 'both'
 * refers to storing using both 'flash' and 'web', not just one or the
 * other.
 *
 * The location array should list the storage types to use in order of
 * preference:
 *
 * ['flash']: flash only storage
 * ['web']: web only storage
 * ['both']: try to store in both
 * ['flash','web']: store in flash first, but if not available, 'web'
 * ['web','flash']: store in web first, but if not available, 'flash'
 *
 * The location array defaults to: ['web', 'flash']
 *
 * @param api the flash interface, null to use only WebStorage.
 * @param id the storage ID to use.
 * @param key the key for the item.
 * @param data the data for the item (any javascript object/primitive).
 * @param location an array with the preferred types of storage to use.
 */
util$2.setItem = function(api, id, key, data, location) {
  _callStorageFunction(_setItem, arguments, location);
};

/**
 * Gets an item on local disk.
 *
 * Set setItem() for details on storage types.
 *
 * @param api the flash interface, null to use only WebStorage.
 * @param id the storage ID to use.
 * @param key the key for the item.
 * @param location an array with the preferred types of storage to use.
 *
 * @return the item.
 */
util$2.getItem = function(api, id, key, location) {
  return _callStorageFunction(_getItem, arguments, location);
};

/**
 * Removes an item on local disk.
 *
 * Set setItem() for details on storage types.
 *
 * @param api the flash interface.
 * @param id the storage ID to use.
 * @param key the key for the item.
 * @param location an array with the preferred types of storage to use.
 */
util$2.removeItem = function(api, id, key, location) {
  _callStorageFunction(_removeItem, arguments, location);
};

/**
 * Clears the local disk storage identified by the given ID.
 *
 * Set setItem() for details on storage types.
 *
 * @param api the flash interface if flash is available.
 * @param id the storage ID to use.
 * @param location an array with the preferred types of storage to use.
 */
util$2.clearItems = function(api, id, location) {
  _callStorageFunction(_clearItems, arguments, location);
};

/**
 * Check if an object is empty.
 *
 * Taken from:
 * http://stackoverflow.com/questions/679915/how-do-i-test-for-an-empty-javascript-object-from-json/679937#679937
 *
 * @param object the object to check.
 */
util$2.isEmpty = function(obj) {
  for(var prop in obj) {
    if(obj.hasOwnProperty(prop)) {
      return false;
    }
  }
  return true;
};

/**
 * Format with simple printf-style interpolation.
 *
 * %%: literal '%'
 * %s,%o: convert next argument into a string.
 *
 * @param format the string to format.
 * @param ... arguments to interpolate into the format string.
 */
util$2.format = function(format) {
  var re = /%./g;
  // current match
  var match;
  // current part
  var part;
  // current arg index
  var argi = 0;
  // collected parts to recombine later
  var parts = [];
  // last index found
  var last = 0;
  // loop while matches remain
  while((match = re.exec(format))) {
    part = format.substring(last, re.lastIndex - 2);
    // don't add empty strings (ie, parts between %s%s)
    if(part.length > 0) {
      parts.push(part);
    }
    last = re.lastIndex;
    // switch on % code
    var code = match[0][1];
    switch(code) {
    case 's':
    case 'o':
      // check if enough arguments were given
      if(argi < arguments.length) {
        parts.push(arguments[argi++ + 1]);
      } else {
        parts.push('<?>');
      }
      break;
    // FIXME: do proper formating for numbers, etc
    //case 'f':
    //case 'd':
    case '%':
      parts.push('%');
      break;
    default:
      parts.push('<%' + code + '?>');
    }
  }
  // add trailing part of format string
  parts.push(format.substring(last));
  return parts.join('');
};

/**
 * Formats a number.
 *
 * http://snipplr.com/view/5945/javascript-numberformat--ported-from-php/
 */
util$2.formatNumber = function(number, decimals, dec_point, thousands_sep) {
  // http://kevin.vanzonneveld.net
  // +   original by: Jonas Raoni Soares Silva (http://www.jsfromhell.com)
  // +   improved by: Kevin van Zonneveld (http://kevin.vanzonneveld.net)
  // +     bugfix by: Michael White (http://crestidg.com)
  // +     bugfix by: Benjamin Lupton
  // +     bugfix by: Allan Jensen (http://www.winternet.no)
  // +    revised by: Jonas Raoni Soares Silva (http://www.jsfromhell.com)
  // *     example 1: number_format(1234.5678, 2, '.', '');
  // *     returns 1: 1234.57

  var n = number, c = isNaN(decimals = Math.abs(decimals)) ? 2 : decimals;
  var d = dec_point === undefined ? ',' : dec_point;
  var t = thousands_sep === undefined ?
   '.' : thousands_sep, s = n < 0 ? '-' : '';
  var i = parseInt((n = Math.abs(+n || 0).toFixed(c)), 10) + '';
  var j = (i.length > 3) ? i.length % 3 : 0;
  return s + (j ? i.substr(0, j) + t : '') +
    i.substr(j).replace(/(\d{3})(?=\d)/g, '$1' + t) +
    (c ? d + Math.abs(n - i).toFixed(c).slice(2) : '');
};

/**
 * Formats a byte size.
 *
 * http://snipplr.com/view/5949/format-humanize-file-byte-size-presentation-in-javascript/
 */
util$2.formatSize = function(size) {
  if(size >= 1073741824) {
    size = util$2.formatNumber(size / 1073741824, 2, '.', '') + ' GiB';
  } else if(size >= 1048576) {
    size = util$2.formatNumber(size / 1048576, 2, '.', '') + ' MiB';
  } else if(size >= 1024) {
    size = util$2.formatNumber(size / 1024, 0) + ' KiB';
  } else {
    size = util$2.formatNumber(size, 0) + ' bytes';
  }
  return size;
};

/**
 * Converts an IPv4 or IPv6 string representation into bytes (in network order).
 *
 * @param ip the IPv4 or IPv6 address to convert.
 *
 * @return the 4-byte IPv6 or 16-byte IPv6 address or null if the address can't
 *         be parsed.
 */
util$2.bytesFromIP = function(ip) {
  if(ip.indexOf('.') !== -1) {
    return util$2.bytesFromIPv4(ip);
  }
  if(ip.indexOf(':') !== -1) {
    return util$2.bytesFromIPv6(ip);
  }
  return null;
};

/**
 * Converts an IPv4 string representation into bytes (in network order).
 *
 * @param ip the IPv4 address to convert.
 *
 * @return the 4-byte address or null if the address can't be parsed.
 */
util$2.bytesFromIPv4 = function(ip) {
  ip = ip.split('.');
  if(ip.length !== 4) {
    return null;
  }
  var b = util$2.createBuffer();
  for(var i = 0; i < ip.length; ++i) {
    var num = parseInt(ip[i], 10);
    if(isNaN(num)) {
      return null;
    }
    b.putByte(num);
  }
  return b.getBytes();
};

/**
 * Converts an IPv6 string representation into bytes (in network order).
 *
 * @param ip the IPv6 address to convert.
 *
 * @return the 16-byte address or null if the address can't be parsed.
 */
util$2.bytesFromIPv6 = function(ip) {
  var blanks = 0;
  ip = ip.split(':').filter(function(e) {
    if(e.length === 0) ++blanks;
    return true;
  });
  var zeros = (8 - ip.length + blanks) * 2;
  var b = util$2.createBuffer();
  for(var i = 0; i < 8; ++i) {
    if(!ip[i] || ip[i].length === 0) {
      b.fillWithByte(0, zeros);
      zeros = 0;
      continue;
    }
    var bytes = util$2.hexToBytes(ip[i]);
    if(bytes.length < 2) {
      b.putByte(0);
    }
    b.putBytes(bytes);
  }
  return b.getBytes();
};

/**
 * Converts 4-bytes into an IPv4 string representation or 16-bytes into
 * an IPv6 string representation. The bytes must be in network order.
 *
 * @param bytes the bytes to convert.
 *
 * @return the IPv4 or IPv6 string representation if 4 or 16 bytes,
 *         respectively, are given, otherwise null.
 */
util$2.bytesToIP = function(bytes) {
  if(bytes.length === 4) {
    return util$2.bytesToIPv4(bytes);
  }
  if(bytes.length === 16) {
    return util$2.bytesToIPv6(bytes);
  }
  return null;
};

/**
 * Converts 4-bytes into an IPv4 string representation. The bytes must be
 * in network order.
 *
 * @param bytes the bytes to convert.
 *
 * @return the IPv4 string representation or null for an invalid # of bytes.
 */
util$2.bytesToIPv4 = function(bytes) {
  if(bytes.length !== 4) {
    return null;
  }
  var ip = [];
  for(var i = 0; i < bytes.length; ++i) {
    ip.push(bytes.charCodeAt(i));
  }
  return ip.join('.');
};

/**
 * Converts 16-bytes into an IPv16 string representation. The bytes must be
 * in network order.
 *
 * @param bytes the bytes to convert.
 *
 * @return the IPv16 string representation or null for an invalid # of bytes.
 */
util$2.bytesToIPv6 = function(bytes) {
  if(bytes.length !== 16) {
    return null;
  }
  var ip = [];
  var zeroGroups = [];
  var zeroMaxGroup = 0;
  for(var i = 0; i < bytes.length; i += 2) {
    var hex = util$2.bytesToHex(bytes[i] + bytes[i + 1]);
    // canonicalize zero representation
    while(hex[0] === '0' && hex !== '0') {
      hex = hex.substr(1);
    }
    if(hex === '0') {
      var last = zeroGroups[zeroGroups.length - 1];
      var idx = ip.length;
      if(!last || idx !== last.end + 1) {
        zeroGroups.push({start: idx, end: idx});
      } else {
        last.end = idx;
        if((last.end - last.start) >
          (zeroGroups[zeroMaxGroup].end - zeroGroups[zeroMaxGroup].start)) {
          zeroMaxGroup = zeroGroups.length - 1;
        }
      }
    }
    ip.push(hex);
  }
  if(zeroGroups.length > 0) {
    var group = zeroGroups[zeroMaxGroup];
    // only shorten group of length > 0
    if(group.end - group.start > 0) {
      ip.splice(group.start, group.end - group.start + 1, '');
      if(group.start === 0) {
        ip.unshift('');
      }
      if(group.end === 7) {
        ip.push('');
      }
    }
  }
  return ip.join(':');
};

/**
 * Estimates the number of processes that can be run concurrently. If
 * creating Web Workers, keep in mind that the main JavaScript process needs
 * its own core.
 *
 * @param options the options to use:
 *          update true to force an update (not use the cached value).
 * @param callback(err, max) called once the operation completes.
 */
util$2.estimateCores = function(options, callback) {
  if(typeof options === 'function') {
    callback = options;
    options = {};
  }
  options = options || {};
  if('cores' in util$2 && !options.update) {
    return callback(null, util$2.cores);
  }
  if(typeof navigator !== 'undefined' &&
    'hardwareConcurrency' in navigator &&
    navigator.hardwareConcurrency > 0) {
    util$2.cores = navigator.hardwareConcurrency;
    return callback(null, util$2.cores);
  }
  if(typeof Worker === 'undefined') {
    // workers not available
    util$2.cores = 1;
    return callback(null, util$2.cores);
  }
  if(typeof Blob === 'undefined') {
    // can't estimate, default to 2
    util$2.cores = 2;
    return callback(null, util$2.cores);
  }

  // create worker concurrency estimation code as blob
  var blobUrl = URL.createObjectURL(new Blob(['(',
    function() {
      self.addEventListener('message', function(e) {
        // run worker for 4 ms
        var st = Date.now();
        var et = st + 4;
        self.postMessage({st: st, et: et});
      });
    }.toString(),
  ')()'], {type: 'application/javascript'}));

  // take 5 samples using 16 workers
  sample([], 5, 16);

  function sample(max, samples, numWorkers) {
    if(samples === 0) {
      // get overlap average
      var avg = Math.floor(max.reduce(function(avg, x) {
        return avg + x;
      }, 0) / max.length);
      util$2.cores = Math.max(1, avg);
      URL.revokeObjectURL(blobUrl);
      return callback(null, util$2.cores);
    }
    map(numWorkers, function(err, results) {
      max.push(reduce(numWorkers, results));
      sample(max, samples - 1, numWorkers);
    });
  }

  function map(numWorkers, callback) {
    var workers = [];
    var results = [];
    for(var i = 0; i < numWorkers; ++i) {
      var worker = new Worker(blobUrl);
      worker.addEventListener('message', function(e) {
        results.push(e.data);
        if(results.length === numWorkers) {
          for(var i = 0; i < numWorkers; ++i) {
            workers[i].terminate();
          }
          callback(null, results);
        }
      });
      workers.push(worker);
    }
    for(var i = 0; i < numWorkers; ++i) {
      workers[i].postMessage(i);
    }
  }

  function reduce(numWorkers, results) {
    // find overlapping time windows
    var overlaps = [];
    for(var n = 0; n < numWorkers; ++n) {
      var r1 = results[n];
      var overlap = overlaps[n] = [];
      for(var i = 0; i < numWorkers; ++i) {
        if(n === i) {
          continue;
        }
        var r2 = results[i];
        if((r1.st > r2.st && r1.st < r2.et) ||
          (r2.st > r1.st && r2.st < r1.et)) {
          overlap.push(i);
        }
      }
    }
    // get maximum overlaps ... don't include overlapping worker itself
    // as the main JS process was also being scheduled during the work and
    // would have to be subtracted from the estimate anyway
    return overlaps.reduce(function(max, overlap) {
      return Math.max(max, overlap.length);
    }, 0);
  }
};

var utilExports = util$3.exports;
var forgeUtil = /*@__PURE__*/getDefaultExportFromCjs(utilExports);

/**
 * Object IDs for ASN.1.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2013 Digital Bazaar, Inc.
 */

var forge$k = forge$m;

forge$k.pki = forge$k.pki || {};
var oids$1 = forge$k.pki.oids = forge$k.oids = forge$k.oids || {};

// set id to name mapping and name to id mapping
function _IN(id, name) {
  oids$1[id] = name;
  oids$1[name] = id;
}
// set id to name mapping only
function _I_(id, name) {
  oids$1[id] = name;
}

// algorithm OIDs
_IN('1.2.840.113549.1.1.1', 'rsaEncryption');
// Note: md2 & md4 not implemented
//_IN('1.2.840.113549.1.1.2', 'md2WithRSAEncryption');
//_IN('1.2.840.113549.1.1.3', 'md4WithRSAEncryption');
_IN('1.2.840.113549.1.1.4', 'md5WithRSAEncryption');
_IN('1.2.840.113549.1.1.5', 'sha1WithRSAEncryption');
_IN('1.2.840.113549.1.1.7', 'RSAES-OAEP');
_IN('1.2.840.113549.1.1.8', 'mgf1');
_IN('1.2.840.113549.1.1.9', 'pSpecified');
_IN('1.2.840.113549.1.1.10', 'RSASSA-PSS');
_IN('1.2.840.113549.1.1.11', 'sha256WithRSAEncryption');
_IN('1.2.840.113549.1.1.12', 'sha384WithRSAEncryption');
_IN('1.2.840.113549.1.1.13', 'sha512WithRSAEncryption');
// Edwards-curve Digital Signature Algorithm (EdDSA) Ed25519
_IN('1.3.101.112', 'EdDSA25519');

_IN('1.2.840.10040.4.3', 'dsa-with-sha1');

_IN('1.3.14.3.2.7', 'desCBC');

_IN('1.3.14.3.2.26', 'sha1');
// Deprecated equivalent of sha1WithRSAEncryption
_IN('1.3.14.3.2.29', 'sha1WithRSASignature');
_IN('2.16.840.1.101.3.4.2.1', 'sha256');
_IN('2.16.840.1.101.3.4.2.2', 'sha384');
_IN('2.16.840.1.101.3.4.2.3', 'sha512');
_IN('2.16.840.1.101.3.4.2.4', 'sha224');
_IN('2.16.840.1.101.3.4.2.5', 'sha512-224');
_IN('2.16.840.1.101.3.4.2.6', 'sha512-256');
_IN('1.2.840.113549.2.2', 'md2');
_IN('1.2.840.113549.2.5', 'md5');

// pkcs#7 content types
_IN('1.2.840.113549.1.7.1', 'data');
_IN('1.2.840.113549.1.7.2', 'signedData');
_IN('1.2.840.113549.1.7.3', 'envelopedData');
_IN('1.2.840.113549.1.7.4', 'signedAndEnvelopedData');
_IN('1.2.840.113549.1.7.5', 'digestedData');
_IN('1.2.840.113549.1.7.6', 'encryptedData');

// pkcs#9 oids
_IN('1.2.840.113549.1.9.1', 'emailAddress');
_IN('1.2.840.113549.1.9.2', 'unstructuredName');
_IN('1.2.840.113549.1.9.3', 'contentType');
_IN('1.2.840.113549.1.9.4', 'messageDigest');
_IN('1.2.840.113549.1.9.5', 'signingTime');
_IN('1.2.840.113549.1.9.6', 'counterSignature');
_IN('1.2.840.113549.1.9.7', 'challengePassword');
_IN('1.2.840.113549.1.9.8', 'unstructuredAddress');
_IN('1.2.840.113549.1.9.14', 'extensionRequest');

_IN('1.2.840.113549.1.9.20', 'friendlyName');
_IN('1.2.840.113549.1.9.21', 'localKeyId');
_IN('1.2.840.113549.1.9.22.1', 'x509Certificate');

// pkcs#12 safe bags
_IN('1.2.840.113549.1.12.10.1.1', 'keyBag');
_IN('1.2.840.113549.1.12.10.1.2', 'pkcs8ShroudedKeyBag');
_IN('1.2.840.113549.1.12.10.1.3', 'certBag');
_IN('1.2.840.113549.1.12.10.1.4', 'crlBag');
_IN('1.2.840.113549.1.12.10.1.5', 'secretBag');
_IN('1.2.840.113549.1.12.10.1.6', 'safeContentsBag');

// password-based-encryption for pkcs#12
_IN('1.2.840.113549.1.5.13', 'pkcs5PBES2');
_IN('1.2.840.113549.1.5.12', 'pkcs5PBKDF2');

_IN('1.2.840.113549.1.12.1.1', 'pbeWithSHAAnd128BitRC4');
_IN('1.2.840.113549.1.12.1.2', 'pbeWithSHAAnd40BitRC4');
_IN('1.2.840.113549.1.12.1.3', 'pbeWithSHAAnd3-KeyTripleDES-CBC');
_IN('1.2.840.113549.1.12.1.4', 'pbeWithSHAAnd2-KeyTripleDES-CBC');
_IN('1.2.840.113549.1.12.1.5', 'pbeWithSHAAnd128BitRC2-CBC');
_IN('1.2.840.113549.1.12.1.6', 'pbewithSHAAnd40BitRC2-CBC');

// hmac OIDs
_IN('1.2.840.113549.2.7', 'hmacWithSHA1');
_IN('1.2.840.113549.2.8', 'hmacWithSHA224');
_IN('1.2.840.113549.2.9', 'hmacWithSHA256');
_IN('1.2.840.113549.2.10', 'hmacWithSHA384');
_IN('1.2.840.113549.2.11', 'hmacWithSHA512');

// symmetric key algorithm oids
_IN('1.2.840.113549.3.7', 'des-EDE3-CBC');
_IN('2.16.840.1.101.3.4.1.2', 'aes128-CBC');
_IN('2.16.840.1.101.3.4.1.22', 'aes192-CBC');
_IN('2.16.840.1.101.3.4.1.42', 'aes256-CBC');

// certificate issuer/subject OIDs
_IN('2.5.4.3', 'commonName');
_IN('2.5.4.4', 'surname');
_IN('2.5.4.5', 'serialNumber');
_IN('2.5.4.6', 'countryName');
_IN('2.5.4.7', 'localityName');
_IN('2.5.4.8', 'stateOrProvinceName');
_IN('2.5.4.9', 'streetAddress');
_IN('2.5.4.10', 'organizationName');
_IN('2.5.4.11', 'organizationalUnitName');
_IN('2.5.4.12', 'title');
_IN('2.5.4.13', 'description');
_IN('2.5.4.15', 'businessCategory');
_IN('2.5.4.17', 'postalCode');
_IN('2.5.4.42', 'givenName');
_IN('1.3.6.1.4.1.311.60.2.1.2', 'jurisdictionOfIncorporationStateOrProvinceName');
_IN('1.3.6.1.4.1.311.60.2.1.3', 'jurisdictionOfIncorporationCountryName');

// X.509 extension OIDs
_IN('2.16.840.1.113730.1.1', 'nsCertType');
_IN('2.16.840.1.113730.1.13', 'nsComment'); // deprecated in theory; still widely used
_I_('2.5.29.1', 'authorityKeyIdentifier'); // deprecated, use .35
_I_('2.5.29.2', 'keyAttributes'); // obsolete use .37 or .15
_I_('2.5.29.3', 'certificatePolicies'); // deprecated, use .32
_I_('2.5.29.4', 'keyUsageRestriction'); // obsolete use .37 or .15
_I_('2.5.29.5', 'policyMapping'); // deprecated use .33
_I_('2.5.29.6', 'subtreesConstraint'); // obsolete use .30
_I_('2.5.29.7', 'subjectAltName'); // deprecated use .17
_I_('2.5.29.8', 'issuerAltName'); // deprecated use .18
_I_('2.5.29.9', 'subjectDirectoryAttributes');
_I_('2.5.29.10', 'basicConstraints'); // deprecated use .19
_I_('2.5.29.11', 'nameConstraints'); // deprecated use .30
_I_('2.5.29.12', 'policyConstraints'); // deprecated use .36
_I_('2.5.29.13', 'basicConstraints'); // deprecated use .19
_IN('2.5.29.14', 'subjectKeyIdentifier');
_IN('2.5.29.15', 'keyUsage');
_I_('2.5.29.16', 'privateKeyUsagePeriod');
_IN('2.5.29.17', 'subjectAltName');
_IN('2.5.29.18', 'issuerAltName');
_IN('2.5.29.19', 'basicConstraints');
_I_('2.5.29.20', 'cRLNumber');
_I_('2.5.29.21', 'cRLReason');
_I_('2.5.29.22', 'expirationDate');
_I_('2.5.29.23', 'instructionCode');
_I_('2.5.29.24', 'invalidityDate');
_I_('2.5.29.25', 'cRLDistributionPoints'); // deprecated use .31
_I_('2.5.29.26', 'issuingDistributionPoint'); // deprecated use .28
_I_('2.5.29.27', 'deltaCRLIndicator');
_I_('2.5.29.28', 'issuingDistributionPoint');
_I_('2.5.29.29', 'certificateIssuer');
_I_('2.5.29.30', 'nameConstraints');
_IN('2.5.29.31', 'cRLDistributionPoints');
_IN('2.5.29.32', 'certificatePolicies');
_I_('2.5.29.33', 'policyMappings');
_I_('2.5.29.34', 'policyConstraints'); // deprecated use .36
_IN('2.5.29.35', 'authorityKeyIdentifier');
_I_('2.5.29.36', 'policyConstraints');
_IN('2.5.29.37', 'extKeyUsage');
_I_('2.5.29.46', 'freshestCRL');
_I_('2.5.29.54', 'inhibitAnyPolicy');

// extKeyUsage purposes
_IN('1.3.6.1.4.1.11129.2.4.2', 'timestampList');
_IN('1.3.6.1.5.5.7.1.1', 'authorityInfoAccess');
_IN('1.3.6.1.5.5.7.3.1', 'serverAuth');
_IN('1.3.6.1.5.5.7.3.2', 'clientAuth');
_IN('1.3.6.1.5.5.7.3.3', 'codeSigning');
_IN('1.3.6.1.5.5.7.3.4', 'emailProtection');
_IN('1.3.6.1.5.5.7.3.8', 'timeStamping');

/**
 * Javascript implementation of Abstract Syntax Notation Number One.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2015 Digital Bazaar, Inc.
 *
 * An API for storing data using the Abstract Syntax Notation Number One
 * format using DER (Distinguished Encoding Rules) encoding. This encoding is
 * commonly used to store data for PKI, i.e. X.509 Certificates, and this
 * implementation exists for that purpose.
 *
 * Abstract Syntax Notation Number One (ASN.1) is used to define the abstract
 * syntax of information without restricting the way the information is encoded
 * for transmission. It provides a standard that allows for open systems
 * communication. ASN.1 defines the syntax of information data and a number of
 * simple data types as well as a notation for describing them and specifying
 * values for them.
 *
 * The RSA algorithm creates public and private keys that are often stored in
 * X.509 or PKCS#X formats -- which use ASN.1 (encoded in DER format). This
 * class provides the most basic functionality required to store and load DSA
 * keys that are encoded according to ASN.1.
 *
 * The most common binary encodings for ASN.1 are BER (Basic Encoding Rules)
 * and DER (Distinguished Encoding Rules). DER is just a subset of BER that
 * has stricter requirements for how data must be encoded.
 *
 * Each ASN.1 structure has a tag (a byte identifying the ASN.1 structure type)
 * and a byte array for the value of this ASN1 structure which may be data or a
 * list of ASN.1 structures.
 *
 * Each ASN.1 structure using BER is (Tag-Length-Value):
 *
 * | byte 0 | bytes X | bytes Y |
 * |--------|---------|----------
 * |  tag   | length  |  value  |
 *
 * ASN.1 allows for tags to be of "High-tag-number form" which allows a tag to
 * be two or more octets, but that is not supported by this class. A tag is
 * only 1 byte. Bits 1-5 give the tag number (ie the data type within a
 * particular 'class'), 6 indicates whether or not the ASN.1 value is
 * constructed from other ASN.1 values, and bits 7 and 8 give the 'class'. If
 * bits 7 and 8 are both zero, the class is UNIVERSAL. If only bit 7 is set,
 * then the class is APPLICATION. If only bit 8 is set, then the class is
 * CONTEXT_SPECIFIC. If both bits 7 and 8 are set, then the class is PRIVATE.
 * The tag numbers for the data types for the class UNIVERSAL are listed below:
 *
 * UNIVERSAL 0 Reserved for use by the encoding rules
 * UNIVERSAL 1 Boolean type
 * UNIVERSAL 2 Integer type
 * UNIVERSAL 3 Bitstring type
 * UNIVERSAL 4 Octetstring type
 * UNIVERSAL 5 Null type
 * UNIVERSAL 6 Object identifier type
 * UNIVERSAL 7 Object descriptor type
 * UNIVERSAL 8 External type and Instance-of type
 * UNIVERSAL 9 Real type
 * UNIVERSAL 10 Enumerated type
 * UNIVERSAL 11 Embedded-pdv type
 * UNIVERSAL 12 UTF8String type
 * UNIVERSAL 13 Relative object identifier type
 * UNIVERSAL 14-15 Reserved for future editions
 * UNIVERSAL 16 Sequence and Sequence-of types
 * UNIVERSAL 17 Set and Set-of types
 * UNIVERSAL 18-22, 25-30 Character string types
 * UNIVERSAL 23-24 Time types
 *
 * The length of an ASN.1 structure is specified after the tag identifier.
 * There is a definite form and an indefinite form. The indefinite form may
 * be used if the encoding is constructed and not all immediately available.
 * The indefinite form is encoded using a length byte with only the 8th bit
 * set. The end of the constructed object is marked using end-of-contents
 * octets (two zero bytes).
 *
 * The definite form looks like this:
 *
 * The length may take up 1 or more bytes, it depends on the length of the
 * value of the ASN.1 structure. DER encoding requires that if the ASN.1
 * structure has a value that has a length greater than 127, more than 1 byte
 * will be used to store its length, otherwise just one byte will be used.
 * This is strict.
 *
 * In the case that the length of the ASN.1 value is less than 127, 1 octet
 * (byte) is used to store the "short form" length. The 8th bit has a value of
 * 0 indicating the length is "short form" and not "long form" and bits 7-1
 * give the length of the data. (The 8th bit is the left-most, most significant
 * bit: also known as big endian or network format).
 *
 * In the case that the length of the ASN.1 value is greater than 127, 2 to
 * 127 octets (bytes) are used to store the "long form" length. The first
 * byte's 8th bit is set to 1 to indicate the length is "long form." Bits 7-1
 * give the number of additional octets. All following octets are in base 256
 * with the most significant digit first (typical big-endian binary unsigned
 * integer storage). So, for instance, if the length of a value was 257, the
 * first byte would be set to:
 *
 * 10000010 = 130 = 0x82.
 *
 * This indicates there are 2 octets (base 256) for the length. The second and
 * third bytes (the octets just mentioned) would store the length in base 256:
 *
 * octet 2: 00000001 = 1 * 256^1 = 256
 * octet 3: 00000001 = 1 * 256^0 = 1
 * total = 257
 *
 * The algorithm for converting a js integer value of 257 to base-256 is:
 *
 * var value = 257;
 * var bytes = [];
 * bytes[0] = (value >>> 8) & 0xFF; // most significant byte first
 * bytes[1] = value & 0xFF;        // least significant byte last
 *
 * On the ASN.1 UNIVERSAL Object Identifier (OID) type:
 *
 * An OID can be written like: "value1.value2.value3...valueN"
 *
 * The DER encoding rules:
 *
 * The first byte has the value 40 * value1 + value2.
 * The following bytes, if any, encode the remaining values. Each value is
 * encoded in base 128, most significant digit first (big endian), with as
 * few digits as possible, and the most significant bit of each byte set
 * to 1 except the last in each value's encoding. For example: Given the
 * OID "1.2.840.113549", its DER encoding is (remember each byte except the
 * last one in each encoding is OR'd with 0x80):
 *
 * byte 1: 40 * 1 + 2 = 42 = 0x2A.
 * bytes 2-3: 128 * 6 + 72 = 840 = 6 72 = 6 72 = 0x0648 = 0x8648
 * bytes 4-6: 16384 * 6 + 128 * 119 + 13 = 6 119 13 = 0x06770D = 0x86F70D
 *
 * The final value is: 0x2A864886F70D.
 * The full OID (including ASN.1 tag and length of 6 bytes) is:
 * 0x06062A864886F70D
 */

var forge$j = forge$m;



/* ASN.1 API */
var asn1$2 = forge$j.asn1 = forge$j.asn1 || {};

/**
 * ASN.1 classes.
 */
asn1$2.Class = {
  UNIVERSAL:        0x00,
  APPLICATION:      0x40,
  CONTEXT_SPECIFIC: 0x80,
  PRIVATE:          0xC0
};

/**
 * ASN.1 types. Not all types are supported by this implementation, only
 * those necessary to implement a simple PKI are implemented.
 */
asn1$2.Type = {
  NONE:             0,
  BOOLEAN:          1,
  INTEGER:          2,
  BITSTRING:        3,
  OCTETSTRING:      4,
  NULL:             5,
  OID:              6,
  ODESC:            7,
  EXTERNAL:         8,
  REAL:             9,
  ENUMERATED:      10,
  EMBEDDED:        11,
  UTF8:            12,
  ROID:            13,
  SEQUENCE:        16,
  SET:             17,
  PRINTABLESTRING: 19,
  IA5STRING:       22,
  UTCTIME:         23,
  GENERALIZEDTIME: 24,
  BMPSTRING:       30
};

/**
 * Creates a new asn1 object.
 *
 * @param tagClass the tag class for the object.
 * @param type the data type (tag number) for the object.
 * @param constructed true if the asn1 object is in constructed form.
 * @param value the value for the object, if it is not constructed.
 * @param [options] the options to use:
 *          [bitStringContents] the plain BIT STRING content including padding
 *            byte.
 *
 * @return the asn1 object.
 */
asn1$2.create = function(tagClass, type, constructed, value, options) {
  /* An asn1 object has a tagClass, a type, a constructed flag, and a
    value. The value's type depends on the constructed flag. If
    constructed, it will contain a list of other asn1 objects. If not,
    it will contain the ASN.1 value as an array of bytes formatted
    according to the ASN.1 data type. */

  // remove undefined values
  if(forge$j.util.isArray(value)) {
    var tmp = [];
    for(var i = 0; i < value.length; ++i) {
      if(value[i] !== undefined) {
        tmp.push(value[i]);
      }
    }
    value = tmp;
  }

  var obj = {
    tagClass: tagClass,
    type: type,
    constructed: constructed,
    composed: constructed || forge$j.util.isArray(value),
    value: value
  };
  if(options && 'bitStringContents' in options) {
    // TODO: copy byte buffer if it's a buffer not a string
    obj.bitStringContents = options.bitStringContents;
    // TODO: add readonly flag to avoid this overhead
    // save copy to detect changes
    obj.original = asn1$2.copy(obj);
  }
  return obj;
};

/**
 * Copies an asn1 object.
 *
 * @param obj the asn1 object.
 * @param [options] copy options:
 *          [excludeBitStringContents] true to not copy bitStringContents
 *
 * @return the a copy of the asn1 object.
 */
asn1$2.copy = function(obj, options) {
  var copy;

  if(forge$j.util.isArray(obj)) {
    copy = [];
    for(var i = 0; i < obj.length; ++i) {
      copy.push(asn1$2.copy(obj[i], options));
    }
    return copy;
  }

  if(typeof obj === 'string') {
    // TODO: copy byte buffer if it's a buffer not a string
    return obj;
  }

  copy = {
    tagClass: obj.tagClass,
    type: obj.type,
    constructed: obj.constructed,
    composed: obj.composed,
    value: asn1$2.copy(obj.value, options)
  };
  if(options && !options.excludeBitStringContents) {
    // TODO: copy byte buffer if it's a buffer not a string
    copy.bitStringContents = obj.bitStringContents;
  }
  return copy;
};

/**
 * Compares asn1 objects for equality.
 *
 * Note this function does not run in constant time.
 *
 * @param obj1 the first asn1 object.
 * @param obj2 the second asn1 object.
 * @param [options] compare options:
 *          [includeBitStringContents] true to compare bitStringContents
 *
 * @return true if the asn1 objects are equal.
 */
asn1$2.equals = function(obj1, obj2, options) {
  if(forge$j.util.isArray(obj1)) {
    if(!forge$j.util.isArray(obj2)) {
      return false;
    }
    if(obj1.length !== obj2.length) {
      return false;
    }
    for(var i = 0; i < obj1.length; ++i) {
      if(!asn1$2.equals(obj1[i], obj2[i])) {
        return false;
      }
    }
    return true;
  }

  if(typeof obj1 !== typeof obj2) {
    return false;
  }

  if(typeof obj1 === 'string') {
    return obj1 === obj2;
  }

  var equal = obj1.tagClass === obj2.tagClass &&
    obj1.type === obj2.type &&
    obj1.constructed === obj2.constructed &&
    obj1.composed === obj2.composed &&
    asn1$2.equals(obj1.value, obj2.value);
  if(options && options.includeBitStringContents) {
    equal = equal && (obj1.bitStringContents === obj2.bitStringContents);
  }

  return equal;
};

/**
 * Gets the length of a BER-encoded ASN.1 value.
 *
 * In case the length is not specified, undefined is returned.
 *
 * @param b the BER-encoded ASN.1 byte buffer, starting with the first
 *          length byte.
 *
 * @return the length of the BER-encoded ASN.1 value or undefined.
 */
asn1$2.getBerValueLength = function(b) {
  // TODO: move this function and related DER/BER functions to a der.js
  // file; better abstract ASN.1 away from der/ber.
  var b2 = b.getByte();
  if(b2 === 0x80) {
    return undefined;
  }

  // see if the length is "short form" or "long form" (bit 8 set)
  var length;
  var longForm = b2 & 0x80;
  if(!longForm) {
    // length is just the first byte
    length = b2;
  } else {
    // the number of bytes the length is specified in bits 7 through 1
    // and each length byte is in big-endian base-256
    length = b.getInt((b2 & 0x7F) << 3);
  }
  return length;
};

/**
 * Check if the byte buffer has enough bytes. Throws an Error if not.
 *
 * @param bytes the byte buffer to parse from.
 * @param remaining the bytes remaining in the current parsing state.
 * @param n the number of bytes the buffer must have.
 */
function _checkBufferLength(bytes, remaining, n) {
  if(n > remaining) {
    var error = new Error('Too few bytes to parse DER.');
    error.available = bytes.length();
    error.remaining = remaining;
    error.requested = n;
    throw error;
  }
}

/**
 * Gets the length of a BER-encoded ASN.1 value.
 *
 * In case the length is not specified, undefined is returned.
 *
 * @param bytes the byte buffer to parse from.
 * @param remaining the bytes remaining in the current parsing state.
 *
 * @return the length of the BER-encoded ASN.1 value or undefined.
 */
var _getValueLength = function(bytes, remaining) {
  // TODO: move this function and related DER/BER functions to a der.js
  // file; better abstract ASN.1 away from der/ber.
  // fromDer already checked that this byte exists
  var b2 = bytes.getByte();
  remaining--;
  if(b2 === 0x80) {
    return undefined;
  }

  // see if the length is "short form" or "long form" (bit 8 set)
  var length;
  var longForm = b2 & 0x80;
  if(!longForm) {
    // length is just the first byte
    length = b2;
  } else {
    // the number of bytes the length is specified in bits 7 through 1
    // and each length byte is in big-endian base-256
    var longFormBytes = b2 & 0x7F;
    _checkBufferLength(bytes, remaining, longFormBytes);
    length = bytes.getInt(longFormBytes << 3);
  }
  // FIXME: this will only happen for 32 bit getInt with high bit set
  if(length < 0) {
    throw new Error('Negative length: ' + length);
  }
  return length;
};

/**
 * Parses an asn1 object from a byte buffer in DER format.
 *
 * @param bytes the byte buffer to parse from.
 * @param [strict] true to be strict when checking value lengths, false to
 *          allow truncated values (default: true).
 * @param [options] object with options or boolean strict flag
 *          [strict] true to be strict when checking value lengths, false to
 *            allow truncated values (default: true).
 *          [parseAllBytes] true to ensure all bytes are parsed
 *            (default: true)
 *          [decodeBitStrings] true to attempt to decode the content of
 *            BIT STRINGs (not OCTET STRINGs) using strict mode. Note that
 *            without schema support to understand the data context this can
 *            erroneously decode values that happen to be valid ASN.1. This
 *            flag will be deprecated or removed as soon as schema support is
 *            available. (default: true)
 *
 * @throws Will throw an error for various malformed input conditions.
 *
 * @return the parsed asn1 object.
 */
asn1$2.fromDer = function(bytes, options) {
  if(options === undefined) {
    options = {
      strict: true,
      parseAllBytes: true,
      decodeBitStrings: true
    };
  }
  if(typeof options === 'boolean') {
    options = {
      strict: options,
      parseAllBytes: true,
      decodeBitStrings: true
    };
  }
  if(!('strict' in options)) {
    options.strict = true;
  }
  if(!('parseAllBytes' in options)) {
    options.parseAllBytes = true;
  }
  if(!('decodeBitStrings' in options)) {
    options.decodeBitStrings = true;
  }

  // wrap in buffer if needed
  if(typeof bytes === 'string') {
    bytes = forge$j.util.createBuffer(bytes);
  }

  var byteCount = bytes.length();
  var value = _fromDer(bytes, bytes.length(), 0, options);
  if(options.parseAllBytes && bytes.length() !== 0) {
    var error = new Error('Unparsed DER bytes remain after ASN.1 parsing.');
    error.byteCount = byteCount;
    error.remaining = bytes.length();
    throw error;
  }
  return value;
};

/**
 * Internal function to parse an asn1 object from a byte buffer in DER format.
 *
 * @param bytes the byte buffer to parse from.
 * @param remaining the number of bytes remaining for this chunk.
 * @param depth the current parsing depth.
 * @param options object with same options as fromDer().
 *
 * @return the parsed asn1 object.
 */
function _fromDer(bytes, remaining, depth, options) {
  // temporary storage for consumption calculations
  var start;

  // minimum length for ASN.1 DER structure is 2
  _checkBufferLength(bytes, remaining, 2);

  // get the first byte
  var b1 = bytes.getByte();
  // consumed one byte
  remaining--;

  // get the tag class
  var tagClass = (b1 & 0xC0);

  // get the type (bits 1-5)
  var type = b1 & 0x1F;

  // get the variable value length and adjust remaining bytes
  start = bytes.length();
  var length = _getValueLength(bytes, remaining);
  remaining -= start - bytes.length();

  // ensure there are enough bytes to get the value
  if(length !== undefined && length > remaining) {
    if(options.strict) {
      var error = new Error('Too few bytes to read ASN.1 value.');
      error.available = bytes.length();
      error.remaining = remaining;
      error.requested = length;
      throw error;
    }
    // Note: be lenient with truncated values and use remaining state bytes
    length = remaining;
  }

  // value storage
  var value;
  // possible BIT STRING contents storage
  var bitStringContents;

  // constructed flag is bit 6 (32 = 0x20) of the first byte
  var constructed = ((b1 & 0x20) === 0x20);
  if(constructed) {
    // parse child asn1 objects from the value
    value = [];
    if(length === undefined) {
      // asn1 object of indefinite length, read until end tag
      for(;;) {
        _checkBufferLength(bytes, remaining, 2);
        if(bytes.bytes(2) === String.fromCharCode(0, 0)) {
          bytes.getBytes(2);
          remaining -= 2;
          break;
        }
        start = bytes.length();
        value.push(_fromDer(bytes, remaining, depth + 1, options));
        remaining -= start - bytes.length();
      }
    } else {
      // parsing asn1 object of definite length
      while(length > 0) {
        start = bytes.length();
        value.push(_fromDer(bytes, length, depth + 1, options));
        remaining -= start - bytes.length();
        length -= start - bytes.length();
      }
    }
  }

  // if a BIT STRING, save the contents including padding
  if(value === undefined && tagClass === asn1$2.Class.UNIVERSAL &&
    type === asn1$2.Type.BITSTRING) {
    bitStringContents = bytes.bytes(length);
  }

  // determine if a non-constructed value should be decoded as a composed
  // value that contains other ASN.1 objects. BIT STRINGs (and OCTET STRINGs)
  // can be used this way.
  if(value === undefined && options.decodeBitStrings &&
    tagClass === asn1$2.Class.UNIVERSAL &&
    // FIXME: OCTET STRINGs not yet supported here
    // .. other parts of forge expect to decode OCTET STRINGs manually
    (type === asn1$2.Type.BITSTRING /*|| type === asn1.Type.OCTETSTRING*/) &&
    length > 1) {
    // save read position
    var savedRead = bytes.read;
    var savedRemaining = remaining;
    var unused = 0;
    if(type === asn1$2.Type.BITSTRING) {
      /* The first octet gives the number of bits by which the length of the
        bit string is less than the next multiple of eight (this is called
        the "number of unused bits").

        The second and following octets give the value of the bit string
        converted to an octet string. */
      _checkBufferLength(bytes, remaining, 1);
      unused = bytes.getByte();
      remaining--;
    }
    // if all bits are used, maybe the BIT/OCTET STRING holds ASN.1 objs
    if(unused === 0) {
      try {
        // attempt to parse child asn1 object from the value
        // (stored in array to signal composed value)
        start = bytes.length();
        var subOptions = {
          // enforce strict mode to avoid parsing ASN.1 from plain data
          strict: true,
          decodeBitStrings: true
        };
        var composed = _fromDer(bytes, remaining, depth + 1, subOptions);
        var used = start - bytes.length();
        remaining -= used;
        if(type == asn1$2.Type.BITSTRING) {
          used++;
        }

        // if the data all decoded and the class indicates UNIVERSAL or
        // CONTEXT_SPECIFIC then assume we've got an encapsulated ASN.1 object
        var tc = composed.tagClass;
        if(used === length &&
          (tc === asn1$2.Class.UNIVERSAL || tc === asn1$2.Class.CONTEXT_SPECIFIC)) {
          value = [composed];
        }
      } catch(ex) {
      }
    }
    if(value === undefined) {
      // restore read position
      bytes.read = savedRead;
      remaining = savedRemaining;
    }
  }

  if(value === undefined) {
    // asn1 not constructed or composed, get raw value
    // TODO: do DER to OID conversion and vice-versa in .toDer?

    if(length === undefined) {
      if(options.strict) {
        throw new Error('Non-constructed ASN.1 object of indefinite length.');
      }
      // be lenient and use remaining state bytes
      length = remaining;
    }

    if(type === asn1$2.Type.BMPSTRING) {
      value = '';
      for(; length > 0; length -= 2) {
        _checkBufferLength(bytes, remaining, 2);
        value += String.fromCharCode(bytes.getInt16());
        remaining -= 2;
      }
    } else {
      value = bytes.getBytes(length);
      remaining -= length;
    }
  }

  // add BIT STRING contents if available
  var asn1Options = bitStringContents === undefined ? null : {
    bitStringContents: bitStringContents
  };

  // create and return asn1 object
  return asn1$2.create(tagClass, type, constructed, value, asn1Options);
}

/**
 * Converts the given asn1 object to a buffer of bytes in DER format.
 *
 * @param asn1 the asn1 object to convert to bytes.
 *
 * @return the buffer of bytes.
 */
asn1$2.toDer = function(obj) {
  var bytes = forge$j.util.createBuffer();

  // build the first byte
  var b1 = obj.tagClass | obj.type;

  // for storing the ASN.1 value
  var value = forge$j.util.createBuffer();

  // use BIT STRING contents if available and data not changed
  var useBitStringContents = false;
  if('bitStringContents' in obj) {
    useBitStringContents = true;
    if(obj.original) {
      useBitStringContents = asn1$2.equals(obj, obj.original);
    }
  }

  if(useBitStringContents) {
    value.putBytes(obj.bitStringContents);
  } else if(obj.composed) {
    // if composed, use each child asn1 object's DER bytes as value
    // turn on 6th bit (0x20 = 32) to indicate asn1 is constructed
    // from other asn1 objects
    if(obj.constructed) {
      b1 |= 0x20;
    } else {
      // type is a bit string, add unused bits of 0x00
      value.putByte(0x00);
    }

    // add all of the child DER bytes together
    for(var i = 0; i < obj.value.length; ++i) {
      if(obj.value[i] !== undefined) {
        value.putBuffer(asn1$2.toDer(obj.value[i]));
      }
    }
  } else {
    // use asn1.value directly
    if(obj.type === asn1$2.Type.BMPSTRING) {
      for(var i = 0; i < obj.value.length; ++i) {
        value.putInt16(obj.value.charCodeAt(i));
      }
    } else {
      // ensure integer is minimally-encoded
      // TODO: should all leading bytes be stripped vs just one?
      // .. ex '00 00 01' => '01'?
      if(obj.type === asn1$2.Type.INTEGER &&
        obj.value.length > 1 &&
        // leading 0x00 for positive integer
        ((obj.value.charCodeAt(0) === 0 &&
        (obj.value.charCodeAt(1) & 0x80) === 0) ||
        // leading 0xFF for negative integer
        (obj.value.charCodeAt(0) === 0xFF &&
        (obj.value.charCodeAt(1) & 0x80) === 0x80))) {
        value.putBytes(obj.value.substr(1));
      } else {
        value.putBytes(obj.value);
      }
    }
  }

  // add tag byte
  bytes.putByte(b1);

  // use "short form" encoding
  if(value.length() <= 127) {
    // one byte describes the length
    // bit 8 = 0 and bits 7-1 = length
    bytes.putByte(value.length() & 0x7F);
  } else {
    // use "long form" encoding
    // 2 to 127 bytes describe the length
    // first byte: bit 8 = 1 and bits 7-1 = # of additional bytes
    // other bytes: length in base 256, big-endian
    var len = value.length();
    var lenBytes = '';
    do {
      lenBytes += String.fromCharCode(len & 0xFF);
      len = len >>> 8;
    } while(len > 0);

    // set first byte to # bytes used to store the length and turn on
    // bit 8 to indicate long-form length is used
    bytes.putByte(lenBytes.length | 0x80);

    // concatenate length bytes in reverse since they were generated
    // little endian and we need big endian
    for(var i = lenBytes.length - 1; i >= 0; --i) {
      bytes.putByte(lenBytes.charCodeAt(i));
    }
  }

  // concatenate value bytes
  bytes.putBuffer(value);
  return bytes;
};

/**
 * Converts an OID dot-separated string to a byte buffer. The byte buffer
 * contains only the DER-encoded value, not any tag or length bytes.
 *
 * @param oid the OID dot-separated string.
 *
 * @return the byte buffer.
 */
asn1$2.oidToDer = function(oid) {
  // split OID into individual values
  var values = oid.split('.');
  var bytes = forge$j.util.createBuffer();

  // first byte is 40 * value1 + value2
  bytes.putByte(40 * parseInt(values[0], 10) + parseInt(values[1], 10));
  // other bytes are each value in base 128 with 8th bit set except for
  // the last byte for each value
  var last, valueBytes, value, b;
  for(var i = 2; i < values.length; ++i) {
    // produce value bytes in reverse because we don't know how many
    // bytes it will take to store the value
    last = true;
    valueBytes = [];
    value = parseInt(values[i], 10);
    do {
      b = value & 0x7F;
      value = value >>> 7;
      // if value is not last, then turn on 8th bit
      if(!last) {
        b |= 0x80;
      }
      valueBytes.push(b);
      last = false;
    } while(value > 0);

    // add value bytes in reverse (needs to be in big endian)
    for(var n = valueBytes.length - 1; n >= 0; --n) {
      bytes.putByte(valueBytes[n]);
    }
  }

  return bytes;
};

/**
 * Converts a DER-encoded byte buffer to an OID dot-separated string. The
 * byte buffer should contain only the DER-encoded value, not any tag or
 * length bytes.
 *
 * @param bytes the byte buffer.
 *
 * @return the OID dot-separated string.
 */
asn1$2.derToOid = function(bytes) {
  var oid;

  // wrap in buffer if needed
  if(typeof bytes === 'string') {
    bytes = forge$j.util.createBuffer(bytes);
  }

  // first byte is 40 * value1 + value2
  var b = bytes.getByte();
  oid = Math.floor(b / 40) + '.' + (b % 40);

  // other bytes are each value in base 128 with 8th bit set except for
  // the last byte for each value
  var value = 0;
  while(bytes.length() > 0) {
    b = bytes.getByte();
    value = value << 7;
    // not the last byte for the value
    if(b & 0x80) {
      value += b & 0x7F;
    } else {
      // last byte
      oid += '.' + (value + b);
      value = 0;
    }
  }

  return oid;
};

/**
 * Converts a UTCTime value to a date.
 *
 * Note: GeneralizedTime has 4 digits for the year and is used for X.509
 * dates past 2049. Parsing that structure hasn't been implemented yet.
 *
 * @param utc the UTCTime value to convert.
 *
 * @return the date.
 */
asn1$2.utcTimeToDate = function(utc) {
  /* The following formats can be used:

    YYMMDDhhmmZ
    YYMMDDhhmm+hh'mm'
    YYMMDDhhmm-hh'mm'
    YYMMDDhhmmssZ
    YYMMDDhhmmss+hh'mm'
    YYMMDDhhmmss-hh'mm'

    Where:

    YY is the least significant two digits of the year
    MM is the month (01 to 12)
    DD is the day (01 to 31)
    hh is the hour (00 to 23)
    mm are the minutes (00 to 59)
    ss are the seconds (00 to 59)
    Z indicates that local time is GMT, + indicates that local time is
    later than GMT, and - indicates that local time is earlier than GMT
    hh' is the absolute value of the offset from GMT in hours
    mm' is the absolute value of the offset from GMT in minutes */
  var date = new Date();

  // if YY >= 50 use 19xx, if YY < 50 use 20xx
  var year = parseInt(utc.substr(0, 2), 10);
  year = (year >= 50) ? 1900 + year : 2000 + year;
  var MM = parseInt(utc.substr(2, 2), 10) - 1; // use 0-11 for month
  var DD = parseInt(utc.substr(4, 2), 10);
  var hh = parseInt(utc.substr(6, 2), 10);
  var mm = parseInt(utc.substr(8, 2), 10);
  var ss = 0;

  // not just YYMMDDhhmmZ
  if(utc.length > 11) {
    // get character after minutes
    var c = utc.charAt(10);
    var end = 10;

    // see if seconds are present
    if(c !== '+' && c !== '-') {
      // get seconds
      ss = parseInt(utc.substr(10, 2), 10);
      end += 2;
    }
  }

  // update date
  date.setUTCFullYear(year, MM, DD);
  date.setUTCHours(hh, mm, ss, 0);

  if(end) {
    // get +/- after end of time
    c = utc.charAt(end);
    if(c === '+' || c === '-') {
      // get hours+minutes offset
      var hhoffset = parseInt(utc.substr(end + 1, 2), 10);
      var mmoffset = parseInt(utc.substr(end + 4, 2), 10);

      // calculate offset in milliseconds
      var offset = hhoffset * 60 + mmoffset;
      offset *= 60000;

      // apply offset
      if(c === '+') {
        date.setTime(+date - offset);
      } else {
        date.setTime(+date + offset);
      }
    }
  }

  return date;
};

/**
 * Converts a GeneralizedTime value to a date.
 *
 * @param gentime the GeneralizedTime value to convert.
 *
 * @return the date.
 */
asn1$2.generalizedTimeToDate = function(gentime) {
  /* The following formats can be used:

    YYYYMMDDHHMMSS
    YYYYMMDDHHMMSS.fff
    YYYYMMDDHHMMSSZ
    YYYYMMDDHHMMSS.fffZ
    YYYYMMDDHHMMSS+hh'mm'
    YYYYMMDDHHMMSS.fff+hh'mm'
    YYYYMMDDHHMMSS-hh'mm'
    YYYYMMDDHHMMSS.fff-hh'mm'

    Where:

    YYYY is the year
    MM is the month (01 to 12)
    DD is the day (01 to 31)
    hh is the hour (00 to 23)
    mm are the minutes (00 to 59)
    ss are the seconds (00 to 59)
    .fff is the second fraction, accurate to three decimal places
    Z indicates that local time is GMT, + indicates that local time is
    later than GMT, and - indicates that local time is earlier than GMT
    hh' is the absolute value of the offset from GMT in hours
    mm' is the absolute value of the offset from GMT in minutes */
  var date = new Date();

  var YYYY = parseInt(gentime.substr(0, 4), 10);
  var MM = parseInt(gentime.substr(4, 2), 10) - 1; // use 0-11 for month
  var DD = parseInt(gentime.substr(6, 2), 10);
  var hh = parseInt(gentime.substr(8, 2), 10);
  var mm = parseInt(gentime.substr(10, 2), 10);
  var ss = parseInt(gentime.substr(12, 2), 10);
  var fff = 0;
  var offset = 0;
  var isUTC = false;

  if(gentime.charAt(gentime.length - 1) === 'Z') {
    isUTC = true;
  }

  var end = gentime.length - 5, c = gentime.charAt(end);
  if(c === '+' || c === '-') {
    // get hours+minutes offset
    var hhoffset = parseInt(gentime.substr(end + 1, 2), 10);
    var mmoffset = parseInt(gentime.substr(end + 4, 2), 10);

    // calculate offset in milliseconds
    offset = hhoffset * 60 + mmoffset;
    offset *= 60000;

    // apply offset
    if(c === '+') {
      offset *= -1;
    }

    isUTC = true;
  }

  // check for second fraction
  if(gentime.charAt(14) === '.') {
    fff = parseFloat(gentime.substr(14), 10) * 1000;
  }

  if(isUTC) {
    date.setUTCFullYear(YYYY, MM, DD);
    date.setUTCHours(hh, mm, ss, fff);

    // apply offset
    date.setTime(+date + offset);
  } else {
    date.setFullYear(YYYY, MM, DD);
    date.setHours(hh, mm, ss, fff);
  }

  return date;
};

/**
 * Converts a date to a UTCTime value.
 *
 * Note: GeneralizedTime has 4 digits for the year and is used for X.509
 * dates past 2049. Converting to a GeneralizedTime hasn't been
 * implemented yet.
 *
 * @param date the date to convert.
 *
 * @return the UTCTime value.
 */
asn1$2.dateToUtcTime = function(date) {
  // TODO: validate; currently assumes proper format
  if(typeof date === 'string') {
    return date;
  }

  var rval = '';

  // create format YYMMDDhhmmssZ
  var format = [];
  format.push(('' + date.getUTCFullYear()).substr(2));
  format.push('' + (date.getUTCMonth() + 1));
  format.push('' + date.getUTCDate());
  format.push('' + date.getUTCHours());
  format.push('' + date.getUTCMinutes());
  format.push('' + date.getUTCSeconds());

  // ensure 2 digits are used for each format entry
  for(var i = 0; i < format.length; ++i) {
    if(format[i].length < 2) {
      rval += '0';
    }
    rval += format[i];
  }
  rval += 'Z';

  return rval;
};

/**
 * Converts a date to a GeneralizedTime value.
 *
 * @param date the date to convert.
 *
 * @return the GeneralizedTime value as a string.
 */
asn1$2.dateToGeneralizedTime = function(date) {
  // TODO: validate; currently assumes proper format
  if(typeof date === 'string') {
    return date;
  }

  var rval = '';

  // create format YYYYMMDDHHMMSSZ
  var format = [];
  format.push('' + date.getUTCFullYear());
  format.push('' + (date.getUTCMonth() + 1));
  format.push('' + date.getUTCDate());
  format.push('' + date.getUTCHours());
  format.push('' + date.getUTCMinutes());
  format.push('' + date.getUTCSeconds());

  // ensure 2 digits are used for each format entry
  for(var i = 0; i < format.length; ++i) {
    if(format[i].length < 2) {
      rval += '0';
    }
    rval += format[i];
  }
  rval += 'Z';

  return rval;
};

/**
 * Converts a javascript integer to a DER-encoded byte buffer to be used
 * as the value for an INTEGER type.
 *
 * @param x the integer.
 *
 * @return the byte buffer.
 */
asn1$2.integerToDer = function(x) {
  var rval = forge$j.util.createBuffer();
  if(x >= -0x80 && x < 0x80) {
    return rval.putSignedInt(x, 8);
  }
  if(x >= -0x8000 && x < 0x8000) {
    return rval.putSignedInt(x, 16);
  }
  if(x >= -0x800000 && x < 0x800000) {
    return rval.putSignedInt(x, 24);
  }
  if(x >= -0x80000000 && x < 0x80000000) {
    return rval.putSignedInt(x, 32);
  }
  var error = new Error('Integer too large; max is 32-bits.');
  error.integer = x;
  throw error;
};

/**
 * Converts a DER-encoded byte buffer to a javascript integer. This is
 * typically used to decode the value of an INTEGER type.
 *
 * @param bytes the byte buffer.
 *
 * @return the integer.
 */
asn1$2.derToInteger = function(bytes) {
  // wrap in buffer if needed
  if(typeof bytes === 'string') {
    bytes = forge$j.util.createBuffer(bytes);
  }

  var n = bytes.length() * 8;
  if(n > 32) {
    throw new Error('Integer too large; max is 32-bits.');
  }
  return bytes.getSignedInt(n);
};

/**
 * Validates that the given ASN.1 object is at least a super set of the
 * given ASN.1 structure. Only tag classes and types are checked. An
 * optional map may also be provided to capture ASN.1 values while the
 * structure is checked.
 *
 * To capture an ASN.1 value, set an object in the validator's 'capture'
 * parameter to the key to use in the capture map. To capture the full
 * ASN.1 object, specify 'captureAsn1'. To capture BIT STRING bytes, including
 * the leading unused bits counter byte, specify 'captureBitStringContents'.
 * To capture BIT STRING bytes, without the leading unused bits counter byte,
 * specify 'captureBitStringValue'.
 *
 * Objects in the validator may set a field 'optional' to true to indicate
 * that it isn't necessary to pass validation.
 *
 * @param obj the ASN.1 object to validate.
 * @param v the ASN.1 structure validator.
 * @param capture an optional map to capture values in.
 * @param errors an optional array for storing validation errors.
 *
 * @return true on success, false on failure.
 */
asn1$2.validate = function(obj, v, capture, errors) {
  var rval = false;

  // ensure tag class and type are the same if specified
  if((obj.tagClass === v.tagClass || typeof(v.tagClass) === 'undefined') &&
    (obj.type === v.type || typeof(v.type) === 'undefined')) {
    // ensure constructed flag is the same if specified
    if(obj.constructed === v.constructed ||
      typeof(v.constructed) === 'undefined') {
      rval = true;

      // handle sub values
      if(v.value && forge$j.util.isArray(v.value)) {
        var j = 0;
        for(var i = 0; rval && i < v.value.length; ++i) {
          rval = v.value[i].optional || false;
          if(obj.value[j]) {
            rval = asn1$2.validate(obj.value[j], v.value[i], capture, errors);
            if(rval) {
              ++j;
            } else if(v.value[i].optional) {
              rval = true;
            }
          }
          if(!rval && errors) {
            errors.push(
              '[' + v.name + '] ' +
              'Tag class "' + v.tagClass + '", type "' +
              v.type + '" expected value length "' +
              v.value.length + '", got "' +
              obj.value.length + '"');
          }
        }
      }

      if(rval && capture) {
        if(v.capture) {
          capture[v.capture] = obj.value;
        }
        if(v.captureAsn1) {
          capture[v.captureAsn1] = obj;
        }
        if(v.captureBitStringContents && 'bitStringContents' in obj) {
          capture[v.captureBitStringContents] = obj.bitStringContents;
        }
        if(v.captureBitStringValue && 'bitStringContents' in obj) {
          if(obj.bitStringContents.length < 2) {
            capture[v.captureBitStringValue] = '';
          } else {
            // FIXME: support unused bits with data shifting
            var unused = obj.bitStringContents.charCodeAt(0);
            if(unused !== 0) {
              throw new Error(
                'captureBitStringValue only supported for zero unused bits');
            }
            capture[v.captureBitStringValue] = obj.bitStringContents.slice(1);
          }
        }
      }
    } else if(errors) {
      errors.push(
        '[' + v.name + '] ' +
        'Expected constructed "' + v.constructed + '", got "' +
        obj.constructed + '"');
    }
  } else if(errors) {
    if(obj.tagClass !== v.tagClass) {
      errors.push(
        '[' + v.name + '] ' +
        'Expected tag class "' + v.tagClass + '", got "' +
        obj.tagClass + '"');
    }
    if(obj.type !== v.type) {
      errors.push(
        '[' + v.name + '] ' +
        'Expected type "' + v.type + '", got "' + obj.type + '"');
    }
  }
  return rval;
};

// regex for testing for non-latin characters
var _nonLatinRegex = /[^\\u0000-\\u00ff]/;

/**
 * Pretty prints an ASN.1 object to a string.
 *
 * @param obj the object to write out.
 * @param level the level in the tree.
 * @param indentation the indentation to use.
 *
 * @return the string.
 */
asn1$2.prettyPrint = function(obj, level, indentation) {
  var rval = '';

  // set default level and indentation
  level = level || 0;
  indentation = indentation || 2;

  // start new line for deep levels
  if(level > 0) {
    rval += '\n';
  }

  // create indent
  var indent = '';
  for(var i = 0; i < level * indentation; ++i) {
    indent += ' ';
  }

  // print class:type
  rval += indent + 'Tag: ';
  switch(obj.tagClass) {
  case asn1$2.Class.UNIVERSAL:
    rval += 'Universal:';
    break;
  case asn1$2.Class.APPLICATION:
    rval += 'Application:';
    break;
  case asn1$2.Class.CONTEXT_SPECIFIC:
    rval += 'Context-Specific:';
    break;
  case asn1$2.Class.PRIVATE:
    rval += 'Private:';
    break;
  }

  if(obj.tagClass === asn1$2.Class.UNIVERSAL) {
    rval += obj.type;

    // known types
    switch(obj.type) {
    case asn1$2.Type.NONE:
      rval += ' (None)';
      break;
    case asn1$2.Type.BOOLEAN:
      rval += ' (Boolean)';
      break;
    case asn1$2.Type.INTEGER:
      rval += ' (Integer)';
      break;
    case asn1$2.Type.BITSTRING:
      rval += ' (Bit string)';
      break;
    case asn1$2.Type.OCTETSTRING:
      rval += ' (Octet string)';
      break;
    case asn1$2.Type.NULL:
      rval += ' (Null)';
      break;
    case asn1$2.Type.OID:
      rval += ' (Object Identifier)';
      break;
    case asn1$2.Type.ODESC:
      rval += ' (Object Descriptor)';
      break;
    case asn1$2.Type.EXTERNAL:
      rval += ' (External or Instance of)';
      break;
    case asn1$2.Type.REAL:
      rval += ' (Real)';
      break;
    case asn1$2.Type.ENUMERATED:
      rval += ' (Enumerated)';
      break;
    case asn1$2.Type.EMBEDDED:
      rval += ' (Embedded PDV)';
      break;
    case asn1$2.Type.UTF8:
      rval += ' (UTF8)';
      break;
    case asn1$2.Type.ROID:
      rval += ' (Relative Object Identifier)';
      break;
    case asn1$2.Type.SEQUENCE:
      rval += ' (Sequence)';
      break;
    case asn1$2.Type.SET:
      rval += ' (Set)';
      break;
    case asn1$2.Type.PRINTABLESTRING:
      rval += ' (Printable String)';
      break;
    case asn1$2.Type.IA5String:
      rval += ' (IA5String (ASCII))';
      break;
    case asn1$2.Type.UTCTIME:
      rval += ' (UTC time)';
      break;
    case asn1$2.Type.GENERALIZEDTIME:
      rval += ' (Generalized time)';
      break;
    case asn1$2.Type.BMPSTRING:
      rval += ' (BMP String)';
      break;
    }
  } else {
    rval += obj.type;
  }

  rval += '\n';
  rval += indent + 'Constructed: ' + obj.constructed + '\n';

  if(obj.composed) {
    var subvalues = 0;
    var sub = '';
    for(var i = 0; i < obj.value.length; ++i) {
      if(obj.value[i] !== undefined) {
        subvalues += 1;
        sub += asn1$2.prettyPrint(obj.value[i], level + 1, indentation);
        if((i + 1) < obj.value.length) {
          sub += ',';
        }
      }
    }
    rval += indent + 'Sub values: ' + subvalues + sub;
  } else {
    rval += indent + 'Value: ';
    if(obj.type === asn1$2.Type.OID) {
      var oid = asn1$2.derToOid(obj.value);
      rval += oid;
      if(forge$j.pki && forge$j.pki.oids) {
        if(oid in forge$j.pki.oids) {
          rval += ' (' + forge$j.pki.oids[oid] + ') ';
        }
      }
    }
    if(obj.type === asn1$2.Type.INTEGER) {
      try {
        rval += asn1$2.derToInteger(obj.value);
      } catch(ex) {
        rval += '0x' + forge$j.util.bytesToHex(obj.value);
      }
    } else if(obj.type === asn1$2.Type.BITSTRING) {
      // TODO: shift bits as needed to display without padding
      if(obj.value.length > 1) {
        // remove unused bits field
        rval += '0x' + forge$j.util.bytesToHex(obj.value.slice(1));
      } else {
        rval += '(none)';
      }
      // show unused bit count
      if(obj.value.length > 0) {
        var unused = obj.value.charCodeAt(0);
        if(unused == 1) {
          rval += ' (1 unused bit shown)';
        } else if(unused > 1) {
          rval += ' (' + unused + ' unused bits shown)';
        }
      }
    } else if(obj.type === asn1$2.Type.OCTETSTRING) {
      if(!_nonLatinRegex.test(obj.value)) {
        rval += '(' + obj.value + ') ';
      }
      rval += '0x' + forge$j.util.bytesToHex(obj.value);
    } else if(obj.type === asn1$2.Type.UTF8) {
      try {
        rval += forge$j.util.decodeUtf8(obj.value);
      } catch(e) {
        if(e.message === 'URI malformed') {
          rval +=
            '0x' + forge$j.util.bytesToHex(obj.value) + ' (malformed UTF8)';
        } else {
          throw e;
        }
      }
    } else if(obj.type === asn1$2.Type.PRINTABLESTRING ||
      obj.type === asn1$2.Type.IA5String) {
      rval += obj.value;
    } else if(_nonLatinRegex.test(obj.value)) {
      rval += '0x' + forge$j.util.bytesToHex(obj.value);
    } else if(obj.value.length === 0) {
      rval += '[null]';
    } else {
      rval += obj.value;
    }
  }

  return rval;
};

/**
 * Cipher base API.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 */

var forge$i = forge$m;


forge$i.cipher = forge$i.cipher || {};

// registered algorithms
forge$i.cipher.algorithms = forge$i.cipher.algorithms || {};

/**
 * Creates a cipher object that can be used to encrypt data using the given
 * algorithm and key. The algorithm may be provided as a string value for a
 * previously registered algorithm or it may be given as a cipher algorithm
 * API object.
 *
 * @param algorithm the algorithm to use, either a string or an algorithm API
 *          object.
 * @param key the key to use, as a binary-encoded string of bytes or a
 *          byte buffer.
 *
 * @return the cipher.
 */
forge$i.cipher.createCipher = function(algorithm, key) {
  var api = algorithm;
  if(typeof api === 'string') {
    api = forge$i.cipher.getAlgorithm(api);
    if(api) {
      api = api();
    }
  }
  if(!api) {
    throw new Error('Unsupported algorithm: ' + algorithm);
  }

  // assume block cipher
  return new forge$i.cipher.BlockCipher({
    algorithm: api,
    key: key,
    decrypt: false
  });
};

/**
 * Creates a decipher object that can be used to decrypt data using the given
 * algorithm and key. The algorithm may be provided as a string value for a
 * previously registered algorithm or it may be given as a cipher algorithm
 * API object.
 *
 * @param algorithm the algorithm to use, either a string or an algorithm API
 *          object.
 * @param key the key to use, as a binary-encoded string of bytes or a
 *          byte buffer.
 *
 * @return the cipher.
 */
forge$i.cipher.createDecipher = function(algorithm, key) {
  var api = algorithm;
  if(typeof api === 'string') {
    api = forge$i.cipher.getAlgorithm(api);
    if(api) {
      api = api();
    }
  }
  if(!api) {
    throw new Error('Unsupported algorithm: ' + algorithm);
  }

  // assume block cipher
  return new forge$i.cipher.BlockCipher({
    algorithm: api,
    key: key,
    decrypt: true
  });
};

/**
 * Registers an algorithm by name. If the name was already registered, the
 * algorithm API object will be overwritten.
 *
 * @param name the name of the algorithm.
 * @param algorithm the algorithm API object.
 */
forge$i.cipher.registerAlgorithm = function(name, algorithm) {
  name = name.toUpperCase();
  forge$i.cipher.algorithms[name] = algorithm;
};

/**
 * Gets a registered algorithm by name.
 *
 * @param name the name of the algorithm.
 *
 * @return the algorithm, if found, null if not.
 */
forge$i.cipher.getAlgorithm = function(name) {
  name = name.toUpperCase();
  if(name in forge$i.cipher.algorithms) {
    return forge$i.cipher.algorithms[name];
  }
  return null;
};

var BlockCipher = forge$i.cipher.BlockCipher = function(options) {
  this.algorithm = options.algorithm;
  this.mode = this.algorithm.mode;
  this.blockSize = this.mode.blockSize;
  this._finish = false;
  this._input = null;
  this.output = null;
  this._op = options.decrypt ? this.mode.decrypt : this.mode.encrypt;
  this._decrypt = options.decrypt;
  this.algorithm.initialize(options);
};

/**
 * Starts or restarts the encryption or decryption process, whichever
 * was previously configured.
 *
 * For non-GCM mode, the IV may be a binary-encoded string of bytes, an array
 * of bytes, a byte buffer, or an array of 32-bit integers. If the IV is in
 * bytes, then it must be Nb (16) bytes in length. If the IV is given in as
 * 32-bit integers, then it must be 4 integers long.
 *
 * Note: an IV is not required or used in ECB mode.
 *
 * For GCM-mode, the IV must be given as a binary-encoded string of bytes or
 * a byte buffer. The number of bytes should be 12 (96 bits) as recommended
 * by NIST SP-800-38D but another length may be given.
 *
 * @param options the options to use:
 *          iv the initialization vector to use as a binary-encoded string of
 *            bytes, null to reuse the last ciphered block from a previous
 *            update() (this "residue" method is for legacy support only).
 *          additionalData additional authentication data as a binary-encoded
 *            string of bytes, for 'GCM' mode, (default: none).
 *          tagLength desired length of authentication tag, in bits, for
 *            'GCM' mode (0-128, default: 128).
 *          tag the authentication tag to check if decrypting, as a
 *             binary-encoded string of bytes.
 *          output the output the buffer to write to, null to create one.
 */
BlockCipher.prototype.start = function(options) {
  options = options || {};
  var opts = {};
  for(var key in options) {
    opts[key] = options[key];
  }
  opts.decrypt = this._decrypt;
  this._finish = false;
  this._input = forge$i.util.createBuffer();
  this.output = options.output || forge$i.util.createBuffer();
  this.mode.start(opts);
};

/**
 * Updates the next block according to the cipher mode.
 *
 * @param input the buffer to read from.
 */
BlockCipher.prototype.update = function(input) {
  if(input) {
    // input given, so empty it into the input buffer
    this._input.putBuffer(input);
  }

  // do cipher operation until it needs more input and not finished
  while(!this._op.call(this.mode, this._input, this.output, this._finish) &&
    !this._finish) {}

  // free consumed memory from input buffer
  this._input.compact();
};

/**
 * Finishes encrypting or decrypting.
 *
 * @param pad a padding function to use in CBC mode, null for default,
 *          signature(blockSize, buffer, decrypt).
 *
 * @return true if successful, false on error.
 */
BlockCipher.prototype.finish = function(pad) {
  // backwards-compatibility w/deprecated padding API
  // Note: will overwrite padding functions even after another start() call
  if(pad && (this.mode.name === 'ECB' || this.mode.name === 'CBC')) {
    this.mode.pad = function(input) {
      return pad(this.blockSize, input, false);
    };
    this.mode.unpad = function(output) {
      return pad(this.blockSize, output, true);
    };
  }

  // build options for padding and afterFinish functions
  var options = {};
  options.decrypt = this._decrypt;

  // get # of bytes that won't fill a block
  options.overflow = this._input.length() % this.blockSize;

  if(!this._decrypt && this.mode.pad) {
    if(!this.mode.pad(this._input, options)) {
      return false;
    }
  }

  // do final update
  this._finish = true;
  this.update();

  if(this._decrypt && this.mode.unpad) {
    if(!this.mode.unpad(this.output, options)) {
      return false;
    }
  }

  if(this.mode.afterFinish) {
    if(!this.mode.afterFinish(this.output, options)) {
      return false;
    }
  }

  return true;
};

/**
 * Supported cipher modes.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 */

var forge$h = forge$m;


forge$h.cipher = forge$h.cipher || {};

// supported cipher modes
var modes = forge$h.cipher.modes = forge$h.cipher.modes || {};

/** Electronic codebook (ECB) (Don't use this; it's not secure) **/

modes.ecb = function(options) {
  options = options || {};
  this.name = 'ECB';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = new Array(this._ints);
  this._outBlock = new Array(this._ints);
};

modes.ecb.prototype.start = function(options) {};

modes.ecb.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {
    return true;
  }

  // get next block
  for(var i = 0; i < this._ints; ++i) {
    this._inBlock[i] = input.getInt32();
  }

  // encrypt block
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // write output
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._outBlock[i]);
  }
};

modes.ecb.prototype.decrypt = function(input, output, finish) {
  // not enough input to decrypt
  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {
    return true;
  }

  // get next block
  for(var i = 0; i < this._ints; ++i) {
    this._inBlock[i] = input.getInt32();
  }

  // decrypt block
  this.cipher.decrypt(this._inBlock, this._outBlock);

  // write output
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._outBlock[i]);
  }
};

modes.ecb.prototype.pad = function(input, options) {
  // add PKCS#7 padding to block (each pad byte is the
  // value of the number of pad bytes)
  var padding = (input.length() === this.blockSize ?
    this.blockSize : (this.blockSize - input.length()));
  input.fillWithByte(padding, padding);
  return true;
};

modes.ecb.prototype.unpad = function(output, options) {
  // check for error: input data not a multiple of blockSize
  if(options.overflow > 0) {
    return false;
  }

  // ensure padding byte count is valid
  var len = output.length();
  var count = output.at(len - 1);
  if(count > (this.blockSize << 2)) {
    return false;
  }

  // trim off padding bytes
  output.truncate(count);
  return true;
};

/** Cipher-block Chaining (CBC) **/

modes.cbc = function(options) {
  options = options || {};
  this.name = 'CBC';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = new Array(this._ints);
  this._outBlock = new Array(this._ints);
};

modes.cbc.prototype.start = function(options) {
  // Note: legacy support for using IV residue (has security flaws)
  // if IV is null, reuse block from previous processing
  if(options.iv === null) {
    // must have a previous block
    if(!this._prev) {
      throw new Error('Invalid IV parameter.');
    }
    this._iv = this._prev.slice(0);
  } else if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  } else {
    // save IV as "previous" block
    this._iv = transformIV(options.iv, this.blockSize);
    this._prev = this._iv.slice(0);
  }
};

modes.cbc.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {
    return true;
  }

  // get next block
  // CBC XOR's IV (or previous block) with plaintext
  for(var i = 0; i < this._ints; ++i) {
    this._inBlock[i] = this._prev[i] ^ input.getInt32();
  }

  // encrypt block
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // write output, save previous block
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._outBlock[i]);
  }
  this._prev = this._outBlock;
};

modes.cbc.prototype.decrypt = function(input, output, finish) {
  // not enough input to decrypt
  if(input.length() < this.blockSize && !(finish && input.length() > 0)) {
    return true;
  }

  // get next block
  for(var i = 0; i < this._ints; ++i) {
    this._inBlock[i] = input.getInt32();
  }

  // decrypt block
  this.cipher.decrypt(this._inBlock, this._outBlock);

  // write output, save previous ciphered block
  // CBC XOR's IV (or previous block) with ciphertext
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._prev[i] ^ this._outBlock[i]);
  }
  this._prev = this._inBlock.slice(0);
};

modes.cbc.prototype.pad = function(input, options) {
  // add PKCS#7 padding to block (each pad byte is the
  // value of the number of pad bytes)
  var padding = (input.length() === this.blockSize ?
    this.blockSize : (this.blockSize - input.length()));
  input.fillWithByte(padding, padding);
  return true;
};

modes.cbc.prototype.unpad = function(output, options) {
  // check for error: input data not a multiple of blockSize
  if(options.overflow > 0) {
    return false;
  }

  // ensure padding byte count is valid
  var len = output.length();
  var count = output.at(len - 1);
  if(count > (this.blockSize << 2)) {
    return false;
  }

  // trim off padding bytes
  output.truncate(count);
  return true;
};

/** Cipher feedback (CFB) **/

modes.cfb = function(options) {
  options = options || {};
  this.name = 'CFB';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = null;
  this._outBlock = new Array(this._ints);
  this._partialBlock = new Array(this._ints);
  this._partialOutput = forge$h.util.createBuffer();
  this._partialBytes = 0;
};

modes.cfb.prototype.start = function(options) {
  if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  }
  // use IV as first input
  this._iv = transformIV(options.iv, this.blockSize);
  this._inBlock = this._iv.slice(0);
  this._partialBytes = 0;
};

modes.cfb.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  var inputLength = input.length();
  if(inputLength === 0) {
    return true;
  }

  // encrypt block
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output, write input as output
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = input.getInt32() ^ this._outBlock[i];
      output.putInt32(this._inBlock[i]);
    }
    return;
  }

  // handle partial block
  var partialBytes = (this.blockSize - inputLength) % this.blockSize;
  if(partialBytes > 0) {
    partialBytes = this.blockSize - partialBytes;
  }

  // XOR input with output, write input as partial output
  this._partialOutput.clear();
  for(var i = 0; i < this._ints; ++i) {
    this._partialBlock[i] = input.getInt32() ^ this._outBlock[i];
    this._partialOutput.putInt32(this._partialBlock[i]);
  }

  if(partialBytes > 0) {
    // block still incomplete, restore input buffer
    input.read -= this.blockSize;
  } else {
    // block complete, update input block
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = this._partialBlock[i];
    }
  }

  // skip any previous partial bytes
  if(this._partialBytes > 0) {
    this._partialOutput.getBytes(this._partialBytes);
  }

  if(partialBytes > 0 && !finish) {
    output.putBytes(this._partialOutput.getBytes(
      partialBytes - this._partialBytes));
    this._partialBytes = partialBytes;
    return true;
  }

  output.putBytes(this._partialOutput.getBytes(
    inputLength - this._partialBytes));
  this._partialBytes = 0;
};

modes.cfb.prototype.decrypt = function(input, output, finish) {
  // not enough input to decrypt
  var inputLength = input.length();
  if(inputLength === 0) {
    return true;
  }

  // encrypt block (CFB always uses encryption mode)
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output, write input as output
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = input.getInt32();
      output.putInt32(this._inBlock[i] ^ this._outBlock[i]);
    }
    return;
  }

  // handle partial block
  var partialBytes = (this.blockSize - inputLength) % this.blockSize;
  if(partialBytes > 0) {
    partialBytes = this.blockSize - partialBytes;
  }

  // XOR input with output, write input as partial output
  this._partialOutput.clear();
  for(var i = 0; i < this._ints; ++i) {
    this._partialBlock[i] = input.getInt32();
    this._partialOutput.putInt32(this._partialBlock[i] ^ this._outBlock[i]);
  }

  if(partialBytes > 0) {
    // block still incomplete, restore input buffer
    input.read -= this.blockSize;
  } else {
    // block complete, update input block
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = this._partialBlock[i];
    }
  }

  // skip any previous partial bytes
  if(this._partialBytes > 0) {
    this._partialOutput.getBytes(this._partialBytes);
  }

  if(partialBytes > 0 && !finish) {
    output.putBytes(this._partialOutput.getBytes(
      partialBytes - this._partialBytes));
    this._partialBytes = partialBytes;
    return true;
  }

  output.putBytes(this._partialOutput.getBytes(
    inputLength - this._partialBytes));
  this._partialBytes = 0;
};

/** Output feedback (OFB) **/

modes.ofb = function(options) {
  options = options || {};
  this.name = 'OFB';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = null;
  this._outBlock = new Array(this._ints);
  this._partialOutput = forge$h.util.createBuffer();
  this._partialBytes = 0;
};

modes.ofb.prototype.start = function(options) {
  if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  }
  // use IV as first input
  this._iv = transformIV(options.iv, this.blockSize);
  this._inBlock = this._iv.slice(0);
  this._partialBytes = 0;
};

modes.ofb.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  var inputLength = input.length();
  if(input.length() === 0) {
    return true;
  }

  // encrypt block (OFB always uses encryption mode)
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output and update next input
    for(var i = 0; i < this._ints; ++i) {
      output.putInt32(input.getInt32() ^ this._outBlock[i]);
      this._inBlock[i] = this._outBlock[i];
    }
    return;
  }

  // handle partial block
  var partialBytes = (this.blockSize - inputLength) % this.blockSize;
  if(partialBytes > 0) {
    partialBytes = this.blockSize - partialBytes;
  }

  // XOR input with output
  this._partialOutput.clear();
  for(var i = 0; i < this._ints; ++i) {
    this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);
  }

  if(partialBytes > 0) {
    // block still incomplete, restore input buffer
    input.read -= this.blockSize;
  } else {
    // block complete, update input block
    for(var i = 0; i < this._ints; ++i) {
      this._inBlock[i] = this._outBlock[i];
    }
  }

  // skip any previous partial bytes
  if(this._partialBytes > 0) {
    this._partialOutput.getBytes(this._partialBytes);
  }

  if(partialBytes > 0 && !finish) {
    output.putBytes(this._partialOutput.getBytes(
      partialBytes - this._partialBytes));
    this._partialBytes = partialBytes;
    return true;
  }

  output.putBytes(this._partialOutput.getBytes(
    inputLength - this._partialBytes));
  this._partialBytes = 0;
};

modes.ofb.prototype.decrypt = modes.ofb.prototype.encrypt;

/** Counter (CTR) **/

modes.ctr = function(options) {
  options = options || {};
  this.name = 'CTR';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = null;
  this._outBlock = new Array(this._ints);
  this._partialOutput = forge$h.util.createBuffer();
  this._partialBytes = 0;
};

modes.ctr.prototype.start = function(options) {
  if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  }
  // use IV as first input
  this._iv = transformIV(options.iv, this.blockSize);
  this._inBlock = this._iv.slice(0);
  this._partialBytes = 0;
};

modes.ctr.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  var inputLength = input.length();
  if(inputLength === 0) {
    return true;
  }

  // encrypt block (CTR always uses encryption mode)
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output
    for(var i = 0; i < this._ints; ++i) {
      output.putInt32(input.getInt32() ^ this._outBlock[i]);
    }
  } else {
    // handle partial block
    var partialBytes = (this.blockSize - inputLength) % this.blockSize;
    if(partialBytes > 0) {
      partialBytes = this.blockSize - partialBytes;
    }

    // XOR input with output
    this._partialOutput.clear();
    for(var i = 0; i < this._ints; ++i) {
      this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);
    }

    if(partialBytes > 0) {
      // block still incomplete, restore input buffer
      input.read -= this.blockSize;
    }

    // skip any previous partial bytes
    if(this._partialBytes > 0) {
      this._partialOutput.getBytes(this._partialBytes);
    }

    if(partialBytes > 0 && !finish) {
      output.putBytes(this._partialOutput.getBytes(
        partialBytes - this._partialBytes));
      this._partialBytes = partialBytes;
      return true;
    }

    output.putBytes(this._partialOutput.getBytes(
      inputLength - this._partialBytes));
    this._partialBytes = 0;
  }

  // block complete, increment counter (input block)
  inc32(this._inBlock);
};

modes.ctr.prototype.decrypt = modes.ctr.prototype.encrypt;

/** Galois/Counter Mode (GCM) **/

modes.gcm = function(options) {
  options = options || {};
  this.name = 'GCM';
  this.cipher = options.cipher;
  this.blockSize = options.blockSize || 16;
  this._ints = this.blockSize / 4;
  this._inBlock = new Array(this._ints);
  this._outBlock = new Array(this._ints);
  this._partialOutput = forge$h.util.createBuffer();
  this._partialBytes = 0;

  // R is actually this value concatenated with 120 more zero bits, but
  // we only XOR against R so the other zeros have no effect -- we just
  // apply this value to the first integer in a block
  this._R = 0xE1000000;
};

modes.gcm.prototype.start = function(options) {
  if(!('iv' in options)) {
    throw new Error('Invalid IV parameter.');
  }
  // ensure IV is a byte buffer
  var iv = forge$h.util.createBuffer(options.iv);

  // no ciphered data processed yet
  this._cipherLength = 0;

  // default additional data is none
  var additionalData;
  if('additionalData' in options) {
    additionalData = forge$h.util.createBuffer(options.additionalData);
  } else {
    additionalData = forge$h.util.createBuffer();
  }

  // default tag length is 128 bits
  if('tagLength' in options) {
    this._tagLength = options.tagLength;
  } else {
    this._tagLength = 128;
  }

  // if tag is given, ensure tag matches tag length
  this._tag = null;
  if(options.decrypt) {
    // save tag to check later
    this._tag = forge$h.util.createBuffer(options.tag).getBytes();
    if(this._tag.length !== (this._tagLength / 8)) {
      throw new Error('Authentication tag does not match tag length.');
    }
  }

  // create tmp storage for hash calculation
  this._hashBlock = new Array(this._ints);

  // no tag generated yet
  this.tag = null;

  // generate hash subkey
  // (apply block cipher to "zero" block)
  this._hashSubkey = new Array(this._ints);
  this.cipher.encrypt([0, 0, 0, 0], this._hashSubkey);

  // generate table M
  // use 4-bit tables (32 component decomposition of a 16 byte value)
  // 8-bit tables take more space and are known to have security
  // vulnerabilities (in native implementations)
  this.componentBits = 4;
  this._m = this.generateHashTable(this._hashSubkey, this.componentBits);

  // Note: support IV length different from 96 bits? (only supporting
  // 96 bits is recommended by NIST SP-800-38D)
  // generate J_0
  var ivLength = iv.length();
  if(ivLength === 12) {
    // 96-bit IV
    this._j0 = [iv.getInt32(), iv.getInt32(), iv.getInt32(), 1];
  } else {
    // IV is NOT 96-bits
    this._j0 = [0, 0, 0, 0];
    while(iv.length() > 0) {
      this._j0 = this.ghash(
        this._hashSubkey, this._j0,
        [iv.getInt32(), iv.getInt32(), iv.getInt32(), iv.getInt32()]);
    }
    this._j0 = this.ghash(
      this._hashSubkey, this._j0, [0, 0].concat(from64To32(ivLength * 8)));
  }

  // generate ICB (initial counter block)
  this._inBlock = this._j0.slice(0);
  inc32(this._inBlock);
  this._partialBytes = 0;

  // consume authentication data
  additionalData = forge$h.util.createBuffer(additionalData);
  // save additional data length as a BE 64-bit number
  this._aDataLength = from64To32(additionalData.length() * 8);
  // pad additional data to 128 bit (16 byte) block size
  var overflow = additionalData.length() % this.blockSize;
  if(overflow) {
    additionalData.fillWithByte(0, this.blockSize - overflow);
  }
  this._s = [0, 0, 0, 0];
  while(additionalData.length() > 0) {
    this._s = this.ghash(this._hashSubkey, this._s, [
      additionalData.getInt32(),
      additionalData.getInt32(),
      additionalData.getInt32(),
      additionalData.getInt32()
    ]);
  }
};

modes.gcm.prototype.encrypt = function(input, output, finish) {
  // not enough input to encrypt
  var inputLength = input.length();
  if(inputLength === 0) {
    return true;
  }

  // encrypt block
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // handle full block
  if(this._partialBytes === 0 && inputLength >= this.blockSize) {
    // XOR input with output
    for(var i = 0; i < this._ints; ++i) {
      output.putInt32(this._outBlock[i] ^= input.getInt32());
    }
    this._cipherLength += this.blockSize;
  } else {
    // handle partial block
    var partialBytes = (this.blockSize - inputLength) % this.blockSize;
    if(partialBytes > 0) {
      partialBytes = this.blockSize - partialBytes;
    }

    // XOR input with output
    this._partialOutput.clear();
    for(var i = 0; i < this._ints; ++i) {
      this._partialOutput.putInt32(input.getInt32() ^ this._outBlock[i]);
    }

    if(partialBytes <= 0 || finish) {
      // handle overflow prior to hashing
      if(finish) {
        // get block overflow
        var overflow = inputLength % this.blockSize;
        this._cipherLength += overflow;
        // truncate for hash function
        this._partialOutput.truncate(this.blockSize - overflow);
      } else {
        this._cipherLength += this.blockSize;
      }

      // get output block for hashing
      for(var i = 0; i < this._ints; ++i) {
        this._outBlock[i] = this._partialOutput.getInt32();
      }
      this._partialOutput.read -= this.blockSize;
    }

    // skip any previous partial bytes
    if(this._partialBytes > 0) {
      this._partialOutput.getBytes(this._partialBytes);
    }

    if(partialBytes > 0 && !finish) {
      // block still incomplete, restore input buffer, get partial output,
      // and return early
      input.read -= this.blockSize;
      output.putBytes(this._partialOutput.getBytes(
        partialBytes - this._partialBytes));
      this._partialBytes = partialBytes;
      return true;
    }

    output.putBytes(this._partialOutput.getBytes(
      inputLength - this._partialBytes));
    this._partialBytes = 0;
  }

  // update hash block S
  this._s = this.ghash(this._hashSubkey, this._s, this._outBlock);

  // increment counter (input block)
  inc32(this._inBlock);
};

modes.gcm.prototype.decrypt = function(input, output, finish) {
  // not enough input to decrypt
  var inputLength = input.length();
  if(inputLength < this.blockSize && !(finish && inputLength > 0)) {
    return true;
  }

  // encrypt block (GCM always uses encryption mode)
  this.cipher.encrypt(this._inBlock, this._outBlock);

  // increment counter (input block)
  inc32(this._inBlock);

  // update hash block S
  this._hashBlock[0] = input.getInt32();
  this._hashBlock[1] = input.getInt32();
  this._hashBlock[2] = input.getInt32();
  this._hashBlock[3] = input.getInt32();
  this._s = this.ghash(this._hashSubkey, this._s, this._hashBlock);

  // XOR hash input with output
  for(var i = 0; i < this._ints; ++i) {
    output.putInt32(this._outBlock[i] ^ this._hashBlock[i]);
  }

  // increment cipher data length
  if(inputLength < this.blockSize) {
    this._cipherLength += inputLength % this.blockSize;
  } else {
    this._cipherLength += this.blockSize;
  }
};

modes.gcm.prototype.afterFinish = function(output, options) {
  var rval = true;

  // handle overflow
  if(options.decrypt && options.overflow) {
    output.truncate(this.blockSize - options.overflow);
  }

  // handle authentication tag
  this.tag = forge$h.util.createBuffer();

  // concatenate additional data length with cipher length
  var lengths = this._aDataLength.concat(from64To32(this._cipherLength * 8));

  // include lengths in hash
  this._s = this.ghash(this._hashSubkey, this._s, lengths);

  // do GCTR(J_0, S)
  var tag = [];
  this.cipher.encrypt(this._j0, tag);
  for(var i = 0; i < this._ints; ++i) {
    this.tag.putInt32(this._s[i] ^ tag[i]);
  }

  // trim tag to length
  this.tag.truncate(this.tag.length() % (this._tagLength / 8));

  // check authentication tag
  if(options.decrypt && this.tag.bytes() !== this._tag) {
    rval = false;
  }

  return rval;
};

/**
 * See NIST SP-800-38D 6.3 (Algorithm 1). This function performs Galois
 * field multiplication. The field, GF(2^128), is defined by the polynomial:
 *
 * x^128 + x^7 + x^2 + x + 1
 *
 * Which is represented in little-endian binary form as: 11100001 (0xe1). When
 * the value of a coefficient is 1, a bit is set. The value R, is the
 * concatenation of this value and 120 zero bits, yielding a 128-bit value
 * which matches the block size.
 *
 * This function will multiply two elements (vectors of bytes), X and Y, in
 * the field GF(2^128). The result is initialized to zero. For each bit of
 * X (out of 128), x_i, if x_i is set, then the result is multiplied (XOR'd)
 * by the current value of Y. For each bit, the value of Y will be raised by
 * a power of x (multiplied by the polynomial x). This can be achieved by
 * shifting Y once to the right. If the current value of Y, prior to being
 * multiplied by x, has 0 as its LSB, then it is a 127th degree polynomial.
 * Otherwise, we must divide by R after shifting to find the remainder.
 *
 * @param x the first block to multiply by the second.
 * @param y the second block to multiply by the first.
 *
 * @return the block result of the multiplication.
 */
modes.gcm.prototype.multiply = function(x, y) {
  var z_i = [0, 0, 0, 0];
  var v_i = y.slice(0);

  // calculate Z_128 (block has 128 bits)
  for(var i = 0; i < 128; ++i) {
    // if x_i is 0, Z_{i+1} = Z_i (unchanged)
    // else Z_{i+1} = Z_i ^ V_i
    // get x_i by finding 32-bit int position, then left shift 1 by remainder
    var x_i = x[(i / 32) | 0] & (1 << (31 - i % 32));
    if(x_i) {
      z_i[0] ^= v_i[0];
      z_i[1] ^= v_i[1];
      z_i[2] ^= v_i[2];
      z_i[3] ^= v_i[3];
    }

    // if LSB(V_i) is 1, V_i = V_i >> 1
    // else V_i = (V_i >> 1) ^ R
    this.pow(v_i, v_i);
  }

  return z_i;
};

modes.gcm.prototype.pow = function(x, out) {
  // if LSB(x) is 1, x = x >>> 1
  // else x = (x >>> 1) ^ R
  var lsb = x[3] & 1;

  // always do x >>> 1:
  // starting with the rightmost integer, shift each integer to the right
  // one bit, pulling in the bit from the integer to the left as its top
  // most bit (do this for the last 3 integers)
  for(var i = 3; i > 0; --i) {
    out[i] = (x[i] >>> 1) | ((x[i - 1] & 1) << 31);
  }
  // shift the first integer normally
  out[0] = x[0] >>> 1;

  // if lsb was not set, then polynomial had a degree of 127 and doesn't
  // need to divided; otherwise, XOR with R to find the remainder; we only
  // need to XOR the first integer since R technically ends w/120 zero bits
  if(lsb) {
    out[0] ^= this._R;
  }
};

modes.gcm.prototype.tableMultiply = function(x) {
  // assumes 4-bit tables are used
  var z = [0, 0, 0, 0];
  for(var i = 0; i < 32; ++i) {
    var idx = (i / 8) | 0;
    var x_i = (x[idx] >>> ((7 - (i % 8)) * 4)) & 0xF;
    var ah = this._m[i][x_i];
    z[0] ^= ah[0];
    z[1] ^= ah[1];
    z[2] ^= ah[2];
    z[3] ^= ah[3];
  }
  return z;
};

/**
 * A continuing version of the GHASH algorithm that operates on a single
 * block. The hash block, last hash value (Ym) and the new block to hash
 * are given.
 *
 * @param h the hash block.
 * @param y the previous value for Ym, use [0, 0, 0, 0] for a new hash.
 * @param x the block to hash.
 *
 * @return the hashed value (Ym).
 */
modes.gcm.prototype.ghash = function(h, y, x) {
  y[0] ^= x[0];
  y[1] ^= x[1];
  y[2] ^= x[2];
  y[3] ^= x[3];
  return this.tableMultiply(y);
  //return this.multiply(y, h);
};

/**
 * Precomputes a table for multiplying against the hash subkey. This
 * mechanism provides a substantial speed increase over multiplication
 * performed without a table. The table-based multiplication this table is
 * for solves X * H by multiplying each component of X by H and then
 * composing the results together using XOR.
 *
 * This function can be used to generate tables with different bit sizes
 * for the components, however, this implementation assumes there are
 * 32 components of X (which is a 16 byte vector), therefore each component
 * takes 4-bits (so the table is constructed with bits=4).
 *
 * @param h the hash subkey.
 * @param bits the bit size for a component.
 */
modes.gcm.prototype.generateHashTable = function(h, bits) {
  // TODO: There are further optimizations that would use only the
  // first table M_0 (or some variant) along with a remainder table;
  // this can be explored in the future
  var multiplier = 8 / bits;
  var perInt = 4 * multiplier;
  var size = 16 * multiplier;
  var m = new Array(size);
  for(var i = 0; i < size; ++i) {
    var tmp = [0, 0, 0, 0];
    var idx = (i / perInt) | 0;
    var shft = ((perInt - 1 - (i % perInt)) * bits);
    tmp[idx] = (1 << (bits - 1)) << shft;
    m[i] = this.generateSubHashTable(this.multiply(tmp, h), bits);
  }
  return m;
};

/**
 * Generates a table for multiplying against the hash subkey for one
 * particular component (out of all possible component values).
 *
 * @param mid the pre-multiplied value for the middle key of the table.
 * @param bits the bit size for a component.
 */
modes.gcm.prototype.generateSubHashTable = function(mid, bits) {
  // compute the table quickly by minimizing the number of
  // POW operations -- they only need to be performed for powers of 2,
  // all other entries can be composed from those powers using XOR
  var size = 1 << bits;
  var half = size >>> 1;
  var m = new Array(size);
  m[half] = mid.slice(0);
  var i = half >>> 1;
  while(i > 0) {
    // raise m0[2 * i] and store in m0[i]
    this.pow(m[2 * i], m[i] = []);
    i >>= 1;
  }
  i = 2;
  while(i < half) {
    for(var j = 1; j < i; ++j) {
      var m_i = m[i];
      var m_j = m[j];
      m[i + j] = [
        m_i[0] ^ m_j[0],
        m_i[1] ^ m_j[1],
        m_i[2] ^ m_j[2],
        m_i[3] ^ m_j[3]
      ];
    }
    i *= 2;
  }
  m[0] = [0, 0, 0, 0];
  /* Note: We could avoid storing these by doing composition during multiply
  calculate top half using composition by speed is preferred. */
  for(i = half + 1; i < size; ++i) {
    var c = m[i ^ half];
    m[i] = [mid[0] ^ c[0], mid[1] ^ c[1], mid[2] ^ c[2], mid[3] ^ c[3]];
  }
  return m;
};

/** Utility functions */

function transformIV(iv, blockSize) {
  if(typeof iv === 'string') {
    // convert iv string into byte buffer
    iv = forge$h.util.createBuffer(iv);
  }

  if(forge$h.util.isArray(iv) && iv.length > 4) {
    // convert iv byte array into byte buffer
    var tmp = iv;
    iv = forge$h.util.createBuffer();
    for(var i = 0; i < tmp.length; ++i) {
      iv.putByte(tmp[i]);
    }
  }

  if(iv.length() < blockSize) {
    throw new Error(
      'Invalid IV length; got ' + iv.length() +
      ' bytes and expected ' + blockSize + ' bytes.');
  }

  if(!forge$h.util.isArray(iv)) {
    // convert iv byte buffer into 32-bit integer array
    var ints = [];
    var blocks = blockSize / 4;
    for(var i = 0; i < blocks; ++i) {
      ints.push(iv.getInt32());
    }
    iv = ints;
  }

  return iv;
}

function inc32(block) {
  // increment last 32 bits of block only
  block[block.length - 1] = (block[block.length - 1] + 1) & 0xFFFFFFFF;
}

function from64To32(num) {
  // convert 64-bit number to two BE Int32s
  return [(num / 0x100000000) | 0, num & 0xFFFFFFFF];
}

/**
 * Advanced Encryption Standard (AES) implementation.
 *
 * This implementation is based on the public domain library 'jscrypto' which
 * was written by:
 *
 * Emily Stark (estark@stanford.edu)
 * Mike Hamburg (mhamburg@stanford.edu)
 * Dan Boneh (dabo@cs.stanford.edu)
 *
 * Parts of this code are based on the OpenSSL implementation of AES:
 * http://www.openssl.org
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 */

var forge$g = forge$m;




/* AES API */
forge$g.aes = forge$g.aes || {};

/**
 * Deprecated. Instead, use:
 *
 * var cipher = forge.cipher.createCipher('AES-<mode>', key);
 * cipher.start({iv: iv});
 *
 * Creates an AES cipher object to encrypt data using the given symmetric key.
 * The output will be stored in the 'output' member of the returned cipher.
 *
 * The key and iv may be given as a string of bytes, an array of bytes,
 * a byte buffer, or an array of 32-bit words.
 *
 * @param key the symmetric key to use.
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$g.aes.startEncrypting = function(key, iv, output, mode) {
  var cipher = _createCipher$1({
    key: key,
    output: output,
    decrypt: false,
    mode: mode
  });
  cipher.start(iv);
  return cipher;
};

/**
 * Deprecated. Instead, use:
 *
 * var cipher = forge.cipher.createCipher('AES-<mode>', key);
 *
 * Creates an AES cipher object to encrypt data using the given symmetric key.
 *
 * The key may be given as a string of bytes, an array of bytes, a
 * byte buffer, or an array of 32-bit words.
 *
 * @param key the symmetric key to use.
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$g.aes.createEncryptionCipher = function(key, mode) {
  return _createCipher$1({
    key: key,
    output: null,
    decrypt: false,
    mode: mode
  });
};

/**
 * Deprecated. Instead, use:
 *
 * var decipher = forge.cipher.createDecipher('AES-<mode>', key);
 * decipher.start({iv: iv});
 *
 * Creates an AES cipher object to decrypt data using the given symmetric key.
 * The output will be stored in the 'output' member of the returned cipher.
 *
 * The key and iv may be given as a string of bytes, an array of bytes,
 * a byte buffer, or an array of 32-bit words.
 *
 * @param key the symmetric key to use.
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$g.aes.startDecrypting = function(key, iv, output, mode) {
  var cipher = _createCipher$1({
    key: key,
    output: output,
    decrypt: true,
    mode: mode
  });
  cipher.start(iv);
  return cipher;
};

/**
 * Deprecated. Instead, use:
 *
 * var decipher = forge.cipher.createDecipher('AES-<mode>', key);
 *
 * Creates an AES cipher object to decrypt data using the given symmetric key.
 *
 * The key may be given as a string of bytes, an array of bytes, a
 * byte buffer, or an array of 32-bit words.
 *
 * @param key the symmetric key to use.
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$g.aes.createDecryptionCipher = function(key, mode) {
  return _createCipher$1({
    key: key,
    output: null,
    decrypt: true,
    mode: mode
  });
};

/**
 * Creates a new AES cipher algorithm object.
 *
 * @param name the name of the algorithm.
 * @param mode the mode factory function.
 *
 * @return the AES algorithm object.
 */
forge$g.aes.Algorithm = function(name, mode) {
  if(!init) {
    initialize();
  }
  var self = this;
  self.name = name;
  self.mode = new mode({
    blockSize: 16,
    cipher: {
      encrypt: function(inBlock, outBlock) {
        return _updateBlock$1(self._w, inBlock, outBlock, false);
      },
      decrypt: function(inBlock, outBlock) {
        return _updateBlock$1(self._w, inBlock, outBlock, true);
      }
    }
  });
  self._init = false;
};

/**
 * Initializes this AES algorithm by expanding its key.
 *
 * @param options the options to use.
 *          key the key to use with this algorithm.
 *          decrypt true if the algorithm should be initialized for decryption,
 *            false for encryption.
 */
forge$g.aes.Algorithm.prototype.initialize = function(options) {
  if(this._init) {
    return;
  }

  var key = options.key;
  var tmp;

  /* Note: The key may be a string of bytes, an array of bytes, a byte
    buffer, or an array of 32-bit integers. If the key is in bytes, then
    it must be 16, 24, or 32 bytes in length. If it is in 32-bit
    integers, it must be 4, 6, or 8 integers long. */

  if(typeof key === 'string' &&
    (key.length === 16 || key.length === 24 || key.length === 32)) {
    // convert key string into byte buffer
    key = forge$g.util.createBuffer(key);
  } else if(forge$g.util.isArray(key) &&
    (key.length === 16 || key.length === 24 || key.length === 32)) {
    // convert key integer array into byte buffer
    tmp = key;
    key = forge$g.util.createBuffer();
    for(var i = 0; i < tmp.length; ++i) {
      key.putByte(tmp[i]);
    }
  }

  // convert key byte buffer into 32-bit integer array
  if(!forge$g.util.isArray(key)) {
    tmp = key;
    key = [];

    // key lengths of 16, 24, 32 bytes allowed
    var len = tmp.length();
    if(len === 16 || len === 24 || len === 32) {
      len = len >>> 2;
      for(var i = 0; i < len; ++i) {
        key.push(tmp.getInt32());
      }
    }
  }

  // key must be an array of 32-bit integers by now
  if(!forge$g.util.isArray(key) ||
    !(key.length === 4 || key.length === 6 || key.length === 8)) {
    throw new Error('Invalid key parameter.');
  }

  // encryption operation is always used for these modes
  var mode = this.mode.name;
  var encryptOp = (['CFB', 'OFB', 'CTR', 'GCM'].indexOf(mode) !== -1);

  // do key expansion
  this._w = _expandKey(key, options.decrypt && !encryptOp);
  this._init = true;
};

/**
 * Expands a key. Typically only used for testing.
 *
 * @param key the symmetric key to expand, as an array of 32-bit words.
 * @param decrypt true to expand for decryption, false for encryption.
 *
 * @return the expanded key.
 */
forge$g.aes._expandKey = function(key, decrypt) {
  if(!init) {
    initialize();
  }
  return _expandKey(key, decrypt);
};

/**
 * Updates a single block. Typically only used for testing.
 *
 * @param w the expanded key to use.
 * @param input an array of block-size 32-bit words.
 * @param output an array of block-size 32-bit words.
 * @param decrypt true to decrypt, false to encrypt.
 */
forge$g.aes._updateBlock = _updateBlock$1;

/** Register AES algorithms **/

registerAlgorithm$1('AES-ECB', forge$g.cipher.modes.ecb);
registerAlgorithm$1('AES-CBC', forge$g.cipher.modes.cbc);
registerAlgorithm$1('AES-CFB', forge$g.cipher.modes.cfb);
registerAlgorithm$1('AES-OFB', forge$g.cipher.modes.ofb);
registerAlgorithm$1('AES-CTR', forge$g.cipher.modes.ctr);
registerAlgorithm$1('AES-GCM', forge$g.cipher.modes.gcm);

function registerAlgorithm$1(name, mode) {
  var factory = function() {
    return new forge$g.aes.Algorithm(name, mode);
  };
  forge$g.cipher.registerAlgorithm(name, factory);
}

/** AES implementation **/

var init = false; // not yet initialized
var Nb = 4;       // number of words comprising the state (AES = 4)
var sbox;         // non-linear substitution table used in key expansion
var isbox;        // inversion of sbox
var rcon;         // round constant word array
var mix;          // mix-columns table
var imix;         // inverse mix-columns table

/**
 * Performs initialization, ie: precomputes tables to optimize for speed.
 *
 * One way to understand how AES works is to imagine that 'addition' and
 * 'multiplication' are interfaces that require certain mathematical
 * properties to hold true (ie: they are associative) but they might have
 * different implementations and produce different kinds of results ...
 * provided that their mathematical properties remain true. AES defines
 * its own methods of addition and multiplication but keeps some important
 * properties the same, ie: associativity and distributivity. The
 * explanation below tries to shed some light on how AES defines addition
 * and multiplication of bytes and 32-bit words in order to perform its
 * encryption and decryption algorithms.
 *
 * The basics:
 *
 * The AES algorithm views bytes as binary representations of polynomials
 * that have either 1 or 0 as the coefficients. It defines the addition
 * or subtraction of two bytes as the XOR operation. It also defines the
 * multiplication of two bytes as a finite field referred to as GF(2^8)
 * (Note: 'GF' means "Galois Field" which is a field that contains a finite
 * number of elements so GF(2^8) has 256 elements).
 *
 * This means that any two bytes can be represented as binary polynomials;
 * when they multiplied together and modularly reduced by an irreducible
 * polynomial of the 8th degree, the results are the field GF(2^8). The
 * specific irreducible polynomial that AES uses in hexadecimal is 0x11b.
 * This multiplication is associative with 0x01 as the identity:
 *
 * (b * 0x01 = GF(b, 0x01) = b).
 *
 * The operation GF(b, 0x02) can be performed at the byte level by left
 * shifting b once and then XOR'ing it (to perform the modular reduction)
 * with 0x11b if b is >= 128. Repeated application of the multiplication
 * of 0x02 can be used to implement the multiplication of any two bytes.
 *
 * For instance, multiplying 0x57 and 0x13, denoted as GF(0x57, 0x13), can
 * be performed by factoring 0x13 into 0x01, 0x02, and 0x10. Then these
 * factors can each be multiplied by 0x57 and then added together. To do
 * the multiplication, values for 0x57 multiplied by each of these 3 factors
 * can be precomputed and stored in a table. To add them, the values from
 * the table are XOR'd together.
 *
 * AES also defines addition and multiplication of words, that is 4-byte
 * numbers represented as polynomials of 3 degrees where the coefficients
 * are the values of the bytes.
 *
 * The word [a0, a1, a2, a3] is a polynomial a3x^3 + a2x^2 + a1x + a0.
 *
 * Addition is performed by XOR'ing like powers of x. Multiplication
 * is performed in two steps, the first is an algebriac expansion as
 * you would do normally (where addition is XOR). But the result is
 * a polynomial larger than 3 degrees and thus it cannot fit in a word. So
 * next the result is modularly reduced by an AES-specific polynomial of
 * degree 4 which will always produce a polynomial of less than 4 degrees
 * such that it will fit in a word. In AES, this polynomial is x^4 + 1.
 *
 * The modular product of two polynomials 'a' and 'b' is thus:
 *
 * d(x) = d3x^3 + d2x^2 + d1x + d0
 * with
 * d0 = GF(a0, b0) ^ GF(a3, b1) ^ GF(a2, b2) ^ GF(a1, b3)
 * d1 = GF(a1, b0) ^ GF(a0, b1) ^ GF(a3, b2) ^ GF(a2, b3)
 * d2 = GF(a2, b0) ^ GF(a1, b1) ^ GF(a0, b2) ^ GF(a3, b3)
 * d3 = GF(a3, b0) ^ GF(a2, b1) ^ GF(a1, b2) ^ GF(a0, b3)
 *
 * As a matrix:
 *
 * [d0] = [a0 a3 a2 a1][b0]
 * [d1]   [a1 a0 a3 a2][b1]
 * [d2]   [a2 a1 a0 a3][b2]
 * [d3]   [a3 a2 a1 a0][b3]
 *
 * Special polynomials defined by AES (0x02 == {02}):
 * a(x)    = {03}x^3 + {01}x^2 + {01}x + {02}
 * a^-1(x) = {0b}x^3 + {0d}x^2 + {09}x + {0e}.
 *
 * These polynomials are used in the MixColumns() and InverseMixColumns()
 * operations, respectively, to cause each element in the state to affect
 * the output (referred to as diffusing).
 *
 * RotWord() uses: a0 = a1 = a2 = {00} and a3 = {01}, which is the
 * polynomial x3.
 *
 * The ShiftRows() method modifies the last 3 rows in the state (where
 * the state is 4 words with 4 bytes per word) by shifting bytes cyclically.
 * The 1st byte in the second row is moved to the end of the row. The 1st
 * and 2nd bytes in the third row are moved to the end of the row. The 1st,
 * 2nd, and 3rd bytes are moved in the fourth row.
 *
 * More details on how AES arithmetic works:
 *
 * In the polynomial representation of binary numbers, XOR performs addition
 * and subtraction and multiplication in GF(2^8) denoted as GF(a, b)
 * corresponds with the multiplication of polynomials modulo an irreducible
 * polynomial of degree 8. In other words, for AES, GF(a, b) will multiply
 * polynomial 'a' with polynomial 'b' and then do a modular reduction by
 * an AES-specific irreducible polynomial of degree 8.
 *
 * A polynomial is irreducible if its only divisors are one and itself. For
 * the AES algorithm, this irreducible polynomial is:
 *
 * m(x) = x^8 + x^4 + x^3 + x + 1,
 *
 * or {01}{1b} in hexadecimal notation, where each coefficient is a bit:
 * 100011011 = 283 = 0x11b.
 *
 * For example, GF(0x57, 0x83) = 0xc1 because
 *
 * 0x57 = 87  = 01010111 = x^6 + x^4 + x^2 + x + 1
 * 0x85 = 131 = 10000101 = x^7 + x + 1
 *
 * (x^6 + x^4 + x^2 + x + 1) * (x^7 + x + 1)
 * =  x^13 + x^11 + x^9 + x^8 + x^7 +
 *    x^7 + x^5 + x^3 + x^2 + x +
 *    x^6 + x^4 + x^2 + x + 1
 * =  x^13 + x^11 + x^9 + x^8 + x^6 + x^5 + x^4 + x^3 + 1 = y
 *    y modulo (x^8 + x^4 + x^3 + x + 1)
 * =  x^7 + x^6 + 1.
 *
 * The modular reduction by m(x) guarantees the result will be a binary
 * polynomial of less than degree 8, so that it can fit in a byte.
 *
 * The operation to multiply a binary polynomial b with x (the polynomial
 * x in binary representation is 00000010) is:
 *
 * b_7x^8 + b_6x^7 + b_5x^6 + b_4x^5 + b_3x^4 + b_2x^3 + b_1x^2 + b_0x^1
 *
 * To get GF(b, x) we must reduce that by m(x). If b_7 is 0 (that is the
 * most significant bit is 0 in b) then the result is already reduced. If
 * it is 1, then we can reduce it by subtracting m(x) via an XOR.
 *
 * It follows that multiplication by x (00000010 or 0x02) can be implemented
 * by performing a left shift followed by a conditional bitwise XOR with
 * 0x1b. This operation on bytes is denoted by xtime(). Multiplication by
 * higher powers of x can be implemented by repeated application of xtime().
 *
 * By adding intermediate results, multiplication by any constant can be
 * implemented. For instance:
 *
 * GF(0x57, 0x13) = 0xfe because:
 *
 * xtime(b) = (b & 128) ? (b << 1 ^ 0x11b) : (b << 1)
 *
 * Note: We XOR with 0x11b instead of 0x1b because in javascript our
 * datatype for b can be larger than 1 byte, so a left shift will not
 * automatically eliminate bits that overflow a byte ... by XOR'ing the
 * overflow bit with 1 (the extra one from 0x11b) we zero it out.
 *
 * GF(0x57, 0x02) = xtime(0x57) = 0xae
 * GF(0x57, 0x04) = xtime(0xae) = 0x47
 * GF(0x57, 0x08) = xtime(0x47) = 0x8e
 * GF(0x57, 0x10) = xtime(0x8e) = 0x07
 *
 * GF(0x57, 0x13) = GF(0x57, (0x01 ^ 0x02 ^ 0x10))
 *
 * And by the distributive property (since XOR is addition and GF() is
 * multiplication):
 *
 * = GF(0x57, 0x01) ^ GF(0x57, 0x02) ^ GF(0x57, 0x10)
 * = 0x57 ^ 0xae ^ 0x07
 * = 0xfe.
 */
function initialize() {
  init = true;

  /* Populate the Rcon table. These are the values given by
    [x^(i-1),{00},{00},{00}] where x^(i-1) are powers of x (and x = 0x02)
    in the field of GF(2^8), where i starts at 1.

    rcon[0] = [0x00, 0x00, 0x00, 0x00]
    rcon[1] = [0x01, 0x00, 0x00, 0x00] 2^(1-1) = 2^0 = 1
    rcon[2] = [0x02, 0x00, 0x00, 0x00] 2^(2-1) = 2^1 = 2
    ...
    rcon[9]  = [0x1B, 0x00, 0x00, 0x00] 2^(9-1)  = 2^8 = 0x1B
    rcon[10] = [0x36, 0x00, 0x00, 0x00] 2^(10-1) = 2^9 = 0x36

    We only store the first byte because it is the only one used.
  */
  rcon = [0x00, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1B, 0x36];

  // compute xtime table which maps i onto GF(i, 0x02)
  var xtime = new Array(256);
  for(var i = 0; i < 128; ++i) {
    xtime[i] = i << 1;
    xtime[i + 128] = (i + 128) << 1 ^ 0x11B;
  }

  // compute all other tables
  sbox = new Array(256);
  isbox = new Array(256);
  mix = new Array(4);
  imix = new Array(4);
  for(var i = 0; i < 4; ++i) {
    mix[i] = new Array(256);
    imix[i] = new Array(256);
  }
  var e = 0, ei = 0, e2, e4, e8, sx, sx2, me, ime;
  for(var i = 0; i < 256; ++i) {
    /* We need to generate the SubBytes() sbox and isbox tables so that
      we can perform byte substitutions. This requires us to traverse
      all of the elements in GF, find their multiplicative inverses,
      and apply to each the following affine transformation:

      bi' = bi ^ b(i + 4) mod 8 ^ b(i + 5) mod 8 ^ b(i + 6) mod 8 ^
            b(i + 7) mod 8 ^ ci
      for 0 <= i < 8, where bi is the ith bit of the byte, and ci is the
      ith bit of a byte c with the value {63} or {01100011}.

      It is possible to traverse every possible value in a Galois field
      using what is referred to as a 'generator'. There are many
      generators (128 out of 256): 3,5,6,9,11,82 to name a few. To fully
      traverse GF we iterate 255 times, multiplying by our generator
      each time.

      On each iteration we can determine the multiplicative inverse for
      the current element.

      Suppose there is an element in GF 'e'. For a given generator 'g',
      e = g^x. The multiplicative inverse of e is g^(255 - x). It turns
      out that if use the inverse of a generator as another generator
      it will produce all of the corresponding multiplicative inverses
      at the same time. For this reason, we choose 5 as our inverse
      generator because it only requires 2 multiplies and 1 add and its
      inverse, 82, requires relatively few operations as well.

      In order to apply the affine transformation, the multiplicative
      inverse 'ei' of 'e' can be repeatedly XOR'd (4 times) with a
      bit-cycling of 'ei'. To do this 'ei' is first stored in 's' and
      'x'. Then 's' is left shifted and the high bit of 's' is made the
      low bit. The resulting value is stored in 's'. Then 'x' is XOR'd
      with 's' and stored in 'x'. On each subsequent iteration the same
      operation is performed. When 4 iterations are complete, 'x' is
      XOR'd with 'c' (0x63) and the transformed value is stored in 'x'.
      For example:

      s = 01000001
      x = 01000001

      iteration 1: s = 10000010, x ^= s
      iteration 2: s = 00000101, x ^= s
      iteration 3: s = 00001010, x ^= s
      iteration 4: s = 00010100, x ^= s
      x ^= 0x63

      This can be done with a loop where s = (s << 1) | (s >> 7). However,
      it can also be done by using a single 16-bit (in this case 32-bit)
      number 'sx'. Since XOR is an associative operation, we can set 'sx'
      to 'ei' and then XOR it with 'sx' left-shifted 1,2,3, and 4 times.
      The most significant bits will flow into the high 8 bit positions
      and be correctly XOR'd with one another. All that remains will be
      to cycle the high 8 bits by XOR'ing them all with the lower 8 bits
      afterwards.

      At the same time we're populating sbox and isbox we can precompute
      the multiplication we'll need to do to do MixColumns() later.
    */

    // apply affine transformation
    sx = ei ^ (ei << 1) ^ (ei << 2) ^ (ei << 3) ^ (ei << 4);
    sx = (sx >> 8) ^ (sx & 255) ^ 0x63;

    // update tables
    sbox[e] = sx;
    isbox[sx] = e;

    /* Mixing columns is done using matrix multiplication. The columns
      that are to be mixed are each a single word in the current state.
      The state has Nb columns (4 columns). Therefore each column is a
      4 byte word. So to mix the columns in a single column 'c' where
      its rows are r0, r1, r2, and r3, we use the following matrix
      multiplication:

      [2 3 1 1]*[r0,c]=[r'0,c]
      [1 2 3 1] [r1,c] [r'1,c]
      [1 1 2 3] [r2,c] [r'2,c]
      [3 1 1 2] [r3,c] [r'3,c]

      r0, r1, r2, and r3 are each 1 byte of one of the words in the
      state (a column). To do matrix multiplication for each mixed
      column c' we multiply the corresponding row from the left matrix
      with the corresponding column from the right matrix. In total, we
      get 4 equations:

      r0,c' = 2*r0,c + 3*r1,c + 1*r2,c + 1*r3,c
      r1,c' = 1*r0,c + 2*r1,c + 3*r2,c + 1*r3,c
      r2,c' = 1*r0,c + 1*r1,c + 2*r2,c + 3*r3,c
      r3,c' = 3*r0,c + 1*r1,c + 1*r2,c + 2*r3,c

      As usual, the multiplication is as previously defined and the
      addition is XOR. In order to optimize mixing columns we can store
      the multiplication results in tables. If you think of the whole
      column as a word (it might help to visualize by mentally rotating
      the equations above by counterclockwise 90 degrees) then you can
      see that it would be useful to map the multiplications performed on
      each byte (r0, r1, r2, r3) onto a word as well. For instance, we
      could map 2*r0,1*r0,1*r0,3*r0 onto a word by storing 2*r0 in the
      highest 8 bits and 3*r0 in the lowest 8 bits (with the other two
      respectively in the middle). This means that a table can be
      constructed that uses r0 as an index to the word. We can do the
      same with r1, r2, and r3, creating a total of 4 tables.

      To construct a full c', we can just look up each byte of c in
      their respective tables and XOR the results together.

      Also, to build each table we only have to calculate the word
      for 2,1,1,3 for every byte ... which we can do on each iteration
      of this loop since we will iterate over every byte. After we have
      calculated 2,1,1,3 we can get the results for the other tables
      by cycling the byte at the end to the beginning. For instance
      we can take the result of table 2,1,1,3 and produce table 3,2,1,1
      by moving the right most byte to the left most position just like
      how you can imagine the 3 moved out of 2,1,1,3 and to the front
      to produce 3,2,1,1.

      There is another optimization in that the same multiples of
      the current element we need in order to advance our generator
      to the next iteration can be reused in performing the 2,1,1,3
      calculation. We also calculate the inverse mix column tables,
      with e,9,d,b being the inverse of 2,1,1,3.

      When we're done, and we need to actually mix columns, the first
      byte of each state word should be put through mix[0] (2,1,1,3),
      the second through mix[1] (3,2,1,1) and so forth. Then they should
      be XOR'd together to produce the fully mixed column.
    */

    // calculate mix and imix table values
    sx2 = xtime[sx];
    e2 = xtime[e];
    e4 = xtime[e2];
    e8 = xtime[e4];
    me =
      (sx2 << 24) ^  // 2
      (sx << 16) ^   // 1
      (sx << 8) ^    // 1
      (sx ^ sx2);    // 3
    ime =
      (e2 ^ e4 ^ e8) << 24 ^  // E (14)
      (e ^ e8) << 16 ^        // 9
      (e ^ e4 ^ e8) << 8 ^    // D (13)
      (e ^ e2 ^ e8);          // B (11)
    // produce each of the mix tables by rotating the 2,1,1,3 value
    for(var n = 0; n < 4; ++n) {
      mix[n][e] = me;
      imix[n][sx] = ime;
      // cycle the right most byte to the left most position
      // ie: 2,1,1,3 becomes 3,2,1,1
      me = me << 24 | me >>> 8;
      ime = ime << 24 | ime >>> 8;
    }

    // get next element and inverse
    if(e === 0) {
      // 1 is the inverse of 1
      e = ei = 1;
    } else {
      // e = 2e + 2*2*2*(10e)) = multiply e by 82 (chosen generator)
      // ei = ei + 2*2*ei = multiply ei by 5 (inverse generator)
      e = e2 ^ xtime[xtime[xtime[e2 ^ e8]]];
      ei ^= xtime[xtime[ei]];
    }
  }
}

/**
 * Generates a key schedule using the AES key expansion algorithm.
 *
 * The AES algorithm takes the Cipher Key, K, and performs a Key Expansion
 * routine to generate a key schedule. The Key Expansion generates a total
 * of Nb*(Nr + 1) words: the algorithm requires an initial set of Nb words,
 * and each of the Nr rounds requires Nb words of key data. The resulting
 * key schedule consists of a linear array of 4-byte words, denoted [wi ],
 * with i in the range 0 <= i < Nb(Nr + 1).
 *
 * KeyExpansion(byte key[4*Nk], word w[Nb*(Nr+1)], Nk)
 * AES-128 (Nb=4, Nk=4, Nr=10)
 * AES-192 (Nb=4, Nk=6, Nr=12)
 * AES-256 (Nb=4, Nk=8, Nr=14)
 * Note: Nr=Nk+6.
 *
 * Nb is the number of columns (32-bit words) comprising the State (or
 * number of bytes in a block). For AES, Nb=4.
 *
 * @param key the key to schedule (as an array of 32-bit words).
 * @param decrypt true to modify the key schedule to decrypt, false not to.
 *
 * @return the generated key schedule.
 */
function _expandKey(key, decrypt) {
  // copy the key's words to initialize the key schedule
  var w = key.slice(0);

  /* RotWord() will rotate a word, moving the first byte to the last
    byte's position (shifting the other bytes left).

    We will be getting the value of Rcon at i / Nk. 'i' will iterate
    from Nk to (Nb * Nr+1). Nk = 4 (4 byte key), Nb = 4 (4 words in
    a block), Nr = Nk + 6 (10). Therefore 'i' will iterate from
    4 to 44 (exclusive). Each time we iterate 4 times, i / Nk will
    increase by 1. We use a counter iNk to keep track of this.
   */

  // go through the rounds expanding the key
  var temp, iNk = 1;
  var Nk = w.length;
  var Nr1 = Nk + 6 + 1;
  var end = Nb * Nr1;
  for(var i = Nk; i < end; ++i) {
    temp = w[i - 1];
    if(i % Nk === 0) {
      // temp = SubWord(RotWord(temp)) ^ Rcon[i / Nk]
      temp =
        sbox[temp >>> 16 & 255] << 24 ^
        sbox[temp >>> 8 & 255] << 16 ^
        sbox[temp & 255] << 8 ^
        sbox[temp >>> 24] ^ (rcon[iNk] << 24);
      iNk++;
    } else if(Nk > 6 && (i % Nk === 4)) {
      // temp = SubWord(temp)
      temp =
        sbox[temp >>> 24] << 24 ^
        sbox[temp >>> 16 & 255] << 16 ^
        sbox[temp >>> 8 & 255] << 8 ^
        sbox[temp & 255];
    }
    w[i] = w[i - Nk] ^ temp;
  }

  /* When we are updating a cipher block we always use the code path for
     encryption whether we are decrypting or not (to shorten code and
     simplify the generation of look up tables). However, because there
     are differences in the decryption algorithm, other than just swapping
     in different look up tables, we must transform our key schedule to
     account for these changes:

     1. The decryption algorithm gets its key rounds in reverse order.
     2. The decryption algorithm adds the round key before mixing columns
       instead of afterwards.

     We don't need to modify our key schedule to handle the first case,
     we can just traverse the key schedule in reverse order when decrypting.

     The second case requires a little work.

     The tables we built for performing rounds will take an input and then
     perform SubBytes() and MixColumns() or, for the decrypt version,
     InvSubBytes() and InvMixColumns(). But the decrypt algorithm requires
     us to AddRoundKey() before InvMixColumns(). This means we'll need to
     apply some transformations to the round key to inverse-mix its columns
     so they'll be correct for moving AddRoundKey() to after the state has
     had its columns inverse-mixed.

     To inverse-mix the columns of the state when we're decrypting we use a
     lookup table that will apply InvSubBytes() and InvMixColumns() at the
     same time. However, the round key's bytes are not inverse-substituted
     in the decryption algorithm. To get around this problem, we can first
     substitute the bytes in the round key so that when we apply the
     transformation via the InvSubBytes()+InvMixColumns() table, it will
     undo our substitution leaving us with the original value that we
     want -- and then inverse-mix that value.

     This change will correctly alter our key schedule so that we can XOR
     each round key with our already transformed decryption state. This
     allows us to use the same code path as the encryption algorithm.

     We make one more change to the decryption key. Since the decryption
     algorithm runs in reverse from the encryption algorithm, we reverse
     the order of the round keys to avoid having to iterate over the key
     schedule backwards when running the encryption algorithm later in
     decryption mode. In addition to reversing the order of the round keys,
     we also swap each round key's 2nd and 4th rows. See the comments
     section where rounds are performed for more details about why this is
     done. These changes are done inline with the other substitution
     described above.
  */
  if(decrypt) {
    var tmp;
    var m0 = imix[0];
    var m1 = imix[1];
    var m2 = imix[2];
    var m3 = imix[3];
    var wnew = w.slice(0);
    end = w.length;
    for(var i = 0, wi = end - Nb; i < end; i += Nb, wi -= Nb) {
      // do not sub the first or last round key (round keys are Nb
      // words) as no column mixing is performed before they are added,
      // but do change the key order
      if(i === 0 || i === (end - Nb)) {
        wnew[i] = w[wi];
        wnew[i + 1] = w[wi + 3];
        wnew[i + 2] = w[wi + 2];
        wnew[i + 3] = w[wi + 1];
      } else {
        // substitute each round key byte because the inverse-mix
        // table will inverse-substitute it (effectively cancel the
        // substitution because round key bytes aren't sub'd in
        // decryption mode) and swap indexes 3 and 1
        for(var n = 0; n < Nb; ++n) {
          tmp = w[wi + n];
          wnew[i + (3&-n)] =
            m0[sbox[tmp >>> 24]] ^
            m1[sbox[tmp >>> 16 & 255]] ^
            m2[sbox[tmp >>> 8 & 255]] ^
            m3[sbox[tmp & 255]];
        }
      }
    }
    w = wnew;
  }

  return w;
}

/**
 * Updates a single block (16 bytes) using AES. The update will either
 * encrypt or decrypt the block.
 *
 * @param w the key schedule.
 * @param input the input block (an array of 32-bit words).
 * @param output the updated output block.
 * @param decrypt true to decrypt the block, false to encrypt it.
 */
function _updateBlock$1(w, input, output, decrypt) {
  /*
  Cipher(byte in[4*Nb], byte out[4*Nb], word w[Nb*(Nr+1)])
  begin
    byte state[4,Nb]
    state = in
    AddRoundKey(state, w[0, Nb-1])
    for round = 1 step 1 to Nr-1
      SubBytes(state)
      ShiftRows(state)
      MixColumns(state)
      AddRoundKey(state, w[round*Nb, (round+1)*Nb-1])
    end for
    SubBytes(state)
    ShiftRows(state)
    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])
    out = state
  end

  InvCipher(byte in[4*Nb], byte out[4*Nb], word w[Nb*(Nr+1)])
  begin
    byte state[4,Nb]
    state = in
    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])
    for round = Nr-1 step -1 downto 1
      InvShiftRows(state)
      InvSubBytes(state)
      AddRoundKey(state, w[round*Nb, (round+1)*Nb-1])
      InvMixColumns(state)
    end for
    InvShiftRows(state)
    InvSubBytes(state)
    AddRoundKey(state, w[0, Nb-1])
    out = state
  end
  */

  // Encrypt: AddRoundKey(state, w[0, Nb-1])
  // Decrypt: AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])
  var Nr = w.length / 4 - 1;
  var m0, m1, m2, m3, sub;
  if(decrypt) {
    m0 = imix[0];
    m1 = imix[1];
    m2 = imix[2];
    m3 = imix[3];
    sub = isbox;
  } else {
    m0 = mix[0];
    m1 = mix[1];
    m2 = mix[2];
    m3 = mix[3];
    sub = sbox;
  }
  var a, b, c, d, a2, b2, c2;
  a = input[0] ^ w[0];
  b = input[decrypt ? 3 : 1] ^ w[1];
  c = input[2] ^ w[2];
  d = input[decrypt ? 1 : 3] ^ w[3];
  var i = 3;

  /* In order to share code we follow the encryption algorithm when both
    encrypting and decrypting. To account for the changes required in the
    decryption algorithm, we use different lookup tables when decrypting
    and use a modified key schedule to account for the difference in the
    order of transformations applied when performing rounds. We also get
    key rounds in reverse order (relative to encryption). */
  for(var round = 1; round < Nr; ++round) {
    /* As described above, we'll be using table lookups to perform the
      column mixing. Each column is stored as a word in the state (the
      array 'input' has one column as a word at each index). In order to
      mix a column, we perform these transformations on each row in c,
      which is 1 byte in each word. The new column for c0 is c'0:

               m0      m1      m2      m3
      r0,c'0 = 2*r0,c0 + 3*r1,c0 + 1*r2,c0 + 1*r3,c0
      r1,c'0 = 1*r0,c0 + 2*r1,c0 + 3*r2,c0 + 1*r3,c0
      r2,c'0 = 1*r0,c0 + 1*r1,c0 + 2*r2,c0 + 3*r3,c0
      r3,c'0 = 3*r0,c0 + 1*r1,c0 + 1*r2,c0 + 2*r3,c0

      So using mix tables where c0 is a word with r0 being its upper
      8 bits and r3 being its lower 8 bits:

      m0[c0 >> 24] will yield this word: [2*r0,1*r0,1*r0,3*r0]
      ...
      m3[c0 & 255] will yield this word: [1*r3,1*r3,3*r3,2*r3]

      Therefore to mix the columns in each word in the state we
      do the following (& 255 omitted for brevity):
      c'0,r0 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]
      c'0,r1 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]
      c'0,r2 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]
      c'0,r3 = m0[c0 >> 24] ^ m1[c1 >> 16] ^ m2[c2 >> 8] ^ m3[c3]

      However, before mixing, the algorithm requires us to perform
      ShiftRows(). The ShiftRows() transformation cyclically shifts the
      last 3 rows of the state over different offsets. The first row
      (r = 0) is not shifted.

      s'_r,c = s_r,(c + shift(r, Nb) mod Nb
      for 0 < r < 4 and 0 <= c < Nb and
      shift(1, 4) = 1
      shift(2, 4) = 2
      shift(3, 4) = 3.

      This causes the first byte in r = 1 to be moved to the end of
      the row, the first 2 bytes in r = 2 to be moved to the end of
      the row, the first 3 bytes in r = 3 to be moved to the end of
      the row:

      r1: [c0 c1 c2 c3] => [c1 c2 c3 c0]
      r2: [c0 c1 c2 c3]    [c2 c3 c0 c1]
      r3: [c0 c1 c2 c3]    [c3 c0 c1 c2]

      We can make these substitutions inline with our column mixing to
      generate an updated set of equations to produce each word in the
      state (note the columns have changed positions):

      c0 c1 c2 c3 => c0 c1 c2 c3
      c0 c1 c2 c3    c1 c2 c3 c0  (cycled 1 byte)
      c0 c1 c2 c3    c2 c3 c0 c1  (cycled 2 bytes)
      c0 c1 c2 c3    c3 c0 c1 c2  (cycled 3 bytes)

      Therefore:

      c'0 = 2*r0,c0 + 3*r1,c1 + 1*r2,c2 + 1*r3,c3
      c'0 = 1*r0,c0 + 2*r1,c1 + 3*r2,c2 + 1*r3,c3
      c'0 = 1*r0,c0 + 1*r1,c1 + 2*r2,c2 + 3*r3,c3
      c'0 = 3*r0,c0 + 1*r1,c1 + 1*r2,c2 + 2*r3,c3

      c'1 = 2*r0,c1 + 3*r1,c2 + 1*r2,c3 + 1*r3,c0
      c'1 = 1*r0,c1 + 2*r1,c2 + 3*r2,c3 + 1*r3,c0
      c'1 = 1*r0,c1 + 1*r1,c2 + 2*r2,c3 + 3*r3,c0
      c'1 = 3*r0,c1 + 1*r1,c2 + 1*r2,c3 + 2*r3,c0

      ... and so forth for c'2 and c'3. The important distinction is
      that the columns are cycling, with c0 being used with the m0
      map when calculating c0, but c1 being used with the m0 map when
      calculating c1 ... and so forth.

      When performing the inverse we transform the mirror image and
      skip the bottom row, instead of the top one, and move upwards:

      c3 c2 c1 c0 => c0 c3 c2 c1  (cycled 3 bytes) *same as encryption
      c3 c2 c1 c0    c1 c0 c3 c2  (cycled 2 bytes)
      c3 c2 c1 c0    c2 c1 c0 c3  (cycled 1 byte)  *same as encryption
      c3 c2 c1 c0    c3 c2 c1 c0

      If you compare the resulting matrices for ShiftRows()+MixColumns()
      and for InvShiftRows()+InvMixColumns() the 2nd and 4th columns are
      different (in encrypt mode vs. decrypt mode). So in order to use
      the same code to handle both encryption and decryption, we will
      need to do some mapping.

      If in encryption mode we let a=c0, b=c1, c=c2, d=c3, and r<N> be
      a row number in the state, then the resulting matrix in encryption
      mode for applying the above transformations would be:

      r1: a b c d
      r2: b c d a
      r3: c d a b
      r4: d a b c

      If we did the same in decryption mode we would get:

      r1: a d c b
      r2: b a d c
      r3: c b a d
      r4: d c b a

      If instead we swap d and b (set b=c3 and d=c1), then we get:

      r1: a b c d
      r2: d a b c
      r3: c d a b
      r4: b c d a

      Now the 1st and 3rd rows are the same as the encryption matrix. All
      we need to do then to make the mapping exactly the same is to swap
      the 2nd and 4th rows when in decryption mode. To do this without
      having to do it on each iteration, we swapped the 2nd and 4th rows
      in the decryption key schedule. We also have to do the swap above
      when we first pull in the input and when we set the final output. */
    a2 =
      m0[a >>> 24] ^
      m1[b >>> 16 & 255] ^
      m2[c >>> 8 & 255] ^
      m3[d & 255] ^ w[++i];
    b2 =
      m0[b >>> 24] ^
      m1[c >>> 16 & 255] ^
      m2[d >>> 8 & 255] ^
      m3[a & 255] ^ w[++i];
    c2 =
      m0[c >>> 24] ^
      m1[d >>> 16 & 255] ^
      m2[a >>> 8 & 255] ^
      m3[b & 255] ^ w[++i];
    d =
      m0[d >>> 24] ^
      m1[a >>> 16 & 255] ^
      m2[b >>> 8 & 255] ^
      m3[c & 255] ^ w[++i];
    a = a2;
    b = b2;
    c = c2;
  }

  /*
    Encrypt:
    SubBytes(state)
    ShiftRows(state)
    AddRoundKey(state, w[Nr*Nb, (Nr+1)*Nb-1])

    Decrypt:
    InvShiftRows(state)
    InvSubBytes(state)
    AddRoundKey(state, w[0, Nb-1])
   */
  // Note: rows are shifted inline
  output[0] =
    (sub[a >>> 24] << 24) ^
    (sub[b >>> 16 & 255] << 16) ^
    (sub[c >>> 8 & 255] << 8) ^
    (sub[d & 255]) ^ w[++i];
  output[decrypt ? 3 : 1] =
    (sub[b >>> 24] << 24) ^
    (sub[c >>> 16 & 255] << 16) ^
    (sub[d >>> 8 & 255] << 8) ^
    (sub[a & 255]) ^ w[++i];
  output[2] =
    (sub[c >>> 24] << 24) ^
    (sub[d >>> 16 & 255] << 16) ^
    (sub[a >>> 8 & 255] << 8) ^
    (sub[b & 255]) ^ w[++i];
  output[decrypt ? 1 : 3] =
    (sub[d >>> 24] << 24) ^
    (sub[a >>> 16 & 255] << 16) ^
    (sub[b >>> 8 & 255] << 8) ^
    (sub[c & 255]) ^ w[++i];
}

/**
 * Deprecated. Instead, use:
 *
 * forge.cipher.createCipher('AES-<mode>', key);
 * forge.cipher.createDecipher('AES-<mode>', key);
 *
 * Creates a deprecated AES cipher object. This object's mode will default to
 * CBC (cipher-block-chaining).
 *
 * The key and iv may be given as a string of bytes, an array of bytes, a
 * byte buffer, or an array of 32-bit words.
 *
 * @param options the options to use.
 *          key the symmetric key to use.
 *          output the buffer to write to.
 *          decrypt true for decryption, false for encryption.
 *          mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
function _createCipher$1(options) {
  options = options || {};
  var mode = (options.mode || 'CBC').toUpperCase();
  var algorithm = 'AES-' + mode;

  var cipher;
  if(options.decrypt) {
    cipher = forge$g.cipher.createDecipher(algorithm, options.key);
  } else {
    cipher = forge$g.cipher.createCipher(algorithm, options.key);
  }

  // backwards compatible start API
  var start = cipher.start;
  cipher.start = function(iv, options) {
    // backwards compatibility: support second arg as output buffer
    var output = null;
    if(options instanceof forge$g.util.ByteBuffer) {
      output = options;
      options = {};
    }
    options = options || {};
    options.output = output;
    options.iv = iv;
    start.call(cipher, options);
  };

  return cipher;
}

/**
 * DES (Data Encryption Standard) implementation.
 *
 * This implementation supports DES as well as 3DES-EDE in ECB and CBC mode.
 * It is based on the BSD-licensed implementation by Paul Tero:
 *
 * Paul Tero, July 2001
 * http://www.tero.co.uk/des/
 *
 * Optimised for performance with large blocks by
 * Michael Hayworth, November 2001
 * http://www.netdealing.com
 *
 * THIS SOFTWARE IS PROVIDED "AS IS" AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * @author Stefan Siegl
 * @author Dave Longley
 *
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 * Copyright (c) 2012-2014 Digital Bazaar, Inc.
 */

var forge$f = forge$m;




/* DES API */
forge$f.des = forge$f.des || {};

/**
 * Deprecated. Instead, use:
 *
 * var cipher = forge.cipher.createCipher('DES-<mode>', key);
 * cipher.start({iv: iv});
 *
 * Creates an DES cipher object to encrypt data using the given symmetric key.
 * The output will be stored in the 'output' member of the returned cipher.
 *
 * The key and iv may be given as binary-encoded strings of bytes or
 * byte buffers.
 *
 * @param key the symmetric key to use (64 or 192 bits).
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 * @param mode the cipher mode to use (default: 'CBC' if IV is
 *          given, 'ECB' if null).
 *
 * @return the cipher.
 */
forge$f.des.startEncrypting = function(key, iv, output, mode) {
  var cipher = _createCipher({
    key: key,
    output: output,
    decrypt: false,
    mode: mode || (iv === null ? 'ECB' : 'CBC')
  });
  cipher.start(iv);
  return cipher;
};

/**
 * Deprecated. Instead, use:
 *
 * var cipher = forge.cipher.createCipher('DES-<mode>', key);
 *
 * Creates an DES cipher object to encrypt data using the given symmetric key.
 *
 * The key may be given as a binary-encoded string of bytes or a byte buffer.
 *
 * @param key the symmetric key to use (64 or 192 bits).
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$f.des.createEncryptionCipher = function(key, mode) {
  return _createCipher({
    key: key,
    output: null,
    decrypt: false,
    mode: mode
  });
};

/**
 * Deprecated. Instead, use:
 *
 * var decipher = forge.cipher.createDecipher('DES-<mode>', key);
 * decipher.start({iv: iv});
 *
 * Creates an DES cipher object to decrypt data using the given symmetric key.
 * The output will be stored in the 'output' member of the returned cipher.
 *
 * The key and iv may be given as binary-encoded strings of bytes or
 * byte buffers.
 *
 * @param key the symmetric key to use (64 or 192 bits).
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 * @param mode the cipher mode to use (default: 'CBC' if IV is
 *          given, 'ECB' if null).
 *
 * @return the cipher.
 */
forge$f.des.startDecrypting = function(key, iv, output, mode) {
  var cipher = _createCipher({
    key: key,
    output: output,
    decrypt: true,
    mode: mode || (iv === null ? 'ECB' : 'CBC')
  });
  cipher.start(iv);
  return cipher;
};

/**
 * Deprecated. Instead, use:
 *
 * var decipher = forge.cipher.createDecipher('DES-<mode>', key);
 *
 * Creates an DES cipher object to decrypt data using the given symmetric key.
 *
 * The key may be given as a binary-encoded string of bytes or a byte buffer.
 *
 * @param key the symmetric key to use (64 or 192 bits).
 * @param mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
forge$f.des.createDecryptionCipher = function(key, mode) {
  return _createCipher({
    key: key,
    output: null,
    decrypt: true,
    mode: mode
  });
};

/**
 * Creates a new DES cipher algorithm object.
 *
 * @param name the name of the algorithm.
 * @param mode the mode factory function.
 *
 * @return the DES algorithm object.
 */
forge$f.des.Algorithm = function(name, mode) {
  var self = this;
  self.name = name;
  self.mode = new mode({
    blockSize: 8,
    cipher: {
      encrypt: function(inBlock, outBlock) {
        return _updateBlock(self._keys, inBlock, outBlock, false);
      },
      decrypt: function(inBlock, outBlock) {
        return _updateBlock(self._keys, inBlock, outBlock, true);
      }
    }
  });
  self._init = false;
};

/**
 * Initializes this DES algorithm by expanding its key.
 *
 * @param options the options to use.
 *          key the key to use with this algorithm.
 *          decrypt true if the algorithm should be initialized for decryption,
 *            false for encryption.
 */
forge$f.des.Algorithm.prototype.initialize = function(options) {
  if(this._init) {
    return;
  }

  var key = forge$f.util.createBuffer(options.key);
  if(this.name.indexOf('3DES') === 0) {
    if(key.length() !== 24) {
      throw new Error('Invalid Triple-DES key size: ' + key.length() * 8);
    }
  }

  // do key expansion to 16 or 48 subkeys (single or triple DES)
  this._keys = _createKeys(key);
  this._init = true;
};

/** Register DES algorithms **/

registerAlgorithm('DES-ECB', forge$f.cipher.modes.ecb);
registerAlgorithm('DES-CBC', forge$f.cipher.modes.cbc);
registerAlgorithm('DES-CFB', forge$f.cipher.modes.cfb);
registerAlgorithm('DES-OFB', forge$f.cipher.modes.ofb);
registerAlgorithm('DES-CTR', forge$f.cipher.modes.ctr);

registerAlgorithm('3DES-ECB', forge$f.cipher.modes.ecb);
registerAlgorithm('3DES-CBC', forge$f.cipher.modes.cbc);
registerAlgorithm('3DES-CFB', forge$f.cipher.modes.cfb);
registerAlgorithm('3DES-OFB', forge$f.cipher.modes.ofb);
registerAlgorithm('3DES-CTR', forge$f.cipher.modes.ctr);

function registerAlgorithm(name, mode) {
  var factory = function() {
    return new forge$f.des.Algorithm(name, mode);
  };
  forge$f.cipher.registerAlgorithm(name, factory);
}

/** DES implementation **/

var spfunction1 = [0x1010400,0,0x10000,0x1010404,0x1010004,0x10404,0x4,0x10000,0x400,0x1010400,0x1010404,0x400,0x1000404,0x1010004,0x1000000,0x4,0x404,0x1000400,0x1000400,0x10400,0x10400,0x1010000,0x1010000,0x1000404,0x10004,0x1000004,0x1000004,0x10004,0,0x404,0x10404,0x1000000,0x10000,0x1010404,0x4,0x1010000,0x1010400,0x1000000,0x1000000,0x400,0x1010004,0x10000,0x10400,0x1000004,0x400,0x4,0x1000404,0x10404,0x1010404,0x10004,0x1010000,0x1000404,0x1000004,0x404,0x10404,0x1010400,0x404,0x1000400,0x1000400,0,0x10004,0x10400,0,0x1010004];
var spfunction2 = [-0x7fef7fe0,-0x7fff8000,0x8000,0x108020,0x100000,0x20,-0x7fefffe0,-0x7fff7fe0,-0x7fffffe0,-0x7fef7fe0,-0x7fef8000,-0x80000000,-0x7fff8000,0x100000,0x20,-0x7fefffe0,0x108000,0x100020,-0x7fff7fe0,0,-0x80000000,0x8000,0x108020,-0x7ff00000,0x100020,-0x7fffffe0,0,0x108000,0x8020,-0x7fef8000,-0x7ff00000,0x8020,0,0x108020,-0x7fefffe0,0x100000,-0x7fff7fe0,-0x7ff00000,-0x7fef8000,0x8000,-0x7ff00000,-0x7fff8000,0x20,-0x7fef7fe0,0x108020,0x20,0x8000,-0x80000000,0x8020,-0x7fef8000,0x100000,-0x7fffffe0,0x100020,-0x7fff7fe0,-0x7fffffe0,0x100020,0x108000,0,-0x7fff8000,0x8020,-0x80000000,-0x7fefffe0,-0x7fef7fe0,0x108000];
var spfunction3 = [0x208,0x8020200,0,0x8020008,0x8000200,0,0x20208,0x8000200,0x20008,0x8000008,0x8000008,0x20000,0x8020208,0x20008,0x8020000,0x208,0x8000000,0x8,0x8020200,0x200,0x20200,0x8020000,0x8020008,0x20208,0x8000208,0x20200,0x20000,0x8000208,0x8,0x8020208,0x200,0x8000000,0x8020200,0x8000000,0x20008,0x208,0x20000,0x8020200,0x8000200,0,0x200,0x20008,0x8020208,0x8000200,0x8000008,0x200,0,0x8020008,0x8000208,0x20000,0x8000000,0x8020208,0x8,0x20208,0x20200,0x8000008,0x8020000,0x8000208,0x208,0x8020000,0x20208,0x8,0x8020008,0x20200];
var spfunction4 = [0x802001,0x2081,0x2081,0x80,0x802080,0x800081,0x800001,0x2001,0,0x802000,0x802000,0x802081,0x81,0,0x800080,0x800001,0x1,0x2000,0x800000,0x802001,0x80,0x800000,0x2001,0x2080,0x800081,0x1,0x2080,0x800080,0x2000,0x802080,0x802081,0x81,0x800080,0x800001,0x802000,0x802081,0x81,0,0,0x802000,0x2080,0x800080,0x800081,0x1,0x802001,0x2081,0x2081,0x80,0x802081,0x81,0x1,0x2000,0x800001,0x2001,0x802080,0x800081,0x2001,0x2080,0x800000,0x802001,0x80,0x800000,0x2000,0x802080];
var spfunction5 = [0x100,0x2080100,0x2080000,0x42000100,0x80000,0x100,0x40000000,0x2080000,0x40080100,0x80000,0x2000100,0x40080100,0x42000100,0x42080000,0x80100,0x40000000,0x2000000,0x40080000,0x40080000,0,0x40000100,0x42080100,0x42080100,0x2000100,0x42080000,0x40000100,0,0x42000000,0x2080100,0x2000000,0x42000000,0x80100,0x80000,0x42000100,0x100,0x2000000,0x40000000,0x2080000,0x42000100,0x40080100,0x2000100,0x40000000,0x42080000,0x2080100,0x40080100,0x100,0x2000000,0x42080000,0x42080100,0x80100,0x42000000,0x42080100,0x2080000,0,0x40080000,0x42000000,0x80100,0x2000100,0x40000100,0x80000,0,0x40080000,0x2080100,0x40000100];
var spfunction6 = [0x20000010,0x20400000,0x4000,0x20404010,0x20400000,0x10,0x20404010,0x400000,0x20004000,0x404010,0x400000,0x20000010,0x400010,0x20004000,0x20000000,0x4010,0,0x400010,0x20004010,0x4000,0x404000,0x20004010,0x10,0x20400010,0x20400010,0,0x404010,0x20404000,0x4010,0x404000,0x20404000,0x20000000,0x20004000,0x10,0x20400010,0x404000,0x20404010,0x400000,0x4010,0x20000010,0x400000,0x20004000,0x20000000,0x4010,0x20000010,0x20404010,0x404000,0x20400000,0x404010,0x20404000,0,0x20400010,0x10,0x4000,0x20400000,0x404010,0x4000,0x400010,0x20004010,0,0x20404000,0x20000000,0x400010,0x20004010];
var spfunction7 = [0x200000,0x4200002,0x4000802,0,0x800,0x4000802,0x200802,0x4200800,0x4200802,0x200000,0,0x4000002,0x2,0x4000000,0x4200002,0x802,0x4000800,0x200802,0x200002,0x4000800,0x4000002,0x4200000,0x4200800,0x200002,0x4200000,0x800,0x802,0x4200802,0x200800,0x2,0x4000000,0x200800,0x4000000,0x200800,0x200000,0x4000802,0x4000802,0x4200002,0x4200002,0x2,0x200002,0x4000000,0x4000800,0x200000,0x4200800,0x802,0x200802,0x4200800,0x802,0x4000002,0x4200802,0x4200000,0x200800,0,0x2,0x4200802,0,0x200802,0x4200000,0x800,0x4000002,0x4000800,0x800,0x200002];
var spfunction8 = [0x10001040,0x1000,0x40000,0x10041040,0x10000000,0x10001040,0x40,0x10000000,0x40040,0x10040000,0x10041040,0x41000,0x10041000,0x41040,0x1000,0x40,0x10040000,0x10000040,0x10001000,0x1040,0x41000,0x40040,0x10040040,0x10041000,0x1040,0,0,0x10040040,0x10000040,0x10001000,0x41040,0x40000,0x41040,0x40000,0x10041000,0x1000,0x40,0x10040040,0x1000,0x41040,0x10001000,0x40,0x10000040,0x10040000,0x10040040,0x10000000,0x40000,0x10001040,0,0x10041040,0x40040,0x10000040,0x10040000,0x10001000,0x10001040,0,0x10041040,0x41000,0x41000,0x1040,0x1040,0x40040,0x10000000,0x10041000];

/**
 * Create necessary sub keys.
 *
 * @param key the 64-bit or 192-bit key.
 *
 * @return the expanded keys.
 */
function _createKeys(key) {
  var pc2bytes0  = [0,0x4,0x20000000,0x20000004,0x10000,0x10004,0x20010000,0x20010004,0x200,0x204,0x20000200,0x20000204,0x10200,0x10204,0x20010200,0x20010204],
      pc2bytes1  = [0,0x1,0x100000,0x100001,0x4000000,0x4000001,0x4100000,0x4100001,0x100,0x101,0x100100,0x100101,0x4000100,0x4000101,0x4100100,0x4100101],
      pc2bytes2  = [0,0x8,0x800,0x808,0x1000000,0x1000008,0x1000800,0x1000808,0,0x8,0x800,0x808,0x1000000,0x1000008,0x1000800,0x1000808],
      pc2bytes3  = [0,0x200000,0x8000000,0x8200000,0x2000,0x202000,0x8002000,0x8202000,0x20000,0x220000,0x8020000,0x8220000,0x22000,0x222000,0x8022000,0x8222000],
      pc2bytes4  = [0,0x40000,0x10,0x40010,0,0x40000,0x10,0x40010,0x1000,0x41000,0x1010,0x41010,0x1000,0x41000,0x1010,0x41010],
      pc2bytes5  = [0,0x400,0x20,0x420,0,0x400,0x20,0x420,0x2000000,0x2000400,0x2000020,0x2000420,0x2000000,0x2000400,0x2000020,0x2000420],
      pc2bytes6  = [0,0x10000000,0x80000,0x10080000,0x2,0x10000002,0x80002,0x10080002,0,0x10000000,0x80000,0x10080000,0x2,0x10000002,0x80002,0x10080002],
      pc2bytes7  = [0,0x10000,0x800,0x10800,0x20000000,0x20010000,0x20000800,0x20010800,0x20000,0x30000,0x20800,0x30800,0x20020000,0x20030000,0x20020800,0x20030800],
      pc2bytes8  = [0,0x40000,0,0x40000,0x2,0x40002,0x2,0x40002,0x2000000,0x2040000,0x2000000,0x2040000,0x2000002,0x2040002,0x2000002,0x2040002],
      pc2bytes9  = [0,0x10000000,0x8,0x10000008,0,0x10000000,0x8,0x10000008,0x400,0x10000400,0x408,0x10000408,0x400,0x10000400,0x408,0x10000408],
      pc2bytes10 = [0,0x20,0,0x20,0x100000,0x100020,0x100000,0x100020,0x2000,0x2020,0x2000,0x2020,0x102000,0x102020,0x102000,0x102020],
      pc2bytes11 = [0,0x1000000,0x200,0x1000200,0x200000,0x1200000,0x200200,0x1200200,0x4000000,0x5000000,0x4000200,0x5000200,0x4200000,0x5200000,0x4200200,0x5200200],
      pc2bytes12 = [0,0x1000,0x8000000,0x8001000,0x80000,0x81000,0x8080000,0x8081000,0x10,0x1010,0x8000010,0x8001010,0x80010,0x81010,0x8080010,0x8081010],
      pc2bytes13 = [0,0x4,0x100,0x104,0,0x4,0x100,0x104,0x1,0x5,0x101,0x105,0x1,0x5,0x101,0x105];

  // how many iterations (1 for des, 3 for triple des)
  // changed by Paul 16/6/2007 to use Triple DES for 9+ byte keys
  var iterations = key.length() > 8 ? 3 : 1;

  // stores the return keys
  var keys = [];

  // now define the left shifts which need to be done
  var shifts = [0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0];

  var n = 0, tmp;
  for(var j = 0; j < iterations; j++) {
    var left = key.getInt32();
    var right = key.getInt32();

    tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;
    right ^= tmp;
    left ^= (tmp << 4);

    tmp = ((right >>> -16) ^ left) & 0x0000ffff;
    left ^= tmp;
    right ^= (tmp << -16);

    tmp = ((left >>> 2) ^ right) & 0x33333333;
    right ^= tmp;
    left ^= (tmp << 2);

    tmp = ((right >>> -16) ^ left) & 0x0000ffff;
    left ^= tmp;
    right ^= (tmp << -16);

    tmp = ((left >>> 1) ^ right) & 0x55555555;
    right ^= tmp;
    left ^= (tmp << 1);

    tmp = ((right >>> 8) ^ left) & 0x00ff00ff;
    left ^= tmp;
    right ^= (tmp << 8);

    tmp = ((left >>> 1) ^ right) & 0x55555555;
    right ^= tmp;
    left ^= (tmp << 1);

    // right needs to be shifted and OR'd with last four bits of left
    tmp = (left << 8) | ((right >>> 20) & 0x000000f0);

    // left needs to be put upside down
    left = ((right << 24) | ((right << 8) & 0xff0000) |
      ((right >>> 8) & 0xff00) | ((right >>> 24) & 0xf0));
    right = tmp;

    // now go through and perform these shifts on the left and right keys
    for(var i = 0; i < shifts.length; ++i) {
      //shift the keys either one or two bits to the left
      if(shifts[i]) {
        left = (left << 2) | (left >>> 26);
        right = (right << 2) | (right >>> 26);
      } else {
        left = (left << 1) | (left >>> 27);
        right = (right << 1) | (right >>> 27);
      }
      left &= -0xf;
      right &= -0xf;

      // now apply PC-2, in such a way that E is easier when encrypting or
      // decrypting this conversion will look like PC-2 except only the last 6
      // bits of each byte are used rather than 48 consecutive bits and the
      // order of lines will be according to how the S selection functions will
      // be applied: S2, S4, S6, S8, S1, S3, S5, S7
      var lefttmp = (
        pc2bytes0[left >>> 28] | pc2bytes1[(left >>> 24) & 0xf] |
        pc2bytes2[(left >>> 20) & 0xf] | pc2bytes3[(left >>> 16) & 0xf] |
        pc2bytes4[(left >>> 12) & 0xf] | pc2bytes5[(left >>> 8) & 0xf] |
        pc2bytes6[(left >>> 4) & 0xf]);
      var righttmp = (
        pc2bytes7[right >>> 28] | pc2bytes8[(right >>> 24) & 0xf] |
        pc2bytes9[(right >>> 20) & 0xf] | pc2bytes10[(right >>> 16) & 0xf] |
        pc2bytes11[(right >>> 12) & 0xf] | pc2bytes12[(right >>> 8) & 0xf] |
        pc2bytes13[(right >>> 4) & 0xf]);
      tmp = ((righttmp >>> 16) ^ lefttmp) & 0x0000ffff;
      keys[n++] = lefttmp ^ tmp;
      keys[n++] = righttmp ^ (tmp << 16);
    }
  }

  return keys;
}

/**
 * Updates a single block (1 byte) using DES. The update will either
 * encrypt or decrypt the block.
 *
 * @param keys the expanded keys.
 * @param input the input block (an array of 32-bit words).
 * @param output the updated output block.
 * @param decrypt true to decrypt the block, false to encrypt it.
 */
function _updateBlock(keys, input, output, decrypt) {
  // set up loops for single or triple DES
  var iterations = keys.length === 32 ? 3 : 9;
  var looping;
  if(iterations === 3) {
    looping = decrypt ? [30, -2, -2] : [0, 32, 2];
  } else {
    looping = (decrypt ?
      [94, 62, -2, 32, 64, 2, 30, -2, -2] :
      [0, 32, 2, 62, 30, -2, 64, 96, 2]);
  }

  var tmp;

  var left = input[0];
  var right = input[1];

  // first each 64 bit chunk of the message must be permuted according to IP
  tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;
  right ^= tmp;
  left ^= (tmp << 4);

  tmp = ((left >>> 16) ^ right) & 0x0000ffff;
  right ^= tmp;
  left ^= (tmp << 16);

  tmp = ((right >>> 2) ^ left) & 0x33333333;
  left ^= tmp;
  right ^= (tmp << 2);

  tmp = ((right >>> 8) ^ left) & 0x00ff00ff;
  left ^= tmp;
  right ^= (tmp << 8);

  tmp = ((left >>> 1) ^ right) & 0x55555555;
  right ^= tmp;
  left ^= (tmp << 1);

  // rotate left 1 bit
  left = ((left << 1) | (left >>> 31));
  right = ((right << 1) | (right >>> 31));

  for(var j = 0; j < iterations; j += 3) {
    var endloop = looping[j + 1];
    var loopinc = looping[j + 2];

    // now go through and perform the encryption or decryption
    for(var i = looping[j]; i != endloop; i += loopinc) {
      var right1 = right ^ keys[i];
      var right2 = ((right >>> 4) | (right << 28)) ^ keys[i + 1];

      // passing these bytes through the S selection functions
      tmp = left;
      left = right;
      right = tmp ^ (
        spfunction2[(right1 >>> 24) & 0x3f] |
        spfunction4[(right1 >>> 16) & 0x3f] |
        spfunction6[(right1 >>>  8) & 0x3f] |
        spfunction8[right1 & 0x3f] |
        spfunction1[(right2 >>> 24) & 0x3f] |
        spfunction3[(right2 >>> 16) & 0x3f] |
        spfunction5[(right2 >>>  8) & 0x3f] |
        spfunction7[right2 & 0x3f]);
    }
    // unreverse left and right
    tmp = left;
    left = right;
    right = tmp;
  }

  // rotate right 1 bit
  left = ((left >>> 1) | (left << 31));
  right = ((right >>> 1) | (right << 31));

  // now perform IP-1, which is IP in the opposite direction
  tmp = ((left >>> 1) ^ right) & 0x55555555;
  right ^= tmp;
  left ^= (tmp << 1);

  tmp = ((right >>> 8) ^ left) & 0x00ff00ff;
  left ^= tmp;
  right ^= (tmp << 8);

  tmp = ((right >>> 2) ^ left) & 0x33333333;
  left ^= tmp;
  right ^= (tmp << 2);

  tmp = ((left >>> 16) ^ right) & 0x0000ffff;
  right ^= tmp;
  left ^= (tmp << 16);

  tmp = ((left >>> 4) ^ right) & 0x0f0f0f0f;
  right ^= tmp;
  left ^= (tmp << 4);

  output[0] = left;
  output[1] = right;
}

/**
 * Deprecated. Instead, use:
 *
 * forge.cipher.createCipher('DES-<mode>', key);
 * forge.cipher.createDecipher('DES-<mode>', key);
 *
 * Creates a deprecated DES cipher object. This object's mode will default to
 * CBC (cipher-block-chaining).
 *
 * The key may be given as a binary-encoded string of bytes or a byte buffer.
 *
 * @param options the options to use.
 *          key the symmetric key to use (64 or 192 bits).
 *          output the buffer to write to.
 *          decrypt true for decryption, false for encryption.
 *          mode the cipher mode to use (default: 'CBC').
 *
 * @return the cipher.
 */
function _createCipher(options) {
  options = options || {};
  var mode = (options.mode || 'CBC').toUpperCase();
  var algorithm = 'DES-' + mode;

  var cipher;
  if(options.decrypt) {
    cipher = forge$f.cipher.createDecipher(algorithm, options.key);
  } else {
    cipher = forge$f.cipher.createCipher(algorithm, options.key);
  }

  // backwards compatible start API
  var start = cipher.start;
  cipher.start = function(iv, options) {
    // backwards compatibility: support second arg as output buffer
    var output = null;
    if(options instanceof forge$f.util.ByteBuffer) {
      output = options;
      options = {};
    }
    options = options || {};
    options.output = output;
    options.iv = iv;
    start.call(cipher, options);
  };

  return cipher;
}

/**
 * Node.js module for Forge message digests.
 *
 * @author Dave Longley
 *
 * Copyright 2011-2017 Digital Bazaar, Inc.
 */

var forge$e = forge$m;

forge$e.md = forge$e.md || {};
forge$e.md.algorithms = forge$e.md.algorithms || {};

/**
 * Hash-based Message Authentication Code implementation. Requires a message
 * digest object that can be obtained, for example, from forge.md.sha1 or
 * forge.md.md5.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2012 Digital Bazaar, Inc. All rights reserved.
 */

var forge$d = forge$m;



/* HMAC API */
var hmac$1 = forge$d.hmac = forge$d.hmac || {};

/**
 * Creates an HMAC object that uses the given message digest object.
 *
 * @return an HMAC object.
 */
hmac$1.create = function() {
  // the hmac key to use
  var _key = null;

  // the message digest to use
  var _md = null;

  // the inner padding
  var _ipadding = null;

  // the outer padding
  var _opadding = null;

  // hmac context
  var ctx = {};

  /**
   * Starts or restarts the HMAC with the given key and message digest.
   *
   * @param md the message digest to use, null to reuse the previous one,
   *           a string to use builtin 'sha1', 'md5', 'sha256'.
   * @param key the key to use as a string, array of bytes, byte buffer,
   *           or null to reuse the previous key.
   */
  ctx.start = function(md, key) {
    if(md !== null) {
      if(typeof md === 'string') {
        // create builtin message digest
        md = md.toLowerCase();
        if(md in forge$d.md.algorithms) {
          _md = forge$d.md.algorithms[md].create();
        } else {
          throw new Error('Unknown hash algorithm "' + md + '"');
        }
      } else {
        // store message digest
        _md = md;
      }
    }

    if(key === null) {
      // reuse previous key
      key = _key;
    } else {
      if(typeof key === 'string') {
        // convert string into byte buffer
        key = forge$d.util.createBuffer(key);
      } else if(forge$d.util.isArray(key)) {
        // convert byte array into byte buffer
        var tmp = key;
        key = forge$d.util.createBuffer();
        for(var i = 0; i < tmp.length; ++i) {
          key.putByte(tmp[i]);
        }
      }

      // if key is longer than blocksize, hash it
      var keylen = key.length();
      if(keylen > _md.blockLength) {
        _md.start();
        _md.update(key.bytes());
        key = _md.digest();
      }

      // mix key into inner and outer padding
      // ipadding = [0x36 * blocksize] ^ key
      // opadding = [0x5C * blocksize] ^ key
      _ipadding = forge$d.util.createBuffer();
      _opadding = forge$d.util.createBuffer();
      keylen = key.length();
      for(var i = 0; i < keylen; ++i) {
        var tmp = key.at(i);
        _ipadding.putByte(0x36 ^ tmp);
        _opadding.putByte(0x5C ^ tmp);
      }

      // if key is shorter than blocksize, add additional padding
      if(keylen < _md.blockLength) {
        var tmp = _md.blockLength - keylen;
        for(var i = 0; i < tmp; ++i) {
          _ipadding.putByte(0x36);
          _opadding.putByte(0x5C);
        }
      }
      _key = key;
      _ipadding = _ipadding.bytes();
      _opadding = _opadding.bytes();
    }

    // digest is done like so: hash(opadding | hash(ipadding | message))

    // prepare to do inner hash
    // hash(ipadding | message)
    _md.start();
    _md.update(_ipadding);
  };

  /**
   * Updates the HMAC with the given message bytes.
   *
   * @param bytes the bytes to update with.
   */
  ctx.update = function(bytes) {
    _md.update(bytes);
  };

  /**
   * Produces the Message Authentication Code (MAC).
   *
   * @return a byte buffer containing the digest value.
   */
  ctx.getMac = function() {
    // digest is done like so: hash(opadding | hash(ipadding | message))
    // here we do the outer hashing
    var inner = _md.digest().bytes();
    _md.start();
    _md.update(_opadding);
    _md.update(inner);
    return _md.digest();
  };
  // alias for getMac
  ctx.digest = ctx.getMac;

  return ctx;
};

var _nodeResolve_empty = {};

var nodeCrypto = /*#__PURE__*/Object.freeze({
    __proto__: null,
    default: _nodeResolve_empty
});

var require$$1 = /*@__PURE__*/getAugmentedNamespace(nodeCrypto);

/**
 * Password-Based Key-Derivation Function #2 implementation.
 *
 * See RFC 2898 for details.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2013 Digital Bazaar, Inc.
 */

var forge$c = forge$m;




var pkcs5 = forge$c.pkcs5 = forge$c.pkcs5 || {};

var crypto$5;
if(forge$c.util.isNodejs && !forge$c.options.usePureJavaScript) {
  crypto$5 = require$$1;
}

/**
 * Derives a key from a password.
 *
 * @param p the password as a binary-encoded string of bytes.
 * @param s the salt as a binary-encoded string of bytes.
 * @param c the iteration count, a positive integer.
 * @param dkLen the intended length, in bytes, of the derived key,
 *          (max: 2^32 - 1) * hash length of the PRF.
 * @param [md] the message digest (or algorithm identifier as a string) to use
 *          in the PRF, defaults to SHA-1.
 * @param [callback(err, key)] presence triggers asynchronous version, called
 *          once the operation completes.
 *
 * @return the derived key, as a binary-encoded string of bytes, for the
 *           synchronous version (if no callback is specified).
 */
var pbkdf2$1 = forge$c.pbkdf2 = pkcs5.pbkdf2 = function(
  p, s, c, dkLen, md, callback) {
  if(typeof md === 'function') {
    callback = md;
    md = null;
  }

  // use native implementation if possible and not disabled, note that
  // some node versions only support SHA-1, others allow digest to be changed
  if(forge$c.util.isNodejs && !forge$c.options.usePureJavaScript &&
    crypto$5.pbkdf2 && (md === null || typeof md !== 'object') &&
    (crypto$5.pbkdf2Sync.length > 4 || (!md || md === 'sha1'))) {
    if(typeof md !== 'string') {
      // default prf to SHA-1
      md = 'sha1';
    }
    p = Buffer.from(p, 'binary');
    s = Buffer.from(s, 'binary');
    if(!callback) {
      if(crypto$5.pbkdf2Sync.length === 4) {
        return crypto$5.pbkdf2Sync(p, s, c, dkLen).toString('binary');
      }
      return crypto$5.pbkdf2Sync(p, s, c, dkLen, md).toString('binary');
    }
    if(crypto$5.pbkdf2Sync.length === 4) {
      return crypto$5.pbkdf2(p, s, c, dkLen, function(err, key) {
        if(err) {
          return callback(err);
        }
        callback(null, key.toString('binary'));
      });
    }
    return crypto$5.pbkdf2(p, s, c, dkLen, md, function(err, key) {
      if(err) {
        return callback(err);
      }
      callback(null, key.toString('binary'));
    });
  }

  if(typeof md === 'undefined' || md === null) {
    // default prf to SHA-1
    md = 'sha1';
  }
  if(typeof md === 'string') {
    if(!(md in forge$c.md.algorithms)) {
      throw new Error('Unknown hash algorithm: ' + md);
    }
    md = forge$c.md[md].create();
  }

  var hLen = md.digestLength;

  /* 1. If dkLen > (2^32 - 1) * hLen, output "derived key too long" and
    stop. */
  if(dkLen > (0xFFFFFFFF * hLen)) {
    var err = new Error('Derived key is too long.');
    if(callback) {
      return callback(err);
    }
    throw err;
  }

  /* 2. Let len be the number of hLen-octet blocks in the derived key,
    rounding up, and let r be the number of octets in the last
    block:

    len = CEIL(dkLen / hLen),
    r = dkLen - (len - 1) * hLen. */
  var len = Math.ceil(dkLen / hLen);
  var r = dkLen - (len - 1) * hLen;

  /* 3. For each block of the derived key apply the function F defined
    below to the password P, the salt S, the iteration count c, and
    the block index to compute the block:

    T_1 = F(P, S, c, 1),
    T_2 = F(P, S, c, 2),
    ...
    T_len = F(P, S, c, len),

    where the function F is defined as the exclusive-or sum of the
    first c iterates of the underlying pseudorandom function PRF
    applied to the password P and the concatenation of the salt S
    and the block index i:

    F(P, S, c, i) = u_1 XOR u_2 XOR ... XOR u_c

    where

    u_1 = PRF(P, S || INT(i)),
    u_2 = PRF(P, u_1),
    ...
    u_c = PRF(P, u_{c-1}).

    Here, INT(i) is a four-octet encoding of the integer i, most
    significant octet first. */
  var prf = forge$c.hmac.create();
  prf.start(md, p);
  var dk = '';
  var xor, u_c, u_c1;

  // sync version
  if(!callback) {
    for(var i = 1; i <= len; ++i) {
      // PRF(P, S || INT(i)) (first iteration)
      prf.start(null, null);
      prf.update(s);
      prf.update(forge$c.util.int32ToBytes(i));
      xor = u_c1 = prf.digest().getBytes();

      // PRF(P, u_{c-1}) (other iterations)
      for(var j = 2; j <= c; ++j) {
        prf.start(null, null);
        prf.update(u_c1);
        u_c = prf.digest().getBytes();
        // F(p, s, c, i)
        xor = forge$c.util.xorBytes(xor, u_c, hLen);
        u_c1 = u_c;
      }

      /* 4. Concatenate the blocks and extract the first dkLen octets to
        produce a derived key DK:

        DK = T_1 || T_2 ||  ...  || T_len<0..r-1> */
      dk += (i < len) ? xor : xor.substr(0, r);
    }
    /* 5. Output the derived key DK. */
    return dk;
  }

  // async version
  var i = 1, j;
  function outer() {
    if(i > len) {
      // done
      return callback(null, dk);
    }

    // PRF(P, S || INT(i)) (first iteration)
    prf.start(null, null);
    prf.update(s);
    prf.update(forge$c.util.int32ToBytes(i));
    xor = u_c1 = prf.digest().getBytes();

    // PRF(P, u_{c-1}) (other iterations)
    j = 2;
    inner();
  }

  function inner() {
    if(j <= c) {
      prf.start(null, null);
      prf.update(u_c1);
      u_c = prf.digest().getBytes();
      // F(p, s, c, i)
      xor = forge$c.util.xorBytes(xor, u_c, hLen);
      u_c1 = u_c;
      ++j;
      return forge$c.util.setImmediate(inner);
    }

    /* 4. Concatenate the blocks and extract the first dkLen octets to
      produce a derived key DK:

      DK = T_1 || T_2 ||  ...  || T_len<0..r-1> */
    dk += (i < len) ? xor : xor.substr(0, r);

    ++i;
    outer();
  }

  outer();
};

var forgePbkdf2 = /*@__PURE__*/getDefaultExportFromCjs(pbkdf2$1);

/**
 * Javascript implementation of basic PEM (Privacy Enhanced Mail) algorithms.
 *
 * See: RFC 1421.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2013-2014 Digital Bazaar, Inc.
 *
 * A Forge PEM object has the following fields:
 *
 * type: identifies the type of message (eg: "RSA PRIVATE KEY").
 *
 * procType: identifies the type of processing performed on the message,
 *   it has two subfields: version and type, eg: 4,ENCRYPTED.
 *
 * contentDomain: identifies the type of content in the message, typically
 *   only uses the value: "RFC822".
 *
 * dekInfo: identifies the message encryption algorithm and mode and includes
 *   any parameters for the algorithm, it has two subfields: algorithm and
 *   parameters, eg: DES-CBC,F8143EDE5960C597.
 *
 * headers: contains all other PEM encapsulated headers -- where order is
 *   significant (for pairing data like recipient ID + key info).
 *
 * body: the binary-encoded body.
 */

var forge$b = forge$m;


// shortcut for pem API
var pem = forge$b.pem = forge$b.pem || {};

/**
 * Encodes (serializes) the given PEM object.
 *
 * @param msg the PEM message object to encode.
 * @param options the options to use:
 *          maxline the maximum characters per line for the body, (default: 64).
 *
 * @return the PEM-formatted string.
 */
pem.encode = function(msg, options) {
  options = options || {};
  var rval = '-----BEGIN ' + msg.type + '-----\r\n';

  // encode special headers
  var header;
  if(msg.procType) {
    header = {
      name: 'Proc-Type',
      values: [String(msg.procType.version), msg.procType.type]
    };
    rval += foldHeader(header);
  }
  if(msg.contentDomain) {
    header = {name: 'Content-Domain', values: [msg.contentDomain]};
    rval += foldHeader(header);
  }
  if(msg.dekInfo) {
    header = {name: 'DEK-Info', values: [msg.dekInfo.algorithm]};
    if(msg.dekInfo.parameters) {
      header.values.push(msg.dekInfo.parameters);
    }
    rval += foldHeader(header);
  }

  if(msg.headers) {
    // encode all other headers
    for(var i = 0; i < msg.headers.length; ++i) {
      rval += foldHeader(msg.headers[i]);
    }
  }

  // terminate header
  if(msg.procType) {
    rval += '\r\n';
  }

  // add body
  rval += forge$b.util.encode64(msg.body, options.maxline || 64) + '\r\n';

  rval += '-----END ' + msg.type + '-----\r\n';
  return rval;
};

/**
 * Decodes (deserializes) all PEM messages found in the given string.
 *
 * @param str the PEM-formatted string to decode.
 *
 * @return the PEM message objects in an array.
 */
pem.decode = function(str) {
  var rval = [];

  // split string into PEM messages (be lenient w/EOF on BEGIN line)
  var rMessage = /\s*-----BEGIN ([A-Z0-9- ]+)-----\r?\n?([\x21-\x7e\s]+?(?:\r?\n\r?\n))?([:A-Za-z0-9+\/=\s]+?)-----END \1-----/g;
  var rHeader = /([\x21-\x7e]+):\s*([\x21-\x7e\s^:]+)/;
  var rCRLF = /\r?\n/;
  var match;
  while(true) {
    match = rMessage.exec(str);
    if(!match) {
      break;
    }

    // accept "NEW CERTIFICATE REQUEST" as "CERTIFICATE REQUEST"
    // https://datatracker.ietf.org/doc/html/rfc7468#section-7
    var type = match[1];
    if(type === 'NEW CERTIFICATE REQUEST') {
      type = 'CERTIFICATE REQUEST';
    }

    var msg = {
      type: type,
      procType: null,
      contentDomain: null,
      dekInfo: null,
      headers: [],
      body: forge$b.util.decode64(match[3])
    };
    rval.push(msg);

    // no headers
    if(!match[2]) {
      continue;
    }

    // parse headers
    var lines = match[2].split(rCRLF);
    var li = 0;
    while(match && li < lines.length) {
      // get line, trim any rhs whitespace
      var line = lines[li].replace(/\s+$/, '');

      // RFC2822 unfold any following folded lines
      for(var nl = li + 1; nl < lines.length; ++nl) {
        var next = lines[nl];
        if(!/\s/.test(next[0])) {
          break;
        }
        line += next;
        li = nl;
      }

      // parse header
      match = line.match(rHeader);
      if(match) {
        var header = {name: match[1], values: []};
        var values = match[2].split(',');
        for(var vi = 0; vi < values.length; ++vi) {
          header.values.push(ltrim(values[vi]));
        }

        // Proc-Type must be the first header
        if(!msg.procType) {
          if(header.name !== 'Proc-Type') {
            throw new Error('Invalid PEM formatted message. The first ' +
              'encapsulated header must be "Proc-Type".');
          } else if(header.values.length !== 2) {
            throw new Error('Invalid PEM formatted message. The "Proc-Type" ' +
              'header must have two subfields.');
          }
          msg.procType = {version: values[0], type: values[1]};
        } else if(!msg.contentDomain && header.name === 'Content-Domain') {
          // special-case Content-Domain
          msg.contentDomain = values[0] || '';
        } else if(!msg.dekInfo && header.name === 'DEK-Info') {
          // special-case DEK-Info
          if(header.values.length === 0) {
            throw new Error('Invalid PEM formatted message. The "DEK-Info" ' +
              'header must have at least one subfield.');
          }
          msg.dekInfo = {algorithm: values[0], parameters: values[1] || null};
        } else {
          msg.headers.push(header);
        }
      }

      ++li;
    }

    if(msg.procType === 'ENCRYPTED' && !msg.dekInfo) {
      throw new Error('Invalid PEM formatted message. The "DEK-Info" ' +
        'header must be present if "Proc-Type" is "ENCRYPTED".');
    }
  }

  if(rval.length === 0) {
    throw new Error('Invalid PEM formatted message.');
  }

  return rval;
};

function foldHeader(header) {
  var rval = header.name + ': ';

  // ensure values with CRLF are folded
  var values = [];
  var insertSpace = function(match, $1) {
    return ' ' + $1;
  };
  for(var i = 0; i < header.values.length; ++i) {
    values.push(header.values[i].replace(/^(\S+\r\n)/, insertSpace));
  }
  rval += values.join(',') + '\r\n';

  // do folding
  var length = 0;
  var candidate = -1;
  for(var i = 0; i < rval.length; ++i, ++length) {
    if(length > 65 && candidate !== -1) {
      var insert = rval[candidate];
      if(insert === ',') {
        ++candidate;
        rval = rval.substr(0, candidate) + '\r\n ' + rval.substr(candidate);
      } else {
        rval = rval.substr(0, candidate) +
          '\r\n' + insert + rval.substr(candidate + 1);
      }
      length = (i - candidate - 1);
      candidate = -1;
      ++i;
    } else if(rval[i] === ' ' || rval[i] === '\t' || rval[i] === ',') {
      candidate = i;
    }
  }

  return rval;
}

function ltrim(str) {
  return str.replace(/^\s+/, '');
}

/**
 * Secure Hash Algorithm with 256-bit digest (SHA-256) implementation.
 *
 * See FIPS 180-2 for details.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2015 Digital Bazaar, Inc.
 */

var forge$a = forge$m;



var sha256$9 = forge$a.sha256 = forge$a.sha256 || {};
forge$a.md.sha256 = forge$a.md.algorithms.sha256 = sha256$9;

/**
 * Creates a SHA-256 message digest object.
 *
 * @return a message digest object.
 */
sha256$9.create = function() {
  // do initialization as necessary
  if(!_initialized$2) {
    _init$2();
  }

  // SHA-256 state contains eight 32-bit integers
  var _state = null;

  // input buffer
  var _input = forge$a.util.createBuffer();

  // used for word storage
  var _w = new Array(64);

  // message digest object
  var md = {
    algorithm: 'sha256',
    blockLength: 64,
    digestLength: 32,
    // 56-bit length of message so far (does not including padding)
    messageLength: 0,
    // true message length
    fullMessageLength: null,
    // size of message length in bytes
    messageLengthSize: 8
  };

  /**
   * Starts the digest.
   *
   * @return this digest object.
   */
  md.start = function() {
    // up to 56-bit message length for convenience
    md.messageLength = 0;

    // full message length (set md.messageLength64 for backwards-compatibility)
    md.fullMessageLength = md.messageLength64 = [];
    var int32s = md.messageLengthSize / 4;
    for(var i = 0; i < int32s; ++i) {
      md.fullMessageLength.push(0);
    }
    _input = forge$a.util.createBuffer();
    _state = {
      h0: 0x6A09E667,
      h1: 0xBB67AE85,
      h2: 0x3C6EF372,
      h3: 0xA54FF53A,
      h4: 0x510E527F,
      h5: 0x9B05688C,
      h6: 0x1F83D9AB,
      h7: 0x5BE0CD19
    };
    return md;
  };
  // start digest automatically for first time
  md.start();

  /**
   * Updates the digest with the given message input. The given input can
   * treated as raw input (no encoding will be applied) or an encoding of
   * 'utf8' maybe given to encode the input using UTF-8.
   *
   * @param msg the message input to update with.
   * @param encoding the encoding to use (default: 'raw', other: 'utf8').
   *
   * @return this digest object.
   */
  md.update = function(msg, encoding) {
    if(encoding === 'utf8') {
      msg = forge$a.util.encodeUtf8(msg);
    }

    // update message length
    var len = msg.length;
    md.messageLength += len;
    len = [(len / 0x100000000) >>> 0, len >>> 0];
    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {
      md.fullMessageLength[i] += len[1];
      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);
      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;
      len[0] = ((len[1] / 0x100000000) >>> 0);
    }

    // add bytes to input buffer
    _input.putBytes(msg);

    // process bytes
    _update$2(_state, _w, _input);

    // compact input buffer every 2K or if empty
    if(_input.read > 2048 || _input.length() === 0) {
      _input.compact();
    }

    return md;
  };

  /**
   * Produces the digest.
   *
   * @return a byte buffer containing the digest value.
   */
  md.digest = function() {
    /* Note: Here we copy the remaining bytes in the input buffer and
    add the appropriate SHA-256 padding. Then we do the final update
    on a copy of the state so that if the user wants to get
    intermediate digests they can do so. */

    /* Determine the number of bytes that must be added to the message
    to ensure its length is congruent to 448 mod 512. In other words,
    the data to be digested must be a multiple of 512 bits (or 128 bytes).
    This data includes the message, some padding, and the length of the
    message. Since the length of the message will be encoded as 8 bytes (64
    bits), that means that the last segment of the data must have 56 bytes
    (448 bits) of message and padding. Therefore, the length of the message
    plus the padding must be congruent to 448 mod 512 because
    512 - 128 = 448.

    In order to fill up the message length it must be filled with
    padding that begins with 1 bit followed by all 0 bits. Padding
    must *always* be present, so if the message length is already
    congruent to 448 mod 512, then 512 padding bits must be added. */

    var finalBlock = forge$a.util.createBuffer();
    finalBlock.putBytes(_input.bytes());

    // compute remaining size to be digested (include message length size)
    var remaining = (
      md.fullMessageLength[md.fullMessageLength.length - 1] +
      md.messageLengthSize);

    // add padding for overflow blockSize - overflow
    // _padding starts with 1 byte with first bit is set (byte value 128), then
    // there may be up to (blockSize - 1) other pad bytes
    var overflow = remaining & (md.blockLength - 1);
    finalBlock.putBytes(_padding$2.substr(0, md.blockLength - overflow));

    // serialize message length in bits in big-endian order; since length
    // is stored in bytes we multiply by 8 and add carry from next int
    var next, carry;
    var bits = md.fullMessageLength[0] * 8;
    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {
      next = md.fullMessageLength[i + 1] * 8;
      carry = (next / 0x100000000) >>> 0;
      bits += carry;
      finalBlock.putInt32(bits >>> 0);
      bits = next >>> 0;
    }
    finalBlock.putInt32(bits);

    var s2 = {
      h0: _state.h0,
      h1: _state.h1,
      h2: _state.h2,
      h3: _state.h3,
      h4: _state.h4,
      h5: _state.h5,
      h6: _state.h6,
      h7: _state.h7
    };
    _update$2(s2, _w, finalBlock);
    var rval = forge$a.util.createBuffer();
    rval.putInt32(s2.h0);
    rval.putInt32(s2.h1);
    rval.putInt32(s2.h2);
    rval.putInt32(s2.h3);
    rval.putInt32(s2.h4);
    rval.putInt32(s2.h5);
    rval.putInt32(s2.h6);
    rval.putInt32(s2.h7);
    return rval;
  };

  return md;
};

// sha-256 padding bytes not initialized yet
var _padding$2 = null;
var _initialized$2 = false;

// table of constants
var _k$1 = null;

/**
 * Initializes the constant tables.
 */
function _init$2() {
  // create padding
  _padding$2 = String.fromCharCode(128);
  _padding$2 += forge$a.util.fillString(String.fromCharCode(0x00), 64);

  // create K table for SHA-256
  _k$1 = [
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
    0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,
    0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,
    0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,
    0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,
    0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2];

  // now initialized
  _initialized$2 = true;
}

/**
 * Updates a SHA-256 state with the given byte buffer.
 *
 * @param s the SHA-256 state to update.
 * @param w the array to use to store words.
 * @param bytes the byte buffer to update with.
 */
function _update$2(s, w, bytes) {
  // consume 512 bit (64 byte) chunks
  var t1, t2, s0, s1, ch, maj, i, a, b, c, d, e, f, g, h;
  var len = bytes.length();
  while(len >= 64) {
    // the w array will be populated with sixteen 32-bit big-endian words
    // and then extended into 64 32-bit words according to SHA-256
    for(i = 0; i < 16; ++i) {
      w[i] = bytes.getInt32();
    }
    for(; i < 64; ++i) {
      // XOR word 2 words ago rot right 17, rot right 19, shft right 10
      t1 = w[i - 2];
      t1 =
        ((t1 >>> 17) | (t1 << 15)) ^
        ((t1 >>> 19) | (t1 << 13)) ^
        (t1 >>> 10);
      // XOR word 15 words ago rot right 7, rot right 18, shft right 3
      t2 = w[i - 15];
      t2 =
        ((t2 >>> 7) | (t2 << 25)) ^
        ((t2 >>> 18) | (t2 << 14)) ^
        (t2 >>> 3);
      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^32
      w[i] = (t1 + w[i - 7] + t2 + w[i - 16]) | 0;
    }

    // initialize hash value for this chunk
    a = s.h0;
    b = s.h1;
    c = s.h2;
    d = s.h3;
    e = s.h4;
    f = s.h5;
    g = s.h6;
    h = s.h7;

    // round function
    for(i = 0; i < 64; ++i) {
      // Sum1(e)
      s1 =
        ((e >>> 6) | (e << 26)) ^
        ((e >>> 11) | (e << 21)) ^
        ((e >>> 25) | (e << 7));
      // Ch(e, f, g) (optimized the same way as SHA-1)
      ch = g ^ (e & (f ^ g));
      // Sum0(a)
      s0 =
        ((a >>> 2) | (a << 30)) ^
        ((a >>> 13) | (a << 19)) ^
        ((a >>> 22) | (a << 10));
      // Maj(a, b, c) (optimized the same way as SHA-1)
      maj = (a & b) | (c & (a ^ b));

      // main algorithm
      t1 = h + s1 + ch + _k$1[i] + w[i];
      t2 = s0 + maj;
      h = g;
      g = f;
      f = e;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      // can't truncate with `| 0`
      e = (d + t1) >>> 0;
      d = c;
      c = b;
      b = a;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      // can't truncate with `| 0`
      a = (t1 + t2) >>> 0;
    }

    // update hash state
    s.h0 = (s.h0 + a) | 0;
    s.h1 = (s.h1 + b) | 0;
    s.h2 = (s.h2 + c) | 0;
    s.h3 = (s.h3 + d) | 0;
    s.h4 = (s.h4 + e) | 0;
    s.h5 = (s.h5 + f) | 0;
    s.h6 = (s.h6 + g) | 0;
    s.h7 = (s.h7 + h) | 0;
    len -= 64;
  }
}

/**
 * A javascript implementation of a cryptographically-secure
 * Pseudo Random Number Generator (PRNG). The Fortuna algorithm is followed
 * here though the use of SHA-256 is not enforced; when generating an
 * a PRNG context, the hashing algorithm and block cipher used for
 * the generator are specified via a plugin.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 */

var forge$9 = forge$m;


var _crypto$1 = null;
if(forge$9.util.isNodejs && !forge$9.options.usePureJavaScript &&
  !process.versions['node-webkit']) {
  _crypto$1 = require$$1;
}

/* PRNG API */
var prng = forge$9.prng = forge$9.prng || {};

/**
 * Creates a new PRNG context.
 *
 * A PRNG plugin must be passed in that will provide:
 *
 * 1. A function that initializes the key and seed of a PRNG context. It
 *   will be given a 16 byte key and a 16 byte seed. Any key expansion
 *   or transformation of the seed from a byte string into an array of
 *   integers (or similar) should be performed.
 * 2. The cryptographic function used by the generator. It takes a key and
 *   a seed.
 * 3. A seed increment function. It takes the seed and returns seed + 1.
 * 4. An api to create a message digest.
 *
 * For an example, see random.js.
 *
 * @param plugin the PRNG plugin to use.
 */
prng.create = function(plugin) {
  var ctx = {
    plugin: plugin,
    key: null,
    seed: null,
    time: null,
    // number of reseeds so far
    reseeds: 0,
    // amount of data generated so far
    generated: 0,
    // no initial key bytes
    keyBytes: ''
  };

  // create 32 entropy pools (each is a message digest)
  var md = plugin.md;
  var pools = new Array(32);
  for(var i = 0; i < 32; ++i) {
    pools[i] = md.create();
  }
  ctx.pools = pools;

  // entropy pools are written to cyclically, starting at index 0
  ctx.pool = 0;

  /**
   * Generates random bytes. The bytes may be generated synchronously or
   * asynchronously. Web workers must use the asynchronous interface or
   * else the behavior is undefined.
   *
   * @param count the number of random bytes to generate.
   * @param [callback(err, bytes)] called once the operation completes.
   *
   * @return count random bytes as a string.
   */
  ctx.generate = function(count, callback) {
    // do synchronously
    if(!callback) {
      return ctx.generateSync(count);
    }

    // simple generator using counter-based CBC
    var cipher = ctx.plugin.cipher;
    var increment = ctx.plugin.increment;
    var formatKey = ctx.plugin.formatKey;
    var formatSeed = ctx.plugin.formatSeed;
    var b = forge$9.util.createBuffer();

    // paranoid deviation from Fortuna:
    // reset key for every request to protect previously
    // generated random bytes should the key be discovered;
    // there is no 100ms based reseeding because of this
    // forced reseed for every `generate` call
    ctx.key = null;

    generate();

    function generate(err) {
      if(err) {
        return callback(err);
      }

      // sufficient bytes generated
      if(b.length() >= count) {
        return callback(null, b.getBytes(count));
      }

      // if amount of data generated is greater than 1 MiB, trigger reseed
      if(ctx.generated > 0xfffff) {
        ctx.key = null;
      }

      if(ctx.key === null) {
        // prevent stack overflow
        return forge$9.util.nextTick(function() {
          _reseed(generate);
        });
      }

      // generate the random bytes
      var bytes = cipher(ctx.key, ctx.seed);
      ctx.generated += bytes.length;
      b.putBytes(bytes);

      // generate bytes for a new key and seed
      ctx.key = formatKey(cipher(ctx.key, increment(ctx.seed)));
      ctx.seed = formatSeed(cipher(ctx.key, ctx.seed));

      forge$9.util.setImmediate(generate);
    }
  };

  /**
   * Generates random bytes synchronously.
   *
   * @param count the number of random bytes to generate.
   *
   * @return count random bytes as a string.
   */
  ctx.generateSync = function(count) {
    // simple generator using counter-based CBC
    var cipher = ctx.plugin.cipher;
    var increment = ctx.plugin.increment;
    var formatKey = ctx.plugin.formatKey;
    var formatSeed = ctx.plugin.formatSeed;

    // paranoid deviation from Fortuna:
    // reset key for every request to protect previously
    // generated random bytes should the key be discovered;
    // there is no 100ms based reseeding because of this
    // forced reseed for every `generateSync` call
    ctx.key = null;

    var b = forge$9.util.createBuffer();
    while(b.length() < count) {
      // if amount of data generated is greater than 1 MiB, trigger reseed
      if(ctx.generated > 0xfffff) {
        ctx.key = null;
      }

      if(ctx.key === null) {
        _reseedSync();
      }

      // generate the random bytes
      var bytes = cipher(ctx.key, ctx.seed);
      ctx.generated += bytes.length;
      b.putBytes(bytes);

      // generate bytes for a new key and seed
      ctx.key = formatKey(cipher(ctx.key, increment(ctx.seed)));
      ctx.seed = formatSeed(cipher(ctx.key, ctx.seed));
    }

    return b.getBytes(count);
  };

  /**
   * Private function that asynchronously reseeds a generator.
   *
   * @param callback(err) called once the operation completes.
   */
  function _reseed(callback) {
    if(ctx.pools[0].messageLength >= 32) {
      _seed();
      return callback();
    }
    // not enough seed data...
    var needed = (32 - ctx.pools[0].messageLength) << 5;
    ctx.seedFile(needed, function(err, bytes) {
      if(err) {
        return callback(err);
      }
      ctx.collect(bytes);
      _seed();
      callback();
    });
  }

  /**
   * Private function that synchronously reseeds a generator.
   */
  function _reseedSync() {
    if(ctx.pools[0].messageLength >= 32) {
      return _seed();
    }
    // not enough seed data...
    var needed = (32 - ctx.pools[0].messageLength) << 5;
    ctx.collect(ctx.seedFileSync(needed));
    _seed();
  }

  /**
   * Private function that seeds a generator once enough bytes are available.
   */
  function _seed() {
    // update reseed count
    ctx.reseeds = (ctx.reseeds === 0xffffffff) ? 0 : ctx.reseeds + 1;

    // goal is to update `key` via:
    // key = hash(key + s)
    //   where 's' is all collected entropy from selected pools, then...

    // create a plugin-based message digest
    var md = ctx.plugin.md.create();

    // consume current key bytes
    md.update(ctx.keyBytes);

    // digest the entropy of pools whose index k meet the
    // condition 'n mod 2^k == 0' where n is the number of reseeds
    var _2powK = 1;
    for(var k = 0; k < 32; ++k) {
      if(ctx.reseeds % _2powK === 0) {
        md.update(ctx.pools[k].digest().getBytes());
        ctx.pools[k].start();
      }
      _2powK = _2powK << 1;
    }

    // get digest for key bytes
    ctx.keyBytes = md.digest().getBytes();

    // paranoid deviation from Fortuna:
    // update `seed` via `seed = hash(key)`
    // instead of initializing to zero once and only
    // ever incrementing it
    md.start();
    md.update(ctx.keyBytes);
    var seedBytes = md.digest().getBytes();

    // update state
    ctx.key = ctx.plugin.formatKey(ctx.keyBytes);
    ctx.seed = ctx.plugin.formatSeed(seedBytes);
    ctx.generated = 0;
  }

  /**
   * The built-in default seedFile. This seedFile is used when entropy
   * is needed immediately.
   *
   * @param needed the number of bytes that are needed.
   *
   * @return the random bytes.
   */
  function defaultSeedFile(needed) {
    // use window.crypto.getRandomValues strong source of entropy if available
    var getRandomValues = null;
    var globalScope = forge$9.util.globalScope;
    var _crypto = globalScope.crypto || globalScope.msCrypto;
    if(_crypto && _crypto.getRandomValues) {
      getRandomValues = function(arr) {
        return _crypto.getRandomValues(arr);
      };
    }

    var b = forge$9.util.createBuffer();
    if(getRandomValues) {
      while(b.length() < needed) {
        // max byte length is 65536 before QuotaExceededError is thrown
        // http://www.w3.org/TR/WebCryptoAPI/#RandomSource-method-getRandomValues
        var count = Math.max(1, Math.min(needed - b.length(), 65536) / 4);
        var entropy = new Uint32Array(Math.floor(count));
        try {
          getRandomValues(entropy);
          for(var i = 0; i < entropy.length; ++i) {
            b.putInt32(entropy[i]);
          }
        } catch(e) {
          /* only ignore QuotaExceededError */
          if(!(typeof QuotaExceededError !== 'undefined' &&
            e instanceof QuotaExceededError)) {
            throw e;
          }
        }
      }
    }

    // be sad and add some weak random data
    if(b.length() < needed) {
      /* Draws from Park-Miller "minimal standard" 31 bit PRNG,
      implemented with David G. Carta's optimization: with 32 bit math
      and without division (Public Domain). */
      var hi, lo, next;
      var seed = Math.floor(Math.random() * 0x010000);
      while(b.length() < needed) {
        lo = 16807 * (seed & 0xFFFF);
        hi = 16807 * (seed >> 16);
        lo += (hi & 0x7FFF) << 16;
        lo += hi >> 15;
        lo = (lo & 0x7FFFFFFF) + (lo >> 31);
        seed = lo & 0xFFFFFFFF;

        // consume lower 3 bytes of seed
        for(var i = 0; i < 3; ++i) {
          // throw in more pseudo random
          next = seed >>> (i << 3);
          next ^= Math.floor(Math.random() * 0x0100);
          b.putByte(next & 0xFF);
        }
      }
    }

    return b.getBytes(needed);
  }
  // initialize seed file APIs
  if(_crypto$1) {
    // use nodejs async API
    ctx.seedFile = function(needed, callback) {
      _crypto$1.randomBytes(needed, function(err, bytes) {
        if(err) {
          return callback(err);
        }
        callback(null, bytes.toString());
      });
    };
    // use nodejs sync API
    ctx.seedFileSync = function(needed) {
      return _crypto$1.randomBytes(needed).toString();
    };
  } else {
    ctx.seedFile = function(needed, callback) {
      try {
        callback(null, defaultSeedFile(needed));
      } catch(e) {
        callback(e);
      }
    };
    ctx.seedFileSync = defaultSeedFile;
  }

  /**
   * Adds entropy to a prng ctx's accumulator.
   *
   * @param bytes the bytes of entropy as a string.
   */
  ctx.collect = function(bytes) {
    // iterate over pools distributing entropy cyclically
    var count = bytes.length;
    for(var i = 0; i < count; ++i) {
      ctx.pools[ctx.pool].update(bytes.substr(i, 1));
      ctx.pool = (ctx.pool === 31) ? 0 : ctx.pool + 1;
    }
  };

  /**
   * Collects an integer of n bits.
   *
   * @param i the integer entropy.
   * @param n the number of bits in the integer.
   */
  ctx.collectInt = function(i, n) {
    var bytes = '';
    for(var x = 0; x < n; x += 8) {
      bytes += String.fromCharCode((i >> x) & 0xFF);
    }
    ctx.collect(bytes);
  };

  /**
   * Registers a Web Worker to receive immediate entropy from the main thread.
   * This method is required until Web Workers can access the native crypto
   * API. This method should be called twice for each created worker, once in
   * the main thread, and once in the worker itself.
   *
   * @param worker the worker to register.
   */
  ctx.registerWorker = function(worker) {
    // worker receives random bytes
    if(worker === self) {
      ctx.seedFile = function(needed, callback) {
        function listener(e) {
          var data = e.data;
          if(data.forge && data.forge.prng) {
            self.removeEventListener('message', listener);
            callback(data.forge.prng.err, data.forge.prng.bytes);
          }
        }
        self.addEventListener('message', listener);
        self.postMessage({forge: {prng: {needed: needed}}});
      };
    } else {
      // main thread sends random bytes upon request
      var listener = function(e) {
        var data = e.data;
        if(data.forge && data.forge.prng) {
          ctx.seedFile(data.forge.prng.needed, function(err, bytes) {
            worker.postMessage({forge: {prng: {err: err, bytes: bytes}}});
          });
        }
      };
      // TODO: do we need to remove the event listener when the worker dies?
      worker.addEventListener('message', listener);
    }
  };

  return ctx;
};

/**
 * An API for getting cryptographically-secure random bytes. The bytes are
 * generated using the Fortuna algorithm devised by Bruce Schneier and
 * Niels Ferguson.
 *
 * Getting strong random bytes is not yet easy to do in javascript. The only
 * truish random entropy that can be collected is from the mouse, keyboard, or
 * from timing with respect to page loads, etc. This generator makes a poor
 * attempt at providing random bytes when those sources haven't yet provided
 * enough entropy to initially seed or to reseed the PRNG.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2009-2014 Digital Bazaar, Inc.
 */

var forge$8 = forge$m;





(function() {

// forge.random already defined
if(forge$8.random && forge$8.random.getBytes) {
  forge$8.random;
  return;
}

(function(jQuery) {

// the default prng plugin, uses AES-128
var prng_aes = {};
var _prng_aes_output = new Array(4);
var _prng_aes_buffer = forge$8.util.createBuffer();
prng_aes.formatKey = function(key) {
  // convert the key into 32-bit integers
  var tmp = forge$8.util.createBuffer(key);
  key = new Array(4);
  key[0] = tmp.getInt32();
  key[1] = tmp.getInt32();
  key[2] = tmp.getInt32();
  key[3] = tmp.getInt32();

  // return the expanded key
  return forge$8.aes._expandKey(key, false);
};
prng_aes.formatSeed = function(seed) {
  // convert seed into 32-bit integers
  var tmp = forge$8.util.createBuffer(seed);
  seed = new Array(4);
  seed[0] = tmp.getInt32();
  seed[1] = tmp.getInt32();
  seed[2] = tmp.getInt32();
  seed[3] = tmp.getInt32();
  return seed;
};
prng_aes.cipher = function(key, seed) {
  forge$8.aes._updateBlock(key, seed, _prng_aes_output, false);
  _prng_aes_buffer.putInt32(_prng_aes_output[0]);
  _prng_aes_buffer.putInt32(_prng_aes_output[1]);
  _prng_aes_buffer.putInt32(_prng_aes_output[2]);
  _prng_aes_buffer.putInt32(_prng_aes_output[3]);
  return _prng_aes_buffer.getBytes();
};
prng_aes.increment = function(seed) {
  // FIXME: do we care about carry or signed issues?
  ++seed[3];
  return seed;
};
prng_aes.md = forge$8.md.sha256;

/**
 * Creates a new PRNG.
 */
function spawnPrng() {
  var ctx = forge$8.prng.create(prng_aes);

  /**
   * Gets random bytes. If a native secure crypto API is unavailable, this
   * method tries to make the bytes more unpredictable by drawing from data that
   * can be collected from the user of the browser, eg: mouse movement.
   *
   * If a callback is given, this method will be called asynchronously.
   *
   * @param count the number of random bytes to get.
   * @param [callback(err, bytes)] called once the operation completes.
   *
   * @return the random bytes in a string.
   */
  ctx.getBytes = function(count, callback) {
    return ctx.generate(count, callback);
  };

  /**
   * Gets random bytes asynchronously. If a native secure crypto API is
   * unavailable, this method tries to make the bytes more unpredictable by
   * drawing from data that can be collected from the user of the browser,
   * eg: mouse movement.
   *
   * @param count the number of random bytes to get.
   *
   * @return the random bytes in a string.
   */
  ctx.getBytesSync = function(count) {
    return ctx.generate(count);
  };

  return ctx;
}

// create default prng context
var _ctx = spawnPrng();

// add other sources of entropy only if window.crypto.getRandomValues is not
// available -- otherwise this source will be automatically used by the prng
var getRandomValues = null;
var globalScope = forge$8.util.globalScope;
var _crypto = globalScope.crypto || globalScope.msCrypto;
if(_crypto && _crypto.getRandomValues) {
  getRandomValues = function(arr) {
    return _crypto.getRandomValues(arr);
  };
}

if(forge$8.options.usePureJavaScript ||
  (!forge$8.util.isNodejs && !getRandomValues)) {

  // get load time entropy
  _ctx.collectInt(+new Date(), 32);

  // add some entropy from navigator object
  if(typeof(navigator) !== 'undefined') {
    var _navBytes = '';
    for(var key in navigator) {
      try {
        if(typeof(navigator[key]) == 'string') {
          _navBytes += navigator[key];
        }
      } catch(e) {
        /* Some navigator keys might not be accessible, e.g. the geolocation
          attribute throws an exception if touched in Mozilla chrome://
          context.

          Silently ignore this and just don't use this as a source of
          entropy. */
      }
    }
    _ctx.collect(_navBytes);
    _navBytes = null;
  }

  // add mouse and keyboard collectors if jquery is available
  if(jQuery) {
    // set up mouse entropy capture
    jQuery().mousemove(function(e) {
      // add mouse coords
      _ctx.collectInt(e.clientX, 16);
      _ctx.collectInt(e.clientY, 16);
    });

    // set up keyboard entropy capture
    jQuery().keypress(function(e) {
      _ctx.collectInt(e.charCode, 8);
    });
  }
}

/* Random API */
if(!forge$8.random) {
  forge$8.random = _ctx;
} else {
  // extend forge.random with _ctx
  for(var key in _ctx) {
    forge$8.random[key] = _ctx[key];
  }
}

// expose spawn PRNG
forge$8.random.createInstance = spawnPrng;

forge$8.random;

})(typeof(jQuery) !== 'undefined' ? jQuery : null);

})();

/**
 * RC2 implementation.
 *
 * @author Stefan Siegl
 *
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 *
 * Information on the RC2 cipher is available from RFC #2268,
 * http://www.ietf.org/rfc/rfc2268.txt
 */

var forge$7 = forge$m;


var piTable = [
  0xd9, 0x78, 0xf9, 0xc4, 0x19, 0xdd, 0xb5, 0xed, 0x28, 0xe9, 0xfd, 0x79, 0x4a, 0xa0, 0xd8, 0x9d,
  0xc6, 0x7e, 0x37, 0x83, 0x2b, 0x76, 0x53, 0x8e, 0x62, 0x4c, 0x64, 0x88, 0x44, 0x8b, 0xfb, 0xa2,
  0x17, 0x9a, 0x59, 0xf5, 0x87, 0xb3, 0x4f, 0x13, 0x61, 0x45, 0x6d, 0x8d, 0x09, 0x81, 0x7d, 0x32,
  0xbd, 0x8f, 0x40, 0xeb, 0x86, 0xb7, 0x7b, 0x0b, 0xf0, 0x95, 0x21, 0x22, 0x5c, 0x6b, 0x4e, 0x82,
  0x54, 0xd6, 0x65, 0x93, 0xce, 0x60, 0xb2, 0x1c, 0x73, 0x56, 0xc0, 0x14, 0xa7, 0x8c, 0xf1, 0xdc,
  0x12, 0x75, 0xca, 0x1f, 0x3b, 0xbe, 0xe4, 0xd1, 0x42, 0x3d, 0xd4, 0x30, 0xa3, 0x3c, 0xb6, 0x26,
  0x6f, 0xbf, 0x0e, 0xda, 0x46, 0x69, 0x07, 0x57, 0x27, 0xf2, 0x1d, 0x9b, 0xbc, 0x94, 0x43, 0x03,
  0xf8, 0x11, 0xc7, 0xf6, 0x90, 0xef, 0x3e, 0xe7, 0x06, 0xc3, 0xd5, 0x2f, 0xc8, 0x66, 0x1e, 0xd7,
  0x08, 0xe8, 0xea, 0xde, 0x80, 0x52, 0xee, 0xf7, 0x84, 0xaa, 0x72, 0xac, 0x35, 0x4d, 0x6a, 0x2a,
  0x96, 0x1a, 0xd2, 0x71, 0x5a, 0x15, 0x49, 0x74, 0x4b, 0x9f, 0xd0, 0x5e, 0x04, 0x18, 0xa4, 0xec,
  0xc2, 0xe0, 0x41, 0x6e, 0x0f, 0x51, 0xcb, 0xcc, 0x24, 0x91, 0xaf, 0x50, 0xa1, 0xf4, 0x70, 0x39,
  0x99, 0x7c, 0x3a, 0x85, 0x23, 0xb8, 0xb4, 0x7a, 0xfc, 0x02, 0x36, 0x5b, 0x25, 0x55, 0x97, 0x31,
  0x2d, 0x5d, 0xfa, 0x98, 0xe3, 0x8a, 0x92, 0xae, 0x05, 0xdf, 0x29, 0x10, 0x67, 0x6c, 0xba, 0xc9,
  0xd3, 0x00, 0xe6, 0xcf, 0xe1, 0x9e, 0xa8, 0x2c, 0x63, 0x16, 0x01, 0x3f, 0x58, 0xe2, 0x89, 0xa9,
  0x0d, 0x38, 0x34, 0x1b, 0xab, 0x33, 0xff, 0xb0, 0xbb, 0x48, 0x0c, 0x5f, 0xb9, 0xb1, 0xcd, 0x2e,
  0xc5, 0xf3, 0xdb, 0x47, 0xe5, 0xa5, 0x9c, 0x77, 0x0a, 0xa6, 0x20, 0x68, 0xfe, 0x7f, 0xc1, 0xad
];

var s = [1, 2, 3, 5];

/**
 * Rotate a word left by given number of bits.
 *
 * Bits that are shifted out on the left are put back in on the right
 * hand side.
 *
 * @param word The word to shift left.
 * @param bits The number of bits to shift by.
 * @return The rotated word.
 */
var rol = function(word, bits) {
  return ((word << bits) & 0xffff) | ((word & 0xffff) >> (16 - bits));
};

/**
 * Rotate a word right by given number of bits.
 *
 * Bits that are shifted out on the right are put back in on the left
 * hand side.
 *
 * @param word The word to shift right.
 * @param bits The number of bits to shift by.
 * @return The rotated word.
 */
var ror = function(word, bits) {
  return ((word & 0xffff) >> bits) | ((word << (16 - bits)) & 0xffff);
};

/* RC2 API */
forge$7.rc2 = forge$7.rc2 || {};

/**
 * Perform RC2 key expansion as per RFC #2268, section 2.
 *
 * @param key variable-length user key (between 1 and 128 bytes)
 * @param effKeyBits number of effective key bits (default: 128)
 * @return the expanded RC2 key (ByteBuffer of 128 bytes)
 */
forge$7.rc2.expandKey = function(key, effKeyBits) {
  if(typeof key === 'string') {
    key = forge$7.util.createBuffer(key);
  }
  effKeyBits = effKeyBits || 128;

  /* introduce variables that match the names used in RFC #2268 */
  var L = key;
  var T = key.length();
  var T1 = effKeyBits;
  var T8 = Math.ceil(T1 / 8);
  var TM = 0xff >> (T1 & 0x07);
  var i;

  for(i = T; i < 128; i++) {
    L.putByte(piTable[(L.at(i - 1) + L.at(i - T)) & 0xff]);
  }

  L.setAt(128 - T8, piTable[L.at(128 - T8) & TM]);

  for(i = 127 - T8; i >= 0; i--) {
    L.setAt(i, piTable[L.at(i + 1) ^ L.at(i + T8)]);
  }

  return L;
};

/**
 * Creates a RC2 cipher object.
 *
 * @param key the symmetric key to use (as base for key generation).
 * @param bits the number of effective key bits.
 * @param encrypt false for decryption, true for encryption.
 *
 * @return the cipher.
 */
var createCipher = function(key, bits, encrypt) {
  var _finish = false, _input = null, _output = null, _iv = null;
  var mixRound, mashRound;
  var i, j, K = [];

  /* Expand key and fill into K[] Array */
  key = forge$7.rc2.expandKey(key, bits);
  for(i = 0; i < 64; i++) {
    K.push(key.getInt16Le());
  }

  if(encrypt) {
    /**
     * Perform one mixing round "in place".
     *
     * @param R Array of four words to perform mixing on.
     */
    mixRound = function(R) {
      for(i = 0; i < 4; i++) {
        R[i] += K[j] + (R[(i + 3) % 4] & R[(i + 2) % 4]) +
          ((~R[(i + 3) % 4]) & R[(i + 1) % 4]);
        R[i] = rol(R[i], s[i]);
        j++;
      }
    };

    /**
     * Perform one mashing round "in place".
     *
     * @param R Array of four words to perform mashing on.
     */
    mashRound = function(R) {
      for(i = 0; i < 4; i++) {
        R[i] += K[R[(i + 3) % 4] & 63];
      }
    };
  } else {
    /**
     * Perform one r-mixing round "in place".
     *
     * @param R Array of four words to perform mixing on.
     */
    mixRound = function(R) {
      for(i = 3; i >= 0; i--) {
        R[i] = ror(R[i], s[i]);
        R[i] -= K[j] + (R[(i + 3) % 4] & R[(i + 2) % 4]) +
          ((~R[(i + 3) % 4]) & R[(i + 1) % 4]);
        j--;
      }
    };

    /**
     * Perform one r-mashing round "in place".
     *
     * @param R Array of four words to perform mashing on.
     */
    mashRound = function(R) {
      for(i = 3; i >= 0; i--) {
        R[i] -= K[R[(i + 3) % 4] & 63];
      }
    };
  }

  /**
   * Run the specified cipher execution plan.
   *
   * This function takes four words from the input buffer, applies the IV on
   * it (if requested) and runs the provided execution plan.
   *
   * The plan must be put together in form of a array of arrays.  Where the
   * outer one is simply a list of steps to perform and the inner one needs
   * to have two elements: the first one telling how many rounds to perform,
   * the second one telling what to do (i.e. the function to call).
   *
   * @param {Array} plan The plan to execute.
   */
  var runPlan = function(plan) {
    var R = [];

    /* Get data from input buffer and fill the four words into R */
    for(i = 0; i < 4; i++) {
      var val = _input.getInt16Le();

      if(_iv !== null) {
        if(encrypt) {
          /* We're encrypting, apply the IV first. */
          val ^= _iv.getInt16Le();
        } else {
          /* We're decryption, keep cipher text for next block. */
          _iv.putInt16Le(val);
        }
      }

      R.push(val & 0xffff);
    }

    /* Reset global "j" variable as per spec. */
    j = encrypt ? 0 : 63;

    /* Run execution plan. */
    for(var ptr = 0; ptr < plan.length; ptr++) {
      for(var ctr = 0; ctr < plan[ptr][0]; ctr++) {
        plan[ptr][1](R);
      }
    }

    /* Write back result to output buffer. */
    for(i = 0; i < 4; i++) {
      if(_iv !== null) {
        if(encrypt) {
          /* We're encrypting in CBC-mode, feed back encrypted bytes into
             IV buffer to carry it forward to next block. */
          _iv.putInt16Le(R[i]);
        } else {
          R[i] ^= _iv.getInt16Le();
        }
      }

      _output.putInt16Le(R[i]);
    }
  };

  /* Create cipher object */
  var cipher = null;
  cipher = {
    /**
     * Starts or restarts the encryption or decryption process, whichever
     * was previously configured.
     *
     * To use the cipher in CBC mode, iv may be given either as a string
     * of bytes, or as a byte buffer.  For ECB mode, give null as iv.
     *
     * @param iv the initialization vector to use, null for ECB mode.
     * @param output the output the buffer to write to, null to create one.
     */
    start: function(iv, output) {
      if(iv) {
        /* CBC mode */
        if(typeof iv === 'string') {
          iv = forge$7.util.createBuffer(iv);
        }
      }

      _finish = false;
      _input = forge$7.util.createBuffer();
      _output = output || new forge$7.util.createBuffer();
      _iv = iv;

      cipher.output = _output;
    },

    /**
     * Updates the next block.
     *
     * @param input the buffer to read from.
     */
    update: function(input) {
      if(!_finish) {
        // not finishing, so fill the input buffer with more input
        _input.putBuffer(input);
      }

      while(_input.length() >= 8) {
        runPlan([
            [ 5, mixRound ],
            [ 1, mashRound ],
            [ 6, mixRound ],
            [ 1, mashRound ],
            [ 5, mixRound ]
          ]);
      }
    },

    /**
     * Finishes encrypting or decrypting.
     *
     * @param pad a padding function to use, null for PKCS#7 padding,
     *           signature(blockSize, buffer, decrypt).
     *
     * @return true if successful, false on error.
     */
    finish: function(pad) {
      var rval = true;

      if(encrypt) {
        if(pad) {
          rval = pad(8, _input, !encrypt);
        } else {
          // add PKCS#7 padding to block (each pad byte is the
          // value of the number of pad bytes)
          var padding = (_input.length() === 8) ? 8 : (8 - _input.length());
          _input.fillWithByte(padding, padding);
        }
      }

      if(rval) {
        // do final update
        _finish = true;
        cipher.update();
      }

      if(!encrypt) {
        // check for error: input data not a multiple of block size
        rval = (_input.length() === 0);
        if(rval) {
          if(pad) {
            rval = pad(8, _output, !encrypt);
          } else {
            // ensure padding byte count is valid
            var len = _output.length();
            var count = _output.at(len - 1);

            if(count > len) {
              rval = false;
            } else {
              // trim off padding bytes
              _output.truncate(count);
            }
          }
        }
      }

      return rval;
    }
  };

  return cipher;
};

/**
 * Creates an RC2 cipher object to encrypt data in ECB or CBC mode using the
 * given symmetric key. The output will be stored in the 'output' member
 * of the returned cipher.
 *
 * The key and iv may be given as a string of bytes or a byte buffer.
 * The cipher is initialized to use 128 effective key bits.
 *
 * @param key the symmetric key to use.
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 *
 * @return the cipher.
 */
forge$7.rc2.startEncrypting = function(key, iv, output) {
  var cipher = forge$7.rc2.createEncryptionCipher(key, 128);
  cipher.start(iv, output);
  return cipher;
};

/**
 * Creates an RC2 cipher object to encrypt data in ECB or CBC mode using the
 * given symmetric key.
 *
 * The key may be given as a string of bytes or a byte buffer.
 *
 * To start encrypting call start() on the cipher with an iv and optional
 * output buffer.
 *
 * @param key the symmetric key to use.
 *
 * @return the cipher.
 */
forge$7.rc2.createEncryptionCipher = function(key, bits) {
  return createCipher(key, bits, true);
};

/**
 * Creates an RC2 cipher object to decrypt data in ECB or CBC mode using the
 * given symmetric key. The output will be stored in the 'output' member
 * of the returned cipher.
 *
 * The key and iv may be given as a string of bytes or a byte buffer.
 * The cipher is initialized to use 128 effective key bits.
 *
 * @param key the symmetric key to use.
 * @param iv the initialization vector to use.
 * @param output the buffer to write to, null to create one.
 *
 * @return the cipher.
 */
forge$7.rc2.startDecrypting = function(key, iv, output) {
  var cipher = forge$7.rc2.createDecryptionCipher(key, 128);
  cipher.start(iv, output);
  return cipher;
};

/**
 * Creates an RC2 cipher object to decrypt data in ECB or CBC mode using the
 * given symmetric key.
 *
 * The key may be given as a string of bytes or a byte buffer.
 *
 * To start decrypting call start() on the cipher with an iv and optional
 * output buffer.
 *
 * @param key the symmetric key to use.
 *
 * @return the cipher.
 */
forge$7.rc2.createDecryptionCipher = function(key, bits) {
  return createCipher(key, bits, false);
};

// Copyright (c) 2005  Tom Wu
// All Rights Reserved.
// See "LICENSE" for details.

// Basic JavaScript BN library - subset useful for RSA encryption.

/*
Licensing (LICENSE)
-------------------

This software is covered under the following copyright:
*/
/*
 * Copyright (c) 2003-2005  Tom Wu
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS-IS" AND WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS, IMPLIED OR OTHERWISE, INCLUDING WITHOUT LIMITATION, ANY
 * WARRANTY OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.
 *
 * IN NO EVENT SHALL TOM WU BE LIABLE FOR ANY SPECIAL, INCIDENTAL,
 * INDIRECT OR CONSEQUENTIAL DAMAGES OF ANY KIND, OR ANY DAMAGES WHATSOEVER
 * RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER OR NOT ADVISED OF
 * THE POSSIBILITY OF DAMAGE, AND ON ANY THEORY OF LIABILITY, ARISING OUT
 * OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *
 * In addition, the following condition applies:
 *
 * All redistributions must retain an intact copy of this copyright notice
 * and disclaimer.
 */
/*
Address all questions regarding this license to:

  Tom Wu
  tjw@cs.Stanford.EDU
*/
var forge$6 = forge$m;

forge$6.jsbn = forge$6.jsbn || {};

// Bits per digit
var dbits;

// (public) Constructor
function BigInteger$2(a,b,c) {
  this.data = [];
  if(a != null)
    if("number" == typeof a) this.fromNumber(a,b,c);
    else if(b == null && "string" != typeof a) this.fromString(a,256);
    else this.fromString(a,b);
}
forge$6.jsbn.BigInteger = BigInteger$2;

// return new, unset BigInteger
function nbi() { return new BigInteger$2(null); }

// am: Compute w_j += (x*this_i), propagate carries,
// c is initial carry, returns final carry.
// c < 3*dvalue, x < 2*dvalue, this_i < dvalue
// We need to select the fastest one that works in this environment.

// am1: use a single mult and divide to get the high bits,
// max digit bits should be 26 because
// max internal value = 2*dvalue^2-2*dvalue (< 2^53)
function am1(i,x,w,j,c,n) {
  while(--n >= 0) {
    var v = x*this.data[i++]+w.data[j]+c;
    c = Math.floor(v/0x4000000);
    w.data[j++] = v&0x3ffffff;
  }
  return c;
}
// am2 avoids a big mult-and-extract completely.
// Max digit bits should be <= 30 because we do bitwise ops
// on values up to 2*hdvalue^2-hdvalue-1 (< 2^31)
function am2(i,x,w,j,c,n) {
  var xl = x&0x7fff, xh = x>>15;
  while(--n >= 0) {
    var l = this.data[i]&0x7fff;
    var h = this.data[i++]>>15;
    var m = xh*l+h*xl;
    l = xl*l+((m&0x7fff)<<15)+w.data[j]+(c&0x3fffffff);
    c = (l>>>30)+(m>>>15)+xh*h+(c>>>30);
    w.data[j++] = l&0x3fffffff;
  }
  return c;
}
// Alternately, set max digit bits to 28 since some
// browsers slow down when dealing with 32-bit numbers.
function am3(i,x,w,j,c,n) {
  var xl = x&0x3fff, xh = x>>14;
  while(--n >= 0) {
    var l = this.data[i]&0x3fff;
    var h = this.data[i++]>>14;
    var m = xh*l+h*xl;
    l = xl*l+((m&0x3fff)<<14)+w.data[j]+c;
    c = (l>>28)+(m>>14)+xh*h;
    w.data[j++] = l&0xfffffff;
  }
  return c;
}

// node.js (no browser)
if(typeof(navigator) === 'undefined')
{
   BigInteger$2.prototype.am = am3;
   dbits = 28;
} else if((navigator.appName == "Microsoft Internet Explorer")) {
  BigInteger$2.prototype.am = am2;
  dbits = 30;
} else if((navigator.appName != "Netscape")) {
  BigInteger$2.prototype.am = am1;
  dbits = 26;
} else { // Mozilla/Netscape seems to prefer am3
  BigInteger$2.prototype.am = am3;
  dbits = 28;
}

BigInteger$2.prototype.DB = dbits;
BigInteger$2.prototype.DM = ((1<<dbits)-1);
BigInteger$2.prototype.DV = (1<<dbits);

var BI_FP = 52;
BigInteger$2.prototype.FV = Math.pow(2,BI_FP);
BigInteger$2.prototype.F1 = BI_FP-dbits;
BigInteger$2.prototype.F2 = 2*dbits-BI_FP;

// Digit conversions
var BI_RM = "0123456789abcdefghijklmnopqrstuvwxyz";
var BI_RC = new Array();
var rr,vv;
rr = "0".charCodeAt(0);
for(vv = 0; vv <= 9; ++vv) BI_RC[rr++] = vv;
rr = "a".charCodeAt(0);
for(vv = 10; vv < 36; ++vv) BI_RC[rr++] = vv;
rr = "A".charCodeAt(0);
for(vv = 10; vv < 36; ++vv) BI_RC[rr++] = vv;

function int2char(n) { return BI_RM.charAt(n); }
function intAt(s,i) {
  var c = BI_RC[s.charCodeAt(i)];
  return (c==null)?-1:c;
}

// (protected) copy this to r
function bnpCopyTo(r) {
  for(var i = this.t-1; i >= 0; --i) r.data[i] = this.data[i];
  r.t = this.t;
  r.s = this.s;
}

// (protected) set from integer value x, -DV <= x < DV
function bnpFromInt(x) {
  this.t = 1;
  this.s = (x<0)?-1:0;
  if(x > 0) this.data[0] = x;
  else if(x < -1) this.data[0] = x+this.DV;
  else this.t = 0;
}

// return bigint initialized to value
function nbv(i) { var r = nbi(); r.fromInt(i); return r; }

// (protected) set from string and radix
function bnpFromString(s,b) {
  var k;
  if(b == 16) k = 4;
  else if(b == 8) k = 3;
  else if(b == 256) k = 8; // byte array
  else if(b == 2) k = 1;
  else if(b == 32) k = 5;
  else if(b == 4) k = 2;
  else { this.fromRadix(s,b); return; }
  this.t = 0;
  this.s = 0;
  var i = s.length, mi = false, sh = 0;
  while(--i >= 0) {
    var x = (k==8)?s[i]&0xff:intAt(s,i);
    if(x < 0) {
      if(s.charAt(i) == "-") mi = true;
      continue;
    }
    mi = false;
    if(sh == 0)
      this.data[this.t++] = x;
    else if(sh+k > this.DB) {
      this.data[this.t-1] |= (x&((1<<(this.DB-sh))-1))<<sh;
      this.data[this.t++] = (x>>(this.DB-sh));
    } else
      this.data[this.t-1] |= x<<sh;
    sh += k;
    if(sh >= this.DB) sh -= this.DB;
  }
  if(k == 8 && (s[0]&0x80) != 0) {
    this.s = -1;
    if(sh > 0) this.data[this.t-1] |= ((1<<(this.DB-sh))-1)<<sh;
  }
  this.clamp();
  if(mi) BigInteger$2.ZERO.subTo(this,this);
}

// (protected) clamp off excess high words
function bnpClamp() {
  var c = this.s&this.DM;
  while(this.t > 0 && this.data[this.t-1] == c) --this.t;
}

// (public) return string representation in given radix
function bnToString(b) {
  if(this.s < 0) return "-"+this.negate().toString(b);
  var k;
  if(b == 16) k = 4;
  else if(b == 8) k = 3;
  else if(b == 2) k = 1;
  else if(b == 32) k = 5;
  else if(b == 4) k = 2;
  else return this.toRadix(b);
  var km = (1<<k)-1, d, m = false, r = "", i = this.t;
  var p = this.DB-(i*this.DB)%k;
  if(i-- > 0) {
    if(p < this.DB && (d = this.data[i]>>p) > 0) { m = true; r = int2char(d); }
    while(i >= 0) {
      if(p < k) {
        d = (this.data[i]&((1<<p)-1))<<(k-p);
        d |= this.data[--i]>>(p+=this.DB-k);
      } else {
        d = (this.data[i]>>(p-=k))&km;
        if(p <= 0) { p += this.DB; --i; }
      }
      if(d > 0) m = true;
      if(m) r += int2char(d);
    }
  }
  return m?r:"0";
}

// (public) -this
function bnNegate() { var r = nbi(); BigInteger$2.ZERO.subTo(this,r); return r; }

// (public) |this|
function bnAbs() { return (this.s<0)?this.negate():this; }

// (public) return + if this > a, - if this < a, 0 if equal
function bnCompareTo(a) {
  var r = this.s-a.s;
  if(r != 0) return r;
  var i = this.t;
  r = i-a.t;
  if(r != 0) return (this.s<0)?-r:r;
  while(--i >= 0) if((r=this.data[i]-a.data[i]) != 0) return r;
  return 0;
}

// returns bit length of the integer x
function nbits(x) {
  var r = 1, t;
  if((t=x>>>16) != 0) { x = t; r += 16; }
  if((t=x>>8) != 0) { x = t; r += 8; }
  if((t=x>>4) != 0) { x = t; r += 4; }
  if((t=x>>2) != 0) { x = t; r += 2; }
  if((t=x>>1) != 0) { x = t; r += 1; }
  return r;
}

// (public) return the number of bits in "this"
function bnBitLength() {
  if(this.t <= 0) return 0;
  return this.DB*(this.t-1)+nbits(this.data[this.t-1]^(this.s&this.DM));
}

// (protected) r = this << n*DB
function bnpDLShiftTo(n,r) {
  var i;
  for(i = this.t-1; i >= 0; --i) r.data[i+n] = this.data[i];
  for(i = n-1; i >= 0; --i) r.data[i] = 0;
  r.t = this.t+n;
  r.s = this.s;
}

// (protected) r = this >> n*DB
function bnpDRShiftTo(n,r) {
  for(var i = n; i < this.t; ++i) r.data[i-n] = this.data[i];
  r.t = Math.max(this.t-n,0);
  r.s = this.s;
}

// (protected) r = this << n
function bnpLShiftTo(n,r) {
  var bs = n%this.DB;
  var cbs = this.DB-bs;
  var bm = (1<<cbs)-1;
  var ds = Math.floor(n/this.DB), c = (this.s<<bs)&this.DM, i;
  for(i = this.t-1; i >= 0; --i) {
    r.data[i+ds+1] = (this.data[i]>>cbs)|c;
    c = (this.data[i]&bm)<<bs;
  }
  for(i = ds-1; i >= 0; --i) r.data[i] = 0;
  r.data[ds] = c;
  r.t = this.t+ds+1;
  r.s = this.s;
  r.clamp();
}

// (protected) r = this >> n
function bnpRShiftTo(n,r) {
  r.s = this.s;
  var ds = Math.floor(n/this.DB);
  if(ds >= this.t) { r.t = 0; return; }
  var bs = n%this.DB;
  var cbs = this.DB-bs;
  var bm = (1<<bs)-1;
  r.data[0] = this.data[ds]>>bs;
  for(var i = ds+1; i < this.t; ++i) {
    r.data[i-ds-1] |= (this.data[i]&bm)<<cbs;
    r.data[i-ds] = this.data[i]>>bs;
  }
  if(bs > 0) r.data[this.t-ds-1] |= (this.s&bm)<<cbs;
  r.t = this.t-ds;
  r.clamp();
}

// (protected) r = this - a
function bnpSubTo(a,r) {
  var i = 0, c = 0, m = Math.min(a.t,this.t);
  while(i < m) {
    c += this.data[i]-a.data[i];
    r.data[i++] = c&this.DM;
    c >>= this.DB;
  }
  if(a.t < this.t) {
    c -= a.s;
    while(i < this.t) {
      c += this.data[i];
      r.data[i++] = c&this.DM;
      c >>= this.DB;
    }
    c += this.s;
  } else {
    c += this.s;
    while(i < a.t) {
      c -= a.data[i];
      r.data[i++] = c&this.DM;
      c >>= this.DB;
    }
    c -= a.s;
  }
  r.s = (c<0)?-1:0;
  if(c < -1) r.data[i++] = this.DV+c;
  else if(c > 0) r.data[i++] = c;
  r.t = i;
  r.clamp();
}

// (protected) r = this * a, r != this,a (HAC 14.12)
// "this" should be the larger one if appropriate.
function bnpMultiplyTo(a,r) {
  var x = this.abs(), y = a.abs();
  var i = x.t;
  r.t = i+y.t;
  while(--i >= 0) r.data[i] = 0;
  for(i = 0; i < y.t; ++i) r.data[i+x.t] = x.am(0,y.data[i],r,i,0,x.t);
  r.s = 0;
  r.clamp();
  if(this.s != a.s) BigInteger$2.ZERO.subTo(r,r);
}

// (protected) r = this^2, r != this (HAC 14.16)
function bnpSquareTo(r) {
  var x = this.abs();
  var i = r.t = 2*x.t;
  while(--i >= 0) r.data[i] = 0;
  for(i = 0; i < x.t-1; ++i) {
    var c = x.am(i,x.data[i],r,2*i,0,1);
    if((r.data[i+x.t]+=x.am(i+1,2*x.data[i],r,2*i+1,c,x.t-i-1)) >= x.DV) {
      r.data[i+x.t] -= x.DV;
      r.data[i+x.t+1] = 1;
    }
  }
  if(r.t > 0) r.data[r.t-1] += x.am(i,x.data[i],r,2*i,0,1);
  r.s = 0;
  r.clamp();
}

// (protected) divide this by m, quotient and remainder to q, r (HAC 14.20)
// r != q, this != m.  q or r may be null.
function bnpDivRemTo(m,q,r) {
  var pm = m.abs();
  if(pm.t <= 0) return;
  var pt = this.abs();
  if(pt.t < pm.t) {
    if(q != null) q.fromInt(0);
    if(r != null) this.copyTo(r);
    return;
  }
  if(r == null) r = nbi();
  var y = nbi(), ts = this.s, ms = m.s;
  var nsh = this.DB-nbits(pm.data[pm.t-1]);	// normalize modulus
  if(nsh > 0) { pm.lShiftTo(nsh,y); pt.lShiftTo(nsh,r); } else { pm.copyTo(y); pt.copyTo(r); }
  var ys = y.t;
  var y0 = y.data[ys-1];
  if(y0 == 0) return;
  var yt = y0*(1<<this.F1)+((ys>1)?y.data[ys-2]>>this.F2:0);
  var d1 = this.FV/yt, d2 = (1<<this.F1)/yt, e = 1<<this.F2;
  var i = r.t, j = i-ys, t = (q==null)?nbi():q;
  y.dlShiftTo(j,t);
  if(r.compareTo(t) >= 0) {
    r.data[r.t++] = 1;
    r.subTo(t,r);
  }
  BigInteger$2.ONE.dlShiftTo(ys,t);
  t.subTo(y,y);	// "negative" y so we can replace sub with am later
  while(y.t < ys) y.data[y.t++] = 0;
  while(--j >= 0) {
    // Estimate quotient digit
    var qd = (r.data[--i]==y0)?this.DM:Math.floor(r.data[i]*d1+(r.data[i-1]+e)*d2);
    if((r.data[i]+=y.am(0,qd,r,j,0,ys)) < qd) {	// Try it out
      y.dlShiftTo(j,t);
      r.subTo(t,r);
      while(r.data[i] < --qd) r.subTo(t,r);
    }
  }
  if(q != null) {
    r.drShiftTo(ys,q);
    if(ts != ms) BigInteger$2.ZERO.subTo(q,q);
  }
  r.t = ys;
  r.clamp();
  if(nsh > 0) r.rShiftTo(nsh,r);	// Denormalize remainder
  if(ts < 0) BigInteger$2.ZERO.subTo(r,r);
}

// (public) this mod a
function bnMod(a) {
  var r = nbi();
  this.abs().divRemTo(a,null,r);
  if(this.s < 0 && r.compareTo(BigInteger$2.ZERO) > 0) a.subTo(r,r);
  return r;
}

// Modular reduction using "classic" algorithm
function Classic(m) { this.m = m; }
function cConvert(x) {
  if(x.s < 0 || x.compareTo(this.m) >= 0) return x.mod(this.m);
  else return x;
}
function cRevert(x) { return x; }
function cReduce(x) { x.divRemTo(this.m,null,x); }
function cMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }
function cSqrTo(x,r) { x.squareTo(r); this.reduce(r); }

Classic.prototype.convert = cConvert;
Classic.prototype.revert = cRevert;
Classic.prototype.reduce = cReduce;
Classic.prototype.mulTo = cMulTo;
Classic.prototype.sqrTo = cSqrTo;

// (protected) return "-1/this % 2^DB"; useful for Mont. reduction
// justification:
//         xy == 1 (mod m)
//         xy =  1+km
//   xy(2-xy) = (1+km)(1-km)
// x[y(2-xy)] = 1-k^2m^2
// x[y(2-xy)] == 1 (mod m^2)
// if y is 1/x mod m, then y(2-xy) is 1/x mod m^2
// should reduce x and y(2-xy) by m^2 at each step to keep size bounded.
// JS multiply "overflows" differently from C/C++, so care is needed here.
function bnpInvDigit() {
  if(this.t < 1) return 0;
  var x = this.data[0];
  if((x&1) == 0) return 0;
  var y = x&3;		// y == 1/x mod 2^2
  y = (y*(2-(x&0xf)*y))&0xf;	// y == 1/x mod 2^4
  y = (y*(2-(x&0xff)*y))&0xff;	// y == 1/x mod 2^8
  y = (y*(2-(((x&0xffff)*y)&0xffff)))&0xffff;	// y == 1/x mod 2^16
  // last step - calculate inverse mod DV directly;
  // assumes 16 < DB <= 32 and assumes ability to handle 48-bit ints
  y = (y*(2-x*y%this.DV))%this.DV;		// y == 1/x mod 2^dbits
  // we really want the negative inverse, and -DV < y < DV
  return (y>0)?this.DV-y:-y;
}

// Montgomery reduction
function Montgomery(m) {
  this.m = m;
  this.mp = m.invDigit();
  this.mpl = this.mp&0x7fff;
  this.mph = this.mp>>15;
  this.um = (1<<(m.DB-15))-1;
  this.mt2 = 2*m.t;
}

// xR mod m
function montConvert(x) {
  var r = nbi();
  x.abs().dlShiftTo(this.m.t,r);
  r.divRemTo(this.m,null,r);
  if(x.s < 0 && r.compareTo(BigInteger$2.ZERO) > 0) this.m.subTo(r,r);
  return r;
}

// x/R mod m
function montRevert(x) {
  var r = nbi();
  x.copyTo(r);
  this.reduce(r);
  return r;
}

// x = x/R mod m (HAC 14.32)
function montReduce(x) {
  while(x.t <= this.mt2)	// pad x so am has enough room later
    x.data[x.t++] = 0;
  for(var i = 0; i < this.m.t; ++i) {
    // faster way of calculating u0 = x.data[i]*mp mod DV
    var j = x.data[i]&0x7fff;
    var u0 = (j*this.mpl+(((j*this.mph+(x.data[i]>>15)*this.mpl)&this.um)<<15))&x.DM;
    // use am to combine the multiply-shift-add into one call
    j = i+this.m.t;
    x.data[j] += this.m.am(0,u0,x,i,0,this.m.t);
    // propagate carry
    while(x.data[j] >= x.DV) { x.data[j] -= x.DV; x.data[++j]++; }
  }
  x.clamp();
  x.drShiftTo(this.m.t,x);
  if(x.compareTo(this.m) >= 0) x.subTo(this.m,x);
}

// r = "x^2/R mod m"; x != r
function montSqrTo(x,r) { x.squareTo(r); this.reduce(r); }

// r = "xy/R mod m"; x,y != r
function montMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }

Montgomery.prototype.convert = montConvert;
Montgomery.prototype.revert = montRevert;
Montgomery.prototype.reduce = montReduce;
Montgomery.prototype.mulTo = montMulTo;
Montgomery.prototype.sqrTo = montSqrTo;

// (protected) true iff this is even
function bnpIsEven() { return ((this.t>0)?(this.data[0]&1):this.s) == 0; }

// (protected) this^e, e < 2^32, doing sqr and mul with "r" (HAC 14.79)
function bnpExp(e,z) {
  if(e > 0xffffffff || e < 1) return BigInteger$2.ONE;
  var r = nbi(), r2 = nbi(), g = z.convert(this), i = nbits(e)-1;
  g.copyTo(r);
  while(--i >= 0) {
    z.sqrTo(r,r2);
    if((e&(1<<i)) > 0) z.mulTo(r2,g,r);
    else { var t = r; r = r2; r2 = t; }
  }
  return z.revert(r);
}

// (public) this^e % m, 0 <= e < 2^32
function bnModPowInt(e,m) {
  var z;
  if(e < 256 || m.isEven()) z = new Classic(m); else z = new Montgomery(m);
  return this.exp(e,z);
}

// protected
BigInteger$2.prototype.copyTo = bnpCopyTo;
BigInteger$2.prototype.fromInt = bnpFromInt;
BigInteger$2.prototype.fromString = bnpFromString;
BigInteger$2.prototype.clamp = bnpClamp;
BigInteger$2.prototype.dlShiftTo = bnpDLShiftTo;
BigInteger$2.prototype.drShiftTo = bnpDRShiftTo;
BigInteger$2.prototype.lShiftTo = bnpLShiftTo;
BigInteger$2.prototype.rShiftTo = bnpRShiftTo;
BigInteger$2.prototype.subTo = bnpSubTo;
BigInteger$2.prototype.multiplyTo = bnpMultiplyTo;
BigInteger$2.prototype.squareTo = bnpSquareTo;
BigInteger$2.prototype.divRemTo = bnpDivRemTo;
BigInteger$2.prototype.invDigit = bnpInvDigit;
BigInteger$2.prototype.isEven = bnpIsEven;
BigInteger$2.prototype.exp = bnpExp;

// public
BigInteger$2.prototype.toString = bnToString;
BigInteger$2.prototype.negate = bnNegate;
BigInteger$2.prototype.abs = bnAbs;
BigInteger$2.prototype.compareTo = bnCompareTo;
BigInteger$2.prototype.bitLength = bnBitLength;
BigInteger$2.prototype.mod = bnMod;
BigInteger$2.prototype.modPowInt = bnModPowInt;

// "constants"
BigInteger$2.ZERO = nbv(0);
BigInteger$2.ONE = nbv(1);

// jsbn2 lib

//Copyright (c) 2005-2009  Tom Wu
//All Rights Reserved.
//See "LICENSE" for details (See jsbn.js for LICENSE).

//Extended JavaScript BN functions, required for RSA private ops.

//Version 1.1: new BigInteger("0", 10) returns "proper" zero

//(public)
function bnClone() { var r = nbi(); this.copyTo(r); return r; }

//(public) return value as integer
function bnIntValue() {
if(this.s < 0) {
 if(this.t == 1) return this.data[0]-this.DV;
 else if(this.t == 0) return -1;
} else if(this.t == 1) return this.data[0];
else if(this.t == 0) return 0;
// assumes 16 < DB < 32
return ((this.data[1]&((1<<(32-this.DB))-1))<<this.DB)|this.data[0];
}

//(public) return value as byte
function bnByteValue() { return (this.t==0)?this.s:(this.data[0]<<24)>>24; }

//(public) return value as short (assumes DB>=16)
function bnShortValue() { return (this.t==0)?this.s:(this.data[0]<<16)>>16; }

//(protected) return x s.t. r^x < DV
function bnpChunkSize(r) { return Math.floor(Math.LN2*this.DB/Math.log(r)); }

//(public) 0 if this == 0, 1 if this > 0
function bnSigNum() {
if(this.s < 0) return -1;
else if(this.t <= 0 || (this.t == 1 && this.data[0] <= 0)) return 0;
else return 1;
}

//(protected) convert to radix string
function bnpToRadix(b) {
if(b == null) b = 10;
if(this.signum() == 0 || b < 2 || b > 36) return "0";
var cs = this.chunkSize(b);
var a = Math.pow(b,cs);
var d = nbv(a), y = nbi(), z = nbi(), r = "";
this.divRemTo(d,y,z);
while(y.signum() > 0) {
 r = (a+z.intValue()).toString(b).substr(1) + r;
 y.divRemTo(d,y,z);
}
return z.intValue().toString(b) + r;
}

//(protected) convert from radix string
function bnpFromRadix(s,b) {
this.fromInt(0);
if(b == null) b = 10;
var cs = this.chunkSize(b);
var d = Math.pow(b,cs), mi = false, j = 0, w = 0;
for(var i = 0; i < s.length; ++i) {
 var x = intAt(s,i);
 if(x < 0) {
   if(s.charAt(i) == "-" && this.signum() == 0) mi = true;
   continue;
 }
 w = b*w+x;
 if(++j >= cs) {
   this.dMultiply(d);
   this.dAddOffset(w,0);
   j = 0;
   w = 0;
 }
}
if(j > 0) {
 this.dMultiply(Math.pow(b,j));
 this.dAddOffset(w,0);
}
if(mi) BigInteger$2.ZERO.subTo(this,this);
}

//(protected) alternate constructor
function bnpFromNumber(a,b,c) {
if("number" == typeof b) {
 // new BigInteger(int,int,RNG)
 if(a < 2) this.fromInt(1);
 else {
   this.fromNumber(a,c);
   if(!this.testBit(a-1))  // force MSB set
     this.bitwiseTo(BigInteger$2.ONE.shiftLeft(a-1),op_or,this);
   if(this.isEven()) this.dAddOffset(1,0); // force odd
   while(!this.isProbablePrime(b)) {
     this.dAddOffset(2,0);
     if(this.bitLength() > a) this.subTo(BigInteger$2.ONE.shiftLeft(a-1),this);
   }
 }
} else {
 // new BigInteger(int,RNG)
 var x = new Array(), t = a&7;
 x.length = (a>>3)+1;
 b.nextBytes(x);
 if(t > 0) x[0] &= ((1<<t)-1); else x[0] = 0;
 this.fromString(x,256);
}
}

//(public) convert to bigendian byte array
function bnToByteArray() {
var i = this.t, r = new Array();
r[0] = this.s;
var p = this.DB-(i*this.DB)%8, d, k = 0;
if(i-- > 0) {
 if(p < this.DB && (d = this.data[i]>>p) != (this.s&this.DM)>>p)
   r[k++] = d|(this.s<<(this.DB-p));
 while(i >= 0) {
   if(p < 8) {
     d = (this.data[i]&((1<<p)-1))<<(8-p);
     d |= this.data[--i]>>(p+=this.DB-8);
   } else {
     d = (this.data[i]>>(p-=8))&0xff;
     if(p <= 0) { p += this.DB; --i; }
   }
   if((d&0x80) != 0) d |= -256;
   if(k == 0 && (this.s&0x80) != (d&0x80)) ++k;
   if(k > 0 || d != this.s) r[k++] = d;
 }
}
return r;
}

function bnEquals(a) { return(this.compareTo(a)==0); }
function bnMin(a) { return (this.compareTo(a)<0)?this:a; }
function bnMax(a) { return (this.compareTo(a)>0)?this:a; }

//(protected) r = this op a (bitwise)
function bnpBitwiseTo(a,op,r) {
var i, f, m = Math.min(a.t,this.t);
for(i = 0; i < m; ++i) r.data[i] = op(this.data[i],a.data[i]);
if(a.t < this.t) {
 f = a.s&this.DM;
 for(i = m; i < this.t; ++i) r.data[i] = op(this.data[i],f);
 r.t = this.t;
} else {
 f = this.s&this.DM;
 for(i = m; i < a.t; ++i) r.data[i] = op(f,a.data[i]);
 r.t = a.t;
}
r.s = op(this.s,a.s);
r.clamp();
}

//(public) this & a
function op_and(x,y) { return x&y; }
function bnAnd(a) { var r = nbi(); this.bitwiseTo(a,op_and,r); return r; }

//(public) this | a
function op_or(x,y) { return x|y; }
function bnOr(a) { var r = nbi(); this.bitwiseTo(a,op_or,r); return r; }

//(public) this ^ a
function op_xor(x,y) { return x^y; }
function bnXor(a) { var r = nbi(); this.bitwiseTo(a,op_xor,r); return r; }

//(public) this & ~a
function op_andnot(x,y) { return x&~y; }
function bnAndNot(a) { var r = nbi(); this.bitwiseTo(a,op_andnot,r); return r; }

//(public) ~this
function bnNot() {
var r = nbi();
for(var i = 0; i < this.t; ++i) r.data[i] = this.DM&~this.data[i];
r.t = this.t;
r.s = ~this.s;
return r;
}

//(public) this << n
function bnShiftLeft(n) {
var r = nbi();
if(n < 0) this.rShiftTo(-n,r); else this.lShiftTo(n,r);
return r;
}

//(public) this >> n
function bnShiftRight(n) {
var r = nbi();
if(n < 0) this.lShiftTo(-n,r); else this.rShiftTo(n,r);
return r;
}

//return index of lowest 1-bit in x, x < 2^31
function lbit(x) {
if(x == 0) return -1;
var r = 0;
if((x&0xffff) == 0) { x >>= 16; r += 16; }
if((x&0xff) == 0) { x >>= 8; r += 8; }
if((x&0xf) == 0) { x >>= 4; r += 4; }
if((x&3) == 0) { x >>= 2; r += 2; }
if((x&1) == 0) ++r;
return r;
}

//(public) returns index of lowest 1-bit (or -1 if none)
function bnGetLowestSetBit() {
for(var i = 0; i < this.t; ++i)
 if(this.data[i] != 0) return i*this.DB+lbit(this.data[i]);
if(this.s < 0) return this.t*this.DB;
return -1;
}

//return number of 1 bits in x
function cbit(x) {
var r = 0;
while(x != 0) { x &= x-1; ++r; }
return r;
}

//(public) return number of set bits
function bnBitCount() {
var r = 0, x = this.s&this.DM;
for(var i = 0; i < this.t; ++i) r += cbit(this.data[i]^x);
return r;
}

//(public) true iff nth bit is set
function bnTestBit(n) {
var j = Math.floor(n/this.DB);
if(j >= this.t) return(this.s!=0);
return((this.data[j]&(1<<(n%this.DB)))!=0);
}

//(protected) this op (1<<n)
function bnpChangeBit(n,op) {
var r = BigInteger$2.ONE.shiftLeft(n);
this.bitwiseTo(r,op,r);
return r;
}

//(public) this | (1<<n)
function bnSetBit(n) { return this.changeBit(n,op_or); }

//(public) this & ~(1<<n)
function bnClearBit(n) { return this.changeBit(n,op_andnot); }

//(public) this ^ (1<<n)
function bnFlipBit(n) { return this.changeBit(n,op_xor); }

//(protected) r = this + a
function bnpAddTo(a,r) {
var i = 0, c = 0, m = Math.min(a.t,this.t);
while(i < m) {
 c += this.data[i]+a.data[i];
 r.data[i++] = c&this.DM;
 c >>= this.DB;
}
if(a.t < this.t) {
 c += a.s;
 while(i < this.t) {
   c += this.data[i];
   r.data[i++] = c&this.DM;
   c >>= this.DB;
 }
 c += this.s;
} else {
 c += this.s;
 while(i < a.t) {
   c += a.data[i];
   r.data[i++] = c&this.DM;
   c >>= this.DB;
 }
 c += a.s;
}
r.s = (c<0)?-1:0;
if(c > 0) r.data[i++] = c;
else if(c < -1) r.data[i++] = this.DV+c;
r.t = i;
r.clamp();
}

//(public) this + a
function bnAdd(a) { var r = nbi(); this.addTo(a,r); return r; }

//(public) this - a
function bnSubtract(a) { var r = nbi(); this.subTo(a,r); return r; }

//(public) this * a
function bnMultiply(a) { var r = nbi(); this.multiplyTo(a,r); return r; }

//(public) this / a
function bnDivide(a) { var r = nbi(); this.divRemTo(a,r,null); return r; }

//(public) this % a
function bnRemainder(a) { var r = nbi(); this.divRemTo(a,null,r); return r; }

//(public) [this/a,this%a]
function bnDivideAndRemainder(a) {
var q = nbi(), r = nbi();
this.divRemTo(a,q,r);
return new Array(q,r);
}

//(protected) this *= n, this >= 0, 1 < n < DV
function bnpDMultiply(n) {
this.data[this.t] = this.am(0,n-1,this,0,0,this.t);
++this.t;
this.clamp();
}

//(protected) this += n << w words, this >= 0
function bnpDAddOffset(n,w) {
if(n == 0) return;
while(this.t <= w) this.data[this.t++] = 0;
this.data[w] += n;
while(this.data[w] >= this.DV) {
 this.data[w] -= this.DV;
 if(++w >= this.t) this.data[this.t++] = 0;
 ++this.data[w];
}
}

//A "null" reducer
function NullExp() {}
function nNop(x) { return x; }
function nMulTo(x,y,r) { x.multiplyTo(y,r); }
function nSqrTo(x,r) { x.squareTo(r); }

NullExp.prototype.convert = nNop;
NullExp.prototype.revert = nNop;
NullExp.prototype.mulTo = nMulTo;
NullExp.prototype.sqrTo = nSqrTo;

//(public) this^e
function bnPow(e) { return this.exp(e,new NullExp()); }

//(protected) r = lower n words of "this * a", a.t <= n
//"this" should be the larger one if appropriate.
function bnpMultiplyLowerTo(a,n,r) {
var i = Math.min(this.t+a.t,n);
r.s = 0; // assumes a,this >= 0
r.t = i;
while(i > 0) r.data[--i] = 0;
var j;
for(j = r.t-this.t; i < j; ++i) r.data[i+this.t] = this.am(0,a.data[i],r,i,0,this.t);
for(j = Math.min(a.t,n); i < j; ++i) this.am(0,a.data[i],r,i,0,n-i);
r.clamp();
}

//(protected) r = "this * a" without lower n words, n > 0
//"this" should be the larger one if appropriate.
function bnpMultiplyUpperTo(a,n,r) {
--n;
var i = r.t = this.t+a.t-n;
r.s = 0; // assumes a,this >= 0
while(--i >= 0) r.data[i] = 0;
for(i = Math.max(n-this.t,0); i < a.t; ++i)
 r.data[this.t+i-n] = this.am(n-i,a.data[i],r,0,0,this.t+i-n);
r.clamp();
r.drShiftTo(1,r);
}

//Barrett modular reduction
function Barrett(m) {
// setup Barrett
this.r2 = nbi();
this.q3 = nbi();
BigInteger$2.ONE.dlShiftTo(2*m.t,this.r2);
this.mu = this.r2.divide(m);
this.m = m;
}

function barrettConvert(x) {
if(x.s < 0 || x.t > 2*this.m.t) return x.mod(this.m);
else if(x.compareTo(this.m) < 0) return x;
else { var r = nbi(); x.copyTo(r); this.reduce(r); return r; }
}

function barrettRevert(x) { return x; }

//x = x mod m (HAC 14.42)
function barrettReduce(x) {
x.drShiftTo(this.m.t-1,this.r2);
if(x.t > this.m.t+1) { x.t = this.m.t+1; x.clamp(); }
this.mu.multiplyUpperTo(this.r2,this.m.t+1,this.q3);
this.m.multiplyLowerTo(this.q3,this.m.t+1,this.r2);
while(x.compareTo(this.r2) < 0) x.dAddOffset(1,this.m.t+1);
x.subTo(this.r2,x);
while(x.compareTo(this.m) >= 0) x.subTo(this.m,x);
}

//r = x^2 mod m; x != r
function barrettSqrTo(x,r) { x.squareTo(r); this.reduce(r); }

//r = x*y mod m; x,y != r
function barrettMulTo(x,y,r) { x.multiplyTo(y,r); this.reduce(r); }

Barrett.prototype.convert = barrettConvert;
Barrett.prototype.revert = barrettRevert;
Barrett.prototype.reduce = barrettReduce;
Barrett.prototype.mulTo = barrettMulTo;
Barrett.prototype.sqrTo = barrettSqrTo;

//(public) this^e % m (HAC 14.85)
function bnModPow(e,m) {
var i = e.bitLength(), k, r = nbv(1), z;
if(i <= 0) return r;
else if(i < 18) k = 1;
else if(i < 48) k = 3;
else if(i < 144) k = 4;
else if(i < 768) k = 5;
else k = 6;
if(i < 8)
 z = new Classic(m);
else if(m.isEven())
 z = new Barrett(m);
else
 z = new Montgomery(m);

// precomputation
var g = new Array(), n = 3, k1 = k-1, km = (1<<k)-1;
g[1] = z.convert(this);
if(k > 1) {
 var g2 = nbi();
 z.sqrTo(g[1],g2);
 while(n <= km) {
   g[n] = nbi();
   z.mulTo(g2,g[n-2],g[n]);
   n += 2;
 }
}

var j = e.t-1, w, is1 = true, r2 = nbi(), t;
i = nbits(e.data[j])-1;
while(j >= 0) {
 if(i >= k1) w = (e.data[j]>>(i-k1))&km;
 else {
   w = (e.data[j]&((1<<(i+1))-1))<<(k1-i);
   if(j > 0) w |= e.data[j-1]>>(this.DB+i-k1);
 }

 n = k;
 while((w&1) == 0) { w >>= 1; --n; }
 if((i -= n) < 0) { i += this.DB; --j; }
 if(is1) {  // ret == 1, don't bother squaring or multiplying it
   g[w].copyTo(r);
   is1 = false;
 } else {
   while(n > 1) { z.sqrTo(r,r2); z.sqrTo(r2,r); n -= 2; }
   if(n > 0) z.sqrTo(r,r2); else { t = r; r = r2; r2 = t; }
   z.mulTo(r2,g[w],r);
 }

 while(j >= 0 && (e.data[j]&(1<<i)) == 0) {
   z.sqrTo(r,r2); t = r; r = r2; r2 = t;
   if(--i < 0) { i = this.DB-1; --j; }
 }
}
return z.revert(r);
}

//(public) gcd(this,a) (HAC 14.54)
function bnGCD(a) {
var x = (this.s<0)?this.negate():this.clone();
var y = (a.s<0)?a.negate():a.clone();
if(x.compareTo(y) < 0) { var t = x; x = y; y = t; }
var i = x.getLowestSetBit(), g = y.getLowestSetBit();
if(g < 0) return x;
if(i < g) g = i;
if(g > 0) {
 x.rShiftTo(g,x);
 y.rShiftTo(g,y);
}
while(x.signum() > 0) {
 if((i = x.getLowestSetBit()) > 0) x.rShiftTo(i,x);
 if((i = y.getLowestSetBit()) > 0) y.rShiftTo(i,y);
 if(x.compareTo(y) >= 0) {
   x.subTo(y,x);
   x.rShiftTo(1,x);
 } else {
   y.subTo(x,y);
   y.rShiftTo(1,y);
 }
}
if(g > 0) y.lShiftTo(g,y);
return y;
}

//(protected) this % n, n < 2^26
function bnpModInt(n) {
if(n <= 0) return 0;
var d = this.DV%n, r = (this.s<0)?n-1:0;
if(this.t > 0)
 if(d == 0) r = this.data[0]%n;
 else for(var i = this.t-1; i >= 0; --i) r = (d*r+this.data[i])%n;
return r;
}

//(public) 1/this % m (HAC 14.61)
function bnModInverse(m) {
var ac = m.isEven();
if((this.isEven() && ac) || m.signum() == 0) return BigInteger$2.ZERO;
var u = m.clone(), v = this.clone();
var a = nbv(1), b = nbv(0), c = nbv(0), d = nbv(1);
while(u.signum() != 0) {
 while(u.isEven()) {
   u.rShiftTo(1,u);
   if(ac) {
     if(!a.isEven() || !b.isEven()) { a.addTo(this,a); b.subTo(m,b); }
     a.rShiftTo(1,a);
   } else if(!b.isEven()) b.subTo(m,b);
   b.rShiftTo(1,b);
 }
 while(v.isEven()) {
   v.rShiftTo(1,v);
   if(ac) {
     if(!c.isEven() || !d.isEven()) { c.addTo(this,c); d.subTo(m,d); }
     c.rShiftTo(1,c);
   } else if(!d.isEven()) d.subTo(m,d);
   d.rShiftTo(1,d);
 }
 if(u.compareTo(v) >= 0) {
   u.subTo(v,u);
   if(ac) a.subTo(c,a);
   b.subTo(d,b);
 } else {
   v.subTo(u,v);
   if(ac) c.subTo(a,c);
   d.subTo(b,d);
 }
}
if(v.compareTo(BigInteger$2.ONE) != 0) return BigInteger$2.ZERO;
if(d.compareTo(m) >= 0) return d.subtract(m);
if(d.signum() < 0) d.addTo(m,d); else return d;
if(d.signum() < 0) return d.add(m); else return d;
}

var lowprimes = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,103,107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211,223,227,229,233,239,241,251,257,263,269,271,277,281,283,293,307,311,313,317,331,337,347,349,353,359,367,373,379,383,389,397,401,409,419,421,431,433,439,443,449,457,461,463,467,479,487,491,499,503,509];
var lplim = (1<<26)/lowprimes[lowprimes.length-1];

//(public) test primality with certainty >= 1-.5^t
function bnIsProbablePrime(t) {
var i, x = this.abs();
if(x.t == 1 && x.data[0] <= lowprimes[lowprimes.length-1]) {
 for(i = 0; i < lowprimes.length; ++i)
   if(x.data[0] == lowprimes[i]) return true;
 return false;
}
if(x.isEven()) return false;
i = 1;
while(i < lowprimes.length) {
 var m = lowprimes[i], j = i+1;
 while(j < lowprimes.length && m < lplim) m *= lowprimes[j++];
 m = x.modInt(m);
 while(i < j) if(m%lowprimes[i++] == 0) return false;
}
return x.millerRabin(t);
}

//(protected) true if probably prime (HAC 4.24, Miller-Rabin)
function bnpMillerRabin(t) {
var n1 = this.subtract(BigInteger$2.ONE);
var k = n1.getLowestSetBit();
if(k <= 0) return false;
var r = n1.shiftRight(k);
var prng = bnGetPrng();
var a;
for(var i = 0; i < t; ++i) {
 // select witness 'a' at random from between 1 and n1
 do {
   a = new BigInteger$2(this.bitLength(), prng);
 }
 while(a.compareTo(BigInteger$2.ONE) <= 0 || a.compareTo(n1) >= 0);
 var y = a.modPow(r,this);
 if(y.compareTo(BigInteger$2.ONE) != 0 && y.compareTo(n1) != 0) {
   var j = 1;
   while(j++ < k && y.compareTo(n1) != 0) {
     y = y.modPowInt(2,this);
     if(y.compareTo(BigInteger$2.ONE) == 0) return false;
   }
   if(y.compareTo(n1) != 0) return false;
 }
}
return true;
}

// get pseudo random number generator
function bnGetPrng() {
  // create prng with api that matches BigInteger secure random
  return {
    // x is an array to fill with bytes
    nextBytes: function(x) {
      for(var i = 0; i < x.length; ++i) {
        x[i] = Math.floor(Math.random() * 0x0100);
      }
    }
  };
}

//protected
BigInteger$2.prototype.chunkSize = bnpChunkSize;
BigInteger$2.prototype.toRadix = bnpToRadix;
BigInteger$2.prototype.fromRadix = bnpFromRadix;
BigInteger$2.prototype.fromNumber = bnpFromNumber;
BigInteger$2.prototype.bitwiseTo = bnpBitwiseTo;
BigInteger$2.prototype.changeBit = bnpChangeBit;
BigInteger$2.prototype.addTo = bnpAddTo;
BigInteger$2.prototype.dMultiply = bnpDMultiply;
BigInteger$2.prototype.dAddOffset = bnpDAddOffset;
BigInteger$2.prototype.multiplyLowerTo = bnpMultiplyLowerTo;
BigInteger$2.prototype.multiplyUpperTo = bnpMultiplyUpperTo;
BigInteger$2.prototype.modInt = bnpModInt;
BigInteger$2.prototype.millerRabin = bnpMillerRabin;

//public
BigInteger$2.prototype.clone = bnClone;
BigInteger$2.prototype.intValue = bnIntValue;
BigInteger$2.prototype.byteValue = bnByteValue;
BigInteger$2.prototype.shortValue = bnShortValue;
BigInteger$2.prototype.signum = bnSigNum;
BigInteger$2.prototype.toByteArray = bnToByteArray;
BigInteger$2.prototype.equals = bnEquals;
BigInteger$2.prototype.min = bnMin;
BigInteger$2.prototype.max = bnMax;
BigInteger$2.prototype.and = bnAnd;
BigInteger$2.prototype.or = bnOr;
BigInteger$2.prototype.xor = bnXor;
BigInteger$2.prototype.andNot = bnAndNot;
BigInteger$2.prototype.not = bnNot;
BigInteger$2.prototype.shiftLeft = bnShiftLeft;
BigInteger$2.prototype.shiftRight = bnShiftRight;
BigInteger$2.prototype.getLowestSetBit = bnGetLowestSetBit;
BigInteger$2.prototype.bitCount = bnBitCount;
BigInteger$2.prototype.testBit = bnTestBit;
BigInteger$2.prototype.setBit = bnSetBit;
BigInteger$2.prototype.clearBit = bnClearBit;
BigInteger$2.prototype.flipBit = bnFlipBit;
BigInteger$2.prototype.add = bnAdd;
BigInteger$2.prototype.subtract = bnSubtract;
BigInteger$2.prototype.multiply = bnMultiply;
BigInteger$2.prototype.divide = bnDivide;
BigInteger$2.prototype.remainder = bnRemainder;
BigInteger$2.prototype.divideAndRemainder = bnDivideAndRemainder;
BigInteger$2.prototype.modPow = bnModPow;
BigInteger$2.prototype.modInverse = bnModInverse;
BigInteger$2.prototype.pow = bnPow;
BigInteger$2.prototype.gcd = bnGCD;
BigInteger$2.prototype.isProbablePrime = bnIsProbablePrime;

/**
 * Secure Hash Algorithm with 160-bit digest (SHA-1) implementation.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2015 Digital Bazaar, Inc.
 */

var forge$5 = forge$m;



var sha1 = forge$5.sha1 = forge$5.sha1 || {};
forge$5.md.sha1 = forge$5.md.algorithms.sha1 = sha1;

/**
 * Creates a SHA-1 message digest object.
 *
 * @return a message digest object.
 */
sha1.create = function() {
  // do initialization as necessary
  if(!_initialized$1) {
    _init$1();
  }

  // SHA-1 state contains five 32-bit integers
  var _state = null;

  // input buffer
  var _input = forge$5.util.createBuffer();

  // used for word storage
  var _w = new Array(80);

  // message digest object
  var md = {
    algorithm: 'sha1',
    blockLength: 64,
    digestLength: 20,
    // 56-bit length of message so far (does not including padding)
    messageLength: 0,
    // true message length
    fullMessageLength: null,
    // size of message length in bytes
    messageLengthSize: 8
  };

  /**
   * Starts the digest.
   *
   * @return this digest object.
   */
  md.start = function() {
    // up to 56-bit message length for convenience
    md.messageLength = 0;

    // full message length (set md.messageLength64 for backwards-compatibility)
    md.fullMessageLength = md.messageLength64 = [];
    var int32s = md.messageLengthSize / 4;
    for(var i = 0; i < int32s; ++i) {
      md.fullMessageLength.push(0);
    }
    _input = forge$5.util.createBuffer();
    _state = {
      h0: 0x67452301,
      h1: 0xEFCDAB89,
      h2: 0x98BADCFE,
      h3: 0x10325476,
      h4: 0xC3D2E1F0
    };
    return md;
  };
  // start digest automatically for first time
  md.start();

  /**
   * Updates the digest with the given message input. The given input can
   * treated as raw input (no encoding will be applied) or an encoding of
   * 'utf8' maybe given to encode the input using UTF-8.
   *
   * @param msg the message input to update with.
   * @param encoding the encoding to use (default: 'raw', other: 'utf8').
   *
   * @return this digest object.
   */
  md.update = function(msg, encoding) {
    if(encoding === 'utf8') {
      msg = forge$5.util.encodeUtf8(msg);
    }

    // update message length
    var len = msg.length;
    md.messageLength += len;
    len = [(len / 0x100000000) >>> 0, len >>> 0];
    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {
      md.fullMessageLength[i] += len[1];
      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);
      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;
      len[0] = ((len[1] / 0x100000000) >>> 0);
    }

    // add bytes to input buffer
    _input.putBytes(msg);

    // process bytes
    _update$1(_state, _w, _input);

    // compact input buffer every 2K or if empty
    if(_input.read > 2048 || _input.length() === 0) {
      _input.compact();
    }

    return md;
  };

  /**
   * Produces the digest.
   *
   * @return a byte buffer containing the digest value.
   */
  md.digest = function() {
    /* Note: Here we copy the remaining bytes in the input buffer and
    add the appropriate SHA-1 padding. Then we do the final update
    on a copy of the state so that if the user wants to get
    intermediate digests they can do so. */

    /* Determine the number of bytes that must be added to the message
    to ensure its length is congruent to 448 mod 512. In other words,
    the data to be digested must be a multiple of 512 bits (or 128 bytes).
    This data includes the message, some padding, and the length of the
    message. Since the length of the message will be encoded as 8 bytes (64
    bits), that means that the last segment of the data must have 56 bytes
    (448 bits) of message and padding. Therefore, the length of the message
    plus the padding must be congruent to 448 mod 512 because
    512 - 128 = 448.

    In order to fill up the message length it must be filled with
    padding that begins with 1 bit followed by all 0 bits. Padding
    must *always* be present, so if the message length is already
    congruent to 448 mod 512, then 512 padding bits must be added. */

    var finalBlock = forge$5.util.createBuffer();
    finalBlock.putBytes(_input.bytes());

    // compute remaining size to be digested (include message length size)
    var remaining = (
      md.fullMessageLength[md.fullMessageLength.length - 1] +
      md.messageLengthSize);

    // add padding for overflow blockSize - overflow
    // _padding starts with 1 byte with first bit is set (byte value 128), then
    // there may be up to (blockSize - 1) other pad bytes
    var overflow = remaining & (md.blockLength - 1);
    finalBlock.putBytes(_padding$1.substr(0, md.blockLength - overflow));

    // serialize message length in bits in big-endian order; since length
    // is stored in bytes we multiply by 8 and add carry from next int
    var next, carry;
    var bits = md.fullMessageLength[0] * 8;
    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {
      next = md.fullMessageLength[i + 1] * 8;
      carry = (next / 0x100000000) >>> 0;
      bits += carry;
      finalBlock.putInt32(bits >>> 0);
      bits = next >>> 0;
    }
    finalBlock.putInt32(bits);

    var s2 = {
      h0: _state.h0,
      h1: _state.h1,
      h2: _state.h2,
      h3: _state.h3,
      h4: _state.h4
    };
    _update$1(s2, _w, finalBlock);
    var rval = forge$5.util.createBuffer();
    rval.putInt32(s2.h0);
    rval.putInt32(s2.h1);
    rval.putInt32(s2.h2);
    rval.putInt32(s2.h3);
    rval.putInt32(s2.h4);
    return rval;
  };

  return md;
};

// sha-1 padding bytes not initialized yet
var _padding$1 = null;
var _initialized$1 = false;

/**
 * Initializes the constant tables.
 */
function _init$1() {
  // create padding
  _padding$1 = String.fromCharCode(128);
  _padding$1 += forge$5.util.fillString(String.fromCharCode(0x00), 64);

  // now initialized
  _initialized$1 = true;
}

/**
 * Updates a SHA-1 state with the given byte buffer.
 *
 * @param s the SHA-1 state to update.
 * @param w the array to use to store words.
 * @param bytes the byte buffer to update with.
 */
function _update$1(s, w, bytes) {
  // consume 512 bit (64 byte) chunks
  var t, a, b, c, d, e, f, i;
  var len = bytes.length();
  while(len >= 64) {
    // the w array will be populated with sixteen 32-bit big-endian words
    // and then extended into 80 32-bit words according to SHA-1 algorithm
    // and for 32-79 using Max Locktyukhin's optimization

    // initialize hash value for this chunk
    a = s.h0;
    b = s.h1;
    c = s.h2;
    d = s.h3;
    e = s.h4;

    // round 1
    for(i = 0; i < 16; ++i) {
      t = bytes.getInt32();
      w[i] = t;
      f = d ^ (b & (c ^ d));
      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    for(; i < 20; ++i) {
      t = (w[i - 3] ^ w[i - 8] ^ w[i - 14] ^ w[i - 16]);
      t = (t << 1) | (t >>> 31);
      w[i] = t;
      f = d ^ (b & (c ^ d));
      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    // round 2
    for(; i < 32; ++i) {
      t = (w[i - 3] ^ w[i - 8] ^ w[i - 14] ^ w[i - 16]);
      t = (t << 1) | (t >>> 31);
      w[i] = t;
      f = b ^ c ^ d;
      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    for(; i < 40; ++i) {
      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);
      t = (t << 2) | (t >>> 30);
      w[i] = t;
      f = b ^ c ^ d;
      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    // round 3
    for(; i < 60; ++i) {
      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);
      t = (t << 2) | (t >>> 30);
      w[i] = t;
      f = (b & c) | (d & (b ^ c));
      t = ((a << 5) | (a >>> 27)) + f + e + 0x8F1BBCDC + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }
    // round 4
    for(; i < 80; ++i) {
      t = (w[i - 6] ^ w[i - 16] ^ w[i - 28] ^ w[i - 32]);
      t = (t << 2) | (t >>> 30);
      w[i] = t;
      f = b ^ c ^ d;
      t = ((a << 5) | (a >>> 27)) + f + e + 0xCA62C1D6 + t;
      e = d;
      d = c;
      // `>>> 0` necessary to avoid iOS/Safari 10 optimization bug
      c = ((b << 30) | (b >>> 2)) >>> 0;
      b = a;
      a = t;
    }

    // update hash state
    s.h0 = (s.h0 + a) | 0;
    s.h1 = (s.h1 + b) | 0;
    s.h2 = (s.h2 + c) | 0;
    s.h3 = (s.h3 + d) | 0;
    s.h4 = (s.h4 + e) | 0;

    len -= 64;
  }
}

/**
 * Partial implementation of PKCS#1 v2.2: RSA-OEAP
 *
 * Modified but based on the following MIT and BSD licensed code:
 *
 * https://github.com/kjur/jsjws/blob/master/rsa.js:
 *
 * The 'jsjws'(JSON Web Signature JavaScript Library) License
 *
 * Copyright (c) 2012 Kenji Urushima
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 *
 * http://webrsa.cvs.sourceforge.net/viewvc/webrsa/Client/RSAES-OAEP.js?content-type=text%2Fplain:
 *
 * RSAES-OAEP.js
 * $Id: RSAES-OAEP.js,v 1.1.1.1 2003/03/19 15:37:20 ellispritchard Exp $
 * JavaScript Implementation of PKCS #1 v2.1 RSA CRYPTOGRAPHY STANDARD (RSA Laboratories, June 14, 2002)
 * Copyright (C) Ellis Pritchard, Guardian Unlimited 2003.
 * Contact: ellis@nukinetics.com
 * Distributed under the BSD License.
 *
 * Official documentation: http://www.rsa.com/rsalabs/node.asp?id=2125
 *
 * @author Evan Jones (http://evanjones.ca/)
 * @author Dave Longley
 *
 * Copyright (c) 2013-2014 Digital Bazaar, Inc.
 */

var forge$4 = forge$m;




// shortcut for PKCS#1 API
var pkcs1 = forge$4.pkcs1 = forge$4.pkcs1 || {};

/**
 * Encode the given RSAES-OAEP message (M) using key, with optional label (L)
 * and seed.
 *
 * This method does not perform RSA encryption, it only encodes the message
 * using RSAES-OAEP.
 *
 * @param key the RSA key to use.
 * @param message the message to encode.
 * @param options the options to use:
 *          label an optional label to use.
 *          seed the seed to use.
 *          md the message digest object to use, undefined for SHA-1.
 *          mgf1 optional mgf1 parameters:
 *            md the message digest object to use for MGF1.
 *
 * @return the encoded message bytes.
 */
pkcs1.encode_rsa_oaep = function(key, message, options) {
  // parse arguments
  var label;
  var seed;
  var md;
  var mgf1Md;
  // legacy args (label, seed, md)
  if(typeof options === 'string') {
    label = options;
    seed = arguments[3] || undefined;
    md = arguments[4] || undefined;
  } else if(options) {
    label = options.label || undefined;
    seed = options.seed || undefined;
    md = options.md || undefined;
    if(options.mgf1 && options.mgf1.md) {
      mgf1Md = options.mgf1.md;
    }
  }

  // default OAEP to SHA-1 message digest
  if(!md) {
    md = forge$4.md.sha1.create();
  } else {
    md.start();
  }

  // default MGF-1 to same as OAEP
  if(!mgf1Md) {
    mgf1Md = md;
  }

  // compute length in bytes and check output
  var keyLength = Math.ceil(key.n.bitLength() / 8);
  var maxLength = keyLength - 2 * md.digestLength - 2;
  if(message.length > maxLength) {
    var error = new Error('RSAES-OAEP input message length is too long.');
    error.length = message.length;
    error.maxLength = maxLength;
    throw error;
  }

  if(!label) {
    label = '';
  }
  md.update(label, 'raw');
  var lHash = md.digest();

  var PS = '';
  var PS_length = maxLength - message.length;
  for(var i = 0; i < PS_length; i++) {
    PS += '\x00';
  }

  var DB = lHash.getBytes() + PS + '\x01' + message;

  if(!seed) {
    seed = forge$4.random.getBytes(md.digestLength);
  } else if(seed.length !== md.digestLength) {
    var error = new Error('Invalid RSAES-OAEP seed. The seed length must ' +
      'match the digest length.');
    error.seedLength = seed.length;
    error.digestLength = md.digestLength;
    throw error;
  }

  var dbMask = rsa_mgf1(seed, keyLength - md.digestLength - 1, mgf1Md);
  var maskedDB = forge$4.util.xorBytes(DB, dbMask, DB.length);

  var seedMask = rsa_mgf1(maskedDB, md.digestLength, mgf1Md);
  var maskedSeed = forge$4.util.xorBytes(seed, seedMask, seed.length);

  // return encoded message
  return '\x00' + maskedSeed + maskedDB;
};

/**
 * Decode the given RSAES-OAEP encoded message (EM) using key, with optional
 * label (L).
 *
 * This method does not perform RSA decryption, it only decodes the message
 * using RSAES-OAEP.
 *
 * @param key the RSA key to use.
 * @param em the encoded message to decode.
 * @param options the options to use:
 *          label an optional label to use.
 *          md the message digest object to use for OAEP, undefined for SHA-1.
 *          mgf1 optional mgf1 parameters:
 *            md the message digest object to use for MGF1.
 *
 * @return the decoded message bytes.
 */
pkcs1.decode_rsa_oaep = function(key, em, options) {
  // parse args
  var label;
  var md;
  var mgf1Md;
  // legacy args
  if(typeof options === 'string') {
    label = options;
    md = arguments[3] || undefined;
  } else if(options) {
    label = options.label || undefined;
    md = options.md || undefined;
    if(options.mgf1 && options.mgf1.md) {
      mgf1Md = options.mgf1.md;
    }
  }

  // compute length in bytes
  var keyLength = Math.ceil(key.n.bitLength() / 8);

  if(em.length !== keyLength) {
    var error = new Error('RSAES-OAEP encoded message length is invalid.');
    error.length = em.length;
    error.expectedLength = keyLength;
    throw error;
  }

  // default OAEP to SHA-1 message digest
  if(md === undefined) {
    md = forge$4.md.sha1.create();
  } else {
    md.start();
  }

  // default MGF-1 to same as OAEP
  if(!mgf1Md) {
    mgf1Md = md;
  }

  if(keyLength < 2 * md.digestLength + 2) {
    throw new Error('RSAES-OAEP key is too short for the hash function.');
  }

  if(!label) {
    label = '';
  }
  md.update(label, 'raw');
  var lHash = md.digest().getBytes();

  // split the message into its parts
  var y = em.charAt(0);
  var maskedSeed = em.substring(1, md.digestLength + 1);
  var maskedDB = em.substring(1 + md.digestLength);

  var seedMask = rsa_mgf1(maskedDB, md.digestLength, mgf1Md);
  var seed = forge$4.util.xorBytes(maskedSeed, seedMask, maskedSeed.length);

  var dbMask = rsa_mgf1(seed, keyLength - md.digestLength - 1, mgf1Md);
  var db = forge$4.util.xorBytes(maskedDB, dbMask, maskedDB.length);

  var lHashPrime = db.substring(0, md.digestLength);

  // constant time check that all values match what is expected
  var error = (y !== '\x00');

  // constant time check lHash vs lHashPrime
  for(var i = 0; i < md.digestLength; ++i) {
    error |= (lHash.charAt(i) !== lHashPrime.charAt(i));
  }

  // "constant time" find the 0x1 byte separating the padding (zeros) from the
  // message
  // TODO: It must be possible to do this in a better/smarter way?
  var in_ps = 1;
  var index = md.digestLength;
  for(var j = md.digestLength; j < db.length; j++) {
    var code = db.charCodeAt(j);

    var is_0 = (code & 0x1) ^ 0x1;

    // non-zero if not 0 or 1 in the ps section
    var error_mask = in_ps ? 0xfffe : 0x0000;
    error |= (code & error_mask);

    // latch in_ps to zero after we find 0x1
    in_ps = in_ps & is_0;
    index += in_ps;
  }

  if(error || db.charCodeAt(index) !== 0x1) {
    throw new Error('Invalid RSAES-OAEP padding.');
  }

  return db.substring(index + 1);
};

function rsa_mgf1(seed, maskLength, hash) {
  // default to SHA-1 message digest
  if(!hash) {
    hash = forge$4.md.sha1.create();
  }
  var t = '';
  var count = Math.ceil(maskLength / hash.digestLength);
  for(var i = 0; i < count; ++i) {
    var c = String.fromCharCode(
      (i >> 24) & 0xFF, (i >> 16) & 0xFF, (i >> 8) & 0xFF, i & 0xFF);
    hash.start();
    hash.update(seed + c);
    t += hash.digest().getBytes();
  }
  return t.substring(0, maskLength);
}

/**
 * Prime number generation API.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2014 Digital Bazaar, Inc.
 */

var forge$3 = forge$m;




(function() {

// forge.prime already defined
if(forge$3.prime) {
  forge$3.prime;
  return;
}

/* PRIME API */
var prime = forge$3.prime = forge$3.prime || {};

var BigInteger = forge$3.jsbn.BigInteger;

// primes are 30k+i for i = 1, 7, 11, 13, 17, 19, 23, 29
var GCD_30_DELTA = [6, 4, 2, 4, 2, 4, 6, 2];
var THIRTY = new BigInteger(null);
THIRTY.fromInt(30);
var op_or = function(x, y) {return x|y;};

/**
 * Generates a random probable prime with the given number of bits.
 *
 * Alternative algorithms can be specified by name as a string or as an
 * object with custom options like so:
 *
 * {
 *   name: 'PRIMEINC',
 *   options: {
 *     maxBlockTime: <the maximum amount of time to block the main
 *       thread before allowing I/O other JS to run>,
 *     millerRabinTests: <the number of miller-rabin tests to run>,
 *     workerScript: <the worker script URL>,
 *     workers: <the number of web workers (if supported) to use,
 *       -1 to use estimated cores minus one>.
 *     workLoad: the size of the work load, ie: number of possible prime
 *       numbers for each web worker to check per work assignment,
 *       (default: 100).
 *   }
 * }
 *
 * @param bits the number of bits for the prime number.
 * @param options the options to use.
 *          [algorithm] the algorithm to use (default: 'PRIMEINC').
 *          [prng] a custom crypto-secure pseudo-random number generator to use,
 *            that must define "getBytesSync".
 *
 * @return callback(err, num) called once the operation completes.
 */
prime.generateProbablePrime = function(bits, options, callback) {
  if(typeof options === 'function') {
    callback = options;
    options = {};
  }
  options = options || {};

  // default to PRIMEINC algorithm
  var algorithm = options.algorithm || 'PRIMEINC';
  if(typeof algorithm === 'string') {
    algorithm = {name: algorithm};
  }
  algorithm.options = algorithm.options || {};

  // create prng with api that matches BigInteger secure random
  var prng = options.prng || forge$3.random;
  var rng = {
    // x is an array to fill with bytes
    nextBytes: function(x) {
      var b = prng.getBytesSync(x.length);
      for(var i = 0; i < x.length; ++i) {
        x[i] = b.charCodeAt(i);
      }
    }
  };

  if(algorithm.name === 'PRIMEINC') {
    return primeincFindPrime(bits, rng, algorithm.options, callback);
  }

  throw new Error('Invalid prime generation algorithm: ' + algorithm.name);
};

function primeincFindPrime(bits, rng, options, callback) {
  if('workers' in options) {
    return primeincFindPrimeWithWorkers(bits, rng, options, callback);
  }
  return primeincFindPrimeWithoutWorkers(bits, rng, options, callback);
}

function primeincFindPrimeWithoutWorkers(bits, rng, options, callback) {
  // initialize random number
  var num = generateRandom(bits, rng);

  /* Note: All primes are of the form 30k+i for i < 30 and gcd(30, i)=1. The
  number we are given is always aligned at 30k + 1. Each time the number is
  determined not to be prime we add to get to the next 'i', eg: if the number
  was at 30k + 1 we add 6. */
  var deltaIdx = 0;

  // get required number of MR tests
  var mrTests = getMillerRabinTests(num.bitLength());
  if('millerRabinTests' in options) {
    mrTests = options.millerRabinTests;
  }

  // find prime nearest to 'num' for maxBlockTime ms
  // 10 ms gives 5ms of leeway for other calculations before dropping
  // below 60fps (1000/60 == 16.67), but in reality, the number will
  // likely be higher due to an 'atomic' big int modPow
  var maxBlockTime = 10;
  if('maxBlockTime' in options) {
    maxBlockTime = options.maxBlockTime;
  }

  _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback);
}

function _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback) {
  var start = +new Date();
  do {
    // overflow, regenerate random number
    if(num.bitLength() > bits) {
      num = generateRandom(bits, rng);
    }
    // do primality test
    if(num.isProbablePrime(mrTests)) {
      return callback(null, num);
    }
    // get next potential prime
    num.dAddOffset(GCD_30_DELTA[deltaIdx++ % 8], 0);
  } while(maxBlockTime < 0 || (+new Date() - start < maxBlockTime));

  // keep trying later
  forge$3.util.setImmediate(function() {
    _primeinc(num, bits, rng, deltaIdx, mrTests, maxBlockTime, callback);
  });
}

// NOTE: This algorithm is indeterminate in nature because workers
// run in parallel looking at different segments of numbers. Even if this
// algorithm is run twice with the same input from a predictable RNG, it
// may produce different outputs.
function primeincFindPrimeWithWorkers(bits, rng, options, callback) {
  // web workers unavailable
  if(typeof Worker === 'undefined') {
    return primeincFindPrimeWithoutWorkers(bits, rng, options, callback);
  }

  // initialize random number
  var num = generateRandom(bits, rng);

  // use web workers to generate keys
  var numWorkers = options.workers;
  var workLoad = options.workLoad || 100;
  var range = workLoad * 30 / 8;
  var workerScript = options.workerScript || 'forge/prime.worker.js';
  if(numWorkers === -1) {
    return forge$3.util.estimateCores(function(err, cores) {
      if(err) {
        // default to 2
        cores = 2;
      }
      numWorkers = cores - 1;
      generate();
    });
  }
  generate();

  function generate() {
    // require at least 1 worker
    numWorkers = Math.max(1, numWorkers);

    // TODO: consider optimizing by starting workers outside getPrime() ...
    // note that in order to clean up they will have to be made internally
    // asynchronous which may actually be slower

    // start workers immediately
    var workers = [];
    for(var i = 0; i < numWorkers; ++i) {
      // FIXME: fix path or use blob URLs
      workers[i] = new Worker(workerScript);
    }

    // listen for requests from workers and assign ranges to find prime
    for(var i = 0; i < numWorkers; ++i) {
      workers[i].addEventListener('message', workerMessage);
    }

    /* Note: The distribution of random numbers is unknown. Therefore, each
    web worker is continuously allocated a range of numbers to check for a
    random number until one is found.

    Every 30 numbers will be checked just 8 times, because prime numbers
    have the form:

    30k+i, for i < 30 and gcd(30, i)=1 (there are 8 values of i for this)

    Therefore, if we want a web worker to run N checks before asking for
    a new range of numbers, each range must contain N*30/8 numbers.

    For 100 checks (workLoad), this is a range of 375. */

    var found = false;
    function workerMessage(e) {
      // ignore message, prime already found
      if(found) {
        return;
      }
      var data = e.data;
      if(data.found) {
        // terminate all workers
        for(var i = 0; i < workers.length; ++i) {
          workers[i].terminate();
        }
        found = true;
        return callback(null, new BigInteger(data.prime, 16));
      }

      // overflow, regenerate random number
      if(num.bitLength() > bits) {
        num = generateRandom(bits, rng);
      }

      // assign new range to check
      var hex = num.toString(16);

      // start prime search
      e.target.postMessage({
        hex: hex,
        workLoad: workLoad
      });

      num.dAddOffset(range, 0);
    }
  }
}

/**
 * Generates a random number using the given number of bits and RNG.
 *
 * @param bits the number of bits for the number.
 * @param rng the random number generator to use.
 *
 * @return the random number.
 */
function generateRandom(bits, rng) {
  var num = new BigInteger(bits, rng);
  // force MSB set
  var bits1 = bits - 1;
  if(!num.testBit(bits1)) {
    num.bitwiseTo(BigInteger.ONE.shiftLeft(bits1), op_or, num);
  }
  // align number on 30k+1 boundary
  num.dAddOffset(31 - num.mod(THIRTY).byteValue(), 0);
  return num;
}

/**
 * Returns the required number of Miller-Rabin tests to generate a
 * prime with an error probability of (1/2)^80.
 *
 * See Handbook of Applied Cryptography Chapter 4, Table 4.4.
 *
 * @param bits the bit size.
 *
 * @return the required number of iterations.
 */
function getMillerRabinTests(bits) {
  if(bits <= 100) return 27;
  if(bits <= 150) return 18;
  if(bits <= 200) return 15;
  if(bits <= 250) return 12;
  if(bits <= 300) return 9;
  if(bits <= 350) return 8;
  if(bits <= 400) return 7;
  if(bits <= 500) return 6;
  if(bits <= 600) return 5;
  if(bits <= 800) return 4;
  if(bits <= 1250) return 3;
  return 2;
}

})();

/**
 * Javascript implementation of basic RSA algorithms.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2010-2014 Digital Bazaar, Inc.
 *
 * The only algorithm currently supported for PKI is RSA.
 *
 * An RSA key is often stored in ASN.1 DER format. The SubjectPublicKeyInfo
 * ASN.1 structure is composed of an algorithm of type AlgorithmIdentifier
 * and a subjectPublicKey of type bit string.
 *
 * The AlgorithmIdentifier contains an Object Identifier (OID) and parameters
 * for the algorithm, if any. In the case of RSA, there aren't any.
 *
 * SubjectPublicKeyInfo ::= SEQUENCE {
 *   algorithm AlgorithmIdentifier,
 *   subjectPublicKey BIT STRING
 * }
 *
 * AlgorithmIdentifer ::= SEQUENCE {
 *   algorithm OBJECT IDENTIFIER,
 *   parameters ANY DEFINED BY algorithm OPTIONAL
 * }
 *
 * For an RSA public key, the subjectPublicKey is:
 *
 * RSAPublicKey ::= SEQUENCE {
 *   modulus            INTEGER,    -- n
 *   publicExponent     INTEGER     -- e
 * }
 *
 * PrivateKeyInfo ::= SEQUENCE {
 *   version                   Version,
 *   privateKeyAlgorithm       PrivateKeyAlgorithmIdentifier,
 *   privateKey                PrivateKey,
 *   attributes           [0]  IMPLICIT Attributes OPTIONAL
 * }
 *
 * Version ::= INTEGER
 * PrivateKeyAlgorithmIdentifier ::= AlgorithmIdentifier
 * PrivateKey ::= OCTET STRING
 * Attributes ::= SET OF Attribute
 *
 * An RSA private key as the following structure:
 *
 * RSAPrivateKey ::= SEQUENCE {
 *   version Version,
 *   modulus INTEGER, -- n
 *   publicExponent INTEGER, -- e
 *   privateExponent INTEGER, -- d
 *   prime1 INTEGER, -- p
 *   prime2 INTEGER, -- q
 *   exponent1 INTEGER, -- d mod (p-1)
 *   exponent2 INTEGER, -- d mod (q-1)
 *   coefficient INTEGER -- (inverse of q) mod p
 * }
 *
 * Version ::= INTEGER
 *
 * The OID for the RSA key algorithm is: 1.2.840.113549.1.1.1
 */

var forge$2 = forge$m;








if(typeof BigInteger$1 === 'undefined') {
  var BigInteger$1 = forge$2.jsbn.BigInteger;
}

var _crypto = forge$2.util.isNodejs ? require$$1 : null;

// shortcut for asn.1 API
var asn1$1 = forge$2.asn1;

// shortcut for util API
var util$1 = forge$2.util;

/*
 * RSA encryption and decryption, see RFC 2313.
 */
forge$2.pki = forge$2.pki || {};
forge$2.pki.rsa = forge$2.rsa = forge$2.rsa || {};
var pki$1 = forge$2.pki;

// for finding primes, which are 30k+i for i = 1, 7, 11, 13, 17, 19, 23, 29
var GCD_30_DELTA = [6, 4, 2, 4, 2, 4, 6, 2];

// validator for a PrivateKeyInfo structure
var privateKeyValidator = {
  // PrivateKeyInfo
  name: 'PrivateKeyInfo',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  value: [{
    // Version (INTEGER)
    name: 'PrivateKeyInfo.version',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyVersion'
  }, {
    // privateKeyAlgorithm
    name: 'PrivateKeyInfo.privateKeyAlgorithm',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'AlgorithmIdentifier.algorithm',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.OID,
      constructed: false,
      capture: 'privateKeyOid'
    }]
  }, {
    // PrivateKey
    name: 'PrivateKeyInfo',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.OCTETSTRING,
    constructed: false,
    capture: 'privateKey'
  }]
};

// validator for an RSA private key
var rsaPrivateKeyValidator = {
  // RSAPrivateKey
  name: 'RSAPrivateKey',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  value: [{
    // Version (INTEGER)
    name: 'RSAPrivateKey.version',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyVersion'
  }, {
    // modulus (n)
    name: 'RSAPrivateKey.modulus',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyModulus'
  }, {
    // publicExponent (e)
    name: 'RSAPrivateKey.publicExponent',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyPublicExponent'
  }, {
    // privateExponent (d)
    name: 'RSAPrivateKey.privateExponent',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyPrivateExponent'
  }, {
    // prime1 (p)
    name: 'RSAPrivateKey.prime1',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyPrime1'
  }, {
    // prime2 (q)
    name: 'RSAPrivateKey.prime2',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyPrime2'
  }, {
    // exponent1 (d mod (p-1))
    name: 'RSAPrivateKey.exponent1',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyExponent1'
  }, {
    // exponent2 (d mod (q-1))
    name: 'RSAPrivateKey.exponent2',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyExponent2'
  }, {
    // coefficient ((inverse of q) mod p)
    name: 'RSAPrivateKey.coefficient',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'privateKeyCoefficient'
  }]
};

// validator for an RSA public key
var rsaPublicKeyValidator = {
  // RSAPublicKey
  name: 'RSAPublicKey',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  value: [{
    // modulus (n)
    name: 'RSAPublicKey.modulus',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'publicKeyModulus'
  }, {
    // publicExponent (e)
    name: 'RSAPublicKey.exponent',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.INTEGER,
    constructed: false,
    capture: 'publicKeyExponent'
  }]
};

// validator for an SubjectPublicKeyInfo structure
// Note: Currently only works with an RSA public key
var publicKeyValidator = forge$2.pki.rsa.publicKeyValidator = {
  name: 'SubjectPublicKeyInfo',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  captureAsn1: 'subjectPublicKeyInfo',
  value: [{
    name: 'SubjectPublicKeyInfo.AlgorithmIdentifier',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'AlgorithmIdentifier.algorithm',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.OID,
      constructed: false,
      capture: 'publicKeyOid'
    }]
  }, {
    // subjectPublicKey
    name: 'SubjectPublicKeyInfo.subjectPublicKey',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.BITSTRING,
    constructed: false,
    value: [{
      // RSAPublicKey
      name: 'SubjectPublicKeyInfo.subjectPublicKey.RSAPublicKey',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.SEQUENCE,
      constructed: true,
      optional: true,
      captureAsn1: 'rsaPublicKey'
    }]
  }]
};

// validator for a DigestInfo structure
var digestInfoValidator = {
  name: 'DigestInfo',
  tagClass: asn1$1.Class.UNIVERSAL,
  type: asn1$1.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'DigestInfo.DigestAlgorithm',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'DigestInfo.DigestAlgorithm.algorithmIdentifier',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.OID,
      constructed: false,
      capture: 'algorithmIdentifier'
    }, {
      // NULL paramters
      name: 'DigestInfo.DigestAlgorithm.parameters',
      tagClass: asn1$1.Class.UNIVERSAL,
      type: asn1$1.Type.NULL,
      // captured only to check existence for md2 and md5
      capture: 'parameters',
      optional: true,
      constructed: false
    }]
  }, {
    // digest
    name: 'DigestInfo.digest',
    tagClass: asn1$1.Class.UNIVERSAL,
    type: asn1$1.Type.OCTETSTRING,
    constructed: false,
    capture: 'digest'
  }]
};

/**
 * Wrap digest in DigestInfo object.
 *
 * This function implements EMSA-PKCS1-v1_5-ENCODE as per RFC 3447.
 *
 * DigestInfo ::= SEQUENCE {
 *   digestAlgorithm DigestAlgorithmIdentifier,
 *   digest Digest
 * }
 *
 * DigestAlgorithmIdentifier ::= AlgorithmIdentifier
 * Digest ::= OCTET STRING
 *
 * @param md the message digest object with the hash to sign.
 *
 * @return the encoded message (ready for RSA encrytion)
 */
var emsaPkcs1v15encode = function(md) {
  // get the oid for the algorithm
  var oid;
  if(md.algorithm in pki$1.oids) {
    oid = pki$1.oids[md.algorithm];
  } else {
    var error = new Error('Unknown message digest algorithm.');
    error.algorithm = md.algorithm;
    throw error;
  }
  var oidBytes = asn1$1.oidToDer(oid).getBytes();

  // create the digest info
  var digestInfo = asn1$1.create(
    asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);
  var digestAlgorithm = asn1$1.create(
    asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, []);
  digestAlgorithm.value.push(asn1$1.create(
    asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false, oidBytes));
  digestAlgorithm.value.push(asn1$1.create(
    asn1$1.Class.UNIVERSAL, asn1$1.Type.NULL, false, ''));
  var digest = asn1$1.create(
    asn1$1.Class.UNIVERSAL, asn1$1.Type.OCTETSTRING,
    false, md.digest().getBytes());
  digestInfo.value.push(digestAlgorithm);
  digestInfo.value.push(digest);

  // encode digest info
  return asn1$1.toDer(digestInfo).getBytes();
};

/**
 * Performs x^c mod n (RSA encryption or decryption operation).
 *
 * @param x the number to raise and mod.
 * @param key the key to use.
 * @param pub true if the key is public, false if private.
 *
 * @return the result of x^c mod n.
 */
var _modPow = function(x, key, pub) {
  if(pub) {
    return x.modPow(key.e, key.n);
  }

  if(!key.p || !key.q) {
    // allow calculation without CRT params (slow)
    return x.modPow(key.d, key.n);
  }

  // pre-compute dP, dQ, and qInv if necessary
  if(!key.dP) {
    key.dP = key.d.mod(key.p.subtract(BigInteger$1.ONE));
  }
  if(!key.dQ) {
    key.dQ = key.d.mod(key.q.subtract(BigInteger$1.ONE));
  }
  if(!key.qInv) {
    key.qInv = key.q.modInverse(key.p);
  }

  /* Chinese remainder theorem (CRT) states:

    Suppose n1, n2, ..., nk are positive integers which are pairwise
    coprime (n1 and n2 have no common factors other than 1). For any
    integers x1, x2, ..., xk there exists an integer x solving the
    system of simultaneous congruences (where ~= means modularly
    congruent so a ~= b mod n means a mod n = b mod n):

    x ~= x1 mod n1
    x ~= x2 mod n2
    ...
    x ~= xk mod nk

    This system of congruences has a single simultaneous solution x
    between 0 and n - 1. Furthermore, each xk solution and x itself
    is congruent modulo the product n = n1*n2*...*nk.
    So x1 mod n = x2 mod n = xk mod n = x mod n.

    The single simultaneous solution x can be solved with the following
    equation:

    x = sum(xi*ri*si) mod n where ri = n/ni and si = ri^-1 mod ni.

    Where x is less than n, xi = x mod ni.

    For RSA we are only concerned with k = 2. The modulus n = pq, where
    p and q are coprime. The RSA decryption algorithm is:

    y = x^d mod n

    Given the above:

    x1 = x^d mod p
    r1 = n/p = q
    s1 = q^-1 mod p
    x2 = x^d mod q
    r2 = n/q = p
    s2 = p^-1 mod q

    So y = (x1r1s1 + x2r2s2) mod n
         = ((x^d mod p)q(q^-1 mod p) + (x^d mod q)p(p^-1 mod q)) mod n

    According to Fermat's Little Theorem, if the modulus P is prime,
    for any integer A not evenly divisible by P, A^(P-1) ~= 1 mod P.
    Since A is not divisible by P it follows that if:
    N ~= M mod (P - 1), then A^N mod P = A^M mod P. Therefore:

    A^N mod P = A^(M mod (P - 1)) mod P. (The latter takes less effort
    to calculate). In order to calculate x^d mod p more quickly the
    exponent d mod (p - 1) is stored in the RSA private key (the same
    is done for x^d mod q). These values are referred to as dP and dQ
    respectively. Therefore we now have:

    y = ((x^dP mod p)q(q^-1 mod p) + (x^dQ mod q)p(p^-1 mod q)) mod n

    Since we'll be reducing x^dP by modulo p (same for q) we can also
    reduce x by p (and q respectively) before hand. Therefore, let

    xp = ((x mod p)^dP mod p), and
    xq = ((x mod q)^dQ mod q), yielding:

    y = (xp*q*(q^-1 mod p) + xq*p*(p^-1 mod q)) mod n

    This can be further reduced to a simple algorithm that only
    requires 1 inverse (the q inverse is used) to be used and stored.
    The algorithm is called Garner's algorithm. If qInv is the
    inverse of q, we simply calculate:

    y = (qInv*(xp - xq) mod p) * q + xq

    However, there are two further complications. First, we need to
    ensure that xp > xq to prevent signed BigIntegers from being used
    so we add p until this is true (since we will be mod'ing with
    p anyway). Then, there is a known timing attack on algorithms
    using the CRT. To mitigate this risk, "cryptographic blinding"
    should be used. This requires simply generating a random number r
    between 0 and n-1 and its inverse and multiplying x by r^e before
    calculating y and then multiplying y by r^-1 afterwards. Note that
    r must be coprime with n (gcd(r, n) === 1) in order to have an
    inverse.
  */

  // cryptographic blinding
  var r;
  do {
    r = new BigInteger$1(
      forge$2.util.bytesToHex(forge$2.random.getBytes(key.n.bitLength() / 8)),
      16);
  } while(r.compareTo(key.n) >= 0 || !r.gcd(key.n).equals(BigInteger$1.ONE));
  x = x.multiply(r.modPow(key.e, key.n)).mod(key.n);

  // calculate xp and xq
  var xp = x.mod(key.p).modPow(key.dP, key.p);
  var xq = x.mod(key.q).modPow(key.dQ, key.q);

  // xp must be larger than xq to avoid signed bit usage
  while(xp.compareTo(xq) < 0) {
    xp = xp.add(key.p);
  }

  // do last step
  var y = xp.subtract(xq)
    .multiply(key.qInv).mod(key.p)
    .multiply(key.q).add(xq);

  // remove effect of random for cryptographic blinding
  y = y.multiply(r.modInverse(key.n)).mod(key.n);

  return y;
};

/**
 * NOTE: THIS METHOD IS DEPRECATED, use 'sign' on a private key object or
 * 'encrypt' on a public key object instead.
 *
 * Performs RSA encryption.
 *
 * The parameter bt controls whether to put padding bytes before the
 * message passed in. Set bt to either true or false to disable padding
 * completely (in order to handle e.g. EMSA-PSS encoding seperately before),
 * signaling whether the encryption operation is a public key operation
 * (i.e. encrypting data) or not, i.e. private key operation (data signing).
 *
 * For PKCS#1 v1.5 padding pass in the block type to use, i.e. either 0x01
 * (for signing) or 0x02 (for encryption). The key operation mode (private
 * or public) is derived from this flag in that case).
 *
 * @param m the message to encrypt as a byte string.
 * @param key the RSA key to use.
 * @param bt for PKCS#1 v1.5 padding, the block type to use
 *   (0x01 for private key, 0x02 for public),
 *   to disable padding: true = public key, false = private key.
 *
 * @return the encrypted bytes as a string.
 */
pki$1.rsa.encrypt = function(m, key, bt) {
  var pub = bt;
  var eb;

  // get the length of the modulus in bytes
  var k = Math.ceil(key.n.bitLength() / 8);

  if(bt !== false && bt !== true) {
    // legacy, default to PKCS#1 v1.5 padding
    pub = (bt === 0x02);
    eb = _encodePkcs1_v1_5(m, key, bt);
  } else {
    eb = forge$2.util.createBuffer();
    eb.putBytes(m);
  }

  // load encryption block as big integer 'x'
  // FIXME: hex conversion inefficient, get BigInteger w/byte strings
  var x = new BigInteger$1(eb.toHex(), 16);

  // do RSA encryption
  var y = _modPow(x, key, pub);

  // convert y into the encrypted data byte string, if y is shorter in
  // bytes than k, then prepend zero bytes to fill up ed
  // FIXME: hex conversion inefficient, get BigInteger w/byte strings
  var yhex = y.toString(16);
  var ed = forge$2.util.createBuffer();
  var zeros = k - Math.ceil(yhex.length / 2);
  while(zeros > 0) {
    ed.putByte(0x00);
    --zeros;
  }
  ed.putBytes(forge$2.util.hexToBytes(yhex));
  return ed.getBytes();
};

/**
 * NOTE: THIS METHOD IS DEPRECATED, use 'decrypt' on a private key object or
 * 'verify' on a public key object instead.
 *
 * Performs RSA decryption.
 *
 * The parameter ml controls whether to apply PKCS#1 v1.5 padding
 * or not.  Set ml = false to disable padding removal completely
 * (in order to handle e.g. EMSA-PSS later on) and simply pass back
 * the RSA encryption block.
 *
 * @param ed the encrypted data to decrypt in as a byte string.
 * @param key the RSA key to use.
 * @param pub true for a public key operation, false for private.
 * @param ml the message length, if known, false to disable padding.
 *
 * @return the decrypted message as a byte string.
 */
pki$1.rsa.decrypt = function(ed, key, pub, ml) {
  // get the length of the modulus in bytes
  var k = Math.ceil(key.n.bitLength() / 8);

  // error if the length of the encrypted data ED is not k
  if(ed.length !== k) {
    var error = new Error('Encrypted message length is invalid.');
    error.length = ed.length;
    error.expected = k;
    throw error;
  }

  // convert encrypted data into a big integer
  // FIXME: hex conversion inefficient, get BigInteger w/byte strings
  var y = new BigInteger$1(forge$2.util.createBuffer(ed).toHex(), 16);

  // y must be less than the modulus or it wasn't the result of
  // a previous mod operation (encryption) using that modulus
  if(y.compareTo(key.n) >= 0) {
    throw new Error('Encrypted message is invalid.');
  }

  // do RSA decryption
  var x = _modPow(y, key, pub);

  // create the encryption block, if x is shorter in bytes than k, then
  // prepend zero bytes to fill up eb
  // FIXME: hex conversion inefficient, get BigInteger w/byte strings
  var xhex = x.toString(16);
  var eb = forge$2.util.createBuffer();
  var zeros = k - Math.ceil(xhex.length / 2);
  while(zeros > 0) {
    eb.putByte(0x00);
    --zeros;
  }
  eb.putBytes(forge$2.util.hexToBytes(xhex));

  if(ml !== false) {
    // legacy, default to PKCS#1 v1.5 padding
    return _decodePkcs1_v1_5(eb.getBytes(), key, pub);
  }

  // return message
  return eb.getBytes();
};

/**
 * Creates an RSA key-pair generation state object. It is used to allow
 * key-generation to be performed in steps. It also allows for a UI to
 * display progress updates.
 *
 * @param bits the size for the private key in bits, defaults to 2048.
 * @param e the public exponent to use, defaults to 65537 (0x10001).
 * @param [options] the options to use.
 *          prng a custom crypto-secure pseudo-random number generator to use,
 *            that must define "getBytesSync".
 *          algorithm the algorithm to use (default: 'PRIMEINC').
 *
 * @return the state object to use to generate the key-pair.
 */
pki$1.rsa.createKeyPairGenerationState = function(bits, e, options) {
  // TODO: migrate step-based prime generation code to forge.prime

  // set default bits
  if(typeof(bits) === 'string') {
    bits = parseInt(bits, 10);
  }
  bits = bits || 2048;

  // create prng with api that matches BigInteger secure random
  options = options || {};
  var prng = options.prng || forge$2.random;
  var rng = {
    // x is an array to fill with bytes
    nextBytes: function(x) {
      var b = prng.getBytesSync(x.length);
      for(var i = 0; i < x.length; ++i) {
        x[i] = b.charCodeAt(i);
      }
    }
  };

  var algorithm = options.algorithm || 'PRIMEINC';

  // create PRIMEINC algorithm state
  var rval;
  if(algorithm === 'PRIMEINC') {
    rval = {
      algorithm: algorithm,
      state: 0,
      bits: bits,
      rng: rng,
      eInt: e || 65537,
      e: new BigInteger$1(null),
      p: null,
      q: null,
      qBits: bits >> 1,
      pBits: bits - (bits >> 1),
      pqState: 0,
      num: null,
      keys: null
    };
    rval.e.fromInt(rval.eInt);
  } else {
    throw new Error('Invalid key generation algorithm: ' + algorithm);
  }

  return rval;
};

/**
 * Attempts to runs the key-generation algorithm for at most n seconds
 * (approximately) using the given state. When key-generation has completed,
 * the keys will be stored in state.keys.
 *
 * To use this function to update a UI while generating a key or to prevent
 * causing browser lockups/warnings, set "n" to a value other than 0. A
 * simple pattern for generating a key and showing a progress indicator is:
 *
 * var state = pki.rsa.createKeyPairGenerationState(2048);
 * var step = function() {
 *   // step key-generation, run algorithm for 100 ms, repeat
 *   if(!forge.pki.rsa.stepKeyPairGenerationState(state, 100)) {
 *     setTimeout(step, 1);
 *   } else {
 *     // key-generation complete
 *     // TODO: turn off progress indicator here
 *     // TODO: use the generated key-pair in "state.keys"
 *   }
 * };
 * // TODO: turn on progress indicator here
 * setTimeout(step, 0);
 *
 * @param state the state to use.
 * @param n the maximum number of milliseconds to run the algorithm for, 0
 *          to run the algorithm to completion.
 *
 * @return true if the key-generation completed, false if not.
 */
pki$1.rsa.stepKeyPairGenerationState = function(state, n) {
  // set default algorithm if not set
  if(!('algorithm' in state)) {
    state.algorithm = 'PRIMEINC';
  }

  // TODO: migrate step-based prime generation code to forge.prime
  // TODO: abstract as PRIMEINC algorithm

  // do key generation (based on Tom Wu's rsa.js, see jsbn.js license)
  // with some minor optimizations and designed to run in steps

  // local state vars
  var THIRTY = new BigInteger$1(null);
  THIRTY.fromInt(30);
  var deltaIdx = 0;
  var op_or = function(x, y) {return x | y;};

  // keep stepping until time limit is reached or done
  var t1 = +new Date();
  var t2;
  var total = 0;
  while(state.keys === null && (n <= 0 || total < n)) {
    // generate p or q
    if(state.state === 0) {
      /* Note: All primes are of the form:

        30k+i, for i < 30 and gcd(30, i)=1, where there are 8 values for i

        When we generate a random number, we always align it at 30k + 1. Each
        time the number is determined not to be prime we add to get to the
        next 'i', eg: if the number was at 30k + 1 we add 6. */
      var bits = (state.p === null) ? state.pBits : state.qBits;
      var bits1 = bits - 1;

      // get a random number
      if(state.pqState === 0) {
        state.num = new BigInteger$1(bits, state.rng);
        // force MSB set
        if(!state.num.testBit(bits1)) {
          state.num.bitwiseTo(
            BigInteger$1.ONE.shiftLeft(bits1), op_or, state.num);
        }
        // align number on 30k+1 boundary
        state.num.dAddOffset(31 - state.num.mod(THIRTY).byteValue(), 0);
        deltaIdx = 0;

        ++state.pqState;
      } else if(state.pqState === 1) {
        // try to make the number a prime
        if(state.num.bitLength() > bits) {
          // overflow, try again
          state.pqState = 0;
          // do primality test
        } else if(state.num.isProbablePrime(
          _getMillerRabinTests(state.num.bitLength()))) {
          ++state.pqState;
        } else {
          // get next potential prime
          state.num.dAddOffset(GCD_30_DELTA[deltaIdx++ % 8], 0);
        }
      } else if(state.pqState === 2) {
        // ensure number is coprime with e
        state.pqState =
          (state.num.subtract(BigInteger$1.ONE).gcd(state.e)
            .compareTo(BigInteger$1.ONE) === 0) ? 3 : 0;
      } else if(state.pqState === 3) {
        // store p or q
        state.pqState = 0;
        if(state.p === null) {
          state.p = state.num;
        } else {
          state.q = state.num;
        }

        // advance state if both p and q are ready
        if(state.p !== null && state.q !== null) {
          ++state.state;
        }
        state.num = null;
      }
    } else if(state.state === 1) {
      // ensure p is larger than q (swap them if not)
      if(state.p.compareTo(state.q) < 0) {
        state.num = state.p;
        state.p = state.q;
        state.q = state.num;
      }
      ++state.state;
    } else if(state.state === 2) {
      // compute phi: (p - 1)(q - 1) (Euler's totient function)
      state.p1 = state.p.subtract(BigInteger$1.ONE);
      state.q1 = state.q.subtract(BigInteger$1.ONE);
      state.phi = state.p1.multiply(state.q1);
      ++state.state;
    } else if(state.state === 3) {
      // ensure e and phi are coprime
      if(state.phi.gcd(state.e).compareTo(BigInteger$1.ONE) === 0) {
        // phi and e are coprime, advance
        ++state.state;
      } else {
        // phi and e aren't coprime, so generate a new p and q
        state.p = null;
        state.q = null;
        state.state = 0;
      }
    } else if(state.state === 4) {
      // create n, ensure n is has the right number of bits
      state.n = state.p.multiply(state.q);

      // ensure n is right number of bits
      if(state.n.bitLength() === state.bits) {
        // success, advance
        ++state.state;
      } else {
        // failed, get new q
        state.q = null;
        state.state = 0;
      }
    } else if(state.state === 5) {
      // set keys
      var d = state.e.modInverse(state.phi);
      state.keys = {
        privateKey: pki$1.rsa.setPrivateKey(
          state.n, state.e, d, state.p, state.q,
          d.mod(state.p1), d.mod(state.q1),
          state.q.modInverse(state.p)),
        publicKey: pki$1.rsa.setPublicKey(state.n, state.e)
      };
    }

    // update timing
    t2 = +new Date();
    total += t2 - t1;
    t1 = t2;
  }

  return state.keys !== null;
};

/**
 * Generates an RSA public-private key pair in a single call.
 *
 * To generate a key-pair in steps (to allow for progress updates and to
 * prevent blocking or warnings in slow browsers) then use the key-pair
 * generation state functions.
 *
 * To generate a key-pair asynchronously (either through web-workers, if
 * available, or by breaking up the work on the main thread), pass a
 * callback function.
 *
 * @param [bits] the size for the private key in bits, defaults to 2048.
 * @param [e] the public exponent to use, defaults to 65537.
 * @param [options] options for key-pair generation, if given then 'bits'
 *            and 'e' must *not* be given:
 *          bits the size for the private key in bits, (default: 2048).
 *          e the public exponent to use, (default: 65537 (0x10001)).
 *          workerScript the worker script URL.
 *          workers the number of web workers (if supported) to use,
 *            (default: 2).
 *          workLoad the size of the work load, ie: number of possible prime
 *            numbers for each web worker to check per work assignment,
 *            (default: 100).
 *          prng a custom crypto-secure pseudo-random number generator to use,
 *            that must define "getBytesSync". Disables use of native APIs.
 *          algorithm the algorithm to use (default: 'PRIMEINC').
 * @param [callback(err, keypair)] called once the operation completes.
 *
 * @return an object with privateKey and publicKey properties.
 */
pki$1.rsa.generateKeyPair = function(bits, e, options, callback) {
  // (bits), (options), (callback)
  if(arguments.length === 1) {
    if(typeof bits === 'object') {
      options = bits;
      bits = undefined;
    } else if(typeof bits === 'function') {
      callback = bits;
      bits = undefined;
    }
  } else if(arguments.length === 2) {
    // (bits, e), (bits, options), (bits, callback), (options, callback)
    if(typeof bits === 'number') {
      if(typeof e === 'function') {
        callback = e;
        e = undefined;
      } else if(typeof e !== 'number') {
        options = e;
        e = undefined;
      }
    } else {
      options = bits;
      callback = e;
      bits = undefined;
      e = undefined;
    }
  } else if(arguments.length === 3) {
    // (bits, e, options), (bits, e, callback), (bits, options, callback)
    if(typeof e === 'number') {
      if(typeof options === 'function') {
        callback = options;
        options = undefined;
      }
    } else {
      callback = options;
      options = e;
      e = undefined;
    }
  }
  options = options || {};
  if(bits === undefined) {
    bits = options.bits || 2048;
  }
  if(e === undefined) {
    e = options.e || 0x10001;
  }

  // use native code if permitted, available, and parameters are acceptable
  if(!forge$2.options.usePureJavaScript && !options.prng &&
    bits >= 256 && bits <= 16384 && (e === 0x10001 || e === 3)) {
    if(callback) {
      // try native async
      if(_detectNodeCrypto('generateKeyPair')) {
        return _crypto.generateKeyPair('rsa', {
          modulusLength: bits,
          publicExponent: e,
          publicKeyEncoding: {
            type: 'spki',
            format: 'pem'
          },
          privateKeyEncoding: {
            type: 'pkcs8',
            format: 'pem'
          }
        }, function(err, pub, priv) {
          if(err) {
            return callback(err);
          }
          callback(null, {
            privateKey: pki$1.privateKeyFromPem(priv),
            publicKey: pki$1.publicKeyFromPem(pub)
          });
        });
      }
      if(_detectSubtleCrypto('generateKey') &&
        _detectSubtleCrypto('exportKey')) {
        // use standard native generateKey
        return util$1.globalScope.crypto.subtle.generateKey({
          name: 'RSASSA-PKCS1-v1_5',
          modulusLength: bits,
          publicExponent: _intToUint8Array(e),
          hash: {name: 'SHA-256'}
        }, true /* key can be exported*/, ['sign', 'verify'])
        .then(function(pair) {
          return util$1.globalScope.crypto.subtle.exportKey(
            'pkcs8', pair.privateKey);
        // avoiding catch(function(err) {...}) to support IE <= 8
        }).then(undefined, function(err) {
          callback(err);
        }).then(function(pkcs8) {
          if(pkcs8) {
            var privateKey = pki$1.privateKeyFromAsn1(
              asn1$1.fromDer(forge$2.util.createBuffer(pkcs8)));
            callback(null, {
              privateKey: privateKey,
              publicKey: pki$1.setRsaPublicKey(privateKey.n, privateKey.e)
            });
          }
        });
      }
      if(_detectSubtleMsCrypto('generateKey') &&
        _detectSubtleMsCrypto('exportKey')) {
        var genOp = util$1.globalScope.msCrypto.subtle.generateKey({
          name: 'RSASSA-PKCS1-v1_5',
          modulusLength: bits,
          publicExponent: _intToUint8Array(e),
          hash: {name: 'SHA-256'}
        }, true /* key can be exported*/, ['sign', 'verify']);
        genOp.oncomplete = function(e) {
          var pair = e.target.result;
          var exportOp = util$1.globalScope.msCrypto.subtle.exportKey(
            'pkcs8', pair.privateKey);
          exportOp.oncomplete = function(e) {
            var pkcs8 = e.target.result;
            var privateKey = pki$1.privateKeyFromAsn1(
              asn1$1.fromDer(forge$2.util.createBuffer(pkcs8)));
            callback(null, {
              privateKey: privateKey,
              publicKey: pki$1.setRsaPublicKey(privateKey.n, privateKey.e)
            });
          };
          exportOp.onerror = function(err) {
            callback(err);
          };
        };
        genOp.onerror = function(err) {
          callback(err);
        };
        return;
      }
    } else {
      // try native sync
      if(_detectNodeCrypto('generateKeyPairSync')) {
        var keypair = _crypto.generateKeyPairSync('rsa', {
          modulusLength: bits,
          publicExponent: e,
          publicKeyEncoding: {
            type: 'spki',
            format: 'pem'
          },
          privateKeyEncoding: {
            type: 'pkcs8',
            format: 'pem'
          }
        });
        return {
          privateKey: pki$1.privateKeyFromPem(keypair.privateKey),
          publicKey: pki$1.publicKeyFromPem(keypair.publicKey)
        };
      }
    }
  }

  // use JavaScript implementation
  var state = pki$1.rsa.createKeyPairGenerationState(bits, e, options);
  if(!callback) {
    pki$1.rsa.stepKeyPairGenerationState(state, 0);
    return state.keys;
  }
  _generateKeyPair(state, options, callback);
};

/**
 * Sets an RSA public key from BigIntegers modulus and exponent.
 *
 * @param n the modulus.
 * @param e the exponent.
 *
 * @return the public key.
 */
pki$1.setRsaPublicKey = pki$1.rsa.setPublicKey = function(n, e) {
  var key = {
    n: n,
    e: e
  };

  /**
   * Encrypts the given data with this public key. Newer applications
   * should use the 'RSA-OAEP' decryption scheme, 'RSAES-PKCS1-V1_5' is for
   * legacy applications.
   *
   * @param data the byte string to encrypt.
   * @param scheme the encryption scheme to use:
   *          'RSAES-PKCS1-V1_5' (default),
   *          'RSA-OAEP',
   *          'RAW', 'NONE', or null to perform raw RSA encryption,
   *          an object with an 'encode' property set to a function
   *          with the signature 'function(data, key)' that returns
   *          a binary-encoded string representing the encoded data.
   * @param schemeOptions any scheme-specific options.
   *
   * @return the encrypted byte string.
   */
  key.encrypt = function(data, scheme, schemeOptions) {
    if(typeof scheme === 'string') {
      scheme = scheme.toUpperCase();
    } else if(scheme === undefined) {
      scheme = 'RSAES-PKCS1-V1_5';
    }

    if(scheme === 'RSAES-PKCS1-V1_5') {
      scheme = {
        encode: function(m, key, pub) {
          return _encodePkcs1_v1_5(m, key, 0x02).getBytes();
        }
      };
    } else if(scheme === 'RSA-OAEP' || scheme === 'RSAES-OAEP') {
      scheme = {
        encode: function(m, key) {
          return forge$2.pkcs1.encode_rsa_oaep(key, m, schemeOptions);
        }
      };
    } else if(['RAW', 'NONE', 'NULL', null].indexOf(scheme) !== -1) {
      scheme = {encode: function(e) {return e;}};
    } else if(typeof scheme === 'string') {
      throw new Error('Unsupported encryption scheme: "' + scheme + '".');
    }

    // do scheme-based encoding then rsa encryption
    var e = scheme.encode(data, key, true);
    return pki$1.rsa.encrypt(e, key, true);
  };

  /**
   * Verifies the given signature against the given digest.
   *
   * PKCS#1 supports multiple (currently two) signature schemes:
   * RSASSA-PKCS1-V1_5 and RSASSA-PSS.
   *
   * By default this implementation uses the "old scheme", i.e.
   * RSASSA-PKCS1-V1_5, in which case once RSA-decrypted, the
   * signature is an OCTET STRING that holds a DigestInfo.
   *
   * DigestInfo ::= SEQUENCE {
   *   digestAlgorithm DigestAlgorithmIdentifier,
   *   digest Digest
   * }
   * DigestAlgorithmIdentifier ::= AlgorithmIdentifier
   * Digest ::= OCTET STRING
   *
   * To perform PSS signature verification, provide an instance
   * of Forge PSS object as the scheme parameter.
   *
   * @param digest the message digest hash to compare against the signature,
   *          as a binary-encoded string.
   * @param signature the signature to verify, as a binary-encoded string.
   * @param scheme signature verification scheme to use:
   *          'RSASSA-PKCS1-V1_5' or undefined for RSASSA PKCS#1 v1.5,
   *          a Forge PSS object for RSASSA-PSS,
   *          'NONE' or null for none, DigestInfo will not be expected, but
   *            PKCS#1 v1.5 padding will still be used.
   * @param options optional verify options
   *          _parseAllDigestBytes testing flag to control parsing of all
   *            digest bytes. Unsupported and not for general usage.
   *            (default: true)
   *
   * @return true if the signature was verified, false if not.
   */
  key.verify = function(digest, signature, scheme, options) {
    if(typeof scheme === 'string') {
      scheme = scheme.toUpperCase();
    } else if(scheme === undefined) {
      scheme = 'RSASSA-PKCS1-V1_5';
    }
    if(options === undefined) {
      options = {
        _parseAllDigestBytes: true
      };
    }
    if(!('_parseAllDigestBytes' in options)) {
      options._parseAllDigestBytes = true;
    }

    if(scheme === 'RSASSA-PKCS1-V1_5') {
      scheme = {
        verify: function(digest, d) {
          // remove padding
          d = _decodePkcs1_v1_5(d, key, true);
          // d is ASN.1 BER-encoded DigestInfo
          var obj = asn1$1.fromDer(d, {
            parseAllBytes: options._parseAllDigestBytes
          });

          // validate DigestInfo
          var capture = {};
          var errors = [];
          if(!asn1$1.validate(obj, digestInfoValidator, capture, errors)) {
            var error = new Error(
              'ASN.1 object does not contain a valid RSASSA-PKCS1-v1_5 ' +
              'DigestInfo value.');
            error.errors = errors;
            throw error;
          }
          // check hash algorithm identifier
          // see PKCS1-v1-5DigestAlgorithms in RFC 8017
          // FIXME: add support to vaidator for strict value choices
          var oid = asn1$1.derToOid(capture.algorithmIdentifier);
          if(!(oid === forge$2.oids.md2 ||
            oid === forge$2.oids.md5 ||
            oid === forge$2.oids.sha1 ||
            oid === forge$2.oids.sha224 ||
            oid === forge$2.oids.sha256 ||
            oid === forge$2.oids.sha384 ||
            oid === forge$2.oids.sha512 ||
            oid === forge$2.oids['sha512-224'] ||
            oid === forge$2.oids['sha512-256'])) {
            var error = new Error(
              'Unknown RSASSA-PKCS1-v1_5 DigestAlgorithm identifier.');
            error.oid = oid;
            throw error;
          }

          // special check for md2 and md5 that NULL parameters exist
          if(oid === forge$2.oids.md2 || oid === forge$2.oids.md5) {
            if(!('parameters' in capture)) {
              throw new Error(
                'ASN.1 object does not contain a valid RSASSA-PKCS1-v1_5 ' +
                'DigestInfo value. ' +
                'Missing algorithm identifer NULL parameters.');
            }
          }

          // compare the given digest to the decrypted one
          return digest === capture.digest;
        }
      };
    } else if(scheme === 'NONE' || scheme === 'NULL' || scheme === null) {
      scheme = {
        verify: function(digest, d) {
          // remove padding
          d = _decodePkcs1_v1_5(d, key, true);
          return digest === d;
        }
      };
    }

    // do rsa decryption w/o any decoding, then verify -- which does decoding
    var d = pki$1.rsa.decrypt(signature, key, true, false);
    return scheme.verify(digest, d, key.n.bitLength());
  };

  return key;
};

/**
 * Sets an RSA private key from BigIntegers modulus, exponent, primes,
 * prime exponents, and modular multiplicative inverse.
 *
 * @param n the modulus.
 * @param e the public exponent.
 * @param d the private exponent ((inverse of e) mod n).
 * @param p the first prime.
 * @param q the second prime.
 * @param dP exponent1 (d mod (p-1)).
 * @param dQ exponent2 (d mod (q-1)).
 * @param qInv ((inverse of q) mod p)
 *
 * @return the private key.
 */
pki$1.setRsaPrivateKey = pki$1.rsa.setPrivateKey = function(
  n, e, d, p, q, dP, dQ, qInv) {
  var key = {
    n: n,
    e: e,
    d: d,
    p: p,
    q: q,
    dP: dP,
    dQ: dQ,
    qInv: qInv
  };

  /**
   * Decrypts the given data with this private key. The decryption scheme
   * must match the one used to encrypt the data.
   *
   * @param data the byte string to decrypt.
   * @param scheme the decryption scheme to use:
   *          'RSAES-PKCS1-V1_5' (default),
   *          'RSA-OAEP',
   *          'RAW', 'NONE', or null to perform raw RSA decryption.
   * @param schemeOptions any scheme-specific options.
   *
   * @return the decrypted byte string.
   */
  key.decrypt = function(data, scheme, schemeOptions) {
    if(typeof scheme === 'string') {
      scheme = scheme.toUpperCase();
    } else if(scheme === undefined) {
      scheme = 'RSAES-PKCS1-V1_5';
    }

    // do rsa decryption w/o any decoding
    var d = pki$1.rsa.decrypt(data, key, false, false);

    if(scheme === 'RSAES-PKCS1-V1_5') {
      scheme = {decode: _decodePkcs1_v1_5};
    } else if(scheme === 'RSA-OAEP' || scheme === 'RSAES-OAEP') {
      scheme = {
        decode: function(d, key) {
          return forge$2.pkcs1.decode_rsa_oaep(key, d, schemeOptions);
        }
      };
    } else if(['RAW', 'NONE', 'NULL', null].indexOf(scheme) !== -1) {
      scheme = {decode: function(d) {return d;}};
    } else {
      throw new Error('Unsupported encryption scheme: "' + scheme + '".');
    }

    // decode according to scheme
    return scheme.decode(d, key, false);
  };

  /**
   * Signs the given digest, producing a signature.
   *
   * PKCS#1 supports multiple (currently two) signature schemes:
   * RSASSA-PKCS1-V1_5 and RSASSA-PSS.
   *
   * By default this implementation uses the "old scheme", i.e.
   * RSASSA-PKCS1-V1_5. In order to generate a PSS signature, provide
   * an instance of Forge PSS object as the scheme parameter.
   *
   * @param md the message digest object with the hash to sign.
   * @param scheme the signature scheme to use:
   *          'RSASSA-PKCS1-V1_5' or undefined for RSASSA PKCS#1 v1.5,
   *          a Forge PSS object for RSASSA-PSS,
   *          'NONE' or null for none, DigestInfo will not be used but
   *            PKCS#1 v1.5 padding will still be used.
   *
   * @return the signature as a byte string.
   */
  key.sign = function(md, scheme) {
    /* Note: The internal implementation of RSA operations is being
      transitioned away from a PKCS#1 v1.5 hard-coded scheme. Some legacy
      code like the use of an encoding block identifier 'bt' will eventually
      be removed. */

    // private key operation
    var bt = false;

    if(typeof scheme === 'string') {
      scheme = scheme.toUpperCase();
    }

    if(scheme === undefined || scheme === 'RSASSA-PKCS1-V1_5') {
      scheme = {encode: emsaPkcs1v15encode};
      bt = 0x01;
    } else if(scheme === 'NONE' || scheme === 'NULL' || scheme === null) {
      scheme = {encode: function() {return md;}};
      bt = 0x01;
    }

    // encode and then encrypt
    var d = scheme.encode(md, key.n.bitLength());
    return pki$1.rsa.encrypt(d, key, bt);
  };

  return key;
};

/**
 * Wraps an RSAPrivateKey ASN.1 object in an ASN.1 PrivateKeyInfo object.
 *
 * @param rsaKey the ASN.1 RSAPrivateKey.
 *
 * @return the ASN.1 PrivateKeyInfo.
 */
pki$1.wrapRsaPrivateKey = function(rsaKey) {
  // PrivateKeyInfo
  return asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
    // version (0)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      asn1$1.integerToDer(0).getBytes()),
    // privateKeyAlgorithm
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
      asn1$1.create(
        asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
        asn1$1.oidToDer(pki$1.oids.rsaEncryption).getBytes()),
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.NULL, false, '')
    ]),
    // PrivateKey
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OCTETSTRING, false,
      asn1$1.toDer(rsaKey).getBytes())
  ]);
};

/**
 * Converts a private key from an ASN.1 object.
 *
 * @param obj the ASN.1 representation of a PrivateKeyInfo containing an
 *          RSAPrivateKey or an RSAPrivateKey.
 *
 * @return the private key.
 */
pki$1.privateKeyFromAsn1 = function(obj) {
  // get PrivateKeyInfo
  var capture = {};
  var errors = [];
  if(asn1$1.validate(obj, privateKeyValidator, capture, errors)) {
    obj = asn1$1.fromDer(forge$2.util.createBuffer(capture.privateKey));
  }

  // get RSAPrivateKey
  capture = {};
  errors = [];
  if(!asn1$1.validate(obj, rsaPrivateKeyValidator, capture, errors)) {
    var error = new Error('Cannot read private key. ' +
      'ASN.1 object does not contain an RSAPrivateKey.');
    error.errors = errors;
    throw error;
  }

  // Note: Version is currently ignored.
  // capture.privateKeyVersion
  // FIXME: inefficient, get a BigInteger that uses byte strings
  var n, e, d, p, q, dP, dQ, qInv;
  n = forge$2.util.createBuffer(capture.privateKeyModulus).toHex();
  e = forge$2.util.createBuffer(capture.privateKeyPublicExponent).toHex();
  d = forge$2.util.createBuffer(capture.privateKeyPrivateExponent).toHex();
  p = forge$2.util.createBuffer(capture.privateKeyPrime1).toHex();
  q = forge$2.util.createBuffer(capture.privateKeyPrime2).toHex();
  dP = forge$2.util.createBuffer(capture.privateKeyExponent1).toHex();
  dQ = forge$2.util.createBuffer(capture.privateKeyExponent2).toHex();
  qInv = forge$2.util.createBuffer(capture.privateKeyCoefficient).toHex();

  // set private key
  return pki$1.setRsaPrivateKey(
    new BigInteger$1(n, 16),
    new BigInteger$1(e, 16),
    new BigInteger$1(d, 16),
    new BigInteger$1(p, 16),
    new BigInteger$1(q, 16),
    new BigInteger$1(dP, 16),
    new BigInteger$1(dQ, 16),
    new BigInteger$1(qInv, 16));
};

/**
 * Converts a private key to an ASN.1 RSAPrivateKey.
 *
 * @param key the private key.
 *
 * @return the ASN.1 representation of an RSAPrivateKey.
 */
pki$1.privateKeyToAsn1 = pki$1.privateKeyToRSAPrivateKey = function(key) {
  // RSAPrivateKey
  return asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
    // version (0 = only 2 primes, 1 multiple primes)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      asn1$1.integerToDer(0).getBytes()),
    // modulus (n)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.n)),
    // publicExponent (e)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.e)),
    // privateExponent (d)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.d)),
    // privateKeyPrime1 (p)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.p)),
    // privateKeyPrime2 (q)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.q)),
    // privateKeyExponent1 (dP)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.dP)),
    // privateKeyExponent2 (dQ)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.dQ)),
    // coefficient (qInv)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.qInv))
  ]);
};

/**
 * Converts a public key from an ASN.1 SubjectPublicKeyInfo or RSAPublicKey.
 *
 * @param obj the asn1 representation of a SubjectPublicKeyInfo or RSAPublicKey.
 *
 * @return the public key.
 */
pki$1.publicKeyFromAsn1 = function(obj) {
  // get SubjectPublicKeyInfo
  var capture = {};
  var errors = [];
  if(asn1$1.validate(obj, publicKeyValidator, capture, errors)) {
    // get oid
    var oid = asn1$1.derToOid(capture.publicKeyOid);
    if(oid !== pki$1.oids.rsaEncryption) {
      var error = new Error('Cannot read public key. Unknown OID.');
      error.oid = oid;
      throw error;
    }
    obj = capture.rsaPublicKey;
  }

  // get RSA params
  errors = [];
  if(!asn1$1.validate(obj, rsaPublicKeyValidator, capture, errors)) {
    var error = new Error('Cannot read public key. ' +
      'ASN.1 object does not contain an RSAPublicKey.');
    error.errors = errors;
    throw error;
  }

  // FIXME: inefficient, get a BigInteger that uses byte strings
  var n = forge$2.util.createBuffer(capture.publicKeyModulus).toHex();
  var e = forge$2.util.createBuffer(capture.publicKeyExponent).toHex();

  // set public key
  return pki$1.setRsaPublicKey(
    new BigInteger$1(n, 16),
    new BigInteger$1(e, 16));
};

/**
 * Converts a public key to an ASN.1 SubjectPublicKeyInfo.
 *
 * @param key the public key.
 *
 * @return the asn1 representation of a SubjectPublicKeyInfo.
 */
pki$1.publicKeyToAsn1 = pki$1.publicKeyToSubjectPublicKeyInfo = function(key) {
  // SubjectPublicKeyInfo
  return asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
    // AlgorithmIdentifier
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
      // algorithm
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.OID, false,
        asn1$1.oidToDer(pki$1.oids.rsaEncryption).getBytes()),
      // parameters (null)
      asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.NULL, false, '')
    ]),
    // subjectPublicKey
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.BITSTRING, false, [
      pki$1.publicKeyToRSAPublicKey(key)
    ])
  ]);
};

/**
 * Converts a public key to an ASN.1 RSAPublicKey.
 *
 * @param key the public key.
 *
 * @return the asn1 representation of a RSAPublicKey.
 */
pki$1.publicKeyToRSAPublicKey = function(key) {
  // RSAPublicKey
  return asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.SEQUENCE, true, [
    // modulus (n)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.n)),
    // publicExponent (e)
    asn1$1.create(asn1$1.Class.UNIVERSAL, asn1$1.Type.INTEGER, false,
      _bnToBytes(key.e))
  ]);
};

/**
 * Encodes a message using PKCS#1 v1.5 padding.
 *
 * @param m the message to encode.
 * @param key the RSA key to use.
 * @param bt the block type to use, i.e. either 0x01 (for signing) or 0x02
 *          (for encryption).
 *
 * @return the padded byte buffer.
 */
function _encodePkcs1_v1_5(m, key, bt) {
  var eb = forge$2.util.createBuffer();

  // get the length of the modulus in bytes
  var k = Math.ceil(key.n.bitLength() / 8);

  /* use PKCS#1 v1.5 padding */
  if(m.length > (k - 11)) {
    var error = new Error('Message is too long for PKCS#1 v1.5 padding.');
    error.length = m.length;
    error.max = k - 11;
    throw error;
  }

  /* A block type BT, a padding string PS, and the data D shall be
    formatted into an octet string EB, the encryption block:

    EB = 00 || BT || PS || 00 || D

    The block type BT shall be a single octet indicating the structure of
    the encryption block. For this version of the document it shall have
    value 00, 01, or 02. For a private-key operation, the block type
    shall be 00 or 01. For a public-key operation, it shall be 02.

    The padding string PS shall consist of k-3-||D|| octets. For block
    type 00, the octets shall have value 00; for block type 01, they
    shall have value FF; and for block type 02, they shall be
    pseudorandomly generated and nonzero. This makes the length of the
    encryption block EB equal to k. */

  // build the encryption block
  eb.putByte(0x00);
  eb.putByte(bt);

  // create the padding
  var padNum = k - 3 - m.length;
  var padByte;
  // private key op
  if(bt === 0x00 || bt === 0x01) {
    padByte = (bt === 0x00) ? 0x00 : 0xFF;
    for(var i = 0; i < padNum; ++i) {
      eb.putByte(padByte);
    }
  } else {
    // public key op
    // pad with random non-zero values
    while(padNum > 0) {
      var numZeros = 0;
      var padBytes = forge$2.random.getBytes(padNum);
      for(var i = 0; i < padNum; ++i) {
        padByte = padBytes.charCodeAt(i);
        if(padByte === 0) {
          ++numZeros;
        } else {
          eb.putByte(padByte);
        }
      }
      padNum = numZeros;
    }
  }

  // zero followed by message
  eb.putByte(0x00);
  eb.putBytes(m);

  return eb;
}

/**
 * Decodes a message using PKCS#1 v1.5 padding.
 *
 * @param em the message to decode.
 * @param key the RSA key to use.
 * @param pub true if the key is a public key, false if it is private.
 * @param ml the message length, if specified.
 *
 * @return the decoded bytes.
 */
function _decodePkcs1_v1_5(em, key, pub, ml) {
  // get the length of the modulus in bytes
  var k = Math.ceil(key.n.bitLength() / 8);

  /* It is an error if any of the following conditions occurs:

    1. The encryption block EB cannot be parsed unambiguously.
    2. The padding string PS consists of fewer than eight octets
      or is inconsisent with the block type BT.
    3. The decryption process is a public-key operation and the block
      type BT is not 00 or 01, or the decryption process is a
      private-key operation and the block type is not 02.
   */

  // parse the encryption block
  var eb = forge$2.util.createBuffer(em);
  var first = eb.getByte();
  var bt = eb.getByte();
  if(first !== 0x00 ||
    (pub && bt !== 0x00 && bt !== 0x01) ||
    (!pub && bt != 0x02) ||
    (pub && bt === 0x00 && typeof(ml) === 'undefined')) {
    throw new Error('Encryption block is invalid.');
  }

  var padNum = 0;
  if(bt === 0x00) {
    // check all padding bytes for 0x00
    padNum = k - 3 - ml;
    for(var i = 0; i < padNum; ++i) {
      if(eb.getByte() !== 0x00) {
        throw new Error('Encryption block is invalid.');
      }
    }
  } else if(bt === 0x01) {
    // find the first byte that isn't 0xFF, should be after all padding
    padNum = 0;
    while(eb.length() > 1) {
      if(eb.getByte() !== 0xFF) {
        --eb.read;
        break;
      }
      ++padNum;
    }
  } else if(bt === 0x02) {
    // look for 0x00 byte
    padNum = 0;
    while(eb.length() > 1) {
      if(eb.getByte() === 0x00) {
        --eb.read;
        break;
      }
      ++padNum;
    }
  }

  // zero must be 0x00 and padNum must be (k - 3 - message length)
  var zero = eb.getByte();
  if(zero !== 0x00 || padNum !== (k - 3 - eb.length())) {
    throw new Error('Encryption block is invalid.');
  }

  return eb.getBytes();
}

/**
 * Runs the key-generation algorithm asynchronously, either in the background
 * via Web Workers, or using the main thread and setImmediate.
 *
 * @param state the key-pair generation state.
 * @param [options] options for key-pair generation:
 *          workerScript the worker script URL.
 *          workers the number of web workers (if supported) to use,
 *            (default: 2, -1 to use estimated cores minus one).
 *          workLoad the size of the work load, ie: number of possible prime
 *            numbers for each web worker to check per work assignment,
 *            (default: 100).
 * @param callback(err, keypair) called once the operation completes.
 */
function _generateKeyPair(state, options, callback) {
  if(typeof options === 'function') {
    callback = options;
    options = {};
  }
  options = options || {};

  var opts = {
    algorithm: {
      name: options.algorithm || 'PRIMEINC',
      options: {
        workers: options.workers || 2,
        workLoad: options.workLoad || 100,
        workerScript: options.workerScript
      }
    }
  };
  if('prng' in options) {
    opts.prng = options.prng;
  }

  generate();

  function generate() {
    // find p and then q (done in series to simplify)
    getPrime(state.pBits, function(err, num) {
      if(err) {
        return callback(err);
      }
      state.p = num;
      if(state.q !== null) {
        return finish(err, state.q);
      }
      getPrime(state.qBits, finish);
    });
  }

  function getPrime(bits, callback) {
    forge$2.prime.generateProbablePrime(bits, opts, callback);
  }

  function finish(err, num) {
    if(err) {
      return callback(err);
    }

    // set q
    state.q = num;

    // ensure p is larger than q (swap them if not)
    if(state.p.compareTo(state.q) < 0) {
      var tmp = state.p;
      state.p = state.q;
      state.q = tmp;
    }

    // ensure p is coprime with e
    if(state.p.subtract(BigInteger$1.ONE).gcd(state.e)
      .compareTo(BigInteger$1.ONE) !== 0) {
      state.p = null;
      generate();
      return;
    }

    // ensure q is coprime with e
    if(state.q.subtract(BigInteger$1.ONE).gcd(state.e)
      .compareTo(BigInteger$1.ONE) !== 0) {
      state.q = null;
      getPrime(state.qBits, finish);
      return;
    }

    // compute phi: (p - 1)(q - 1) (Euler's totient function)
    state.p1 = state.p.subtract(BigInteger$1.ONE);
    state.q1 = state.q.subtract(BigInteger$1.ONE);
    state.phi = state.p1.multiply(state.q1);

    // ensure e and phi are coprime
    if(state.phi.gcd(state.e).compareTo(BigInteger$1.ONE) !== 0) {
      // phi and e aren't coprime, so generate a new p and q
      state.p = state.q = null;
      generate();
      return;
    }

    // create n, ensure n is has the right number of bits
    state.n = state.p.multiply(state.q);
    if(state.n.bitLength() !== state.bits) {
      // failed, get new q
      state.q = null;
      getPrime(state.qBits, finish);
      return;
    }

    // set keys
    var d = state.e.modInverse(state.phi);
    state.keys = {
      privateKey: pki$1.rsa.setPrivateKey(
        state.n, state.e, d, state.p, state.q,
        d.mod(state.p1), d.mod(state.q1),
        state.q.modInverse(state.p)),
      publicKey: pki$1.rsa.setPublicKey(state.n, state.e)
    };

    callback(null, state.keys);
  }
}

/**
 * Converts a positive BigInteger into 2's-complement big-endian bytes.
 *
 * @param b the big integer to convert.
 *
 * @return the bytes.
 */
function _bnToBytes(b) {
  // prepend 0x00 if first byte >= 0x80
  var hex = b.toString(16);
  if(hex[0] >= '8') {
    hex = '00' + hex;
  }
  var bytes = forge$2.util.hexToBytes(hex);

  // ensure integer is minimally-encoded
  if(bytes.length > 1 &&
    // leading 0x00 for positive integer
    ((bytes.charCodeAt(0) === 0 &&
    (bytes.charCodeAt(1) & 0x80) === 0) ||
    // leading 0xFF for negative integer
    (bytes.charCodeAt(0) === 0xFF &&
    (bytes.charCodeAt(1) & 0x80) === 0x80))) {
    return bytes.substr(1);
  }
  return bytes;
}

/**
 * Returns the required number of Miller-Rabin tests to generate a
 * prime with an error probability of (1/2)^80.
 *
 * See Handbook of Applied Cryptography Chapter 4, Table 4.4.
 *
 * @param bits the bit size.
 *
 * @return the required number of iterations.
 */
function _getMillerRabinTests(bits) {
  if(bits <= 100) return 27;
  if(bits <= 150) return 18;
  if(bits <= 200) return 15;
  if(bits <= 250) return 12;
  if(bits <= 300) return 9;
  if(bits <= 350) return 8;
  if(bits <= 400) return 7;
  if(bits <= 500) return 6;
  if(bits <= 600) return 5;
  if(bits <= 800) return 4;
  if(bits <= 1250) return 3;
  return 2;
}

/**
 * Performs feature detection on the Node crypto interface.
 *
 * @param fn the feature (function) to detect.
 *
 * @return true if detected, false if not.
 */
function _detectNodeCrypto(fn) {
  return forge$2.util.isNodejs && typeof _crypto[fn] === 'function';
}

/**
 * Performs feature detection on the SubtleCrypto interface.
 *
 * @param fn the feature (function) to detect.
 *
 * @return true if detected, false if not.
 */
function _detectSubtleCrypto(fn) {
  return (typeof util$1.globalScope !== 'undefined' &&
    typeof util$1.globalScope.crypto === 'object' &&
    typeof util$1.globalScope.crypto.subtle === 'object' &&
    typeof util$1.globalScope.crypto.subtle[fn] === 'function');
}

/**
 * Performs feature detection on the deprecated Microsoft Internet Explorer
 * outdated SubtleCrypto interface. This function should only be used after
 * checking for the modern, standard SubtleCrypto interface.
 *
 * @param fn the feature (function) to detect.
 *
 * @return true if detected, false if not.
 */
function _detectSubtleMsCrypto(fn) {
  return (typeof util$1.globalScope !== 'undefined' &&
    typeof util$1.globalScope.msCrypto === 'object' &&
    typeof util$1.globalScope.msCrypto.subtle === 'object' &&
    typeof util$1.globalScope.msCrypto.subtle[fn] === 'function');
}

function _intToUint8Array(x) {
  var bytes = forge$2.util.hexToBytes(x.toString(16));
  var buffer = new Uint8Array(bytes.length);
  for(var i = 0; i < bytes.length; ++i) {
    buffer[i] = bytes.charCodeAt(i);
  }
  return buffer;
}

/**
 * Password-based encryption functions.
 *
 * @author Dave Longley
 * @author Stefan Siegl <stesie@brokenpipe.de>
 *
 * Copyright (c) 2010-2013 Digital Bazaar, Inc.
 * Copyright (c) 2012 Stefan Siegl <stesie@brokenpipe.de>
 *
 * An EncryptedPrivateKeyInfo:
 *
 * EncryptedPrivateKeyInfo ::= SEQUENCE {
 *   encryptionAlgorithm  EncryptionAlgorithmIdentifier,
 *   encryptedData        EncryptedData }
 *
 * EncryptionAlgorithmIdentifier ::= AlgorithmIdentifier
 *
 * EncryptedData ::= OCTET STRING
 */

var forge$1 = forge$m;












if(typeof BigInteger === 'undefined') {
  var BigInteger = forge$1.jsbn.BigInteger;
}

// shortcut for asn.1 API
var asn1 = forge$1.asn1;

/* Password-based encryption implementation. */
var pki = forge$1.pki = forge$1.pki || {};
pki.pbe = forge$1.pbe = forge$1.pbe || {};
var oids = pki.oids;

// validator for an EncryptedPrivateKeyInfo structure
// Note: Currently only works w/algorithm params
var encryptedPrivateKeyValidator = {
  name: 'EncryptedPrivateKeyInfo',
  tagClass: asn1.Class.UNIVERSAL,
  type: asn1.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'EncryptedPrivateKeyInfo.encryptionAlgorithm',
    tagClass: asn1.Class.UNIVERSAL,
    type: asn1.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'AlgorithmIdentifier.algorithm',
      tagClass: asn1.Class.UNIVERSAL,
      type: asn1.Type.OID,
      constructed: false,
      capture: 'encryptionOid'
    }, {
      name: 'AlgorithmIdentifier.parameters',
      tagClass: asn1.Class.UNIVERSAL,
      type: asn1.Type.SEQUENCE,
      constructed: true,
      captureAsn1: 'encryptionParams'
    }]
  }, {
    // encryptedData
    name: 'EncryptedPrivateKeyInfo.encryptedData',
    tagClass: asn1.Class.UNIVERSAL,
    type: asn1.Type.OCTETSTRING,
    constructed: false,
    capture: 'encryptedData'
  }]
};

// validator for a PBES2Algorithms structure
// Note: Currently only works w/PBKDF2 + AES encryption schemes
var PBES2AlgorithmsValidator = {
  name: 'PBES2Algorithms',
  tagClass: asn1.Class.UNIVERSAL,
  type: asn1.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'PBES2Algorithms.keyDerivationFunc',
    tagClass: asn1.Class.UNIVERSAL,
    type: asn1.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'PBES2Algorithms.keyDerivationFunc.oid',
      tagClass: asn1.Class.UNIVERSAL,
      type: asn1.Type.OID,
      constructed: false,
      capture: 'kdfOid'
    }, {
      name: 'PBES2Algorithms.params',
      tagClass: asn1.Class.UNIVERSAL,
      type: asn1.Type.SEQUENCE,
      constructed: true,
      value: [{
        name: 'PBES2Algorithms.params.salt',
        tagClass: asn1.Class.UNIVERSAL,
        type: asn1.Type.OCTETSTRING,
        constructed: false,
        capture: 'kdfSalt'
      }, {
        name: 'PBES2Algorithms.params.iterationCount',
        tagClass: asn1.Class.UNIVERSAL,
        type: asn1.Type.INTEGER,
        constructed: false,
        capture: 'kdfIterationCount'
      }, {
        name: 'PBES2Algorithms.params.keyLength',
        tagClass: asn1.Class.UNIVERSAL,
        type: asn1.Type.INTEGER,
        constructed: false,
        optional: true,
        capture: 'keyLength'
      }, {
        // prf
        name: 'PBES2Algorithms.params.prf',
        tagClass: asn1.Class.UNIVERSAL,
        type: asn1.Type.SEQUENCE,
        constructed: true,
        optional: true,
        value: [{
          name: 'PBES2Algorithms.params.prf.algorithm',
          tagClass: asn1.Class.UNIVERSAL,
          type: asn1.Type.OID,
          constructed: false,
          capture: 'prfOid'
        }]
      }]
    }]
  }, {
    name: 'PBES2Algorithms.encryptionScheme',
    tagClass: asn1.Class.UNIVERSAL,
    type: asn1.Type.SEQUENCE,
    constructed: true,
    value: [{
      name: 'PBES2Algorithms.encryptionScheme.oid',
      tagClass: asn1.Class.UNIVERSAL,
      type: asn1.Type.OID,
      constructed: false,
      capture: 'encOid'
    }, {
      name: 'PBES2Algorithms.encryptionScheme.iv',
      tagClass: asn1.Class.UNIVERSAL,
      type: asn1.Type.OCTETSTRING,
      constructed: false,
      capture: 'encIv'
    }]
  }]
};

var pkcs12PbeParamsValidator = {
  name: 'pkcs-12PbeParams',
  tagClass: asn1.Class.UNIVERSAL,
  type: asn1.Type.SEQUENCE,
  constructed: true,
  value: [{
    name: 'pkcs-12PbeParams.salt',
    tagClass: asn1.Class.UNIVERSAL,
    type: asn1.Type.OCTETSTRING,
    constructed: false,
    capture: 'salt'
  }, {
    name: 'pkcs-12PbeParams.iterations',
    tagClass: asn1.Class.UNIVERSAL,
    type: asn1.Type.INTEGER,
    constructed: false,
    capture: 'iterations'
  }]
};

/**
 * Encrypts a ASN.1 PrivateKeyInfo object, producing an EncryptedPrivateKeyInfo.
 *
 * PBES2Algorithms ALGORITHM-IDENTIFIER ::=
 *   { {PBES2-params IDENTIFIED BY id-PBES2}, ...}
 *
 * id-PBES2 OBJECT IDENTIFIER ::= {pkcs-5 13}
 *
 * PBES2-params ::= SEQUENCE {
 *   keyDerivationFunc AlgorithmIdentifier {{PBES2-KDFs}},
 *   encryptionScheme AlgorithmIdentifier {{PBES2-Encs}}
 * }
 *
 * PBES2-KDFs ALGORITHM-IDENTIFIER ::=
 *   { {PBKDF2-params IDENTIFIED BY id-PBKDF2}, ... }
 *
 * PBES2-Encs ALGORITHM-IDENTIFIER ::= { ... }
 *
 * PBKDF2-params ::= SEQUENCE {
 *   salt CHOICE {
 *     specified OCTET STRING,
 *     otherSource AlgorithmIdentifier {{PBKDF2-SaltSources}}
 *   },
 *   iterationCount INTEGER (1..MAX),
 *   keyLength INTEGER (1..MAX) OPTIONAL,
 *   prf AlgorithmIdentifier {{PBKDF2-PRFs}} DEFAULT algid-hmacWithSHA1
 * }
 *
 * @param obj the ASN.1 PrivateKeyInfo object.
 * @param password the password to encrypt with.
 * @param options:
 *          algorithm the encryption algorithm to use
 *            ('aes128', 'aes192', 'aes256', '3des'), defaults to 'aes128'.
 *          count the iteration count to use.
 *          saltSize the salt size to use.
 *          prfAlgorithm the PRF message digest algorithm to use
 *            ('sha1', 'sha224', 'sha256', 'sha384', 'sha512')
 *
 * @return the ASN.1 EncryptedPrivateKeyInfo.
 */
pki.encryptPrivateKeyInfo = function(obj, password, options) {
  // set default options
  options = options || {};
  options.saltSize = options.saltSize || 8;
  options.count = options.count || 2048;
  options.algorithm = options.algorithm || 'aes128';
  options.prfAlgorithm = options.prfAlgorithm || 'sha1';

  // generate PBE params
  var salt = forge$1.random.getBytesSync(options.saltSize);
  var count = options.count;
  var countBytes = asn1.integerToDer(count);
  var dkLen;
  var encryptionAlgorithm;
  var encryptedData;
  if(options.algorithm.indexOf('aes') === 0 || options.algorithm === 'des') {
    // do PBES2
    var ivLen, encOid, cipherFn;
    switch(options.algorithm) {
    case 'aes128':
      dkLen = 16;
      ivLen = 16;
      encOid = oids['aes128-CBC'];
      cipherFn = forge$1.aes.createEncryptionCipher;
      break;
    case 'aes192':
      dkLen = 24;
      ivLen = 16;
      encOid = oids['aes192-CBC'];
      cipherFn = forge$1.aes.createEncryptionCipher;
      break;
    case 'aes256':
      dkLen = 32;
      ivLen = 16;
      encOid = oids['aes256-CBC'];
      cipherFn = forge$1.aes.createEncryptionCipher;
      break;
    case 'des':
      dkLen = 8;
      ivLen = 8;
      encOid = oids['desCBC'];
      cipherFn = forge$1.des.createEncryptionCipher;
      break;
    default:
      var error = new Error('Cannot encrypt private key. Unknown encryption algorithm.');
      error.algorithm = options.algorithm;
      throw error;
    }

    // get PRF message digest
    var prfAlgorithm = 'hmacWith' + options.prfAlgorithm.toUpperCase();
    var md = prfAlgorithmToMessageDigest(prfAlgorithm);

    // encrypt private key using pbe SHA-1 and AES/DES
    var dk = forge$1.pkcs5.pbkdf2(password, salt, count, dkLen, md);
    var iv = forge$1.random.getBytesSync(ivLen);
    var cipher = cipherFn(dk);
    cipher.start(iv);
    cipher.update(asn1.toDer(obj));
    cipher.finish();
    encryptedData = cipher.output.getBytes();

    // get PBKDF2-params
    var params = createPbkdf2Params(salt, countBytes, dkLen, prfAlgorithm);

    encryptionAlgorithm = asn1.create(
      asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
        asn1.oidToDer(oids['pkcs5PBES2']).getBytes()),
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
        // keyDerivationFunc
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
            asn1.oidToDer(oids['pkcs5PBKDF2']).getBytes()),
          // PBKDF2-params
          params
        ]),
        // encryptionScheme
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
          asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
            asn1.oidToDer(encOid).getBytes()),
          // iv
          asn1.create(
            asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, iv)
        ])
      ])
    ]);
  } else if(options.algorithm === '3des') {
    // Do PKCS12 PBE
    dkLen = 24;

    var saltBytes = new forge$1.util.ByteBuffer(salt);
    var dk = pki.pbe.generatePkcs12Key(password, saltBytes, 1, count, dkLen);
    var iv = pki.pbe.generatePkcs12Key(password, saltBytes, 2, count, dkLen);
    var cipher = forge$1.des.createEncryptionCipher(dk);
    cipher.start(iv);
    cipher.update(asn1.toDer(obj));
    cipher.finish();
    encryptedData = cipher.output.getBytes();

    encryptionAlgorithm = asn1.create(
      asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
        asn1.oidToDer(oids['pbeWithSHAAnd3-KeyTripleDES-CBC']).getBytes()),
      // pkcs-12PbeParams
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
        // salt
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, salt),
        // iteration count
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
          countBytes.getBytes())
      ])
    ]);
  } else {
    var error = new Error('Cannot encrypt private key. Unknown encryption algorithm.');
    error.algorithm = options.algorithm;
    throw error;
  }

  // EncryptedPrivateKeyInfo
  var rval = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
    // encryptionAlgorithm
    encryptionAlgorithm,
    // encryptedData
    asn1.create(
      asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, encryptedData)
  ]);
  return rval;
};

/**
 * Decrypts a ASN.1 PrivateKeyInfo object.
 *
 * @param obj the ASN.1 EncryptedPrivateKeyInfo object.
 * @param password the password to decrypt with.
 *
 * @return the ASN.1 PrivateKeyInfo on success, null on failure.
 */
pki.decryptPrivateKeyInfo = function(obj, password) {
  var rval = null;

  // get PBE params
  var capture = {};
  var errors = [];
  if(!asn1.validate(obj, encryptedPrivateKeyValidator, capture, errors)) {
    var error = new Error('Cannot read encrypted private key. ' +
      'ASN.1 object is not a supported EncryptedPrivateKeyInfo.');
    error.errors = errors;
    throw error;
  }

  // get cipher
  var oid = asn1.derToOid(capture.encryptionOid);
  var cipher = pki.pbe.getCipher(oid, capture.encryptionParams, password);

  // get encrypted data
  var encrypted = forge$1.util.createBuffer(capture.encryptedData);

  cipher.update(encrypted);
  if(cipher.finish()) {
    rval = asn1.fromDer(cipher.output);
  }

  return rval;
};

/**
 * Converts a EncryptedPrivateKeyInfo to PEM format.
 *
 * @param epki the EncryptedPrivateKeyInfo.
 * @param maxline the maximum characters per line, defaults to 64.
 *
 * @return the PEM-formatted encrypted private key.
 */
pki.encryptedPrivateKeyToPem = function(epki, maxline) {
  // convert to DER, then PEM-encode
  var msg = {
    type: 'ENCRYPTED PRIVATE KEY',
    body: asn1.toDer(epki).getBytes()
  };
  return forge$1.pem.encode(msg, {maxline: maxline});
};

/**
 * Converts a PEM-encoded EncryptedPrivateKeyInfo to ASN.1 format. Decryption
 * is not performed.
 *
 * @param pem the EncryptedPrivateKeyInfo in PEM-format.
 *
 * @return the ASN.1 EncryptedPrivateKeyInfo.
 */
pki.encryptedPrivateKeyFromPem = function(pem) {
  var msg = forge$1.pem.decode(pem)[0];

  if(msg.type !== 'ENCRYPTED PRIVATE KEY') {
    var error = new Error('Could not convert encrypted private key from PEM; ' +
      'PEM header type is "ENCRYPTED PRIVATE KEY".');
    error.headerType = msg.type;
    throw error;
  }
  if(msg.procType && msg.procType.type === 'ENCRYPTED') {
    throw new Error('Could not convert encrypted private key from PEM; ' +
      'PEM is encrypted.');
  }

  // convert DER to ASN.1 object
  return asn1.fromDer(msg.body);
};

/**
 * Encrypts an RSA private key. By default, the key will be wrapped in
 * a PrivateKeyInfo and encrypted to produce a PKCS#8 EncryptedPrivateKeyInfo.
 * This is the standard, preferred way to encrypt a private key.
 *
 * To produce a non-standard PEM-encrypted private key that uses encapsulated
 * headers to indicate the encryption algorithm (old-style non-PKCS#8 OpenSSL
 * private key encryption), set the 'legacy' option to true. Note: Using this
 * option will cause the iteration count to be forced to 1.
 *
 * Note: The 'des' algorithm is supported, but it is not considered to be
 * secure because it only uses a single 56-bit key. If possible, it is highly
 * recommended that a different algorithm be used.
 *
 * @param rsaKey the RSA key to encrypt.
 * @param password the password to use.
 * @param options:
 *          algorithm: the encryption algorithm to use
 *            ('aes128', 'aes192', 'aes256', '3des', 'des').
 *          count: the iteration count to use.
 *          saltSize: the salt size to use.
 *          legacy: output an old non-PKCS#8 PEM-encrypted+encapsulated
 *            headers (DEK-Info) private key.
 *
 * @return the PEM-encoded ASN.1 EncryptedPrivateKeyInfo.
 */
pki.encryptRsaPrivateKey = function(rsaKey, password, options) {
  // standard PKCS#8
  options = options || {};
  if(!options.legacy) {
    // encrypt PrivateKeyInfo
    var rval = pki.wrapRsaPrivateKey(pki.privateKeyToAsn1(rsaKey));
    rval = pki.encryptPrivateKeyInfo(rval, password, options);
    return pki.encryptedPrivateKeyToPem(rval);
  }

  // legacy non-PKCS#8
  var algorithm;
  var iv;
  var dkLen;
  var cipherFn;
  switch(options.algorithm) {
  case 'aes128':
    algorithm = 'AES-128-CBC';
    dkLen = 16;
    iv = forge$1.random.getBytesSync(16);
    cipherFn = forge$1.aes.createEncryptionCipher;
    break;
  case 'aes192':
    algorithm = 'AES-192-CBC';
    dkLen = 24;
    iv = forge$1.random.getBytesSync(16);
    cipherFn = forge$1.aes.createEncryptionCipher;
    break;
  case 'aes256':
    algorithm = 'AES-256-CBC';
    dkLen = 32;
    iv = forge$1.random.getBytesSync(16);
    cipherFn = forge$1.aes.createEncryptionCipher;
    break;
  case '3des':
    algorithm = 'DES-EDE3-CBC';
    dkLen = 24;
    iv = forge$1.random.getBytesSync(8);
    cipherFn = forge$1.des.createEncryptionCipher;
    break;
  case 'des':
    algorithm = 'DES-CBC';
    dkLen = 8;
    iv = forge$1.random.getBytesSync(8);
    cipherFn = forge$1.des.createEncryptionCipher;
    break;
  default:
    var error = new Error('Could not encrypt RSA private key; unsupported ' +
      'encryption algorithm "' + options.algorithm + '".');
    error.algorithm = options.algorithm;
    throw error;
  }

  // encrypt private key using OpenSSL legacy key derivation
  var dk = forge$1.pbe.opensslDeriveBytes(password, iv.substr(0, 8), dkLen);
  var cipher = cipherFn(dk);
  cipher.start(iv);
  cipher.update(asn1.toDer(pki.privateKeyToAsn1(rsaKey)));
  cipher.finish();

  var msg = {
    type: 'RSA PRIVATE KEY',
    procType: {
      version: '4',
      type: 'ENCRYPTED'
    },
    dekInfo: {
      algorithm: algorithm,
      parameters: forge$1.util.bytesToHex(iv).toUpperCase()
    },
    body: cipher.output.getBytes()
  };
  return forge$1.pem.encode(msg);
};

/**
 * Decrypts an RSA private key.
 *
 * @param pem the PEM-formatted EncryptedPrivateKeyInfo to decrypt.
 * @param password the password to use.
 *
 * @return the RSA key on success, null on failure.
 */
pki.decryptRsaPrivateKey = function(pem, password) {
  var rval = null;

  var msg = forge$1.pem.decode(pem)[0];

  if(msg.type !== 'ENCRYPTED PRIVATE KEY' &&
    msg.type !== 'PRIVATE KEY' &&
    msg.type !== 'RSA PRIVATE KEY') {
    var error = new Error('Could not convert private key from PEM; PEM header type ' +
      'is not "ENCRYPTED PRIVATE KEY", "PRIVATE KEY", or "RSA PRIVATE KEY".');
    error.headerType = error;
    throw error;
  }

  if(msg.procType && msg.procType.type === 'ENCRYPTED') {
    var dkLen;
    var cipherFn;
    switch(msg.dekInfo.algorithm) {
    case 'DES-CBC':
      dkLen = 8;
      cipherFn = forge$1.des.createDecryptionCipher;
      break;
    case 'DES-EDE3-CBC':
      dkLen = 24;
      cipherFn = forge$1.des.createDecryptionCipher;
      break;
    case 'AES-128-CBC':
      dkLen = 16;
      cipherFn = forge$1.aes.createDecryptionCipher;
      break;
    case 'AES-192-CBC':
      dkLen = 24;
      cipherFn = forge$1.aes.createDecryptionCipher;
      break;
    case 'AES-256-CBC':
      dkLen = 32;
      cipherFn = forge$1.aes.createDecryptionCipher;
      break;
    case 'RC2-40-CBC':
      dkLen = 5;
      cipherFn = function(key) {
        return forge$1.rc2.createDecryptionCipher(key, 40);
      };
      break;
    case 'RC2-64-CBC':
      dkLen = 8;
      cipherFn = function(key) {
        return forge$1.rc2.createDecryptionCipher(key, 64);
      };
      break;
    case 'RC2-128-CBC':
      dkLen = 16;
      cipherFn = function(key) {
        return forge$1.rc2.createDecryptionCipher(key, 128);
      };
      break;
    default:
      var error = new Error('Could not decrypt private key; unsupported ' +
        'encryption algorithm "' + msg.dekInfo.algorithm + '".');
      error.algorithm = msg.dekInfo.algorithm;
      throw error;
    }

    // use OpenSSL legacy key derivation
    var iv = forge$1.util.hexToBytes(msg.dekInfo.parameters);
    var dk = forge$1.pbe.opensslDeriveBytes(password, iv.substr(0, 8), dkLen);
    var cipher = cipherFn(dk);
    cipher.start(iv);
    cipher.update(forge$1.util.createBuffer(msg.body));
    if(cipher.finish()) {
      rval = cipher.output.getBytes();
    } else {
      return rval;
    }
  } else {
    rval = msg.body;
  }

  if(msg.type === 'ENCRYPTED PRIVATE KEY') {
    rval = pki.decryptPrivateKeyInfo(asn1.fromDer(rval), password);
  } else {
    // decryption already performed above
    rval = asn1.fromDer(rval);
  }

  if(rval !== null) {
    rval = pki.privateKeyFromAsn1(rval);
  }

  return rval;
};

/**
 * Derives a PKCS#12 key.
 *
 * @param password the password to derive the key material from, null or
 *          undefined for none.
 * @param salt the salt, as a ByteBuffer, to use.
 * @param id the PKCS#12 ID byte (1 = key material, 2 = IV, 3 = MAC).
 * @param iter the iteration count.
 * @param n the number of bytes to derive from the password.
 * @param md the message digest to use, defaults to SHA-1.
 *
 * @return a ByteBuffer with the bytes derived from the password.
 */
pki.pbe.generatePkcs12Key = function(password, salt, id, iter, n, md) {
  var j, l;

  if(typeof md === 'undefined' || md === null) {
    if(!('sha1' in forge$1.md)) {
      throw new Error('"sha1" hash algorithm unavailable.');
    }
    md = forge$1.md.sha1.create();
  }

  var u = md.digestLength;
  var v = md.blockLength;
  var result = new forge$1.util.ByteBuffer();

  /* Convert password to Unicode byte buffer + trailing 0-byte. */
  var passBuf = new forge$1.util.ByteBuffer();
  if(password !== null && password !== undefined) {
    for(l = 0; l < password.length; l++) {
      passBuf.putInt16(password.charCodeAt(l));
    }
    passBuf.putInt16(0);
  }

  /* Length of salt and password in BYTES. */
  var p = passBuf.length();
  var s = salt.length();

  /* 1. Construct a string, D (the "diversifier"), by concatenating
        v copies of ID. */
  var D = new forge$1.util.ByteBuffer();
  D.fillWithByte(id, v);

  /* 2. Concatenate copies of the salt together to create a string S of length
        v * ceil(s / v) bytes (the final copy of the salt may be trunacted
        to create S).
        Note that if the salt is the empty string, then so is S. */
  var Slen = v * Math.ceil(s / v);
  var S = new forge$1.util.ByteBuffer();
  for(l = 0; l < Slen; l++) {
    S.putByte(salt.at(l % s));
  }

  /* 3. Concatenate copies of the password together to create a string P of
        length v * ceil(p / v) bytes (the final copy of the password may be
        truncated to create P).
        Note that if the password is the empty string, then so is P. */
  var Plen = v * Math.ceil(p / v);
  var P = new forge$1.util.ByteBuffer();
  for(l = 0; l < Plen; l++) {
    P.putByte(passBuf.at(l % p));
  }

  /* 4. Set I=S||P to be the concatenation of S and P. */
  var I = S;
  I.putBuffer(P);

  /* 5. Set c=ceil(n / u). */
  var c = Math.ceil(n / u);

  /* 6. For i=1, 2, ..., c, do the following: */
  for(var i = 1; i <= c; i++) {
    /* a) Set Ai=H^r(D||I). (l.e. the rth hash of D||I, H(H(H(...H(D||I)))) */
    var buf = new forge$1.util.ByteBuffer();
    buf.putBytes(D.bytes());
    buf.putBytes(I.bytes());
    for(var round = 0; round < iter; round++) {
      md.start();
      md.update(buf.getBytes());
      buf = md.digest();
    }

    /* b) Concatenate copies of Ai to create a string B of length v bytes (the
          final copy of Ai may be truncated to create B). */
    var B = new forge$1.util.ByteBuffer();
    for(l = 0; l < v; l++) {
      B.putByte(buf.at(l % u));
    }

    /* c) Treating I as a concatenation I0, I1, ..., Ik-1 of v-byte blocks,
          where k=ceil(s / v) + ceil(p / v), modify I by setting
          Ij=(Ij+B+1) mod 2v for each j.  */
    var k = Math.ceil(s / v) + Math.ceil(p / v);
    var Inew = new forge$1.util.ByteBuffer();
    for(j = 0; j < k; j++) {
      var chunk = new forge$1.util.ByteBuffer(I.getBytes(v));
      var x = 0x1ff;
      for(l = B.length() - 1; l >= 0; l--) {
        x = x >> 8;
        x += B.at(l) + chunk.at(l);
        chunk.setAt(l, x & 0xff);
      }
      Inew.putBuffer(chunk);
    }
    I = Inew;

    /* Add Ai to A. */
    result.putBuffer(buf);
  }

  result.truncate(result.length() - n);
  return result;
};

/**
 * Get new Forge cipher object instance.
 *
 * @param oid the OID (in string notation).
 * @param params the ASN.1 params object.
 * @param password the password to decrypt with.
 *
 * @return new cipher object instance.
 */
pki.pbe.getCipher = function(oid, params, password) {
  switch(oid) {
  case pki.oids['pkcs5PBES2']:
    return pki.pbe.getCipherForPBES2(oid, params, password);

  case pki.oids['pbeWithSHAAnd3-KeyTripleDES-CBC']:
  case pki.oids['pbewithSHAAnd40BitRC2-CBC']:
    return pki.pbe.getCipherForPKCS12PBE(oid, params, password);

  default:
    var error = new Error('Cannot read encrypted PBE data block. Unsupported OID.');
    error.oid = oid;
    error.supportedOids = [
      'pkcs5PBES2',
      'pbeWithSHAAnd3-KeyTripleDES-CBC',
      'pbewithSHAAnd40BitRC2-CBC'
    ];
    throw error;
  }
};

/**
 * Get new Forge cipher object instance according to PBES2 params block.
 *
 * The returned cipher instance is already started using the IV
 * from PBES2 parameter block.
 *
 * @param oid the PKCS#5 PBKDF2 OID (in string notation).
 * @param params the ASN.1 PBES2-params object.
 * @param password the password to decrypt with.
 *
 * @return new cipher object instance.
 */
pki.pbe.getCipherForPBES2 = function(oid, params, password) {
  // get PBE params
  var capture = {};
  var errors = [];
  if(!asn1.validate(params, PBES2AlgorithmsValidator, capture, errors)) {
    var error = new Error('Cannot read password-based-encryption algorithm ' +
      'parameters. ASN.1 object is not a supported EncryptedPrivateKeyInfo.');
    error.errors = errors;
    throw error;
  }

  // check oids
  oid = asn1.derToOid(capture.kdfOid);
  if(oid !== pki.oids['pkcs5PBKDF2']) {
    var error = new Error('Cannot read encrypted private key. ' +
      'Unsupported key derivation function OID.');
    error.oid = oid;
    error.supportedOids = ['pkcs5PBKDF2'];
    throw error;
  }
  oid = asn1.derToOid(capture.encOid);
  if(oid !== pki.oids['aes128-CBC'] &&
    oid !== pki.oids['aes192-CBC'] &&
    oid !== pki.oids['aes256-CBC'] &&
    oid !== pki.oids['des-EDE3-CBC'] &&
    oid !== pki.oids['desCBC']) {
    var error = new Error('Cannot read encrypted private key. ' +
      'Unsupported encryption scheme OID.');
    error.oid = oid;
    error.supportedOids = [
      'aes128-CBC', 'aes192-CBC', 'aes256-CBC', 'des-EDE3-CBC', 'desCBC'];
    throw error;
  }

  // set PBE params
  var salt = capture.kdfSalt;
  var count = forge$1.util.createBuffer(capture.kdfIterationCount);
  count = count.getInt(count.length() << 3);
  var dkLen;
  var cipherFn;
  switch(pki.oids[oid]) {
  case 'aes128-CBC':
    dkLen = 16;
    cipherFn = forge$1.aes.createDecryptionCipher;
    break;
  case 'aes192-CBC':
    dkLen = 24;
    cipherFn = forge$1.aes.createDecryptionCipher;
    break;
  case 'aes256-CBC':
    dkLen = 32;
    cipherFn = forge$1.aes.createDecryptionCipher;
    break;
  case 'des-EDE3-CBC':
    dkLen = 24;
    cipherFn = forge$1.des.createDecryptionCipher;
    break;
  case 'desCBC':
    dkLen = 8;
    cipherFn = forge$1.des.createDecryptionCipher;
    break;
  }

  // get PRF message digest
  var md = prfOidToMessageDigest(capture.prfOid);

  // decrypt private key using pbe with chosen PRF and AES/DES
  var dk = forge$1.pkcs5.pbkdf2(password, salt, count, dkLen, md);
  var iv = capture.encIv;
  var cipher = cipherFn(dk);
  cipher.start(iv);

  return cipher;
};

/**
 * Get new Forge cipher object instance for PKCS#12 PBE.
 *
 * The returned cipher instance is already started using the key & IV
 * derived from the provided password and PKCS#12 PBE salt.
 *
 * @param oid The PKCS#12 PBE OID (in string notation).
 * @param params The ASN.1 PKCS#12 PBE-params object.
 * @param password The password to decrypt with.
 *
 * @return the new cipher object instance.
 */
pki.pbe.getCipherForPKCS12PBE = function(oid, params, password) {
  // get PBE params
  var capture = {};
  var errors = [];
  if(!asn1.validate(params, pkcs12PbeParamsValidator, capture, errors)) {
    var error = new Error('Cannot read password-based-encryption algorithm ' +
      'parameters. ASN.1 object is not a supported EncryptedPrivateKeyInfo.');
    error.errors = errors;
    throw error;
  }

  var salt = forge$1.util.createBuffer(capture.salt);
  var count = forge$1.util.createBuffer(capture.iterations);
  count = count.getInt(count.length() << 3);

  var dkLen, dIvLen, cipherFn;
  switch(oid) {
    case pki.oids['pbeWithSHAAnd3-KeyTripleDES-CBC']:
      dkLen = 24;
      dIvLen = 8;
      cipherFn = forge$1.des.startDecrypting;
      break;

    case pki.oids['pbewithSHAAnd40BitRC2-CBC']:
      dkLen = 5;
      dIvLen = 8;
      cipherFn = function(key, iv) {
        var cipher = forge$1.rc2.createDecryptionCipher(key, 40);
        cipher.start(iv, null);
        return cipher;
      };
      break;

    default:
      var error = new Error('Cannot read PKCS #12 PBE data block. Unsupported OID.');
      error.oid = oid;
      throw error;
  }

  // get PRF message digest
  var md = prfOidToMessageDigest(capture.prfOid);
  var key = pki.pbe.generatePkcs12Key(password, salt, 1, count, dkLen, md);
  md.start();
  var iv = pki.pbe.generatePkcs12Key(password, salt, 2, count, dIvLen, md);

  return cipherFn(key, iv);
};

/**
 * OpenSSL's legacy key derivation function.
 *
 * See: http://www.openssl.org/docs/crypto/EVP_BytesToKey.html
 *
 * @param password the password to derive the key from.
 * @param salt the salt to use, null for none.
 * @param dkLen the number of bytes needed for the derived key.
 * @param [options] the options to use:
 *          [md] an optional message digest object to use.
 */
pki.pbe.opensslDeriveBytes = function(password, salt, dkLen, md) {
  if(typeof md === 'undefined' || md === null) {
    if(!('md5' in forge$1.md)) {
      throw new Error('"md5" hash algorithm unavailable.');
    }
    md = forge$1.md.md5.create();
  }
  if(salt === null) {
    salt = '';
  }
  var digests = [hash(md, password + salt)];
  for(var length = 16, i = 1; length < dkLen; ++i, length += 16) {
    digests.push(hash(md, digests[i - 1] + password + salt));
  }
  return digests.join('').substr(0, dkLen);
};

function hash(md, bytes) {
  return md.start().update(bytes).digest().getBytes();
}

function prfOidToMessageDigest(prfOid) {
  // get PRF algorithm, default to SHA-1
  var prfAlgorithm;
  if(!prfOid) {
    prfAlgorithm = 'hmacWithSHA1';
  } else {
    prfAlgorithm = pki.oids[asn1.derToOid(prfOid)];
    if(!prfAlgorithm) {
      var error = new Error('Unsupported PRF OID.');
      error.oid = prfOid;
      error.supported = [
        'hmacWithSHA1', 'hmacWithSHA224', 'hmacWithSHA256', 'hmacWithSHA384',
        'hmacWithSHA512'];
      throw error;
    }
  }
  return prfAlgorithmToMessageDigest(prfAlgorithm);
}

function prfAlgorithmToMessageDigest(prfAlgorithm) {
  var factory = forge$1.md;
  switch(prfAlgorithm) {
  case 'hmacWithSHA224':
    factory = forge$1.md.sha512;
  case 'hmacWithSHA1':
  case 'hmacWithSHA256':
  case 'hmacWithSHA384':
  case 'hmacWithSHA512':
    prfAlgorithm = prfAlgorithm.substr(8).toLowerCase();
    break;
  default:
    var error = new Error('Unsupported PRF algorithm.');
    error.algorithm = prfAlgorithm;
    error.supported = [
      'hmacWithSHA1', 'hmacWithSHA224', 'hmacWithSHA256', 'hmacWithSHA384',
      'hmacWithSHA512'];
    throw error;
  }
  if(!factory || !(prfAlgorithm in factory)) {
    throw new Error('Unknown hash algorithm: ' + prfAlgorithm);
  }
  return factory[prfAlgorithm].create();
}

function createPbkdf2Params(salt, countBytes, dkLen, prfAlgorithm) {
  var params = asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
    // salt
    asn1.create(
      asn1.Class.UNIVERSAL, asn1.Type.OCTETSTRING, false, salt),
    // iteration count
    asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
      countBytes.getBytes())
  ]);
  // when PRF algorithm is not SHA-1 default, add key length and PRF algorithm
  if(prfAlgorithm !== 'hmacWithSHA1') {
    params.value.push(
      // key length
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.INTEGER, false,
        forge$1.util.hexToBytes(dkLen.toString(16))),
      // AlgorithmIdentifier
      asn1.create(asn1.Class.UNIVERSAL, asn1.Type.SEQUENCE, true, [
        // algorithm
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.OID, false,
          asn1.oidToDer(pki.oids[prfAlgorithm]).getBytes()),
        // parameters (null)
        asn1.create(asn1.Class.UNIVERSAL, asn1.Type.NULL, false, '')
      ]));
  }
  return params;
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$d (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$c = base$d;

var _brrp__multiformats_scope_baseX$c = src$c;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$c = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$d = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$d = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$d(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$c = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$d(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$d = (left, right) => new ComposedDecoder$c(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$c = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$d(name, prefix, baseEncode);
    this.decoder = new Decoder$d(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$l = ({ name, prefix, encode, decode }) =>
  new Codec$c(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$c = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$c(alphabet, name);
  return from$l({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$c(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$u = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$A = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$c = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$l({
    prefix,
    name,
    encode (input) {
      return encode$A(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$u(input, alphabet, bitsPerChar, name)
    }
  })
};

const base58btc$b = baseX$c({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$c({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var encode_1$7 = encode$z;

var MSB$9 = 0x80
  , REST$9 = 0x7F
  , MSBALL$7 = ~REST$9
  , INT$7 = Math.pow(2, 31);

function encode$z(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$7) {
    out[offset++] = (num & 0xFF) | MSB$9;
    num /= 128;
  }
  while(num & MSBALL$7) {
    out[offset++] = (num & 0xFF) | MSB$9;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$z.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$t = read$8;

var MSB$1$7 = 0x80
  , REST$1$7 = 0x7F;

function read$8(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$8.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$7) << shift
      : (b & REST$1$7) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$7)

  read$8.bytes = counter - offset;

  return res
}

var N1$7 = Math.pow(2,  7);
var N2$7 = Math.pow(2, 14);
var N3$7 = Math.pow(2, 21);
var N4$7 = Math.pow(2, 28);
var N5$7 = Math.pow(2, 35);
var N6$7 = Math.pow(2, 42);
var N7$7 = Math.pow(2, 49);
var N8$7 = Math.pow(2, 56);
var N9$7 = Math.pow(2, 63);

var length$7 = function (value) {
  return (
    value < N1$7 ? 1
  : value < N2$7 ? 2
  : value < N3$7 ? 3
  : value < N4$7 ? 4
  : value < N5$7 ? 5
  : value < N6$7 ? 6
  : value < N7$7 ? 7
  : value < N8$7 ? 8
  : value < N9$7 ? 9
  :              10
  )
};

var varint$7 = {
    encode: encode_1$7
  , decode: decode$t
  , encodingLength: length$7
};

var _brrp_varint$7 = varint$7;

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo$7 = (int, target, offset = 0) => {
  _brrp_varint$7.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$9 = (int) => {
  return _brrp_varint$7.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$e = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$9(code);
  const digestOffset = sizeOffset + encodingLength$9(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo$7(code, bytes, 0);
  encodeTo$7(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest$7(code, size, digest, bytes)
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
let Digest$7 = class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
};

const code$7 = 0x0;
const name$8 = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$y = coerce$c;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest$7 = (input) => create$e(code$7, encode$y(input));

const identity$9 = { code: code$7, name: name$8, encode: encode$y, digest: digest$7 };

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$k = ({ name, code, encode }) => new Hasher$7(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
let Hasher$7 = class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$e(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$e(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
};

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */


/**
 * @param {AlgorithmIdentifier} name
 */
const sha$7 = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256$8 = from$k({
  name: 'sha2-256',
  code: 0x12,
  encode: sha$7('SHA-256')
});

/*! noble-ed25519 - MIT License (c) 2019 Paul Miller (paulmillr.com) */
const _0n$2 = BigInt(0);
const _1n$3 = BigInt(1);
const _2n$2 = BigInt(2);
const _8n$1 = BigInt(8);
const CU_O = BigInt('7237005577332262213973186563042994240857116359379907606001950938285454250989');
const CURVE$1 = Object.freeze({
    a: BigInt(-1),
    d: BigInt('37095705934669439343138083508754565189542113879843219016388785533085940283555'),
    P: BigInt('57896044618658097711785492504343953926634992332820282019728792003956564819949'),
    l: CU_O,
    n: CU_O,
    h: BigInt(8),
    Gx: BigInt('15112221349535400772501151409588531511454012693041857206046113283949847762202'),
    Gy: BigInt('46316835694926478169428394003475163141307993866256225615783033603165251855960'),
});
const POW_2_256$1 = BigInt('0x10000000000000000000000000000000000000000000000000000000000000000');
const SQRT_M1 = BigInt('19681161376707505956807079304988542015446066515923890162744021073123829784752');
BigInt('6853475219497561581579357271197624642482790079785650197046958215289687604742');
const SQRT_AD_MINUS_ONE = BigInt('25063068953384623474111414158702152701244531502492656460079210482610430750235');
const INVSQRT_A_MINUS_D = BigInt('54469307008909316920995813868745141605393597292927456921205312896311721017578');
const ONE_MINUS_D_SQ = BigInt('1159843021668779879193775521855586647937357759715417654439879720876111806838');
const D_MINUS_ONE_SQ = BigInt('40440834346308536858101042469323190826248399146238708352240133220865137265952');
class ExtendedPoint {
    constructor(x, y, z, t) {
        this.x = x;
        this.y = y;
        this.z = z;
        this.t = t;
    }
    static fromAffine(p) {
        if (!(p instanceof Point$1)) {
            throw new TypeError('ExtendedPoint#fromAffine: expected Point');
        }
        if (p.equals(Point$1.ZERO))
            return ExtendedPoint.ZERO;
        return new ExtendedPoint(p.x, p.y, _1n$3, mod$1(p.x * p.y));
    }
    static toAffineBatch(points) {
        const toInv = invertBatch$1(points.map((p) => p.z));
        return points.map((p, i) => p.toAffine(toInv[i]));
    }
    static normalizeZ(points) {
        return this.toAffineBatch(points).map(this.fromAffine);
    }
    equals(other) {
        assertExtPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        const X1Z2 = mod$1(X1 * Z2);
        const X2Z1 = mod$1(X2 * Z1);
        const Y1Z2 = mod$1(Y1 * Z2);
        const Y2Z1 = mod$1(Y2 * Z1);
        return X1Z2 === X2Z1 && Y1Z2 === Y2Z1;
    }
    negate() {
        return new ExtendedPoint(mod$1(-this.x), this.y, this.z, mod$1(-this.t));
    }
    double() {
        const { x: X1, y: Y1, z: Z1 } = this;
        const { a } = CURVE$1;
        const A = mod$1(X1 * X1);
        const B = mod$1(Y1 * Y1);
        const C = mod$1(_2n$2 * mod$1(Z1 * Z1));
        const D = mod$1(a * A);
        const x1y1 = X1 + Y1;
        const E = mod$1(mod$1(x1y1 * x1y1) - A - B);
        const G = D + B;
        const F = G - C;
        const H = D - B;
        const X3 = mod$1(E * F);
        const Y3 = mod$1(G * H);
        const T3 = mod$1(E * H);
        const Z3 = mod$1(F * G);
        return new ExtendedPoint(X3, Y3, Z3, T3);
    }
    add(other) {
        assertExtPoint(other);
        const { x: X1, y: Y1, z: Z1, t: T1 } = this;
        const { x: X2, y: Y2, z: Z2, t: T2 } = other;
        const A = mod$1((Y1 - X1) * (Y2 + X2));
        const B = mod$1((Y1 + X1) * (Y2 - X2));
        const F = mod$1(B - A);
        if (F === _0n$2)
            return this.double();
        const C = mod$1(Z1 * _2n$2 * T2);
        const D = mod$1(T1 * _2n$2 * Z2);
        const E = D + C;
        const G = B + A;
        const H = D - C;
        const X3 = mod$1(E * F);
        const Y3 = mod$1(G * H);
        const T3 = mod$1(E * H);
        const Z3 = mod$1(F * G);
        return new ExtendedPoint(X3, Y3, Z3, T3);
    }
    subtract(other) {
        return this.add(other.negate());
    }
    precomputeWindow(W) {
        const windows = 1 + 256 / W;
        const points = [];
        let p = this;
        let base = p;
        for (let window = 0; window < windows; window++) {
            base = p;
            points.push(base);
            for (let i = 1; i < 2 ** (W - 1); i++) {
                base = base.add(p);
                points.push(base);
            }
            p = base.double();
        }
        return points;
    }
    wNAF(n, affinePoint) {
        if (!affinePoint && this.equals(ExtendedPoint.BASE))
            affinePoint = Point$1.BASE;
        const W = (affinePoint && affinePoint._WINDOW_SIZE) || 1;
        if (256 % W) {
            throw new Error('Point#wNAF: Invalid precomputation window, must be power of 2');
        }
        let precomputes = affinePoint && pointPrecomputes$1.get(affinePoint);
        if (!precomputes) {
            precomputes = this.precomputeWindow(W);
            if (affinePoint && W !== 1) {
                precomputes = ExtendedPoint.normalizeZ(precomputes);
                pointPrecomputes$1.set(affinePoint, precomputes);
            }
        }
        let p = ExtendedPoint.ZERO;
        let f = ExtendedPoint.BASE;
        const windows = 1 + 256 / W;
        const windowSize = 2 ** (W - 1);
        const mask = BigInt(2 ** W - 1);
        const maxNumber = 2 ** W;
        const shiftBy = BigInt(W);
        for (let window = 0; window < windows; window++) {
            const offset = window * windowSize;
            let wbits = Number(n & mask);
            n >>= shiftBy;
            if (wbits > windowSize) {
                wbits -= maxNumber;
                n += _1n$3;
            }
            const offset1 = offset;
            const offset2 = offset + Math.abs(wbits) - 1;
            const cond1 = window % 2 !== 0;
            const cond2 = wbits < 0;
            if (wbits === 0) {
                f = f.add(constTimeNegate$1(cond1, precomputes[offset1]));
            }
            else {
                p = p.add(constTimeNegate$1(cond2, precomputes[offset2]));
            }
        }
        return ExtendedPoint.normalizeZ([p, f])[0];
    }
    multiply(scalar, affinePoint) {
        return this.wNAF(normalizeScalar$1(scalar, CURVE$1.l), affinePoint);
    }
    multiplyUnsafe(scalar) {
        let n = normalizeScalar$1(scalar, CURVE$1.l, false);
        const G = ExtendedPoint.BASE;
        const P0 = ExtendedPoint.ZERO;
        if (n === _0n$2)
            return P0;
        if (this.equals(P0) || n === _1n$3)
            return this;
        if (this.equals(G))
            return this.wNAF(n);
        let p = P0;
        let d = this;
        while (n > _0n$2) {
            if (n & _1n$3)
                p = p.add(d);
            d = d.double();
            n >>= _1n$3;
        }
        return p;
    }
    isSmallOrder() {
        return this.multiplyUnsafe(CURVE$1.h).equals(ExtendedPoint.ZERO);
    }
    isTorsionFree() {
        let p = this.multiplyUnsafe(CURVE$1.l / _2n$2).double();
        if (CURVE$1.l % _2n$2)
            p = p.add(this);
        return p.equals(ExtendedPoint.ZERO);
    }
    toAffine(invZ) {
        const { x, y, z } = this;
        const is0 = this.equals(ExtendedPoint.ZERO);
        if (invZ == null)
            invZ = is0 ? _8n$1 : invert$1(z);
        const ax = mod$1(x * invZ);
        const ay = mod$1(y * invZ);
        const zz = mod$1(z * invZ);
        if (is0)
            return Point$1.ZERO;
        if (zz !== _1n$3)
            throw new Error('invZ was invalid');
        return new Point$1(ax, ay);
    }
    fromRistrettoBytes() {
        legacyRist();
    }
    toRistrettoBytes() {
        legacyRist();
    }
    fromRistrettoHash() {
        legacyRist();
    }
}
ExtendedPoint.BASE = new ExtendedPoint(CURVE$1.Gx, CURVE$1.Gy, _1n$3, mod$1(CURVE$1.Gx * CURVE$1.Gy));
ExtendedPoint.ZERO = new ExtendedPoint(_0n$2, _1n$3, _1n$3, _0n$2);
function constTimeNegate$1(condition, item) {
    const neg = item.negate();
    return condition ? neg : item;
}
function assertExtPoint(other) {
    if (!(other instanceof ExtendedPoint))
        throw new TypeError('ExtendedPoint expected');
}
function assertRstPoint(other) {
    if (!(other instanceof RistrettoPoint))
        throw new TypeError('RistrettoPoint expected');
}
function legacyRist() {
    throw new Error('Legacy method: switch to RistrettoPoint');
}
class RistrettoPoint {
    constructor(ep) {
        this.ep = ep;
    }
    static calcElligatorRistrettoMap(r0) {
        const { d } = CURVE$1;
        const r = mod$1(SQRT_M1 * r0 * r0);
        const Ns = mod$1((r + _1n$3) * ONE_MINUS_D_SQ);
        let c = BigInt(-1);
        const D = mod$1((c - d * r) * mod$1(r + d));
        let { isValid: Ns_D_is_sq, value: s } = uvRatio(Ns, D);
        let s_ = mod$1(s * r0);
        if (!edIsNegative(s_))
            s_ = mod$1(-s_);
        if (!Ns_D_is_sq)
            s = s_;
        if (!Ns_D_is_sq)
            c = r;
        const Nt = mod$1(c * (r - _1n$3) * D_MINUS_ONE_SQ - D);
        const s2 = s * s;
        const W0 = mod$1((s + s) * D);
        const W1 = mod$1(Nt * SQRT_AD_MINUS_ONE);
        const W2 = mod$1(_1n$3 - s2);
        const W3 = mod$1(_1n$3 + s2);
        return new ExtendedPoint(mod$1(W0 * W3), mod$1(W2 * W1), mod$1(W1 * W3), mod$1(W0 * W2));
    }
    static hashToCurve(hex) {
        hex = ensureBytes$1(hex, 64);
        const r1 = bytes255ToNumberLE(hex.slice(0, 32));
        const R1 = this.calcElligatorRistrettoMap(r1);
        const r2 = bytes255ToNumberLE(hex.slice(32, 64));
        const R2 = this.calcElligatorRistrettoMap(r2);
        return new RistrettoPoint(R1.add(R2));
    }
    static fromHex(hex) {
        hex = ensureBytes$1(hex, 32);
        const { a, d } = CURVE$1;
        const emsg = 'RistrettoPoint.fromHex: the hex is not valid encoding of RistrettoPoint';
        const s = bytes255ToNumberLE(hex);
        if (!equalBytes(numberTo32BytesLE(s), hex) || edIsNegative(s))
            throw new Error(emsg);
        const s2 = mod$1(s * s);
        const u1 = mod$1(_1n$3 + a * s2);
        const u2 = mod$1(_1n$3 - a * s2);
        const u1_2 = mod$1(u1 * u1);
        const u2_2 = mod$1(u2 * u2);
        const v = mod$1(a * d * u1_2 - u2_2);
        const { isValid, value: I } = invertSqrt(mod$1(v * u2_2));
        const Dx = mod$1(I * u2);
        const Dy = mod$1(I * Dx * v);
        let x = mod$1((s + s) * Dx);
        if (edIsNegative(x))
            x = mod$1(-x);
        const y = mod$1(u1 * Dy);
        const t = mod$1(x * y);
        if (!isValid || edIsNegative(t) || y === _0n$2)
            throw new Error(emsg);
        return new RistrettoPoint(new ExtendedPoint(x, y, _1n$3, t));
    }
    toRawBytes() {
        let { x, y, z, t } = this.ep;
        const u1 = mod$1(mod$1(z + y) * mod$1(z - y));
        const u2 = mod$1(x * y);
        const u2sq = mod$1(u2 * u2);
        const { value: invsqrt } = invertSqrt(mod$1(u1 * u2sq));
        const D1 = mod$1(invsqrt * u1);
        const D2 = mod$1(invsqrt * u2);
        const zInv = mod$1(D1 * D2 * t);
        let D;
        if (edIsNegative(t * zInv)) {
            let _x = mod$1(y * SQRT_M1);
            let _y = mod$1(x * SQRT_M1);
            x = _x;
            y = _y;
            D = mod$1(D1 * INVSQRT_A_MINUS_D);
        }
        else {
            D = D2;
        }
        if (edIsNegative(x * zInv))
            y = mod$1(-y);
        let s = mod$1((z - y) * D);
        if (edIsNegative(s))
            s = mod$1(-s);
        return numberTo32BytesLE(s);
    }
    toHex() {
        return bytesToHex$1(this.toRawBytes());
    }
    toString() {
        return this.toHex();
    }
    equals(other) {
        assertRstPoint(other);
        const a = this.ep;
        const b = other.ep;
        const one = mod$1(a.x * b.y) === mod$1(a.y * b.x);
        const two = mod$1(a.y * b.y) === mod$1(a.x * b.x);
        return one || two;
    }
    add(other) {
        assertRstPoint(other);
        return new RistrettoPoint(this.ep.add(other.ep));
    }
    subtract(other) {
        assertRstPoint(other);
        return new RistrettoPoint(this.ep.subtract(other.ep));
    }
    multiply(scalar) {
        return new RistrettoPoint(this.ep.multiply(scalar));
    }
    multiplyUnsafe(scalar) {
        return new RistrettoPoint(this.ep.multiplyUnsafe(scalar));
    }
}
RistrettoPoint.BASE = new RistrettoPoint(ExtendedPoint.BASE);
RistrettoPoint.ZERO = new RistrettoPoint(ExtendedPoint.ZERO);
const pointPrecomputes$1 = new WeakMap();
let Point$1 = class Point {
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }
    _setWindowSize(windowSize) {
        this._WINDOW_SIZE = windowSize;
        pointPrecomputes$1.delete(this);
    }
    static fromHex(hex, strict = true) {
        const { d, P } = CURVE$1;
        hex = ensureBytes$1(hex, 32);
        const normed = hex.slice();
        normed[31] = hex[31] & ~0x80;
        const y = bytesToNumberLE(normed);
        if (strict && y >= P)
            throw new Error('Expected 0 < hex < P');
        if (!strict && y >= POW_2_256$1)
            throw new Error('Expected 0 < hex < 2**256');
        const y2 = mod$1(y * y);
        const u = mod$1(y2 - _1n$3);
        const v = mod$1(d * y2 + _1n$3);
        let { isValid, value: x } = uvRatio(u, v);
        if (!isValid)
            throw new Error('Point.fromHex: invalid y coordinate');
        const isXOdd = (x & _1n$3) === _1n$3;
        const isLastByteOdd = (hex[31] & 0x80) !== 0;
        if (isLastByteOdd !== isXOdd) {
            x = mod$1(-x);
        }
        return new Point(x, y);
    }
    static async fromPrivateKey(privateKey) {
        return (await getExtendedPublicKey(privateKey)).point;
    }
    toRawBytes() {
        const bytes = numberTo32BytesLE(this.y);
        bytes[31] |= this.x & _1n$3 ? 0x80 : 0;
        return bytes;
    }
    toHex() {
        return bytesToHex$1(this.toRawBytes());
    }
    toX25519() {
        const { y } = this;
        const u = mod$1((_1n$3 + y) * invert$1(_1n$3 - y));
        return numberTo32BytesLE(u);
    }
    isTorsionFree() {
        return ExtendedPoint.fromAffine(this).isTorsionFree();
    }
    equals(other) {
        return this.x === other.x && this.y === other.y;
    }
    negate() {
        return new Point(mod$1(-this.x), this.y);
    }
    add(other) {
        return ExtendedPoint.fromAffine(this).add(ExtendedPoint.fromAffine(other)).toAffine();
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiply(scalar) {
        return ExtendedPoint.fromAffine(this).multiply(scalar, this).toAffine();
    }
};
Point$1.BASE = new Point$1(CURVE$1.Gx, CURVE$1.Gy);
Point$1.ZERO = new Point$1(_0n$2, _1n$3);
let Signature$1 = class Signature {
    constructor(r, s) {
        this.r = r;
        this.s = s;
        this.assertValidity();
    }
    static fromHex(hex) {
        const bytes = ensureBytes$1(hex, 64);
        const r = Point$1.fromHex(bytes.slice(0, 32), false);
        const s = bytesToNumberLE(bytes.slice(32, 64));
        return new Signature(r, s);
    }
    assertValidity() {
        const { r, s } = this;
        if (!(r instanceof Point$1))
            throw new Error('Expected Point instance');
        normalizeScalar$1(s, CURVE$1.l, false);
        return this;
    }
    toRawBytes() {
        const u8 = new Uint8Array(64);
        u8.set(this.r.toRawBytes());
        u8.set(numberTo32BytesLE(this.s), 32);
        return u8;
    }
    toHex() {
        return bytesToHex$1(this.toRawBytes());
    }
};
function concatBytes$1(...arrays) {
    if (!arrays.every((a) => a instanceof Uint8Array))
        throw new Error('Expected Uint8Array list');
    if (arrays.length === 1)
        return arrays[0];
    const length = arrays.reduce((a, arr) => a + arr.length, 0);
    const result = new Uint8Array(length);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const arr = arrays[i];
        result.set(arr, pad);
        pad += arr.length;
    }
    return result;
}
const hexes$1 = Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, '0'));
function bytesToHex$1(uint8a) {
    if (!(uint8a instanceof Uint8Array))
        throw new Error('Uint8Array expected');
    let hex = '';
    for (let i = 0; i < uint8a.length; i++) {
        hex += hexes$1[uint8a[i]];
    }
    return hex;
}
function hexToBytes$1(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToBytes: expected string, got ' + typeof hex);
    }
    if (hex.length % 2)
        throw new Error('hexToBytes: received invalid unpadded hex');
    const array = new Uint8Array(hex.length / 2);
    for (let i = 0; i < array.length; i++) {
        const j = i * 2;
        const hexByte = hex.slice(j, j + 2);
        const byte = Number.parseInt(hexByte, 16);
        if (Number.isNaN(byte) || byte < 0)
            throw new Error('Invalid byte sequence');
        array[i] = byte;
    }
    return array;
}
function numberTo32BytesBE(num) {
    const length = 32;
    const hex = num.toString(16).padStart(length * 2, '0');
    return hexToBytes$1(hex);
}
function numberTo32BytesLE(num) {
    return numberTo32BytesBE(num).reverse();
}
function edIsNegative(num) {
    return (mod$1(num) & _1n$3) === _1n$3;
}
function bytesToNumberLE(uint8a) {
    if (!(uint8a instanceof Uint8Array))
        throw new Error('Expected Uint8Array');
    return BigInt('0x' + bytesToHex$1(Uint8Array.from(uint8a).reverse()));
}
const MAX_255B = BigInt('0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff');
function bytes255ToNumberLE(bytes) {
    return mod$1(bytesToNumberLE(bytes) & MAX_255B);
}
function mod$1(a, b = CURVE$1.P) {
    const res = a % b;
    return res >= _0n$2 ? res : b + res;
}
function invert$1(number, modulo = CURVE$1.P) {
    if (number === _0n$2 || modulo <= _0n$2) {
        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);
    }
    let a = mod$1(number, modulo);
    let b = modulo;
    let x = _0n$2, u = _1n$3;
    while (a !== _0n$2) {
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n$3)
        throw new Error('invert: does not exist');
    return mod$1(x, modulo);
}
function invertBatch$1(nums, p = CURVE$1.P) {
    const tmp = new Array(nums.length);
    const lastMultiplied = nums.reduce((acc, num, i) => {
        if (num === _0n$2)
            return acc;
        tmp[i] = acc;
        return mod$1(acc * num, p);
    }, _1n$3);
    const inverted = invert$1(lastMultiplied, p);
    nums.reduceRight((acc, num, i) => {
        if (num === _0n$2)
            return acc;
        tmp[i] = mod$1(acc * tmp[i], p);
        return mod$1(acc * num, p);
    }, inverted);
    return tmp;
}
function pow2$1(x, power) {
    const { P } = CURVE$1;
    let res = x;
    while (power-- > _0n$2) {
        res *= res;
        res %= P;
    }
    return res;
}
function pow_2_252_3(x) {
    const { P } = CURVE$1;
    const _5n = BigInt(5);
    const _10n = BigInt(10);
    const _20n = BigInt(20);
    const _40n = BigInt(40);
    const _80n = BigInt(80);
    const x2 = (x * x) % P;
    const b2 = (x2 * x) % P;
    const b4 = (pow2$1(b2, _2n$2) * b2) % P;
    const b5 = (pow2$1(b4, _1n$3) * x) % P;
    const b10 = (pow2$1(b5, _5n) * b5) % P;
    const b20 = (pow2$1(b10, _10n) * b10) % P;
    const b40 = (pow2$1(b20, _20n) * b20) % P;
    const b80 = (pow2$1(b40, _40n) * b40) % P;
    const b160 = (pow2$1(b80, _80n) * b80) % P;
    const b240 = (pow2$1(b160, _80n) * b80) % P;
    const b250 = (pow2$1(b240, _10n) * b10) % P;
    const pow_p_5_8 = (pow2$1(b250, _2n$2) * x) % P;
    return { pow_p_5_8, b2 };
}
function uvRatio(u, v) {
    const v3 = mod$1(v * v * v);
    const v7 = mod$1(v3 * v3 * v);
    const pow = pow_2_252_3(u * v7).pow_p_5_8;
    let x = mod$1(u * v3 * pow);
    const vx2 = mod$1(v * x * x);
    const root1 = x;
    const root2 = mod$1(x * SQRT_M1);
    const useRoot1 = vx2 === u;
    const useRoot2 = vx2 === mod$1(-u);
    const noRoot = vx2 === mod$1(-u * SQRT_M1);
    if (useRoot1)
        x = root1;
    if (useRoot2 || noRoot)
        x = root2;
    if (edIsNegative(x))
        x = mod$1(-x);
    return { isValid: useRoot1 || useRoot2, value: x };
}
function invertSqrt(number) {
    return uvRatio(_1n$3, number);
}
function modlLE(hash) {
    return mod$1(bytesToNumberLE(hash), CURVE$1.l);
}
function equalBytes(b1, b2) {
    if (b1.length !== b2.length) {
        return false;
    }
    for (let i = 0; i < b1.length; i++) {
        if (b1[i] !== b2[i]) {
            return false;
        }
    }
    return true;
}
function ensureBytes$1(hex, expectedLength) {
    const bytes = hex instanceof Uint8Array ? Uint8Array.from(hex) : hexToBytes$1(hex);
    if (typeof expectedLength === 'number' && bytes.length !== expectedLength)
        throw new Error(`Expected ${expectedLength} bytes`);
    return bytes;
}
function normalizeScalar$1(num, max, strict = true) {
    if (!max)
        throw new TypeError('Specify max value');
    if (typeof num === 'number' && Number.isSafeInteger(num))
        num = BigInt(num);
    if (typeof num === 'bigint' && num < max) {
        if (strict) {
            if (_0n$2 < num)
                return num;
        }
        else {
            if (_0n$2 <= num)
                return num;
        }
    }
    throw new TypeError('Expected valid scalar: 0 < scalar < max');
}
function adjustBytes25519(bytes) {
    bytes[0] &= 248;
    bytes[31] &= 127;
    bytes[31] |= 64;
    return bytes;
}
function checkPrivateKey(key) {
    key =
        typeof key === 'bigint' || typeof key === 'number'
            ? numberTo32BytesBE(normalizeScalar$1(key, POW_2_256$1))
            : ensureBytes$1(key);
    if (key.length !== 32)
        throw new Error(`Expected 32 bytes`);
    return key;
}
function getKeyFromHash(hashed) {
    const head = adjustBytes25519(hashed.slice(0, 32));
    const prefix = hashed.slice(32, 64);
    const scalar = modlLE(head);
    const point = Point$1.BASE.multiply(scalar);
    const pointBytes = point.toRawBytes();
    return { head, prefix, scalar, point, pointBytes };
}
let _sha512Sync;
async function getExtendedPublicKey(key) {
    return getKeyFromHash(await utils$1.sha512(checkPrivateKey(key)));
}
async function getPublicKey$1(privateKey) {
    return (await getExtendedPublicKey(privateKey)).pointBytes;
}
async function sign$2(message, privateKey) {
    message = ensureBytes$1(message);
    const { prefix, scalar, pointBytes } = await getExtendedPublicKey(privateKey);
    const r = modlLE(await utils$1.sha512(prefix, message));
    const R = Point$1.BASE.multiply(r);
    const k = modlLE(await utils$1.sha512(R.toRawBytes(), pointBytes, message));
    const s = mod$1(r + k * scalar, CURVE$1.l);
    return new Signature$1(R, s).toRawBytes();
}
function prepareVerification(sig, message, publicKey) {
    message = ensureBytes$1(message);
    if (!(publicKey instanceof Point$1))
        publicKey = Point$1.fromHex(publicKey, false);
    const { r, s } = sig instanceof Signature$1 ? sig.assertValidity() : Signature$1.fromHex(sig);
    const SB = ExtendedPoint.BASE.multiplyUnsafe(s);
    return { r, s, SB, pub: publicKey, msg: message };
}
function finishVerification(publicKey, r, SB, hashed) {
    const k = modlLE(hashed);
    const kA = ExtendedPoint.fromAffine(publicKey).multiplyUnsafe(k);
    const RkA = ExtendedPoint.fromAffine(r).add(kA);
    return RkA.subtract(SB).multiplyUnsafe(CURVE$1.h).equals(ExtendedPoint.ZERO);
}
async function verify$1(sig, message, publicKey) {
    const { r, SB, msg, pub } = prepareVerification(sig, message, publicKey);
    const hashed = await utils$1.sha512(r.toRawBytes(), pub.toRawBytes(), msg);
    return finishVerification(pub, r, SB, hashed);
}
Point$1.BASE._setWindowSize(8);
const crypto$4 = {
    node: nodeCrypto,
    web: typeof self === 'object' && 'crypto' in self ? self.crypto : undefined,
};
const utils$1 = {
    bytesToHex: bytesToHex$1,
    hexToBytes: hexToBytes$1,
    concatBytes: concatBytes$1,
    getExtendedPublicKey,
    mod: mod$1,
    invert: invert$1,
    TORSION_SUBGROUP: [
        '0100000000000000000000000000000000000000000000000000000000000000',
        'c7176a703d4dd84fba3c0b760d10670f2a2053fa2c39ccc64ec7fd7792ac037a',
        '0000000000000000000000000000000000000000000000000000000000000080',
        '26e8958fc2b227b045c3f489f2ef98f0d5dfac05d3c63339b13802886d53fc05',
        'ecffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff7f',
        '26e8958fc2b227b045c3f489f2ef98f0d5dfac05d3c63339b13802886d53fc85',
        '0000000000000000000000000000000000000000000000000000000000000000',
        'c7176a703d4dd84fba3c0b760d10670f2a2053fa2c39ccc64ec7fd7792ac03fa',
    ],
    hashToPrivateScalar: (hash) => {
        hash = ensureBytes$1(hash);
        if (hash.length < 40 || hash.length > 1024)
            throw new Error('Expected 40-1024 bytes of private key as per FIPS 186');
        return mod$1(bytesToNumberLE(hash), CURVE$1.l - _1n$3) + _1n$3;
    },
    randomBytes: (bytesLength = 32) => {
        if (crypto$4.web) {
            return crypto$4.web.getRandomValues(new Uint8Array(bytesLength));
        }
        else if (crypto$4.node) {
            const { randomBytes } = crypto$4.node;
            return new Uint8Array(randomBytes(bytesLength).buffer);
        }
        else {
            throw new Error("The environment doesn't have randomBytes function");
        }
    },
    randomPrivateKey: () => {
        return utils$1.randomBytes(32);
    },
    sha512: async (...messages) => {
        const message = concatBytes$1(...messages);
        if (crypto$4.web) {
            const buffer = await crypto$4.web.subtle.digest('SHA-512', message.buffer);
            return new Uint8Array(buffer);
        }
        else if (crypto$4.node) {
            return Uint8Array.from(crypto$4.node.createHash('sha512').update(message).digest());
        }
        else {
            throw new Error("The environment doesn't have sha512 function");
        }
    },
    precompute(windowSize = 8, point = Point$1.BASE) {
        const cached = point.equals(Point$1.BASE) ? point : new Point$1(point.x, point.y);
        cached._setWindowSize(windowSize);
        cached.multiply(_2n$2);
        return cached;
    },
    sha512Sync: undefined,
};
Object.defineProperties(utils$1, {
    sha512Sync: {
        configurable: false,
        get() {
            return _sha512Sync;
        },
        set(val) {
            if (!_sha512Sync)
                _sha512Sync = val;
        },
    },
});

const PUBLIC_KEY_BYTE_LENGTH$6 = 32;
const PRIVATE_KEY_BYTE_LENGTH$6 = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH$6 = 32;
async function generateKey$k() {
    // the actual private key (32 bytes)
    const privateKeyRaw = utils$1.randomPrivateKey();
    const publicKey = await getPublicKey$1(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys$6(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
async function generateKeyFromSeed$6(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH$6) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = await getPublicKey$1(privateKeyRaw);
    const privateKey = concatKeys$6(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSign$k(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH$6);
    return sign$2(msg, privateKeyRaw);
}
async function hashAndVerify$k(publicKey, sig, msg) {
    return verify$1(sig, msg, publicKey);
}
function concatKeys$6(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH$6);
    for (let i = 0; i < KEYS_BYTE_LENGTH$6; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH$6 + i] = publicKey[i];
    }
    return privateKey;
}

// @ts-check


const base64$d = rfc4648$c({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$c({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$c({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$c({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto$6 = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto == null || nativeCrypto.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p-crypto/blob/master/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

// WebKit on Linux does not support deriving a key from an empty PBKDF2 key.
// So, as a workaround, we provide the generated key as a constant. We test that
// this generated key is accurate in test/workaround.spec.ts
// Generated via:
// await crypto.subtle.exportKey('jwk',
//   await crypto.subtle.deriveKey(
//     { name: 'PBKDF2', salt: new Uint8Array(16), iterations: 32767, hash: { name: 'SHA-256' } },
//     await crypto.subtle.importKey('raw', new Uint8Array(0), { name: 'PBKDF2' }, false, ['deriveKey']),
//     { name: 'AES-GCM', length: 128 }, true, ['encrypt', 'decrypt'])
// )
const derivedEmptyPasswordKey$6 = { alg: 'A128GCM', ext: true, k: 'scm9jmO_4BJAgdwWGVulLg', key_ops: ['encrypt', 'decrypt'], kty: 'oct' };
// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create$d(opts) {
    const algorithm = opts?.algorithm ?? 'AES-GCM';
    let keyLength = opts?.keyLength ?? 16;
    const nonceLength = opts?.nonceLength ?? 12;
    const digest = opts?.digest ?? 'SHA-256';
    const saltLength = opts?.saltLength ?? 16;
    const iterations = opts?.iterations ?? 32767;
    const crypto = webcrypto$6.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$6, { name: 'AES-GCM' }, true, ['encrypt']);
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['encrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$6, { name: 'AES-GCM' }, true, ['encrypt']);
            }
        }
        else {
            // Derive a key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        }
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat$1([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['decrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$6, { name: 'AES-GCM' }, true, ['decrypt']);
            }
        }
        else {
            // Derive the key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        }
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter$6(privateKey, password) {
    const cipher = create$d();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64$d.encode(encryptedKey);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType$7;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType$7 || (KeyType$7 = {}));
var __KeyTypeValues$7;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues$7 || (__KeyTypeValues$7 = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues$7);
    };
})(KeyType$7 || (KeyType$7 = {}));
var PublicKey$7;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$7.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$7.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$1(buf, PublicKey.codec());
    };
})(PublicKey$7 || (PublicKey$7 = {}));
var PrivateKey$7;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$7.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$7.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$1(buf, PrivateKey.codec());
    };
})(PrivateKey$7 || (PrivateKey$7 = {}));

let Ed25519PublicKey$6 = class Ed25519PublicKey {
    _key;
    constructor(key) {
        this._key = ensureKey$6(key, PUBLIC_KEY_BYTE_LENGTH$6);
    }
    async verify(data, sig) {
        return hashAndVerify$k(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey$7.encode({
            Type: KeyType$7.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$8.digest(this.bytes);
        return bytes;
    }
};
let Ed25519PrivateKey$6 = class Ed25519PrivateKey {
    _key;
    _publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey$6(key, PRIVATE_KEY_BYTE_LENGTH$6);
        this._publicKey = ensureKey$6(publicKey, PUBLIC_KEY_BYTE_LENGTH$6);
    }
    async sign(message) {
        return hashAndSign$k(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey$6(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$7.encode({
            Type: KeyType$7.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$8.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity$9.digest(this.public.bytes);
        return base58btc$b.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$6(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalEd25519PrivateKey$6(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH$6) {
        bytes = ensureKey$6(bytes, PRIVATE_KEY_BYTE_LENGTH$6 + PUBLIC_KEY_BYTE_LENGTH$6);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$6);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH$6, bytes.length);
        return new Ed25519PrivateKey$6(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey$6(bytes, PRIVATE_KEY_BYTE_LENGTH$6);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$6);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH$6);
    return new Ed25519PrivateKey$6(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey$6(bytes) {
    bytes = ensureKey$6(bytes, PUBLIC_KEY_BYTE_LENGTH$6);
    return new Ed25519PublicKey$6(bytes);
}
async function generateKeyPair$m() {
    const { privateKey, publicKey } = await generateKey$k();
    return new Ed25519PrivateKey$6(privateKey, publicKey);
}
async function generateKeyPairFromSeed$6(seed) {
    const { privateKey, publicKey } = await generateKeyFromSeed$6(seed);
    return new Ed25519PrivateKey$6(privateKey, publicKey);
}
function ensureKey$6(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError$3(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519$6 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey$6,
    Ed25519PublicKey: Ed25519PublicKey$6,
    generateKeyPair: generateKeyPair$m,
    generateKeyPairFromSeed: generateKeyPairFromSeed$6,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey$6,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey$6
});

function bigIntegerToUintBase64url$6(num, len) {
    // Call `.abs()` to convert to unsigned
    let buf = Uint8Array.from(num.abs().toByteArray()); // toByteArray converts to big endian
    // toByteArray() gives us back a signed array, which will include a leading 0
    // byte if the most significant bit of the number is 1:
    // https://docs.microsoft.com/en-us/windows/win32/seccertenroll/about-integer
    // Our number will always be positive so we should remove the leading padding.
    buf = buf[0] === 0 ? buf.subarray(1) : buf;
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return toString$9(buf, 'base64url');
}
// Convert a base64url encoded string to a BigInteger
function base64urlToBigInteger$6(str) {
    const buf = base64urlToBuffer$6(str);
    return new forge$n.jsbn.BigInteger(toString$9(buf, 'base16'), 16);
}
function base64urlToBuffer$6(str, len) {
    let buf = fromString$3(str, 'base64urlpad');
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return buf;
}

const bits$7 = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes$7 = Object.keys(bits$7);
curveTypes$7.join(' / ');

/**
 * Secure Hash Algorithm with a 1024-bit block size implementation.
 *
 * This includes: SHA-512, SHA-384, SHA-512/224, and SHA-512/256. For
 * SHA-256 (block size 512 bits), see sha256.js.
 *
 * See FIPS 180-4 for details.
 *
 * @author Dave Longley
 *
 * Copyright (c) 2014-2015 Digital Bazaar, Inc.
 */

var forge = forge$m;



var sha512 = forge.sha512 = forge.sha512 || {};

// SHA-512
forge.md.sha512 = forge.md.algorithms.sha512 = sha512;

// SHA-384
var sha384 = forge.sha384 = forge.sha512.sha384 = forge.sha512.sha384 || {};
sha384.create = function() {
  return sha512.create('SHA-384');
};
forge.md.sha384 = forge.md.algorithms.sha384 = sha384;

// SHA-512/256
forge.sha512.sha256 = forge.sha512.sha256 || {
  create: function() {
    return sha512.create('SHA-512/256');
  }
};
forge.md['sha512/256'] = forge.md.algorithms['sha512/256'] =
  forge.sha512.sha256;

// SHA-512/224
forge.sha512.sha224 = forge.sha512.sha224 || {
  create: function() {
    return sha512.create('SHA-512/224');
  }
};
forge.md['sha512/224'] = forge.md.algorithms['sha512/224'] =
  forge.sha512.sha224;

/**
 * Creates a SHA-2 message digest object.
 *
 * @param algorithm the algorithm to use (SHA-512, SHA-384, SHA-512/224,
 *          SHA-512/256).
 *
 * @return a message digest object.
 */
sha512.create = function(algorithm) {
  // do initialization as necessary
  if(!_initialized) {
    _init();
  }

  if(typeof algorithm === 'undefined') {
    algorithm = 'SHA-512';
  }

  if(!(algorithm in _states)) {
    throw new Error('Invalid SHA-512 algorithm: ' + algorithm);
  }

  // SHA-512 state contains eight 64-bit integers (each as two 32-bit ints)
  var _state = _states[algorithm];
  var _h = null;

  // input buffer
  var _input = forge.util.createBuffer();

  // used for 64-bit word storage
  var _w = new Array(80);
  for(var wi = 0; wi < 80; ++wi) {
    _w[wi] = new Array(2);
  }

  // determine digest length by algorithm name (default)
  var digestLength = 64;
  switch(algorithm) {
    case 'SHA-384':
      digestLength = 48;
      break;
    case 'SHA-512/256':
      digestLength = 32;
      break;
    case 'SHA-512/224':
      digestLength = 28;
      break;
  }

  // message digest object
  var md = {
    // SHA-512 => sha512
    algorithm: algorithm.replace('-', '').toLowerCase(),
    blockLength: 128,
    digestLength: digestLength,
    // 56-bit length of message so far (does not including padding)
    messageLength: 0,
    // true message length
    fullMessageLength: null,
    // size of message length in bytes
    messageLengthSize: 16
  };

  /**
   * Starts the digest.
   *
   * @return this digest object.
   */
  md.start = function() {
    // up to 56-bit message length for convenience
    md.messageLength = 0;

    // full message length (set md.messageLength128 for backwards-compatibility)
    md.fullMessageLength = md.messageLength128 = [];
    var int32s = md.messageLengthSize / 4;
    for(var i = 0; i < int32s; ++i) {
      md.fullMessageLength.push(0);
    }
    _input = forge.util.createBuffer();
    _h = new Array(_state.length);
    for(var i = 0; i < _state.length; ++i) {
      _h[i] = _state[i].slice(0);
    }
    return md;
  };
  // start digest automatically for first time
  md.start();

  /**
   * Updates the digest with the given message input. The given input can
   * treated as raw input (no encoding will be applied) or an encoding of
   * 'utf8' maybe given to encode the input using UTF-8.
   *
   * @param msg the message input to update with.
   * @param encoding the encoding to use (default: 'raw', other: 'utf8').
   *
   * @return this digest object.
   */
  md.update = function(msg, encoding) {
    if(encoding === 'utf8') {
      msg = forge.util.encodeUtf8(msg);
    }

    // update message length
    var len = msg.length;
    md.messageLength += len;
    len = [(len / 0x100000000) >>> 0, len >>> 0];
    for(var i = md.fullMessageLength.length - 1; i >= 0; --i) {
      md.fullMessageLength[i] += len[1];
      len[1] = len[0] + ((md.fullMessageLength[i] / 0x100000000) >>> 0);
      md.fullMessageLength[i] = md.fullMessageLength[i] >>> 0;
      len[0] = ((len[1] / 0x100000000) >>> 0);
    }

    // add bytes to input buffer
    _input.putBytes(msg);

    // process bytes
    _update(_h, _w, _input);

    // compact input buffer every 2K or if empty
    if(_input.read > 2048 || _input.length() === 0) {
      _input.compact();
    }

    return md;
  };

  /**
   * Produces the digest.
   *
   * @return a byte buffer containing the digest value.
   */
  md.digest = function() {
    /* Note: Here we copy the remaining bytes in the input buffer and
    add the appropriate SHA-512 padding. Then we do the final update
    on a copy of the state so that if the user wants to get
    intermediate digests they can do so. */

    /* Determine the number of bytes that must be added to the message
    to ensure its length is congruent to 896 mod 1024. In other words,
    the data to be digested must be a multiple of 1024 bits (or 128 bytes).
    This data includes the message, some padding, and the length of the
    message. Since the length of the message will be encoded as 16 bytes (128
    bits), that means that the last segment of the data must have 112 bytes
    (896 bits) of message and padding. Therefore, the length of the message
    plus the padding must be congruent to 896 mod 1024 because
    1024 - 128 = 896.

    In order to fill up the message length it must be filled with
    padding that begins with 1 bit followed by all 0 bits. Padding
    must *always* be present, so if the message length is already
    congruent to 896 mod 1024, then 1024 padding bits must be added. */

    var finalBlock = forge.util.createBuffer();
    finalBlock.putBytes(_input.bytes());

    // compute remaining size to be digested (include message length size)
    var remaining = (
      md.fullMessageLength[md.fullMessageLength.length - 1] +
      md.messageLengthSize);

    // add padding for overflow blockSize - overflow
    // _padding starts with 1 byte with first bit is set (byte value 128), then
    // there may be up to (blockSize - 1) other pad bytes
    var overflow = remaining & (md.blockLength - 1);
    finalBlock.putBytes(_padding.substr(0, md.blockLength - overflow));

    // serialize message length in bits in big-endian order; since length
    // is stored in bytes we multiply by 8 and add carry from next int
    var next, carry;
    var bits = md.fullMessageLength[0] * 8;
    for(var i = 0; i < md.fullMessageLength.length - 1; ++i) {
      next = md.fullMessageLength[i + 1] * 8;
      carry = (next / 0x100000000) >>> 0;
      bits += carry;
      finalBlock.putInt32(bits >>> 0);
      bits = next >>> 0;
    }
    finalBlock.putInt32(bits);

    var h = new Array(_h.length);
    for(var i = 0; i < _h.length; ++i) {
      h[i] = _h[i].slice(0);
    }
    _update(h, _w, finalBlock);
    var rval = forge.util.createBuffer();
    var hlen;
    if(algorithm === 'SHA-512') {
      hlen = h.length;
    } else if(algorithm === 'SHA-384') {
      hlen = h.length - 2;
    } else {
      hlen = h.length - 4;
    }
    for(var i = 0; i < hlen; ++i) {
      rval.putInt32(h[i][0]);
      if(i !== hlen - 1 || algorithm !== 'SHA-512/224') {
        rval.putInt32(h[i][1]);
      }
    }
    return rval;
  };

  return md;
};

// sha-512 padding bytes not initialized yet
var _padding = null;
var _initialized = false;

// table of constants
var _k = null;

// initial hash states
var _states = null;

/**
 * Initializes the constant tables.
 */
function _init() {
  // create padding
  _padding = String.fromCharCode(128);
  _padding += forge.util.fillString(String.fromCharCode(0x00), 128);

  // create K table for SHA-512
  _k = [
    [0x428a2f98, 0xd728ae22], [0x71374491, 0x23ef65cd],
    [0xb5c0fbcf, 0xec4d3b2f], [0xe9b5dba5, 0x8189dbbc],
    [0x3956c25b, 0xf348b538], [0x59f111f1, 0xb605d019],
    [0x923f82a4, 0xaf194f9b], [0xab1c5ed5, 0xda6d8118],
    [0xd807aa98, 0xa3030242], [0x12835b01, 0x45706fbe],
    [0x243185be, 0x4ee4b28c], [0x550c7dc3, 0xd5ffb4e2],
    [0x72be5d74, 0xf27b896f], [0x80deb1fe, 0x3b1696b1],
    [0x9bdc06a7, 0x25c71235], [0xc19bf174, 0xcf692694],
    [0xe49b69c1, 0x9ef14ad2], [0xefbe4786, 0x384f25e3],
    [0x0fc19dc6, 0x8b8cd5b5], [0x240ca1cc, 0x77ac9c65],
    [0x2de92c6f, 0x592b0275], [0x4a7484aa, 0x6ea6e483],
    [0x5cb0a9dc, 0xbd41fbd4], [0x76f988da, 0x831153b5],
    [0x983e5152, 0xee66dfab], [0xa831c66d, 0x2db43210],
    [0xb00327c8, 0x98fb213f], [0xbf597fc7, 0xbeef0ee4],
    [0xc6e00bf3, 0x3da88fc2], [0xd5a79147, 0x930aa725],
    [0x06ca6351, 0xe003826f], [0x14292967, 0x0a0e6e70],
    [0x27b70a85, 0x46d22ffc], [0x2e1b2138, 0x5c26c926],
    [0x4d2c6dfc, 0x5ac42aed], [0x53380d13, 0x9d95b3df],
    [0x650a7354, 0x8baf63de], [0x766a0abb, 0x3c77b2a8],
    [0x81c2c92e, 0x47edaee6], [0x92722c85, 0x1482353b],
    [0xa2bfe8a1, 0x4cf10364], [0xa81a664b, 0xbc423001],
    [0xc24b8b70, 0xd0f89791], [0xc76c51a3, 0x0654be30],
    [0xd192e819, 0xd6ef5218], [0xd6990624, 0x5565a910],
    [0xf40e3585, 0x5771202a], [0x106aa070, 0x32bbd1b8],
    [0x19a4c116, 0xb8d2d0c8], [0x1e376c08, 0x5141ab53],
    [0x2748774c, 0xdf8eeb99], [0x34b0bcb5, 0xe19b48a8],
    [0x391c0cb3, 0xc5c95a63], [0x4ed8aa4a, 0xe3418acb],
    [0x5b9cca4f, 0x7763e373], [0x682e6ff3, 0xd6b2b8a3],
    [0x748f82ee, 0x5defb2fc], [0x78a5636f, 0x43172f60],
    [0x84c87814, 0xa1f0ab72], [0x8cc70208, 0x1a6439ec],
    [0x90befffa, 0x23631e28], [0xa4506ceb, 0xde82bde9],
    [0xbef9a3f7, 0xb2c67915], [0xc67178f2, 0xe372532b],
    [0xca273ece, 0xea26619c], [0xd186b8c7, 0x21c0c207],
    [0xeada7dd6, 0xcde0eb1e], [0xf57d4f7f, 0xee6ed178],
    [0x06f067aa, 0x72176fba], [0x0a637dc5, 0xa2c898a6],
    [0x113f9804, 0xbef90dae], [0x1b710b35, 0x131c471b],
    [0x28db77f5, 0x23047d84], [0x32caab7b, 0x40c72493],
    [0x3c9ebe0a, 0x15c9bebc], [0x431d67c4, 0x9c100d4c],
    [0x4cc5d4be, 0xcb3e42b6], [0x597f299c, 0xfc657e2a],
    [0x5fcb6fab, 0x3ad6faec], [0x6c44198c, 0x4a475817]
  ];

  // initial hash states
  _states = {};
  _states['SHA-512'] = [
    [0x6a09e667, 0xf3bcc908],
    [0xbb67ae85, 0x84caa73b],
    [0x3c6ef372, 0xfe94f82b],
    [0xa54ff53a, 0x5f1d36f1],
    [0x510e527f, 0xade682d1],
    [0x9b05688c, 0x2b3e6c1f],
    [0x1f83d9ab, 0xfb41bd6b],
    [0x5be0cd19, 0x137e2179]
  ];
  _states['SHA-384'] = [
    [0xcbbb9d5d, 0xc1059ed8],
    [0x629a292a, 0x367cd507],
    [0x9159015a, 0x3070dd17],
    [0x152fecd8, 0xf70e5939],
    [0x67332667, 0xffc00b31],
    [0x8eb44a87, 0x68581511],
    [0xdb0c2e0d, 0x64f98fa7],
    [0x47b5481d, 0xbefa4fa4]
  ];
  _states['SHA-512/256'] = [
    [0x22312194, 0xFC2BF72C],
    [0x9F555FA3, 0xC84C64C2],
    [0x2393B86B, 0x6F53B151],
    [0x96387719, 0x5940EABD],
    [0x96283EE2, 0xA88EFFE3],
    [0xBE5E1E25, 0x53863992],
    [0x2B0199FC, 0x2C85B8AA],
    [0x0EB72DDC, 0x81C52CA2]
  ];
  _states['SHA-512/224'] = [
    [0x8C3D37C8, 0x19544DA2],
    [0x73E19966, 0x89DCD4D6],
    [0x1DFAB7AE, 0x32FF9C82],
    [0x679DD514, 0x582F9FCF],
    [0x0F6D2B69, 0x7BD44DA8],
    [0x77E36F73, 0x04C48942],
    [0x3F9D85A8, 0x6A1D36C8],
    [0x1112E6AD, 0x91D692A1]
  ];

  // now initialized
  _initialized = true;
}

/**
 * Updates a SHA-512 state with the given byte buffer.
 *
 * @param s the SHA-512 state to update.
 * @param w the array to use to store words.
 * @param bytes the byte buffer to update with.
 */
function _update(s, w, bytes) {
  // consume 512 bit (128 byte) chunks
  var t1_hi, t1_lo;
  var t2_hi, t2_lo;
  var s0_hi, s0_lo;
  var s1_hi, s1_lo;
  var ch_hi, ch_lo;
  var maj_hi, maj_lo;
  var a_hi, a_lo;
  var b_hi, b_lo;
  var c_hi, c_lo;
  var d_hi, d_lo;
  var e_hi, e_lo;
  var f_hi, f_lo;
  var g_hi, g_lo;
  var h_hi, h_lo;
  var i, hi, lo, w2, w7, w15, w16;
  var len = bytes.length();
  while(len >= 128) {
    // the w array will be populated with sixteen 64-bit big-endian words
    // and then extended into 64 64-bit words according to SHA-512
    for(i = 0; i < 16; ++i) {
      w[i][0] = bytes.getInt32() >>> 0;
      w[i][1] = bytes.getInt32() >>> 0;
    }
    for(; i < 80; ++i) {
      // for word 2 words ago: ROTR 19(x) ^ ROTR 61(x) ^ SHR 6(x)
      w2 = w[i - 2];
      hi = w2[0];
      lo = w2[1];

      // high bits
      t1_hi = (
        ((hi >>> 19) | (lo << 13)) ^ // ROTR 19
        ((lo >>> 29) | (hi << 3)) ^ // ROTR 61/(swap + ROTR 29)
        (hi >>> 6)) >>> 0; // SHR 6
      // low bits
      t1_lo = (
        ((hi << 13) | (lo >>> 19)) ^ // ROTR 19
        ((lo << 3) | (hi >>> 29)) ^ // ROTR 61/(swap + ROTR 29)
        ((hi << 26) | (lo >>> 6))) >>> 0; // SHR 6

      // for word 15 words ago: ROTR 1(x) ^ ROTR 8(x) ^ SHR 7(x)
      w15 = w[i - 15];
      hi = w15[0];
      lo = w15[1];

      // high bits
      t2_hi = (
        ((hi >>> 1) | (lo << 31)) ^ // ROTR 1
        ((hi >>> 8) | (lo << 24)) ^ // ROTR 8
        (hi >>> 7)) >>> 0; // SHR 7
      // low bits
      t2_lo = (
        ((hi << 31) | (lo >>> 1)) ^ // ROTR 1
        ((hi << 24) | (lo >>> 8)) ^ // ROTR 8
        ((hi << 25) | (lo >>> 7))) >>> 0; // SHR 7

      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^64 (carry lo overflow)
      w7 = w[i - 7];
      w16 = w[i - 16];
      lo = (t1_lo + w7[1] + t2_lo + w16[1]);
      w[i][0] = (t1_hi + w7[0] + t2_hi + w16[0] +
        ((lo / 0x100000000) >>> 0)) >>> 0;
      w[i][1] = lo >>> 0;
    }

    // initialize hash value for this chunk
    a_hi = s[0][0];
    a_lo = s[0][1];
    b_hi = s[1][0];
    b_lo = s[1][1];
    c_hi = s[2][0];
    c_lo = s[2][1];
    d_hi = s[3][0];
    d_lo = s[3][1];
    e_hi = s[4][0];
    e_lo = s[4][1];
    f_hi = s[5][0];
    f_lo = s[5][1];
    g_hi = s[6][0];
    g_lo = s[6][1];
    h_hi = s[7][0];
    h_lo = s[7][1];

    // round function
    for(i = 0; i < 80; ++i) {
      // Sum1(e) = ROTR 14(e) ^ ROTR 18(e) ^ ROTR 41(e)
      s1_hi = (
        ((e_hi >>> 14) | (e_lo << 18)) ^ // ROTR 14
        ((e_hi >>> 18) | (e_lo << 14)) ^ // ROTR 18
        ((e_lo >>> 9) | (e_hi << 23))) >>> 0; // ROTR 41/(swap + ROTR 9)
      s1_lo = (
        ((e_hi << 18) | (e_lo >>> 14)) ^ // ROTR 14
        ((e_hi << 14) | (e_lo >>> 18)) ^ // ROTR 18
        ((e_lo << 23) | (e_hi >>> 9))) >>> 0; // ROTR 41/(swap + ROTR 9)

      // Ch(e, f, g) (optimized the same way as SHA-1)
      ch_hi = (g_hi ^ (e_hi & (f_hi ^ g_hi))) >>> 0;
      ch_lo = (g_lo ^ (e_lo & (f_lo ^ g_lo))) >>> 0;

      // Sum0(a) = ROTR 28(a) ^ ROTR 34(a) ^ ROTR 39(a)
      s0_hi = (
        ((a_hi >>> 28) | (a_lo << 4)) ^ // ROTR 28
        ((a_lo >>> 2) | (a_hi << 30)) ^ // ROTR 34/(swap + ROTR 2)
        ((a_lo >>> 7) | (a_hi << 25))) >>> 0; // ROTR 39/(swap + ROTR 7)
      s0_lo = (
        ((a_hi << 4) | (a_lo >>> 28)) ^ // ROTR 28
        ((a_lo << 30) | (a_hi >>> 2)) ^ // ROTR 34/(swap + ROTR 2)
        ((a_lo << 25) | (a_hi >>> 7))) >>> 0; // ROTR 39/(swap + ROTR 7)

      // Maj(a, b, c) (optimized the same way as SHA-1)
      maj_hi = ((a_hi & b_hi) | (c_hi & (a_hi ^ b_hi))) >>> 0;
      maj_lo = ((a_lo & b_lo) | (c_lo & (a_lo ^ b_lo))) >>> 0;

      // main algorithm
      // t1 = (h + s1 + ch + _k[i] + _w[i]) modulo 2^64 (carry lo overflow)
      lo = (h_lo + s1_lo + ch_lo + _k[i][1] + w[i][1]);
      t1_hi = (h_hi + s1_hi + ch_hi + _k[i][0] + w[i][0] +
        ((lo / 0x100000000) >>> 0)) >>> 0;
      t1_lo = lo >>> 0;

      // t2 = s0 + maj modulo 2^64 (carry lo overflow)
      lo = s0_lo + maj_lo;
      t2_hi = (s0_hi + maj_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
      t2_lo = lo >>> 0;

      h_hi = g_hi;
      h_lo = g_lo;

      g_hi = f_hi;
      g_lo = f_lo;

      f_hi = e_hi;
      f_lo = e_lo;

      // e = (d + t1) modulo 2^64 (carry lo overflow)
      lo = d_lo + t1_lo;
      e_hi = (d_hi + t1_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
      e_lo = lo >>> 0;

      d_hi = c_hi;
      d_lo = c_lo;

      c_hi = b_hi;
      c_lo = b_lo;

      b_hi = a_hi;
      b_lo = a_lo;

      // a = (t1 + t2) modulo 2^64 (carry lo overflow)
      lo = t1_lo + t2_lo;
      a_hi = (t1_hi + t2_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
      a_lo = lo >>> 0;
    }

    // update hash state (additional modulo 2^64)
    lo = s[0][1] + a_lo;
    s[0][0] = (s[0][0] + a_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[0][1] = lo >>> 0;

    lo = s[1][1] + b_lo;
    s[1][0] = (s[1][0] + b_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[1][1] = lo >>> 0;

    lo = s[2][1] + c_lo;
    s[2][0] = (s[2][0] + c_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[2][1] = lo >>> 0;

    lo = s[3][1] + d_lo;
    s[3][0] = (s[3][0] + d_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[3][1] = lo >>> 0;

    lo = s[4][1] + e_lo;
    s[4][0] = (s[4][0] + e_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[4][1] = lo >>> 0;

    lo = s[5][1] + f_lo;
    s[5][0] = (s[5][0] + f_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[5][1] = lo >>> 0;

    lo = s[6][1] + g_lo;
    s[6][0] = (s[6][0] + g_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[6][1] = lo >>> 0;

    lo = s[7][1] + h_lo;
    s[7][0] = (s[7][0] + h_hi + ((lo / 0x100000000) >>> 0)) >>> 0;
    s[7][1] = lo >>> 0;

    len -= 128;
  }
}

/*! noble-secp256k1 - MIT License (c) 2019 Paul Miller (paulmillr.com) */
const _0n$1 = BigInt(0);
const _1n$2 = BigInt(1);
const _2n$1 = BigInt(2);
const _3n$1 = BigInt(3);
const _8n = BigInt(8);
const CURVE = Object.freeze({
    a: _0n$1,
    b: BigInt(7),
    P: BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f'),
    n: BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141'),
    h: _1n$2,
    Gx: BigInt('55066263022277343669578718895168534326250603453777594175500187360389116729240'),
    Gy: BigInt('32670510020758816978083085130507043184471273380659243275938904335757337482424'),
    beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
});
const divNearest$1 = (a, b) => (a + b / _2n$1) / b;
const endo = {
    beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
    splitScalar(k) {
        const { n } = CURVE;
        const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');
        const b1 = -_1n$2 * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');
        const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');
        const b2 = a1;
        const POW_2_128 = BigInt('0x100000000000000000000000000000000');
        const c1 = divNearest$1(b2 * k, n);
        const c2 = divNearest$1(-b1 * k, n);
        let k1 = mod(k - c1 * a1 - c2 * a2, n);
        let k2 = mod(-c1 * b1 - c2 * b2, n);
        const k1neg = k1 > POW_2_128;
        const k2neg = k2 > POW_2_128;
        if (k1neg)
            k1 = n - k1;
        if (k2neg)
            k2 = n - k2;
        if (k1 > POW_2_128 || k2 > POW_2_128) {
            throw new Error('splitScalarEndo: Endomorphism failed, k=' + k);
        }
        return { k1neg, k1, k2neg, k2 };
    },
};
const fieldLen = 32;
const groupLen = 32;
const hashLen = 32;
const compressedLen = fieldLen + 1;
const uncompressedLen = 2 * fieldLen + 1;
function weierstrass$1(x) {
    const { a, b } = CURVE;
    const x2 = mod(x * x);
    const x3 = mod(x2 * x);
    return mod(x3 + a * x + b);
}
const USE_ENDOMORPHISM = CURVE.a === _0n$1;
class ShaError extends Error {
    constructor(message) {
        super(message);
    }
}
function assertJacPoint(other) {
    if (!(other instanceof JacobianPoint))
        throw new TypeError('JacobianPoint expected');
}
class JacobianPoint {
    constructor(x, y, z) {
        this.x = x;
        this.y = y;
        this.z = z;
    }
    static fromAffine(p) {
        if (!(p instanceof Point)) {
            throw new TypeError('JacobianPoint#fromAffine: expected Point');
        }
        if (p.equals(Point.ZERO))
            return JacobianPoint.ZERO;
        return new JacobianPoint(p.x, p.y, _1n$2);
    }
    static toAffineBatch(points) {
        const toInv = invertBatch(points.map((p) => p.z));
        return points.map((p, i) => p.toAffine(toInv[i]));
    }
    static normalizeZ(points) {
        return JacobianPoint.toAffineBatch(points).map(JacobianPoint.fromAffine);
    }
    equals(other) {
        assertJacPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        const Z1Z1 = mod(Z1 * Z1);
        const Z2Z2 = mod(Z2 * Z2);
        const U1 = mod(X1 * Z2Z2);
        const U2 = mod(X2 * Z1Z1);
        const S1 = mod(mod(Y1 * Z2) * Z2Z2);
        const S2 = mod(mod(Y2 * Z1) * Z1Z1);
        return U1 === U2 && S1 === S2;
    }
    negate() {
        return new JacobianPoint(this.x, mod(-this.y), this.z);
    }
    double() {
        const { x: X1, y: Y1, z: Z1 } = this;
        const A = mod(X1 * X1);
        const B = mod(Y1 * Y1);
        const C = mod(B * B);
        const x1b = X1 + B;
        const D = mod(_2n$1 * (mod(x1b * x1b) - A - C));
        const E = mod(_3n$1 * A);
        const F = mod(E * E);
        const X3 = mod(F - _2n$1 * D);
        const Y3 = mod(E * (D - X3) - _8n * C);
        const Z3 = mod(_2n$1 * Y1 * Z1);
        return new JacobianPoint(X3, Y3, Z3);
    }
    add(other) {
        assertJacPoint(other);
        const { x: X1, y: Y1, z: Z1 } = this;
        const { x: X2, y: Y2, z: Z2 } = other;
        if (X2 === _0n$1 || Y2 === _0n$1)
            return this;
        if (X1 === _0n$1 || Y1 === _0n$1)
            return other;
        const Z1Z1 = mod(Z1 * Z1);
        const Z2Z2 = mod(Z2 * Z2);
        const U1 = mod(X1 * Z2Z2);
        const U2 = mod(X2 * Z1Z1);
        const S1 = mod(mod(Y1 * Z2) * Z2Z2);
        const S2 = mod(mod(Y2 * Z1) * Z1Z1);
        const H = mod(U2 - U1);
        const r = mod(S2 - S1);
        if (H === _0n$1) {
            if (r === _0n$1) {
                return this.double();
            }
            else {
                return JacobianPoint.ZERO;
            }
        }
        const HH = mod(H * H);
        const HHH = mod(H * HH);
        const V = mod(U1 * HH);
        const X3 = mod(r * r - HHH - _2n$1 * V);
        const Y3 = mod(r * (V - X3) - S1 * HHH);
        const Z3 = mod(Z1 * Z2 * H);
        return new JacobianPoint(X3, Y3, Z3);
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiplyUnsafe(scalar) {
        const P0 = JacobianPoint.ZERO;
        if (typeof scalar === 'bigint' && scalar === _0n$1)
            return P0;
        let n = normalizeScalar(scalar);
        if (n === _1n$2)
            return this;
        if (!USE_ENDOMORPHISM) {
            let p = P0;
            let d = this;
            while (n > _0n$1) {
                if (n & _1n$2)
                    p = p.add(d);
                d = d.double();
                n >>= _1n$2;
            }
            return p;
        }
        let { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
        let k1p = P0;
        let k2p = P0;
        let d = this;
        while (k1 > _0n$1 || k2 > _0n$1) {
            if (k1 & _1n$2)
                k1p = k1p.add(d);
            if (k2 & _1n$2)
                k2p = k2p.add(d);
            d = d.double();
            k1 >>= _1n$2;
            k2 >>= _1n$2;
        }
        if (k1neg)
            k1p = k1p.negate();
        if (k2neg)
            k2p = k2p.negate();
        k2p = new JacobianPoint(mod(k2p.x * endo.beta), k2p.y, k2p.z);
        return k1p.add(k2p);
    }
    precomputeWindow(W) {
        const windows = USE_ENDOMORPHISM ? 128 / W + 1 : 256 / W + 1;
        const points = [];
        let p = this;
        let base = p;
        for (let window = 0; window < windows; window++) {
            base = p;
            points.push(base);
            for (let i = 1; i < 2 ** (W - 1); i++) {
                base = base.add(p);
                points.push(base);
            }
            p = base.double();
        }
        return points;
    }
    wNAF(n, affinePoint) {
        if (!affinePoint && this.equals(JacobianPoint.BASE))
            affinePoint = Point.BASE;
        const W = (affinePoint && affinePoint._WINDOW_SIZE) || 1;
        if (256 % W) {
            throw new Error('Point#wNAF: Invalid precomputation window, must be power of 2');
        }
        let precomputes = affinePoint && pointPrecomputes.get(affinePoint);
        if (!precomputes) {
            precomputes = this.precomputeWindow(W);
            if (affinePoint && W !== 1) {
                precomputes = JacobianPoint.normalizeZ(precomputes);
                pointPrecomputes.set(affinePoint, precomputes);
            }
        }
        let p = JacobianPoint.ZERO;
        let f = JacobianPoint.BASE;
        const windows = 1 + (USE_ENDOMORPHISM ? 128 / W : 256 / W);
        const windowSize = 2 ** (W - 1);
        const mask = BigInt(2 ** W - 1);
        const maxNumber = 2 ** W;
        const shiftBy = BigInt(W);
        for (let window = 0; window < windows; window++) {
            const offset = window * windowSize;
            let wbits = Number(n & mask);
            n >>= shiftBy;
            if (wbits > windowSize) {
                wbits -= maxNumber;
                n += _1n$2;
            }
            const offset1 = offset;
            const offset2 = offset + Math.abs(wbits) - 1;
            const cond1 = window % 2 !== 0;
            const cond2 = wbits < 0;
            if (wbits === 0) {
                f = f.add(constTimeNegate(cond1, precomputes[offset1]));
            }
            else {
                p = p.add(constTimeNegate(cond2, precomputes[offset2]));
            }
        }
        return { p, f };
    }
    multiply(scalar, affinePoint) {
        let n = normalizeScalar(scalar);
        let point;
        let fake;
        if (USE_ENDOMORPHISM) {
            const { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
            let { p: k1p, f: f1p } = this.wNAF(k1, affinePoint);
            let { p: k2p, f: f2p } = this.wNAF(k2, affinePoint);
            k1p = constTimeNegate(k1neg, k1p);
            k2p = constTimeNegate(k2neg, k2p);
            k2p = new JacobianPoint(mod(k2p.x * endo.beta), k2p.y, k2p.z);
            point = k1p.add(k2p);
            fake = f1p.add(f2p);
        }
        else {
            const { p, f } = this.wNAF(n, affinePoint);
            point = p;
            fake = f;
        }
        return JacobianPoint.normalizeZ([point, fake])[0];
    }
    toAffine(invZ) {
        const { x, y, z } = this;
        const is0 = this.equals(JacobianPoint.ZERO);
        if (invZ == null)
            invZ = is0 ? _8n : invert(z);
        const iz1 = invZ;
        const iz2 = mod(iz1 * iz1);
        const iz3 = mod(iz2 * iz1);
        const ax = mod(x * iz2);
        const ay = mod(y * iz3);
        const zz = mod(z * iz1);
        if (is0)
            return Point.ZERO;
        if (zz !== _1n$2)
            throw new Error('invZ was invalid');
        return new Point(ax, ay);
    }
}
JacobianPoint.BASE = new JacobianPoint(CURVE.Gx, CURVE.Gy, _1n$2);
JacobianPoint.ZERO = new JacobianPoint(_0n$1, _1n$2, _0n$1);
function constTimeNegate(condition, item) {
    const neg = item.negate();
    return condition ? neg : item;
}
const pointPrecomputes = new WeakMap();
class Point {
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }
    _setWindowSize(windowSize) {
        this._WINDOW_SIZE = windowSize;
        pointPrecomputes.delete(this);
    }
    hasEvenY() {
        return this.y % _2n$1 === _0n$1;
    }
    static fromCompressedHex(bytes) {
        const isShort = bytes.length === 32;
        const x = bytesToNumber(isShort ? bytes : bytes.subarray(1));
        if (!isValidFieldElement(x))
            throw new Error('Point is not on curve');
        const y2 = weierstrass$1(x);
        let y = sqrtMod$1(y2);
        const isYOdd = (y & _1n$2) === _1n$2;
        if (isShort) {
            if (isYOdd)
                y = mod(-y);
        }
        else {
            const isFirstByteOdd = (bytes[0] & 1) === 1;
            if (isFirstByteOdd !== isYOdd)
                y = mod(-y);
        }
        const point = new Point(x, y);
        point.assertValidity();
        return point;
    }
    static fromUncompressedHex(bytes) {
        const x = bytesToNumber(bytes.subarray(1, fieldLen + 1));
        const y = bytesToNumber(bytes.subarray(fieldLen + 1, fieldLen * 2 + 1));
        const point = new Point(x, y);
        point.assertValidity();
        return point;
    }
    static fromHex(hex) {
        const bytes = ensureBytes(hex);
        const len = bytes.length;
        const header = bytes[0];
        if (len === fieldLen)
            return this.fromCompressedHex(bytes);
        if (len === compressedLen && (header === 0x02 || header === 0x03)) {
            return this.fromCompressedHex(bytes);
        }
        if (len === uncompressedLen && header === 0x04)
            return this.fromUncompressedHex(bytes);
        throw new Error(`Point.fromHex: received invalid point. Expected 32-${compressedLen} compressed bytes or ${uncompressedLen} uncompressed bytes, not ${len}`);
    }
    static fromPrivateKey(privateKey) {
        return Point.BASE.multiply(normalizePrivateKey(privateKey));
    }
    static fromSignature(msgHash, signature, recovery) {
        const { r, s } = normalizeSignature(signature);
        if (![0, 1, 2, 3].includes(recovery))
            throw new Error('Cannot recover: invalid recovery bit');
        const h = truncateHash(ensureBytes(msgHash));
        const { n } = CURVE;
        const radj = recovery === 2 || recovery === 3 ? r + n : r;
        const rinv = invert(radj, n);
        const u1 = mod(-h * rinv, n);
        const u2 = mod(s * rinv, n);
        const prefix = recovery & 1 ? '03' : '02';
        const R = Point.fromHex(prefix + numTo32bStr(radj));
        const Q = Point.BASE.multiplyAndAddUnsafe(R, u1, u2);
        if (!Q)
            throw new Error('Cannot recover signature: point at infinify');
        Q.assertValidity();
        return Q;
    }
    toRawBytes(isCompressed = false) {
        return hexToBytes(this.toHex(isCompressed));
    }
    toHex(isCompressed = false) {
        const x = numTo32bStr(this.x);
        if (isCompressed) {
            const prefix = this.hasEvenY() ? '02' : '03';
            return `${prefix}${x}`;
        }
        else {
            return `04${x}${numTo32bStr(this.y)}`;
        }
    }
    toHexX() {
        return this.toHex(true).slice(2);
    }
    toRawX() {
        return this.toRawBytes(true).slice(1);
    }
    assertValidity() {
        const msg = 'Point is not on elliptic curve';
        const { x, y } = this;
        if (!isValidFieldElement(x) || !isValidFieldElement(y))
            throw new Error(msg);
        const left = mod(y * y);
        const right = weierstrass$1(x);
        if (mod(left - right) !== _0n$1)
            throw new Error(msg);
    }
    equals(other) {
        return this.x === other.x && this.y === other.y;
    }
    negate() {
        return new Point(this.x, mod(-this.y));
    }
    double() {
        return JacobianPoint.fromAffine(this).double().toAffine();
    }
    add(other) {
        return JacobianPoint.fromAffine(this).add(JacobianPoint.fromAffine(other)).toAffine();
    }
    subtract(other) {
        return this.add(other.negate());
    }
    multiply(scalar) {
        return JacobianPoint.fromAffine(this).multiply(scalar, this).toAffine();
    }
    multiplyAndAddUnsafe(Q, a, b) {
        const P = JacobianPoint.fromAffine(this);
        const aP = a === _0n$1 || a === _1n$2 || this !== Point.BASE ? P.multiplyUnsafe(a) : P.multiply(a);
        const bQ = JacobianPoint.fromAffine(Q).multiplyUnsafe(b);
        const sum = aP.add(bQ);
        return sum.equals(JacobianPoint.ZERO) ? undefined : sum.toAffine();
    }
}
Point.BASE = new Point(CURVE.Gx, CURVE.Gy);
Point.ZERO = new Point(_0n$1, _0n$1);
function sliceDER(s) {
    return Number.parseInt(s[0], 16) >= 8 ? '00' + s : s;
}
function parseDERInt(data) {
    if (data.length < 2 || data[0] !== 0x02) {
        throw new Error(`Invalid signature integer tag: ${bytesToHex(data)}`);
    }
    const len = data[1];
    const res = data.subarray(2, len + 2);
    if (!len || res.length !== len) {
        throw new Error(`Invalid signature integer: wrong length`);
    }
    if (res[0] === 0x00 && res[1] <= 0x7f) {
        throw new Error('Invalid signature integer: trailing length');
    }
    return { data: bytesToNumber(res), left: data.subarray(len + 2) };
}
function parseDERSignature(data) {
    if (data.length < 2 || data[0] != 0x30) {
        throw new Error(`Invalid signature tag: ${bytesToHex(data)}`);
    }
    if (data[1] !== data.length - 2) {
        throw new Error('Invalid signature: incorrect length');
    }
    const { data: r, left: sBytes } = parseDERInt(data.subarray(2));
    const { data: s, left: rBytesLeft } = parseDERInt(sBytes);
    if (rBytesLeft.length) {
        throw new Error(`Invalid signature: left bytes after parsing: ${bytesToHex(rBytesLeft)}`);
    }
    return { r, s };
}
class Signature {
    constructor(r, s) {
        this.r = r;
        this.s = s;
        this.assertValidity();
    }
    static fromCompact(hex) {
        const arr = hex instanceof Uint8Array;
        const name = 'Signature.fromCompact';
        if (typeof hex !== 'string' && !arr)
            throw new TypeError(`${name}: Expected string or Uint8Array`);
        const str = arr ? bytesToHex(hex) : hex;
        if (str.length !== 128)
            throw new Error(`${name}: Expected 64-byte hex`);
        return new Signature(hexToNumber(str.slice(0, 64)), hexToNumber(str.slice(64, 128)));
    }
    static fromDER(hex) {
        const arr = hex instanceof Uint8Array;
        if (typeof hex !== 'string' && !arr)
            throw new TypeError(`Signature.fromDER: Expected string or Uint8Array`);
        const { r, s } = parseDERSignature(arr ? hex : hexToBytes(hex));
        return new Signature(r, s);
    }
    static fromHex(hex) {
        return this.fromDER(hex);
    }
    assertValidity() {
        const { r, s } = this;
        if (!isWithinCurveOrder(r))
            throw new Error('Invalid Signature: r must be 0 < r < n');
        if (!isWithinCurveOrder(s))
            throw new Error('Invalid Signature: s must be 0 < s < n');
    }
    hasHighS() {
        const HALF = CURVE.n >> _1n$2;
        return this.s > HALF;
    }
    normalizeS() {
        return this.hasHighS() ? new Signature(this.r, mod(-this.s, CURVE.n)) : this;
    }
    toDERRawBytes() {
        return hexToBytes(this.toDERHex());
    }
    toDERHex() {
        const sHex = sliceDER(numberToHexUnpadded(this.s));
        const rHex = sliceDER(numberToHexUnpadded(this.r));
        const sHexL = sHex.length / 2;
        const rHexL = rHex.length / 2;
        const sLen = numberToHexUnpadded(sHexL);
        const rLen = numberToHexUnpadded(rHexL);
        const length = numberToHexUnpadded(rHexL + sHexL + 4);
        return `30${length}02${rLen}${rHex}02${sLen}${sHex}`;
    }
    toRawBytes() {
        return this.toDERRawBytes();
    }
    toHex() {
        return this.toDERHex();
    }
    toCompactRawBytes() {
        return hexToBytes(this.toCompactHex());
    }
    toCompactHex() {
        return numTo32bStr(this.r) + numTo32bStr(this.s);
    }
}
function concatBytes(...arrays) {
    if (!arrays.every((b) => b instanceof Uint8Array))
        throw new Error('Uint8Array list expected');
    if (arrays.length === 1)
        return arrays[0];
    const length = arrays.reduce((a, arr) => a + arr.length, 0);
    const result = new Uint8Array(length);
    for (let i = 0, pad = 0; i < arrays.length; i++) {
        const arr = arrays[i];
        result.set(arr, pad);
        pad += arr.length;
    }
    return result;
}
const hexes = Array.from({ length: 256 }, (v, i) => i.toString(16).padStart(2, '0'));
function bytesToHex(uint8a) {
    if (!(uint8a instanceof Uint8Array))
        throw new Error('Expected Uint8Array');
    let hex = '';
    for (let i = 0; i < uint8a.length; i++) {
        hex += hexes[uint8a[i]];
    }
    return hex;
}
const POW_2_256 = BigInt('0x10000000000000000000000000000000000000000000000000000000000000000');
function numTo32bStr(num) {
    if (typeof num !== 'bigint')
        throw new Error('Expected bigint');
    if (!(_0n$1 <= num && num < POW_2_256))
        throw new Error('Expected number 0 <= n < 2^256');
    return num.toString(16).padStart(64, '0');
}
function numTo32b(num) {
    const b = hexToBytes(numTo32bStr(num));
    if (b.length !== 32)
        throw new Error('Error: expected 32 bytes');
    return b;
}
function numberToHexUnpadded(num) {
    const hex = num.toString(16);
    return hex.length & 1 ? `0${hex}` : hex;
}
function hexToNumber(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToNumber: expected string, got ' + typeof hex);
    }
    return BigInt(`0x${hex}`);
}
function hexToBytes(hex) {
    if (typeof hex !== 'string') {
        throw new TypeError('hexToBytes: expected string, got ' + typeof hex);
    }
    if (hex.length % 2)
        throw new Error('hexToBytes: received invalid unpadded hex' + hex.length);
    const array = new Uint8Array(hex.length / 2);
    for (let i = 0; i < array.length; i++) {
        const j = i * 2;
        const hexByte = hex.slice(j, j + 2);
        const byte = Number.parseInt(hexByte, 16);
        if (Number.isNaN(byte) || byte < 0)
            throw new Error('Invalid byte sequence');
        array[i] = byte;
    }
    return array;
}
function bytesToNumber(bytes) {
    return hexToNumber(bytesToHex(bytes));
}
function ensureBytes(hex) {
    return hex instanceof Uint8Array ? Uint8Array.from(hex) : hexToBytes(hex);
}
function normalizeScalar(num) {
    if (typeof num === 'number' && Number.isSafeInteger(num) && num > 0)
        return BigInt(num);
    if (typeof num === 'bigint' && isWithinCurveOrder(num))
        return num;
    throw new TypeError('Expected valid private scalar: 0 < scalar < curve.n');
}
function mod(a, b = CURVE.P) {
    const result = a % b;
    return result >= _0n$1 ? result : b + result;
}
function pow2(x, power) {
    const { P } = CURVE;
    let res = x;
    while (power-- > _0n$1) {
        res *= res;
        res %= P;
    }
    return res;
}
function sqrtMod$1(x) {
    const { P } = CURVE;
    const _6n = BigInt(6);
    const _11n = BigInt(11);
    const _22n = BigInt(22);
    const _23n = BigInt(23);
    const _44n = BigInt(44);
    const _88n = BigInt(88);
    const b2 = (x * x * x) % P;
    const b3 = (b2 * b2 * x) % P;
    const b6 = (pow2(b3, _3n$1) * b3) % P;
    const b9 = (pow2(b6, _3n$1) * b3) % P;
    const b11 = (pow2(b9, _2n$1) * b2) % P;
    const b22 = (pow2(b11, _11n) * b11) % P;
    const b44 = (pow2(b22, _22n) * b22) % P;
    const b88 = (pow2(b44, _44n) * b44) % P;
    const b176 = (pow2(b88, _88n) * b88) % P;
    const b220 = (pow2(b176, _44n) * b44) % P;
    const b223 = (pow2(b220, _3n$1) * b3) % P;
    const t1 = (pow2(b223, _23n) * b22) % P;
    const t2 = (pow2(t1, _6n) * b2) % P;
    const rt = pow2(t2, _2n$1);
    const xc = (rt * rt) % P;
    if (xc !== x)
        throw new Error('Cannot find square root');
    return rt;
}
function invert(number, modulo = CURVE.P) {
    if (number === _0n$1 || modulo <= _0n$1) {
        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);
    }
    let a = mod(number, modulo);
    let b = modulo;
    let x = _0n$1, u = _1n$2;
    while (a !== _0n$1) {
        const q = b / a;
        const r = b % a;
        const m = x - u * q;
        b = a, a = r, x = u, u = m;
    }
    const gcd = b;
    if (gcd !== _1n$2)
        throw new Error('invert: does not exist');
    return mod(x, modulo);
}
function invertBatch(nums, p = CURVE.P) {
    const scratch = new Array(nums.length);
    const lastMultiplied = nums.reduce((acc, num, i) => {
        if (num === _0n$1)
            return acc;
        scratch[i] = acc;
        return mod(acc * num, p);
    }, _1n$2);
    const inverted = invert(lastMultiplied, p);
    nums.reduceRight((acc, num, i) => {
        if (num === _0n$1)
            return acc;
        scratch[i] = mod(acc * scratch[i], p);
        return mod(acc * num, p);
    }, inverted);
    return scratch;
}
function bits2int_2(bytes) {
    const delta = bytes.length * 8 - groupLen * 8;
    const num = bytesToNumber(bytes);
    return delta > 0 ? num >> BigInt(delta) : num;
}
function truncateHash(hash, truncateOnly = false) {
    const h = bits2int_2(hash);
    if (truncateOnly)
        return h;
    const { n } = CURVE;
    return h >= n ? h - n : h;
}
let _sha256Sync;
let _hmacSha256Sync;
class HmacDrbg {
    constructor(hashLen, qByteLen) {
        this.hashLen = hashLen;
        this.qByteLen = qByteLen;
        if (typeof hashLen !== 'number' || hashLen < 2)
            throw new Error('hashLen must be a number');
        if (typeof qByteLen !== 'number' || qByteLen < 2)
            throw new Error('qByteLen must be a number');
        this.v = new Uint8Array(hashLen).fill(1);
        this.k = new Uint8Array(hashLen).fill(0);
        this.counter = 0;
    }
    hmac(...values) {
        return utils.hmacSha256(this.k, ...values);
    }
    hmacSync(...values) {
        return _hmacSha256Sync(this.k, ...values);
    }
    checkSync() {
        if (typeof _hmacSha256Sync !== 'function')
            throw new ShaError('hmacSha256Sync needs to be set');
    }
    incr() {
        if (this.counter >= 1000)
            throw new Error('Tried 1,000 k values for sign(), all were invalid');
        this.counter += 1;
    }
    async reseed(seed = new Uint8Array()) {
        this.k = await this.hmac(this.v, Uint8Array.from([0x00]), seed);
        this.v = await this.hmac(this.v);
        if (seed.length === 0)
            return;
        this.k = await this.hmac(this.v, Uint8Array.from([0x01]), seed);
        this.v = await this.hmac(this.v);
    }
    reseedSync(seed = new Uint8Array()) {
        this.checkSync();
        this.k = this.hmacSync(this.v, Uint8Array.from([0x00]), seed);
        this.v = this.hmacSync(this.v);
        if (seed.length === 0)
            return;
        this.k = this.hmacSync(this.v, Uint8Array.from([0x01]), seed);
        this.v = this.hmacSync(this.v);
    }
    async generate() {
        this.incr();
        let len = 0;
        const out = [];
        while (len < this.qByteLen) {
            this.v = await this.hmac(this.v);
            const sl = this.v.slice();
            out.push(sl);
            len += this.v.length;
        }
        return concatBytes(...out);
    }
    generateSync() {
        this.checkSync();
        this.incr();
        let len = 0;
        const out = [];
        while (len < this.qByteLen) {
            this.v = this.hmacSync(this.v);
            const sl = this.v.slice();
            out.push(sl);
            len += this.v.length;
        }
        return concatBytes(...out);
    }
}
function isWithinCurveOrder(num) {
    return _0n$1 < num && num < CURVE.n;
}
function isValidFieldElement(num) {
    return _0n$1 < num && num < CURVE.P;
}
function kmdToSig(kBytes, m, d, lowS = true) {
    const { n } = CURVE;
    const k = truncateHash(kBytes, true);
    if (!isWithinCurveOrder(k))
        return;
    const kinv = invert(k, n);
    const q = Point.BASE.multiply(k);
    const r = mod(q.x, n);
    if (r === _0n$1)
        return;
    const s = mod(kinv * mod(m + d * r, n), n);
    if (s === _0n$1)
        return;
    let sig = new Signature(r, s);
    let recovery = (q.x === sig.r ? 0 : 2) | Number(q.y & _1n$2);
    if (lowS && sig.hasHighS()) {
        sig = sig.normalizeS();
        recovery ^= 1;
    }
    return { sig, recovery };
}
function normalizePrivateKey(key) {
    let num;
    if (typeof key === 'bigint') {
        num = key;
    }
    else if (typeof key === 'number' && Number.isSafeInteger(key) && key > 0) {
        num = BigInt(key);
    }
    else if (typeof key === 'string') {
        if (key.length !== 2 * groupLen)
            throw new Error('Expected 32 bytes of private key');
        num = hexToNumber(key);
    }
    else if (key instanceof Uint8Array) {
        if (key.length !== groupLen)
            throw new Error('Expected 32 bytes of private key');
        num = bytesToNumber(key);
    }
    else {
        throw new TypeError('Expected valid private key');
    }
    if (!isWithinCurveOrder(num))
        throw new Error('Expected private key: 0 < key < n');
    return num;
}
function normalizePublicKey(publicKey) {
    if (publicKey instanceof Point) {
        publicKey.assertValidity();
        return publicKey;
    }
    else {
        return Point.fromHex(publicKey);
    }
}
function normalizeSignature(signature) {
    if (signature instanceof Signature) {
        signature.assertValidity();
        return signature;
    }
    try {
        return Signature.fromDER(signature);
    }
    catch (error) {
        return Signature.fromCompact(signature);
    }
}
function getPublicKey(privateKey, isCompressed = false) {
    return Point.fromPrivateKey(privateKey).toRawBytes(isCompressed);
}
function bits2int(bytes) {
    const slice = bytes.length > fieldLen ? bytes.slice(0, fieldLen) : bytes;
    return bytesToNumber(slice);
}
function bits2octets(bytes) {
    const z1 = bits2int(bytes);
    const z2 = mod(z1, CURVE.n);
    return int2octets(z2 < _0n$1 ? z1 : z2);
}
function int2octets(num) {
    return numTo32b(num);
}
function initSigArgs(msgHash, privateKey, extraEntropy) {
    if (msgHash == null)
        throw new Error(`sign: expected valid message hash, not "${msgHash}"`);
    const h1 = ensureBytes(msgHash);
    const d = normalizePrivateKey(privateKey);
    const seedArgs = [int2octets(d), bits2octets(h1)];
    if (extraEntropy != null) {
        if (extraEntropy === true)
            extraEntropy = utils.randomBytes(fieldLen);
        const e = ensureBytes(extraEntropy);
        if (e.length !== fieldLen)
            throw new Error(`sign: Expected ${fieldLen} bytes of extra data`);
        seedArgs.push(e);
    }
    const seed = concatBytes(...seedArgs);
    const m = bits2int(h1);
    return { seed, m, d };
}
function finalizeSig(recSig, opts) {
    const { sig, recovery } = recSig;
    const { der, recovered } = Object.assign({ canonical: true, der: true }, opts);
    const hashed = der ? sig.toDERRawBytes() : sig.toCompactRawBytes();
    return recovered ? [hashed, recovery] : hashed;
}
async function sign$1(msgHash, privKey, opts = {}) {
    const { seed, m, d } = initSigArgs(msgHash, privKey, opts.extraEntropy);
    const drbg = new HmacDrbg(hashLen, groupLen);
    await drbg.reseed(seed);
    let sig;
    while (!(sig = kmdToSig(await drbg.generate(), m, d, opts.canonical)))
        await drbg.reseed();
    return finalizeSig(sig, opts);
}
const vopts = { strict: true };
function verify(signature, msgHash, publicKey, opts = vopts) {
    let sig;
    try {
        sig = normalizeSignature(signature);
        msgHash = ensureBytes(msgHash);
    }
    catch (error) {
        return false;
    }
    const { r, s } = sig;
    if (opts.strict && sig.hasHighS())
        return false;
    const h = truncateHash(msgHash);
    let P;
    try {
        P = normalizePublicKey(publicKey);
    }
    catch (error) {
        return false;
    }
    const { n } = CURVE;
    const sinv = invert(s, n);
    const u1 = mod(h * sinv, n);
    const u2 = mod(r * sinv, n);
    const R = Point.BASE.multiplyAndAddUnsafe(P, u1, u2);
    if (!R)
        return false;
    const v = mod(R.x, n);
    return v === r;
}
Point.BASE._setWindowSize(8);
const crypto$3 = {
    node: nodeCrypto,
    web: typeof self === 'object' && 'crypto' in self ? self.crypto : undefined,
};
const TAGGED_HASH_PREFIXES = {};
const utils = {
    bytesToHex,
    hexToBytes,
    concatBytes,
    mod,
    invert,
    isValidPrivateKey(privateKey) {
        try {
            normalizePrivateKey(privateKey);
            return true;
        }
        catch (error) {
            return false;
        }
    },
    _bigintTo32Bytes: numTo32b,
    _normalizePrivateKey: normalizePrivateKey,
    hashToPrivateKey: (hash) => {
        hash = ensureBytes(hash);
        const minLen = groupLen + 8;
        if (hash.length < minLen || hash.length > 1024) {
            throw new Error(`Expected valid bytes of private key as per FIPS 186`);
        }
        const num = mod(bytesToNumber(hash), CURVE.n - _1n$2) + _1n$2;
        return numTo32b(num);
    },
    randomBytes: (bytesLength = 32) => {
        if (crypto$3.web) {
            return crypto$3.web.getRandomValues(new Uint8Array(bytesLength));
        }
        else if (crypto$3.node) {
            const { randomBytes } = crypto$3.node;
            return Uint8Array.from(randomBytes(bytesLength));
        }
        else {
            throw new Error("The environment doesn't have randomBytes function");
        }
    },
    randomPrivateKey: () => utils.hashToPrivateKey(utils.randomBytes(groupLen + 8)),
    precompute(windowSize = 8, point = Point.BASE) {
        const cached = point === Point.BASE ? point : new Point(point.x, point.y);
        cached._setWindowSize(windowSize);
        cached.multiply(_3n$1);
        return cached;
    },
    sha256: async (...messages) => {
        if (crypto$3.web) {
            const buffer = await crypto$3.web.subtle.digest('SHA-256', concatBytes(...messages));
            return new Uint8Array(buffer);
        }
        else if (crypto$3.node) {
            const { createHash } = crypto$3.node;
            const hash = createHash('sha256');
            messages.forEach((m) => hash.update(m));
            return Uint8Array.from(hash.digest());
        }
        else {
            throw new Error("The environment doesn't have sha256 function");
        }
    },
    hmacSha256: async (key, ...messages) => {
        if (crypto$3.web) {
            const ckey = await crypto$3.web.subtle.importKey('raw', key, { name: 'HMAC', hash: { name: 'SHA-256' } }, false, ['sign']);
            const message = concatBytes(...messages);
            const buffer = await crypto$3.web.subtle.sign('HMAC', ckey, message);
            return new Uint8Array(buffer);
        }
        else if (crypto$3.node) {
            const { createHmac } = crypto$3.node;
            const hash = createHmac('sha256', key);
            messages.forEach((m) => hash.update(m));
            return Uint8Array.from(hash.digest());
        }
        else {
            throw new Error("The environment doesn't have hmac-sha256 function");
        }
    },
    sha256Sync: undefined,
    hmacSha256Sync: undefined,
    taggedHash: async (tag, ...messages) => {
        let tagP = TAGGED_HASH_PREFIXES[tag];
        if (tagP === undefined) {
            const tagH = await utils.sha256(Uint8Array.from(tag, (c) => c.charCodeAt(0)));
            tagP = concatBytes(tagH, tagH);
            TAGGED_HASH_PREFIXES[tag] = tagP;
        }
        return utils.sha256(tagP, ...messages);
    },
    taggedHashSync: (tag, ...messages) => {
        if (typeof _sha256Sync !== 'function')
            throw new ShaError('sha256Sync is undefined, you need to set it');
        let tagP = TAGGED_HASH_PREFIXES[tag];
        if (tagP === undefined) {
            const tagH = _sha256Sync(Uint8Array.from(tag, (c) => c.charCodeAt(0)));
            tagP = concatBytes(tagH, tagH);
            TAGGED_HASH_PREFIXES[tag] = tagP;
        }
        return _sha256Sync(tagP, ...messages);
    },
    _JacobianPoint: JacobianPoint,
};
Object.defineProperties(utils, {
    sha256Sync: {
        configurable: false,
        get() {
            return _sha256Sync;
        },
        set(val) {
            if (!_sha256Sync)
                _sha256Sync = val;
        },
    },
    hmacSha256Sync: {
        configurable: false,
        get() {
            return _hmacSha256Sync;
        },
        set(val) {
            if (!_hmacSha256Sync)
                _hmacSha256Sync = val;
        },
    },
});

function randomBytes$6(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError$3('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return utils.randomBytes(length);
}

function convert$6(key, types) {
    return types.map(t => base64urlToBigInteger$6(key[t]));
}
function jwk2priv$6(key) {
    return forge$n.pki.setRsaPrivateKey(...convert$6(key, ['n', 'e', 'd', 'p', 'q', 'dp', 'dq', 'qi']));
}
function jwk2pub$6(key) {
    return forge$n.pki.setRsaPublicKey(...convert$6(key, ['n', 'e']));
}

// Convert a PKCS#1 in ASN1 DER format to a JWK key
function pkcs1ToJwk$6(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
    // https://tools.ietf.org/html/rfc7518#section-6.3.1
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$6(privateKey.n),
        e: bigIntegerToUintBase64url$6(privateKey.e),
        d: bigIntegerToUintBase64url$6(privateKey.d),
        p: bigIntegerToUintBase64url$6(privateKey.p),
        q: bigIntegerToUintBase64url$6(privateKey.q),
        dp: bigIntegerToUintBase64url$6(privateKey.dP),
        dq: bigIntegerToUintBase64url$6(privateKey.dQ),
        qi: bigIntegerToUintBase64url$6(privateKey.qInv),
        alg: 'RS256'
    };
}
// Convert a JWK key into PKCS#1 in ASN1 DER format
function jwkToPkcs1$6(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.privateKeyToAsn1({
        n: base64urlToBigInteger$6(jwk.n),
        e: base64urlToBigInteger$6(jwk.e),
        d: base64urlToBigInteger$6(jwk.d),
        p: base64urlToBigInteger$6(jwk.p),
        q: base64urlToBigInteger$6(jwk.q),
        dP: base64urlToBigInteger$6(jwk.dp),
        dQ: base64urlToBigInteger$6(jwk.dq),
        qInv: base64urlToBigInteger$6(jwk.qi)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}
// Convert a PKCIX in ASN1 DER format to a JWK key
function pkixToJwk$6(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const publicKey = forge$n.pki.publicKeyFromAsn1(asn1);
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$6(publicKey.n),
        e: bigIntegerToUintBase64url$6(publicKey.e)
    };
}
// Convert a JWK key to PKCIX in ASN1 DER format
function jwkToPkix$6(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.publicKeyToAsn1({
        n: base64urlToBigInteger$6(jwk.n),
        e: base64urlToBigInteger$6(jwk.e)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}

async function generateKey$j(bits) {
    const pair = await webcrypto$6.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey$6(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$a(key) {
    const privateKey = await webcrypto$6.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate$6(key)
    ];
    const keys = await exportKey$6({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$j(key, msg) {
    const privateKey = await webcrypto$6.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto$6.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, Uint8Array.from(msg));
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$j(key, sig, msg) {
    const publicKey = await webcrypto$6.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return webcrypto$6.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg);
}
async function exportKey$6(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError$3('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return Promise.all([
        webcrypto$6.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto$6.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate$6(jwKey) {
    return webcrypto$6.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
/*

RSA encryption/decryption for the browser with webcrypto workaround
"bloody dark magic. webcrypto's why."

Explanation:
  - Convert JWK to nodeForge
  - Convert msg Uint8Array to nodeForge buffer: ByteBuffer is a "binary-string backed buffer", so let's make our Uint8Array a binary string
  - Convert resulting nodeForge buffer to Uint8Array: it returns a binary string, turn that into a Uint8Array

*/
function convertKey$6(key, pub, msg, handle) {
    const fkey = pub ? jwk2pub$6(key) : jwk2priv$6(key);
    const fmsg = toString$9(Uint8Array.from(msg), 'ascii');
    const fomsg = handle(fmsg, fkey);
    return fromString$3(fomsg, 'ascii');
}
function encrypt$6(key, msg) {
    return convertKey$6(key, true, msg, (msg, key) => key.encrypt(msg));
}
function decrypt$6(key, msg) {
    return convertKey$6(key, false, msg, (msg, key) => key.decrypt(msg));
}
function keySize$5(jwk) {
    if (jwk.kty !== 'RSA') {
        throw new CodeError$3('invalid key type', 'ERR_INVALID_KEY_TYPE');
    }
    else if (jwk.n == null) {
        throw new CodeError$3('invalid key modulus', 'ERR_INVALID_KEY_MODULUS');
    }
    const bytes = fromString$3(jwk.n, 'base64url');
    return bytes.length * 8;
}

const MAX_KEY_SIZE$5 = 8192;
let RsaPublicKey$6 = class RsaPublicKey {
    _key;
    constructor(key) {
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$j(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix$6(this._key);
    }
    get bytes() {
        return PublicKey$7.encode({
            Type: KeyType$7.RSA,
            Data: this.marshal()
        }).subarray();
    }
    encrypt(bytes) {
        return encrypt$6(this._key, bytes);
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$8.digest(this.bytes);
        return bytes;
    }
};
let RsaPrivateKey$6 = class RsaPrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes$6(16);
    }
    async sign(message) {
        return hashAndSign$j(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError$3('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey$6(this._publicKey);
    }
    decrypt(bytes) {
        return decrypt$6(this._key, bytes);
    }
    marshal() {
        return jwkToPkcs1$6(this._key);
    }
    get bytes() {
        return PrivateKey$7.encode({
            Type: KeyType$7.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$8.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected PEM format
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            const buffer = new forge$n.util.ByteBuffer(this.marshal());
            const asn1 = forge$n.asn1.fromDer(buffer);
            const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
            const options = {
                algorithm: 'aes256',
                count: 10000,
                saltSize: 128 / 8,
                prfAlgorithm: 'sha512'
            };
            return forge$n.pki.encryptRsaPrivateKey(privateKey, password, options);
        }
        else if (format === 'libp2p-key') {
            return exporter$6(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
async function unmarshalRsaPrivateKey$6(bytes) {
    const jwk = pkcs1ToJwk$6(bytes);
    if (keySize$5(jwk) > MAX_KEY_SIZE$5) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$a(jwk);
    return new RsaPrivateKey$6(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey$6(bytes) {
    const jwk = pkixToJwk$6(bytes);
    if (keySize$5(jwk) > MAX_KEY_SIZE$5) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    return new RsaPublicKey$6(jwk);
}
async function fromJwk$6(jwk) {
    if (keySize$5(jwk) > MAX_KEY_SIZE$5) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$a(jwk);
    return new RsaPrivateKey$6(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$l(bits) {
    if (bits > MAX_KEY_SIZE$5) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await generateKey$j(bits);
    return new RsaPrivateKey$6(keys.privateKey, keys.publicKey);
}

var RSA$6 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MAX_KEY_SIZE: MAX_KEY_SIZE$5,
    RsaPrivateKey: RsaPrivateKey$6,
    RsaPublicKey: RsaPublicKey$6,
    fromJwk: fromJwk$6,
    generateKeyPair: generateKeyPair$l,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey$6,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey$6
});

function generateKey$i() {
    return utils.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
async function hashAndSign$i(key, msg) {
    const { digest } = await sha256$8.digest(msg);
    try {
        return await sign$1(digest, key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
async function hashAndVerify$i(key, sig, msg) {
    try {
        const { digest } = await sha256$8.digest(msg);
        return verify(sig, digest, key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey$6(key) {
    const point = Point.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey$6(key) {
    try {
        getPublicKey(key, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey$6(key) {
    try {
        Point.fromHex(key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey$6(privateKey) {
    try {
        return getPublicKey(privateKey, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

let Secp256k1PublicKey$6 = class Secp256k1PublicKey {
    _key;
    constructor(key) {
        validatePublicKey$6(key);
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$i(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey$6(this._key);
    }
    get bytes() {
        return PublicKey$7.encode({
            Type: KeyType$7.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$8.digest(this.bytes);
        return bytes;
    }
};
let Secp256k1PrivateKey$6 = class Secp256k1PrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey$6(key);
        validatePrivateKey$6(this._key);
        validatePublicKey$6(this._publicKey);
    }
    async sign(message) {
        return hashAndSign$i(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey$6(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$7.encode({
            Type: KeyType$7.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$8.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$6(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalSecp256k1PrivateKey$6(bytes) {
    return new Secp256k1PrivateKey$6(bytes);
}
function unmarshalSecp256k1PublicKey$6(bytes) {
    return new Secp256k1PublicKey$6(bytes);
}
async function generateKeyPair$k() {
    const privateKeyBytes = generateKey$i();
    return new Secp256k1PrivateKey$6(privateKeyBytes);
}

var Secp256k1$6 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey$6,
    Secp256k1PublicKey: Secp256k1PublicKey$6,
    generateKeyPair: generateKeyPair$k,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey$6,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey$6
});

const supportedKeys$6 = {
    rsa: RSA$6,
    ed25519: Ed25519$6,
    secp256k1: Secp256k1$6
};
function unsupportedKey$5(type) {
    const supported = Object.keys(supportedKeys$6).join(' / ');
    return new CodeError$3(`invalid or unsupported key type ${type}. Must be ${supported}`, 'ERR_UNSUPPORTED_KEY_TYPE');
}
// Converts a protobuf serialized public key into its
// representative object
function unmarshalPublicKey$3(buf) {
    const decoded = PublicKey$7.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType$7.RSA:
            return supportedKeys$6.rsa.unmarshalRsaPublicKey(data);
        case KeyType$7.Ed25519:
            return supportedKeys$6.ed25519.unmarshalEd25519PublicKey(data);
        case KeyType$7.Secp256k1:
            return supportedKeys$6.secp256k1.unmarshalSecp256k1PublicKey(data);
        default:
            throw unsupportedKey$5(decoded.Type ?? 'RSA');
    }
}
// Converts a protobuf serialized private key into its
// representative object
async function unmarshalPrivateKey$9(buf) {
    const decoded = PrivateKey$7.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType$7.RSA:
            return supportedKeys$6.rsa.unmarshalRsaPrivateKey(data);
        case KeyType$7.Ed25519:
            return supportedKeys$6.ed25519.unmarshalEd25519PrivateKey(data);
        case KeyType$7.Secp256k1:
            return supportedKeys$6.secp256k1.unmarshalSecp256k1PrivateKey(data);
        default:
            throw unsupportedKey$5(decoded.Type ?? 'RSA');
    }
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$c (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$b = base$c;

var _brrp__multiformats_scope_baseX$b = src$b;

/**
 * @param {Uint8Array} aa
 * @param {Uint8Array} bb
 */
const equals$3 = (aa, bb) => {
  if (aa === bb) return true
  if (aa.byteLength !== bb.byteLength) {
    return false
  }

  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false
    }
  }

  return true
};

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$b = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
const fromString$2 = str => (new TextEncoder()).encode(str);

/**
 * @param {Uint8Array} b
 * @returns {string}
 */
const toString$7 = b => (new TextDecoder()).decode(b);

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$c = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$c = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$c(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$b = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$c(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$c = (left, right) => new ComposedDecoder$b(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$b = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$c(name, prefix, baseEncode);
    this.decoder = new Decoder$c(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$j = ({ name, prefix, encode, decode }) =>
  new Codec$b(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$b = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$b(alphabet, name);
  return from$j({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$b(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$s = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$x = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$b = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$j({
    prefix,
    name,
    encode (input) {
      return encode$x(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$s(input, alphabet, bitsPerChar, name)
    }
  })
};

const base58btc$a = baseX$b({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

const base58flickr$1 = baseX$b({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var base58$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base58btc: base58btc$a,
    base58flickr: base58flickr$1
});

const base10$2 = baseX$b({
  prefix: '9',
  name: 'base10',
  alphabet: '0123456789'
});

var base10$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base10: base10$2
});

// @ts-check


const base16$2 = rfc4648$b({
  prefix: 'f',
  name: 'base16',
  alphabet: '0123456789abcdef',
  bitsPerChar: 4
});

const base16upper$1 = rfc4648$b({
  prefix: 'F',
  name: 'base16upper',
  alphabet: '0123456789ABCDEF',
  bitsPerChar: 4
});

var base16$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base16: base16$2,
    base16upper: base16upper$1
});

// @ts-check


const base2$2 = rfc4648$b({
  prefix: '0',
  name: 'base2',
  alphabet: '01',
  bitsPerChar: 1
});

var base2$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base2: base2$2
});

const alphabet$1 = Array.from('🚀🪐☄🛰🌌🌑🌒🌓🌔🌕🌖🌗🌘🌍🌏🌎🐉☀💻🖥💾💿😂❤😍🤣😊🙏💕😭😘👍😅👏😁🔥🥰💔💖💙😢🤔😆🙄💪😉☺👌🤗💜😔😎😇🌹🤦🎉💞✌✨🤷😱😌🌸🙌😋💗💚😏💛🙂💓🤩😄😀🖤😃💯🙈👇🎶😒🤭❣😜💋👀😪😑💥🙋😞😩😡🤪👊🥳😥🤤👉💃😳✋😚😝😴🌟😬🙃🍀🌷😻😓⭐✅🥺🌈😈🤘💦✔😣🏃💐☹🎊💘😠☝😕🌺🎂🌻😐🖕💝🙊😹🗣💫💀👑🎵🤞😛🔴😤🌼😫⚽🤙☕🏆🤫👈😮🙆🍻🍃🐶💁😲🌿🧡🎁⚡🌞🎈❌✊👋😰🤨😶🤝🚶💰🍓💢🤟🙁🚨💨🤬✈🎀🍺🤓😙💟🌱😖👶🥴▶➡❓💎💸⬇😨🌚🦋😷🕺⚠🙅😟😵👎🤲🤠🤧📌🔵💅🧐🐾🍒😗🤑🌊🤯🐷☎💧😯💆👆🎤🙇🍑❄🌴💣🐸💌📍🥀🤢👅💡💩👐📸👻🤐🤮🎼🥵🚩🍎🍊👼💍📣🥂');
const alphabetBytesToChars$1 = /** @type {string[]} */ (alphabet$1.reduce((p, c, i) => { p[i] = c; return p }, /** @type {string[]} */([])));
const alphabetCharsToBytes$1 = /** @type {number[]} */ (alphabet$1.reduce((p, c, i) => { p[/** @type {number} */ (c.codePointAt(0))] = i; return p }, /** @type {number[]} */([])));

/**
 * @param {Uint8Array} data
 * @returns {string}
 */
function encode$w (data) {
  return data.reduce((p, c) => {
    p += alphabetBytesToChars$1[c];
    return p
  }, '')
}

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
function decode$r (str) {
  const byts = [];
  for (const char of str) {
    const byt = alphabetCharsToBytes$1[/** @type {number} */ (char.codePointAt(0))];
    if (byt === undefined) {
      throw new Error(`Non-base256emoji character: ${char}`)
    }
    byts.push(byt);
  }
  return new Uint8Array(byts)
}

const base256emoji$2 = from$j({
  prefix: '🚀',
  name: 'base256emoji',
  encode: encode$w,
  decode: decode$r
});

var base256emoji$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base256emoji: base256emoji$2
});

const base32$c = rfc4648$b({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

const base32upper$1 = rfc4648$b({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

const base32pad$1 = rfc4648$b({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

const base32padupper$1 = rfc4648$b({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

const base32hex$1 = rfc4648$b({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

const base32hexupper$1 = rfc4648$b({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

const base32hexpad$1 = rfc4648$b({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

const base32hexpadupper$1 = rfc4648$b({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

const base32z$1 = rfc4648$b({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

var base32$d = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base32: base32$c,
    base32hex: base32hex$1,
    base32hexpad: base32hexpad$1,
    base32hexpadupper: base32hexpadupper$1,
    base32hexupper: base32hexupper$1,
    base32pad: base32pad$1,
    base32padupper: base32padupper$1,
    base32upper: base32upper$1,
    base32z: base32z$1
});

const base36$2 = baseX$b({
  prefix: 'k',
  name: 'base36',
  alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'
});

const base36upper$1 = baseX$b({
  prefix: 'K',
  name: 'base36upper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
});

var base36$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base36: base36$2,
    base36upper: base36upper$1
});

// @ts-check


const base64$b = rfc4648$b({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

const base64pad$1 = rfc4648$b({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

const base64url$1 = rfc4648$b({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

const base64urlpad$1 = rfc4648$b({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

var base64$c = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base64: base64$b,
    base64pad: base64pad$1,
    base64url: base64url$1,
    base64urlpad: base64urlpad$1
});

// @ts-check


const base8$2 = rfc4648$b({
  prefix: '7',
  name: 'base8',
  alphabet: '01234567',
  bitsPerChar: 3
});

var base8$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base8: base8$2
});

// @ts-check


const identity$8 = from$j({
  prefix: '\x00',
  name: 'identity',
  encode: (buf) => toString$7(buf),
  decode: (str) => fromString$2(str)
});

var identityBase$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identity: identity$8
});

// @ts-check

/**
 * @template T
 * @typedef {import('./interface.js').ByteView<T>} ByteView
 */

new TextEncoder();
new TextDecoder();

var encode_1$6 = encode$v;

var MSB$8 = 0x80
  , REST$8 = 0x7F
  , MSBALL$6 = ~REST$8
  , INT$6 = Math.pow(2, 31);

function encode$v(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$6) {
    out[offset++] = (num & 0xFF) | MSB$8;
    num /= 128;
  }
  while(num & MSBALL$6) {
    out[offset++] = (num & 0xFF) | MSB$8;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$v.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$q = read$7;

var MSB$1$6 = 0x80
  , REST$1$6 = 0x7F;

function read$7(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$7.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$6) << shift
      : (b & REST$1$6) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$6)

  read$7.bytes = counter - offset;

  return res
}

var N1$6 = Math.pow(2,  7);
var N2$6 = Math.pow(2, 14);
var N3$6 = Math.pow(2, 21);
var N4$6 = Math.pow(2, 28);
var N5$6 = Math.pow(2, 35);
var N6$6 = Math.pow(2, 42);
var N7$6 = Math.pow(2, 49);
var N8$6 = Math.pow(2, 56);
var N9$6 = Math.pow(2, 63);

var length$6 = function (value) {
  return (
    value < N1$6 ? 1
  : value < N2$6 ? 2
  : value < N3$6 ? 3
  : value < N4$6 ? 4
  : value < N5$6 ? 5
  : value < N6$6 ? 6
  : value < N7$6 ? 7
  : value < N8$6 ? 8
  : value < N9$6 ? 9
  :              10
  )
};

var varint$6 = {
    encode: encode_1$6
  , decode: decode$q
  , encodingLength: length$6
};

var _brrp_varint$6 = varint$6;

/**
 * @param {Uint8Array} data
 * @param {number} [offset=0]
 * @returns {[number, number]}
 */
const decode$p = (data, offset = 0) => {
  const code = _brrp_varint$6.decode(data, offset);
  return [code, _brrp_varint$6.decode.bytes]
};

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo$6 = (int, target, offset = 0) => {
  _brrp_varint$6.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$8 = (int) => {
  return _brrp_varint$6.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$c = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$8(code);
  const digestOffset = sizeOffset + encodingLength$8(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo$6(code, bytes, 0);
  encodeTo$6(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest$6(code, size, digest, bytes)
};

/**
 * Turns bytes representation of multihash digest into an instance.
 *
 * @param {Uint8Array} multihash
 * @returns {MultihashDigest}
 */
const decode$o = (multihash) => {
  const bytes = coerce$b(multihash);
  const [code, sizeOffset] = decode$p(bytes);
  const [size, digestOffset] = decode$p(bytes.subarray(sizeOffset));
  const digest = bytes.subarray(sizeOffset + digestOffset);

  if (digest.byteLength !== size) {
    throw new Error('Incorrect length')
  }

  return new Digest$6(code, size, digest, bytes)
};

/**
 * @param {MultihashDigest} a
 * @param {unknown} b
 * @returns {b is MultihashDigest}
 */
const equals$2 = (a, b) => {
  if (a === b) {
    return true
  } else {
    const data = /** @type {{code?:unknown, size?:unknown, bytes?:unknown}} */(b);

    return (
      a.code === data.code &&
      a.size === data.size &&
      data.bytes instanceof Uint8Array &&
      equals$3(a.bytes, data.bytes)
    )
  }
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
let Digest$6 = class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
};

const code$6 = 0x0;
const name$7 = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$u = coerce$b;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest$6 = (input) => create$c(code$6, encode$u(input));

const identity$7 = { code: code$6, name: name$7, encode: encode$u, digest: digest$6 };

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$i = ({ name, code, encode }) => new Hasher$6(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
let Hasher$6 = class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$c(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$c(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
};

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */


/**
 * @param {AlgorithmIdentifier} name
 */
const sha$6 = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256$7 = from$i({
  name: 'sha2-256',
  code: 0x12,
  encode: sha$6('SHA-256')
});

/**
 * @template {API.Link<unknown, number, number, API.Version>} T
 * @template {string} Prefix
 * @param {T} link
 * @param {API.MultibaseEncoder<Prefix>} [base]
 * @returns {API.ToString<T, Prefix>}
 */
const format$4 = (link, base) => {
  const { bytes, version } = link;
  switch (version) {
    case 0:
      return toStringV0$1(
        bytes,
        baseCache$1(link),
        /** @type {API.MultibaseEncoder<"z">} */ (base) || base58btc$a.encoder
      )
    default:
      return toStringV1$1(
        bytes,
        baseCache$1(link),
        /** @type {API.MultibaseEncoder<Prefix>} */ (base || base32$c.encoder)
      )
  }
};

/** @type {WeakMap<API.UnknownLink, Map<string, string>>} */
const cache$2 = new WeakMap();

/**
 * @param {API.UnknownLink} cid
 * @returns {Map<string, string>}
 */
const baseCache$1 = cid => {
  const baseCache = cache$2.get(cid);
  if (baseCache == null) {
    const baseCache = new Map();
    cache$2.set(cid, baseCache);
    return baseCache
  }
  return baseCache
};

/**
 * @template {unknown} [Data=unknown]
 * @template {number} [Format=number]
 * @template {number} [Alg=number]
 * @template {API.Version} [Version=API.Version]
 * @implements {API.Link<Data, Format, Alg, Version>}
 */

let CID$1 = class CID {
  /**
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} multihash - (Multi)hash of the of the content.
   * @param {Uint8Array} bytes
   */
  constructor (version, code, multihash, bytes) {
    /** @readonly */
    this.code = code;
    /** @readonly */
    this.version = version;
    /** @readonly */
    this.multihash = multihash;
    /** @readonly */
    this.bytes = bytes;

    // flag to serializers that this is a CID and
    // should be treated specially
    /** @readonly */
    this['/'] = bytes;
  }

  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID () {
    return this
  }

  // ArrayBufferView
  get byteOffset () {
    return this.bytes.byteOffset
  }

  // ArrayBufferView
  get byteLength () {
    return this.bytes.byteLength
  }

  /**
   * @returns {CID<Data, API.DAG_PB, API.SHA_256, 0>}
   */
  toV0 () {
    switch (this.version) {
      case 0: {
        return /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */ (this)
      }
      case 1: {
        const { code, multihash } = this;

        if (code !== DAG_PB_CODE$1) {
          throw new Error('Cannot convert a non dag-pb CID to CIDv0')
        }

        // sha2-256
        if (multihash.code !== SHA_256_CODE$1) {
          throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0')
        }

        return /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */ (
          CID.createV0(
            /** @type {API.MultihashDigest<API.SHA_256>} */ (multihash)
          )
        )
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 0. This is a bug please report`
        )
      }
    }
  }

  /**
   * @returns {CID<Data, Format, Alg, 1>}
   */
  toV1 () {
    switch (this.version) {
      case 0: {
        const { code, digest } = this.multihash;
        const multihash = create$c(code, digest);
        return /** @type {CID<Data, Format, Alg, 1>} */ (
          CID.createV1(this.code, multihash)
        )
      }
      case 1: {
        return /** @type {CID<Data, Format, Alg, 1>} */ (this)
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 1. This is a bug please report`
        )
      }
    }
  }

  /**
   * @param {unknown} other
   * @returns {other is CID<Data, Format, Alg, Version>}
   */
  equals (other) {
    return CID.equals(this, other)
  }

  /**
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {API.Link<Data, Format, Alg, Version>} self
   * @param {unknown} other
   * @returns {other is CID}
   */
  static equals (self, other) {
    const unknown =
      /** @type {{code?:unknown, version?:unknown, multihash?:unknown}} */ (
        other
      );
    return (
      unknown &&
      self.code === unknown.code &&
      self.version === unknown.version &&
      equals$2(self.multihash, unknown.multihash)
    )
  }

  /**
   * @param {API.MultibaseEncoder<string>} [base]
   * @returns {string}
   */
  toString (base) {
    return format$4(this, base)
  }

  /**
   * @returns {API.LinkJSON<this>}
   */
  toJSON () {
    return { '/': format$4(this) }
  }

  link () {
    return this
  }

  get [Symbol.toStringTag] () {
    return 'CID'
  }

  // Legacy

  [Symbol.for('nodejs.util.inspect.custom')] () {
    return `CID(${this.toString()})`
  }

  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @template {unknown} U
   * @param {API.Link<Data, Format, Alg, Version>|U} input
   * @returns {CID<Data, Format, Alg, Version>|null}
   */
  static asCID (input) {
    if (input == null) {
      return null
    }

    const value = /** @type {any} */ (input);
    if (value instanceof CID) {
      // If value is instance of CID then we're all set.
      return value
    } else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {
      // If value isn't instance of this CID class but `this.asCID === this` or
      // `value['/'] === value.bytes` is true it is CID instance coming from a
      // different implementation (diff version or duplicate). In that case we
      // rebase it to this `CID` implementation so caller is guaranteed to get
      // instance with expected API.
      const { version, code, multihash, bytes } = value;
      return new CID(
        version,
        code,
        /** @type {API.MultihashDigest<Alg>} */ (multihash),
        bytes || encodeCID$1(version, code, multihash.bytes)
      )
    } else if (value[cidSymbol$1] === true) {
      // If value is a CID from older implementation that used to be tagged via
      // symbol we still rebase it to the this `CID` implementation by
      // delegating that to a constructor.
      const { version, multihash, code } = value;
      const digest =
        /** @type {API.MultihashDigest<Alg>} */
        (decode$o(multihash));
      return CID.create(version, code, digest)
    } else {
      // Otherwise value is not a CID (or an incompatible version of it) in
      // which case we return `null`.
      return null
    }
  }

  /**
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} digest - (Multi)hash of the of the content.
   * @returns {CID<Data, Format, Alg, Version>}
   */
  static create (version, code, digest) {
    if (typeof code !== 'number') {
      throw new Error('String codecs are no longer supported')
    }

    if (!(digest.bytes instanceof Uint8Array)) {
      throw new Error('Invalid digest')
    }

    switch (version) {
      case 0: {
        if (code !== DAG_PB_CODE$1) {
          throw new Error(
            `Version 0 CID must use dag-pb (code: ${DAG_PB_CODE$1}) block encoding`
          )
        } else {
          return new CID(version, code, digest, digest.bytes)
        }
      }
      case 1: {
        const bytes = encodeCID$1(version, code, digest.bytes);
        return new CID(version, code, digest, bytes)
      }
      default: {
        throw new Error('Invalid version')
      }
    }
  }

  /**
   * Simplified version of `create` for CIDv0.
   *
   * @template {unknown} [T=unknown]
   * @param {API.MultihashDigest<typeof SHA_256_CODE>} digest - Multihash.
   * @returns {CID<T, typeof DAG_PB_CODE, typeof SHA_256_CODE, 0>}
   */
  static createV0 (digest) {
    return CID.create(0, DAG_PB_CODE$1, digest)
  }

  /**
   * Simplified version of `create` for CIDv1.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @param {Code} code - Content encoding format code.
   * @param {API.MultihashDigest<Alg>} digest - Miltihash of the content.
   * @returns {CID<Data, Code, Alg, 1>}
   */
  static createV1 (code, digest) {
    return CID.create(1, code, digest)
  }

  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ByteView<API.Link<Data, Code, Alg, Ver>>} bytes
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static decode (bytes) {
    const [cid, remainder] = CID.decodeFirst(bytes);
    if (remainder.length) {
      throw new Error('Incorrect length')
    }
    return cid
  }

  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} bytes
   * @returns {[CID<T, C, A, V>, Uint8Array]}
   */
  static decodeFirst (bytes) {
    const specs = CID.inspectBytes(bytes);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce$b(
      bytes.subarray(prefixSize, prefixSize + specs.multihashSize)
    );
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error('Incorrect length')
    }
    const digestBytes = multihashBytes.subarray(
      specs.multihashSize - specs.digestSize
    );
    const digest = new Digest$6(
      specs.multihashCode,
      specs.digestSize,
      digestBytes,
      multihashBytes
    );
    const cid =
      specs.version === 0
        ? CID.createV0(/** @type {API.MultihashDigest<API.SHA_256>} */ (digest))
        : CID.createV1(specs.codec, digest);
    return [/** @type {CID<T, C, A, V>} */(cid), bytes.subarray(specs.size)]
  }

  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} initialBytes
   * @returns {{ version:V, codec:C, multihashCode:A, digestSize:number, multihashSize:number, size:number }}
   */
  static inspectBytes (initialBytes) {
    let offset = 0;
    const next = () => {
      const [i, length] = decode$p(initialBytes.subarray(offset));
      offset += length;
      return i
    };

    let version = /** @type {V} */ (next());
    let codec = /** @type {C} */ (DAG_PB_CODE$1);
    if (/** @type {number} */(version) === 18) {
      // CIDv0
      version = /** @type {V} */ (0);
      offset = 0;
    } else {
      codec = /** @type {C} */ (next());
    }

    if (version !== 0 && version !== 1) {
      throw new RangeError(`Invalid CID version ${version}`)
    }

    const prefixSize = offset;
    const multihashCode = /** @type {A} */ (next()); // multihash code
    const digestSize = next(); // multihash length
    const size = offset + digestSize;
    const multihashSize = size - prefixSize;

    return { version, codec, multihashCode, digestSize, multihashSize, size }
  }

  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   *
   * @template {string} Prefix
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
   * @param {API.MultibaseDecoder<Prefix>} [base]
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static parse (source, base) {
    const [prefix, bytes] = parseCIDtoBytes$1(source, base);

    const cid = CID.decode(bytes);

    if (cid.version === 0 && source[0] !== 'Q') {
      throw Error('Version 0 CID string must not include multibase prefix')
    }

    // Cache string representation to avoid computing it on `this.toString()`
    baseCache$1(cid).set(prefix, source);

    return cid
  }
};

/**
 * @template {string} Prefix
 * @template {unknown} Data
 * @template {number} Code
 * @template {number} Alg
 * @template {API.Version} Ver
 * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
 * @param {API.MultibaseDecoder<Prefix>} [base]
 * @returns {[Prefix, API.ByteView<API.Link<Data, Code, Alg, Ver>>]}
 */
const parseCIDtoBytes$1 = (source, base) => {
  switch (source[0]) {
    // CIDv0 is parsed differently
    case 'Q': {
      const decoder = base || base58btc$a;
      return [
        /** @type {Prefix} */ (base58btc$a.prefix),
        decoder.decode(`${base58btc$a.prefix}${source}`)
      ]
    }
    case base58btc$a.prefix: {
      const decoder = base || base58btc$a;
      return [/** @type {Prefix} */(base58btc$a.prefix), decoder.decode(source)]
    }
    case base32$c.prefix: {
      const decoder = base || base32$c;
      return [/** @type {Prefix} */(base32$c.prefix), decoder.decode(source)]
    }
    default: {
      if (base == null) {
        throw Error(
          'To parse non base32 or base58btc encoded CID multibase decoder must be provided'
        )
      }
      return [/** @type {Prefix} */(source[0]), base.decode(source)]
    }
  }
};

/**
 *
 * @param {Uint8Array} bytes
 * @param {Map<string, string>} cache
 * @param {API.MultibaseEncoder<'z'>} base
 */
const toStringV0$1 = (bytes, cache, base) => {
  const { prefix } = base;
  if (prefix !== base58btc$a.prefix) {
    throw Error(`Cannot string encode V0 in ${base.name} encoding`)
  }

  const cid = cache.get(prefix);
  if (cid == null) {
    const cid = base.encode(bytes).slice(1);
    cache.set(prefix, cid);
    return cid
  } else {
    return cid
  }
};

/**
 * @template {string} Prefix
 * @param {Uint8Array} bytes
 * @param {Map<string, string>} cache
 * @param {API.MultibaseEncoder<Prefix>} base
 */
const toStringV1$1 = (bytes, cache, base) => {
  const { prefix } = base;
  const cid = cache.get(prefix);
  if (cid == null) {
    const cid = base.encode(bytes);
    cache.set(prefix, cid);
    return cid
  } else {
    return cid
  }
};

const DAG_PB_CODE$1 = 0x70;
const SHA_256_CODE$1 = 0x12;

/**
 * @param {API.Version} version
 * @param {number} code
 * @param {Uint8Array} multihash
 * @returns {Uint8Array}
 */
const encodeCID$1 = (version, code, multihash) => {
  const codeOffset = encodingLength$8(version);
  const hashOffset = codeOffset + encodingLength$8(code);
  const bytes = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo$6(version, bytes, 0);
  encodeTo$6(code, bytes, codeOffset);
  bytes.set(multihash, hashOffset);
  return bytes
};

const cidSymbol$1 = Symbol.for('@ipld/js-cid/CID');

// @ts-check


const bases$1 = { ...identityBase$1, ...base2$3, ...base8$3, ...base10$3, ...base16$3, ...base32$d, ...base36$3, ...base58$1, ...base64$c, ...base256emoji$3 };

const inspect$1 = Symbol.for('nodejs.util.inspect.custom');
const baseDecoder = Object
    .values(bases$1)
    .map(codec => codec.decoder)
    // @ts-expect-error https://github.com/multiformats/js-multiformats/issues/141
    .reduce((acc, curr) => acc.or(curr), bases$1.identity.decoder);
// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv
const LIBP2P_KEY_CODE = 0x72;
const MARSHALLED_ED225519_PUBLIC_KEY_LENGTH = 36;
const MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH = 37;
class PeerIdImpl {
    type;
    multihash;
    privateKey;
    publicKey;
    string;
    constructor(init) {
        this.type = init.type;
        this.multihash = init.multihash;
        this.privateKey = init.privateKey;
        // mark string cache as non-enumerable
        Object.defineProperty(this, 'string', {
            enumerable: false,
            writable: true
        });
    }
    get [Symbol.toStringTag]() {
        return `PeerId(${this.toString()})`;
    }
    [symbol$5] = true;
    toString() {
        if (this.string == null) {
            this.string = base58btc$a.encode(this.multihash.bytes).slice(1);
        }
        return this.string;
    }
    // return self-describing String representation
    // in default format from RFC 0001: https://github.com/libp2p/specs/pull/209
    toCID() {
        return CID$1.createV1(LIBP2P_KEY_CODE, this.multihash);
    }
    toBytes() {
        return this.multihash.bytes;
    }
    /**
     * Returns Multiaddr as a JSON string
     */
    toJSON() {
        return this.toString();
    }
    /**
     * Checks the equality of `this` peer against a given PeerId
     */
    equals(id) {
        if (id instanceof Uint8Array) {
            return equals$4(this.multihash.bytes, id);
        }
        else if (typeof id === 'string') {
            return peerIdFromString(id).equals(this);
        }
        else if (id?.multihash?.bytes != null) {
            return equals$4(this.multihash.bytes, id.multihash.bytes);
        }
        else {
            throw new Error('not valid Id');
        }
    }
    /**
     * Returns PeerId as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { peerIdFromString } from '@libp2p/peer-id'
     *
     * console.info(peerIdFromString('QmFoo'))
     * // 'PeerId(QmFoo)'
     * ```
     */
    [inspect$1]() {
        return `PeerId(${this.toString()})`;
    }
}
class RSAPeerIdImpl extends PeerIdImpl {
    type = 'RSA';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'RSA' });
        this.publicKey = init.publicKey;
    }
}
class Ed25519PeerIdImpl extends PeerIdImpl {
    type = 'Ed25519';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'Ed25519' });
        this.publicKey = init.multihash.digest;
    }
}
class Secp256k1PeerIdImpl extends PeerIdImpl {
    type = 'secp256k1';
    publicKey;
    constructor(init) {
        super({ ...init, type: 'secp256k1' });
        this.publicKey = init.multihash.digest;
    }
}
function peerIdFromPeerId(other) {
    if (other.type === 'RSA') {
        return new RSAPeerIdImpl(other);
    }
    if (other.type === 'Ed25519') {
        return new Ed25519PeerIdImpl(other);
    }
    if (other.type === 'secp256k1') {
        return new Secp256k1PeerIdImpl(other);
    }
    throw new CodeError$3('Not a PeerId', 'ERR_INVALID_PARAMETERS');
}
function peerIdFromString(str, decoder) {
    if (str.charAt(0) === '1' || str.charAt(0) === 'Q') {
        // identity hash ed25519/secp256k1 key or sha2-256 hash of
        // rsa public key - base58btc encoded either way
        const multihash = decode$o(base58btc$a.decode(`z${str}`));
        if (str.startsWith('12D')) {
            return new Ed25519PeerIdImpl({ multihash });
        }
        else if (str.startsWith('16U')) {
            return new Secp256k1PeerIdImpl({ multihash });
        }
        else {
            return new RSAPeerIdImpl({ multihash });
        }
    }
    return peerIdFromBytes(baseDecoder.decode(str));
}
function peerIdFromBytes(buf) {
    try {
        const multihash = decode$o(buf);
        if (multihash.code === identity$7.code) {
            if (multihash.digest.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
                return new Ed25519PeerIdImpl({ multihash });
            }
            else if (multihash.digest.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
                return new Secp256k1PeerIdImpl({ multihash });
            }
        }
        if (multihash.code === sha256$7.code) {
            return new RSAPeerIdImpl({ multihash });
        }
    }
    catch {
        return peerIdFromCID(CID$1.decode(buf));
    }
    throw new Error('Supplied PeerID CID is invalid');
}
function peerIdFromCID(cid) {
    if (cid == null || cid.multihash == null || cid.version == null || (cid.version === 1 && cid.code !== LIBP2P_KEY_CODE)) {
        throw new Error('Supplied PeerID CID is invalid');
    }
    const multihash = cid.multihash;
    if (multihash.code === sha256$7.code) {
        return new RSAPeerIdImpl({ multihash: cid.multihash });
    }
    else if (multihash.code === identity$7.code) {
        if (multihash.digest.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
            return new Ed25519PeerIdImpl({ multihash: cid.multihash });
        }
        else if (multihash.digest.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
            return new Secp256k1PeerIdImpl({ multihash: cid.multihash });
        }
    }
    throw new Error('Supplied PeerID CID is invalid');
}
/**
 * @param publicKey - A marshalled public key
 * @param privateKey - A marshalled private key
 */
async function peerIdFromKeys(publicKey, privateKey) {
    if (publicKey.length === MARSHALLED_ED225519_PUBLIC_KEY_LENGTH) {
        return new Ed25519PeerIdImpl({ multihash: create$c(identity$7.code, publicKey), privateKey });
    }
    if (publicKey.length === MARSHALLED_SECP256K1_PUBLIC_KEY_LENGTH) {
        return new Secp256k1PeerIdImpl({ multihash: create$c(identity$7.code, publicKey), privateKey });
    }
    return new RSAPeerIdImpl({ multihash: await sha256$7.digest(publicKey), publicKey, privateKey });
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var NoiseExtensions;
(function (NoiseExtensions) {
    let _codec;
    NoiseExtensions.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.webtransportCerthashes != null) {
                    for (const value of obj.webtransportCerthashes) {
                        w.uint32(10);
                        w.bytes(value);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    webtransportCerthashes: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.webtransportCerthashes.push(reader.bytes());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    NoiseExtensions.encode = (obj) => {
        return encodeMessage(obj, NoiseExtensions.codec());
    };
    NoiseExtensions.decode = (buf) => {
        return decodeMessage$1(buf, NoiseExtensions.codec());
    };
})(NoiseExtensions || (NoiseExtensions = {}));
var NoiseHandshakePayload;
(function (NoiseHandshakePayload) {
    let _codec;
    NoiseHandshakePayload.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (opts.writeDefaults === true || (obj.identityKey != null && obj.identityKey.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.identityKey ?? new Uint8Array(0));
                }
                if (opts.writeDefaults === true || (obj.identitySig != null && obj.identitySig.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.identitySig ?? new Uint8Array(0));
                }
                if (obj.extensions != null) {
                    w.uint32(34);
                    NoiseExtensions.codec().encode(obj.extensions, w, {
                        writeDefaults: false
                    });
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    identityKey: new Uint8Array(0),
                    identitySig: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.identityKey = reader.bytes();
                            break;
                        case 2:
                            obj.identitySig = reader.bytes();
                            break;
                        case 4:
                            obj.extensions = NoiseExtensions.codec().decode(reader, reader.uint32());
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    NoiseHandshakePayload.encode = (obj) => {
        return encodeMessage(obj, NoiseHandshakePayload.codec());
    };
    NoiseHandshakePayload.decode = (buf) => {
        return decodeMessage$1(buf, NoiseHandshakePayload.codec());
    };
})(NoiseHandshakePayload || (NoiseHandshakePayload = {}));

async function getPayload(localPeer, staticPublicKey, extensions) {
    const signedPayload = await signPayload(localPeer, getHandshakePayload(staticPublicKey));
    if (localPeer.publicKey == null) {
        throw new Error('PublicKey was missing from local PeerId');
    }
    return createHandshakePayload(localPeer.publicKey, signedPayload, extensions);
}
function createHandshakePayload(libp2pPublicKey, signedPayload, extensions) {
    return NoiseHandshakePayload.encode({
        identityKey: libp2pPublicKey,
        identitySig: signedPayload,
        extensions: extensions ?? { webtransportCerthashes: [] }
    }).subarray();
}
async function signPayload(peerId, payload) {
    if (peerId.privateKey == null) {
        throw new Error('PrivateKey was missing from PeerId');
    }
    const privateKey = await unmarshalPrivateKey$9(peerId.privateKey);
    return privateKey.sign(payload);
}
async function getPeerIdFromPayload(payload) {
    return peerIdFromKeys(payload.identityKey);
}
function decodePayload(payload) {
    return NoiseHandshakePayload.decode(payload);
}
function getHandshakePayload(publicKey) {
    const prefix = fromString$3('noise-libp2p-static-key:');
    return concat$1([prefix, publicKey], prefix.length + publicKey.length);
}
/**
 * Verifies signed payload, throws on any irregularities.
 *
 * @param {bytes} noiseStaticKey - owner's noise static key
 * @param {bytes} payload - decoded payload
 * @param {PeerId} remotePeer - owner's libp2p peer ID
 * @returns {Promise<PeerId>} - peer ID of payload owner
 */
async function verifySignedPayload(noiseStaticKey, payload, remotePeer) {
    // Unmarshaling from PublicKey protobuf
    const payloadPeerId = await peerIdFromKeys(payload.identityKey);
    if (!payloadPeerId.equals(remotePeer)) {
        throw new Error(`Payload identity key ${payloadPeerId.toString()} does not match expected remote peer ${remotePeer.toString()}`);
    }
    const generatedPayload = getHandshakePayload(noiseStaticKey);
    if (payloadPeerId.publicKey == null) {
        throw new Error('PublicKey was missing from PeerId');
    }
    if (payload.identitySig == null) {
        throw new Error('Signature was missing from message');
    }
    const publicKey = unmarshalPublicKey$3(payloadPeerId.publicKey);
    const valid = await publicKey.verify(generatedPayload, payload.identitySig);
    if (!valid) {
        throw new Error("Static key doesn't match to peer that signed payload!");
    }
    return payloadPeerId;
}
function isValidPublicKey(pk) {
    if (!(pk instanceof Uint8Array)) {
        return false;
    }
    if (pk.length !== 32) {
        return false;
    }
    return true;
}

const base32$b = rfc4648$c({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

rfc4648$c({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

rfc4648$c({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

rfc4648$c({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

rfc4648$c({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

rfc4648$c({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

rfc4648$c({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

rfc4648$c({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

rfc4648$c({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc$b.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$b.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64$d.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
debug.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger$7(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
function logger$9(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger$7(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (debug.enabled(`${name}:trace`) && debug.names.map(r => r.toString()).find(n => n.includes(':trace')) != null) {
        trace = debug(`${name}:trace`);
    }
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace
    });
}

const log$z = logger$9('libp2p:noise');
let keyLogger;
if (DUMP_SESSION_KEYS) {
    keyLogger = log$z;
}
else {
    keyLogger = Object.assign(() => { }, {
        enabled: false,
        trace: () => { },
        error: () => { }
    });
}
function logLocalStaticKeys(s) {
    keyLogger(`LOCAL_STATIC_PUBLIC_KEY ${toString$9(s.publicKey, 'hex')}`);
    keyLogger(`LOCAL_STATIC_PRIVATE_KEY ${toString$9(s.privateKey, 'hex')}`);
}
function logLocalEphemeralKeys(e) {
    if (e) {
        keyLogger(`LOCAL_PUBLIC_EPHEMERAL_KEY ${toString$9(e.publicKey, 'hex')}`);
        keyLogger(`LOCAL_PRIVATE_EPHEMERAL_KEY ${toString$9(e.privateKey, 'hex')}`);
    }
    else {
        keyLogger('Missing local ephemeral keys.');
    }
}
function logRemoteStaticKey(rs) {
    keyLogger(`REMOTE_STATIC_PUBLIC_KEY ${toString$9(rs, 'hex')}`);
}
function logRemoteEphemeralKey(re) {
    keyLogger(`REMOTE_EPHEMERAL_PUBLIC_KEY ${toString$9(re, 'hex')}`);
}
function logCipherState(session) {
    if (session.cs1 && session.cs2) {
        keyLogger(`CIPHER_STATE_1 ${session.cs1.n.getUint64()} ${toString$9(session.cs1.k, 'hex')}`);
        keyLogger(`CIPHER_STATE_2 ${session.cs2.n.getUint64()} ${toString$9(session.cs2.k, 'hex')}`);
    }
    else {
        keyLogger('Missing cipher state.');
    }
}

const MIN_NONCE = 0;
// For performance reasons, the nonce is represented as a JS `number`
// Although JS `number` can safely represent integers up to 2 ** 53 - 1, we choose to only use
// 4 bytes to store the data for performance reason.
// This is a slight deviation from the noise spec, which describes the max nonce as 2 ** 64 - 2
// The effect is that this implementation will need a new handshake to be performed after fewer messages are exchanged than other implementations with full uint64 nonces.
// this MAX_NONCE is still a large number of messages, so the practical effect of this is negligible.
const MAX_NONCE = 0xffffffff;
const ERR_MAX_NONCE = 'Cipherstate has reached maximum n, a new handshake must be performed';
/**
 * The nonce is an uint that's increased over time.
 * Maintaining different representations help improve performance.
 */
class Nonce {
    n;
    bytes;
    view;
    constructor(n = MIN_NONCE) {
        this.n = n;
        this.bytes = new Uint8Array(12);
        this.view = new DataView(this.bytes.buffer, this.bytes.byteOffset, this.bytes.byteLength);
        this.view.setUint32(4, n, true);
    }
    increment() {
        this.n++;
        // Even though we're treating the nonce as 8 bytes, RFC7539 specifies 12 bytes for a nonce.
        this.view.setUint32(4, this.n, true);
    }
    getBytes() {
        return this.bytes;
    }
    getUint64() {
        return this.n;
    }
    assertValue() {
        if (this.n > MAX_NONCE) {
            throw new Error(ERR_MAX_NONCE);
        }
    }
}

class AbstractHandshake {
    crypto;
    constructor(crypto) {
        this.crypto = crypto;
    }
    encryptWithAd(cs, ad, plaintext) {
        const e = this.encrypt(cs.k, cs.n, ad, plaintext);
        cs.n.increment();
        return e;
    }
    decryptWithAd(cs, ad, ciphertext, dst) {
        const { plaintext, valid } = this.decrypt(cs.k, cs.n, ad, ciphertext, dst);
        if (valid)
            cs.n.increment();
        return { plaintext, valid };
    }
    // Cipher state related
    hasKey(cs) {
        return !this.isEmptyKey(cs.k);
    }
    createEmptyKey() {
        return new Uint8Array(32);
    }
    isEmptyKey(k) {
        const emptyKey = this.createEmptyKey();
        return equals$4(emptyKey, k);
    }
    encrypt(k, n, ad, plaintext) {
        n.assertValue();
        return this.crypto.chaCha20Poly1305Encrypt(plaintext, n.getBytes(), ad, k);
    }
    encryptAndHash(ss, plaintext) {
        let ciphertext;
        if (this.hasKey(ss.cs)) {
            ciphertext = this.encryptWithAd(ss.cs, ss.h, plaintext);
        }
        else {
            ciphertext = plaintext;
        }
        this.mixHash(ss, ciphertext);
        return ciphertext;
    }
    decrypt(k, n, ad, ciphertext, dst) {
        n.assertValue();
        const encryptedMessage = this.crypto.chaCha20Poly1305Decrypt(ciphertext, n.getBytes(), ad, k, dst);
        if (encryptedMessage) {
            return {
                plaintext: encryptedMessage,
                valid: true
            };
        }
        else {
            return {
                plaintext: new Uint8Array(0),
                valid: false
            };
        }
    }
    decryptAndHash(ss, ciphertext) {
        let plaintext;
        let valid = true;
        if (this.hasKey(ss.cs)) {
            ({ plaintext, valid } = this.decryptWithAd(ss.cs, ss.h, ciphertext));
        }
        else {
            plaintext = ciphertext;
        }
        this.mixHash(ss, ciphertext);
        return { plaintext, valid };
    }
    dh(privateKey, publicKey) {
        try {
            const derivedU8 = this.crypto.generateX25519SharedKey(privateKey, publicKey);
            if (derivedU8.length === 32) {
                return derivedU8;
            }
            return derivedU8.subarray(0, 32);
        }
        catch (e) {
            const err = e;
            log$z.error(err);
            return new Uint8Array(32);
        }
    }
    mixHash(ss, data) {
        ss.h = this.getHash(ss.h, data);
    }
    getHash(a, b) {
        const u = this.crypto.hashSHA256(concat$1([a, b], a.length + b.length));
        return u;
    }
    mixKey(ss, ikm) {
        const [ck, tempK] = this.crypto.getHKDF(ss.ck, ikm);
        ss.cs = this.initializeKey(tempK);
        ss.ck = ck;
    }
    initializeKey(k) {
        return { k, n: new Nonce() };
    }
    // Symmetric state related
    initializeSymmetric(protocolName) {
        const protocolNameBytes = fromString$3(protocolName, 'utf-8');
        const h = this.hashProtocolName(protocolNameBytes);
        const ck = h;
        const key = this.createEmptyKey();
        const cs = this.initializeKey(key);
        return { cs, ck, h };
    }
    hashProtocolName(protocolName) {
        if (protocolName.length <= 32) {
            const h = new Uint8Array(32);
            h.set(protocolName);
            return h;
        }
        else {
            return this.getHash(protocolName, new Uint8Array(0));
        }
    }
    split(ss) {
        const [tempk1, tempk2] = this.crypto.getHKDF(ss.ck, new Uint8Array(0));
        const cs1 = this.initializeKey(tempk1);
        const cs2 = this.initializeKey(tempk2);
        return { cs1, cs2 };
    }
    writeMessageRegular(cs, payload) {
        const ciphertext = this.encryptWithAd(cs, new Uint8Array(0), payload);
        const ne = this.createEmptyKey();
        const ns = new Uint8Array(0);
        return { ne, ns, ciphertext };
    }
    readMessageRegular(cs, message) {
        return this.decryptWithAd(cs, new Uint8Array(0), message.ciphertext);
    }
}

class XX extends AbstractHandshake {
    initializeInitiator(prologue, s, rs, psk) {
        const name = 'Noise_XX_25519_ChaChaPoly_SHA256';
        const ss = this.initializeSymmetric(name);
        this.mixHash(ss, prologue);
        const re = new Uint8Array(32);
        return { ss, s, rs, psk, re };
    }
    initializeResponder(prologue, s, rs, psk) {
        const name = 'Noise_XX_25519_ChaChaPoly_SHA256';
        const ss = this.initializeSymmetric(name);
        this.mixHash(ss, prologue);
        const re = new Uint8Array(32);
        return { ss, s, rs, psk, re };
    }
    writeMessageA(hs, payload, e) {
        const ns = new Uint8Array(0);
        if (e !== undefined) {
            hs.e = e;
        }
        else {
            hs.e = this.crypto.generateX25519KeyPair();
        }
        const ne = hs.e.publicKey;
        this.mixHash(hs.ss, ne);
        const ciphertext = this.encryptAndHash(hs.ss, payload);
        return { ne, ns, ciphertext };
    }
    writeMessageB(hs, payload) {
        hs.e = this.crypto.generateX25519KeyPair();
        const ne = hs.e.publicKey;
        this.mixHash(hs.ss, ne);
        this.mixKey(hs.ss, this.dh(hs.e.privateKey, hs.re));
        const spk = hs.s.publicKey;
        const ns = this.encryptAndHash(hs.ss, spk);
        this.mixKey(hs.ss, this.dh(hs.s.privateKey, hs.re));
        const ciphertext = this.encryptAndHash(hs.ss, payload);
        return { ne, ns, ciphertext };
    }
    writeMessageC(hs, payload) {
        const spk = hs.s.publicKey;
        const ns = this.encryptAndHash(hs.ss, spk);
        this.mixKey(hs.ss, this.dh(hs.s.privateKey, hs.re));
        const ciphertext = this.encryptAndHash(hs.ss, payload);
        const ne = this.createEmptyKey();
        const messageBuffer = { ne, ns, ciphertext };
        const { cs1, cs2 } = this.split(hs.ss);
        return { h: hs.ss.h, messageBuffer, cs1, cs2 };
    }
    readMessageA(hs, message) {
        if (isValidPublicKey(message.ne)) {
            hs.re = message.ne;
        }
        this.mixHash(hs.ss, hs.re);
        return this.decryptAndHash(hs.ss, message.ciphertext);
    }
    readMessageB(hs, message) {
        if (isValidPublicKey(message.ne)) {
            hs.re = message.ne;
        }
        this.mixHash(hs.ss, hs.re);
        if (!hs.e) {
            throw new Error('Handshake state `e` param is missing.');
        }
        this.mixKey(hs.ss, this.dh(hs.e.privateKey, hs.re));
        const { plaintext: ns, valid: valid1 } = this.decryptAndHash(hs.ss, message.ns);
        if (valid1 && isValidPublicKey(ns)) {
            hs.rs = ns;
        }
        this.mixKey(hs.ss, this.dh(hs.e.privateKey, hs.rs));
        const { plaintext, valid: valid2 } = this.decryptAndHash(hs.ss, message.ciphertext);
        return { plaintext, valid: (valid1 && valid2) };
    }
    readMessageC(hs, message) {
        const { plaintext: ns, valid: valid1 } = this.decryptAndHash(hs.ss, message.ns);
        if (valid1 && isValidPublicKey(ns)) {
            hs.rs = ns;
        }
        if (!hs.e) {
            throw new Error('Handshake state `e` param is missing.');
        }
        this.mixKey(hs.ss, this.dh(hs.e.privateKey, hs.rs));
        const { plaintext, valid: valid2 } = this.decryptAndHash(hs.ss, message.ciphertext);
        const { cs1, cs2 } = this.split(hs.ss);
        return { h: hs.ss.h, plaintext, valid: (valid1 && valid2), cs1, cs2 };
    }
    initSession(initiator, prologue, s) {
        const psk = this.createEmptyKey();
        const rs = new Uint8Array(32); // no static key yet
        let hs;
        if (initiator) {
            hs = this.initializeInitiator(prologue, s, rs, psk);
        }
        else {
            hs = this.initializeResponder(prologue, s, rs, psk);
        }
        return {
            hs,
            i: initiator,
            mc: 0
        };
    }
    sendMessage(session, message, ephemeral) {
        let messageBuffer;
        if (session.mc === 0) {
            messageBuffer = this.writeMessageA(session.hs, message, ephemeral);
        }
        else if (session.mc === 1) {
            messageBuffer = this.writeMessageB(session.hs, message);
        }
        else if (session.mc === 2) {
            const { h, messageBuffer: resultingBuffer, cs1, cs2 } = this.writeMessageC(session.hs, message);
            messageBuffer = resultingBuffer;
            session.h = h;
            session.cs1 = cs1;
            session.cs2 = cs2;
        }
        else if (session.mc > 2) {
            if (session.i) {
                if (!session.cs1) {
                    throw new Error('CS1 (cipher state) is not defined');
                }
                messageBuffer = this.writeMessageRegular(session.cs1, message);
            }
            else {
                if (!session.cs2) {
                    throw new Error('CS2 (cipher state) is not defined');
                }
                messageBuffer = this.writeMessageRegular(session.cs2, message);
            }
        }
        else {
            throw new Error('Session invalid.');
        }
        session.mc++;
        return messageBuffer;
    }
    recvMessage(session, message) {
        let plaintext = new Uint8Array(0);
        let valid = false;
        if (session.mc === 0) {
            ({ plaintext, valid } = this.readMessageA(session.hs, message));
        }
        else if (session.mc === 1) {
            ({ plaintext, valid } = this.readMessageB(session.hs, message));
        }
        else if (session.mc === 2) {
            const { h, plaintext: resultingPlaintext, valid: resultingValid, cs1, cs2 } = this.readMessageC(session.hs, message);
            plaintext = resultingPlaintext;
            valid = resultingValid;
            session.h = h;
            session.cs1 = cs1;
            session.cs2 = cs2;
        }
        session.mc++;
        return { plaintext, valid };
    }
}

class XXHandshake {
    isInitiator;
    session;
    remotePeer;
    remoteExtensions = { webtransportCerthashes: [] };
    payload;
    connection;
    xx;
    staticKeypair;
    prologue;
    constructor(isInitiator, payload, prologue, crypto, staticKeypair, connection, remotePeer, handshake) {
        this.isInitiator = isInitiator;
        this.payload = payload;
        this.prologue = prologue;
        this.staticKeypair = staticKeypair;
        this.connection = connection;
        if (remotePeer) {
            this.remotePeer = remotePeer;
        }
        this.xx = handshake ?? new XX(crypto);
        this.session = this.xx.initSession(this.isInitiator, this.prologue, this.staticKeypair);
    }
    // stage 0
    async propose() {
        logLocalStaticKeys(this.session.hs.s);
        if (this.isInitiator) {
            log$z.trace('Stage 0 - Initiator starting to send first message.');
            const messageBuffer = this.xx.sendMessage(this.session, new Uint8Array(0));
            await this.connection.write(encode0(messageBuffer));
            log$z.trace('Stage 0 - Initiator finished sending first message.');
            logLocalEphemeralKeys(this.session.hs.e);
        }
        else {
            log$z.trace('Stage 0 - Responder waiting to receive first message...');
            const receivedMessageBuffer = decode0((await this.connection.read()).subarray());
            const { valid } = this.xx.recvMessage(this.session, receivedMessageBuffer);
            if (!valid) {
                throw new InvalidCryptoExchangeError('xx handshake stage 0 validation fail');
            }
            log$z.trace('Stage 0 - Responder received first message.');
            logRemoteEphemeralKey(this.session.hs.re);
        }
    }
    // stage 1
    async exchange() {
        if (this.isInitiator) {
            log$z.trace('Stage 1 - Initiator waiting to receive first message from responder...');
            const receivedMessageBuffer = decode1((await this.connection.read()).subarray());
            const { plaintext, valid } = this.xx.recvMessage(this.session, receivedMessageBuffer);
            if (!valid) {
                throw new InvalidCryptoExchangeError('xx handshake stage 1 validation fail');
            }
            log$z.trace('Stage 1 - Initiator received the message.');
            logRemoteEphemeralKey(this.session.hs.re);
            logRemoteStaticKey(this.session.hs.rs);
            log$z.trace("Initiator going to check remote's signature...");
            try {
                const decodedPayload = decodePayload(plaintext);
                this.remotePeer = this.remotePeer || await getPeerIdFromPayload(decodedPayload);
                await verifySignedPayload(this.session.hs.rs, decodedPayload, this.remotePeer);
                this.setRemoteNoiseExtension(decodedPayload.extensions);
            }
            catch (e) {
                const err = e;
                throw new UnexpectedPeerError(`Error occurred while verifying signed payload: ${err.message}`);
            }
            log$z.trace('All good with the signature!');
        }
        else {
            log$z.trace('Stage 1 - Responder sending out first message with signed payload and static key.');
            const messageBuffer = this.xx.sendMessage(this.session, this.payload);
            await this.connection.write(encode1(messageBuffer));
            log$z.trace('Stage 1 - Responder sent the second handshake message with signed payload.');
            logLocalEphemeralKeys(this.session.hs.e);
        }
    }
    // stage 2
    async finish() {
        if (this.isInitiator) {
            log$z.trace('Stage 2 - Initiator sending third handshake message.');
            const messageBuffer = this.xx.sendMessage(this.session, this.payload);
            await this.connection.write(encode2(messageBuffer));
            log$z.trace('Stage 2 - Initiator sent message with signed payload.');
        }
        else {
            log$z.trace('Stage 2 - Responder waiting for third handshake message...');
            const receivedMessageBuffer = decode2((await this.connection.read()).subarray());
            const { plaintext, valid } = this.xx.recvMessage(this.session, receivedMessageBuffer);
            if (!valid) {
                throw new InvalidCryptoExchangeError('xx handshake stage 2 validation fail');
            }
            log$z.trace('Stage 2 - Responder received the message, finished handshake.');
            try {
                const decodedPayload = decodePayload(plaintext);
                this.remotePeer = this.remotePeer || await getPeerIdFromPayload(decodedPayload);
                await verifySignedPayload(this.session.hs.rs, decodedPayload, this.remotePeer);
                this.setRemoteNoiseExtension(decodedPayload.extensions);
            }
            catch (e) {
                const err = e;
                throw new UnexpectedPeerError(`Error occurred while verifying signed payload: ${err.message}`);
            }
        }
        logCipherState(this.session);
    }
    encrypt(plaintext, session) {
        const cs = this.getCS(session);
        return this.xx.encryptWithAd(cs, new Uint8Array(0), plaintext);
    }
    decrypt(ciphertext, session, dst) {
        const cs = this.getCS(session, false);
        return this.xx.decryptWithAd(cs, new Uint8Array(0), ciphertext, dst);
    }
    getRemoteStaticKey() {
        return this.session.hs.rs;
    }
    getCS(session, encryption = true) {
        if (!session.cs1 || !session.cs2) {
            throw new InvalidCryptoExchangeError('Handshake not completed properly, cipher state does not exist.');
        }
        if (this.isInitiator) {
            return encryption ? session.cs1 : session.cs2;
        }
        else {
            return encryption ? session.cs2 : session.cs1;
        }
    }
    setRemoteNoiseExtension(e) {
        if (e) {
            this.remoteExtensions = e;
        }
    }
}

function registerMetrics(metrics) {
    return {
        xxHandshakeSuccesses: metrics.registerCounter('libp2p_noise_xxhandshake_successes_total', {
            help: 'Total count of noise xxHandshakes successes_'
        }),
        xxHandshakeErrors: metrics.registerCounter('libp2p_noise_xxhandshake_error_total', {
            help: 'Total count of noise xxHandshakes errors'
        }),
        encryptedPackets: metrics.registerCounter('libp2p_noise_encrypted_packets_total', {
            help: 'Total count of noise encrypted packets successfully'
        }),
        decryptedPackets: metrics.registerCounter('libp2p_noise_decrypted_packets_total', {
            help: 'Total count of noise decrypted packets'
        }),
        decryptErrors: metrics.registerCounter('libp2p_noise_decrypt_errors_total', {
            help: 'Total count of noise decrypt errors'
        })
    };
}

class Noise {
    protocol = '/noise';
    crypto;
    prologue;
    staticKeys;
    extensions;
    metrics;
    constructor(init = {}) {
        const { staticNoiseKey, extensions, crypto, prologueBytes, metrics } = init;
        this.crypto = crypto ?? pureJsCrypto;
        this.extensions = extensions;
        this.metrics = metrics ? registerMetrics(metrics) : undefined;
        if (staticNoiseKey) {
            // accepts x25519 private key of length 32
            this.staticKeys = this.crypto.generateX25519KeyPairFromSeed(staticNoiseKey);
        }
        else {
            this.staticKeys = this.crypto.generateX25519KeyPair();
        }
        this.prologue = prologueBytes ?? new Uint8Array(0);
    }
    /**
     * Encrypt outgoing data to the remote party (handshake as initiator)
     *
     * @param {PeerId} localPeer - PeerId of the receiving peer
     * @param {Duplex<AsyncGenerator<Uint8Array>, AsyncIterable<Uint8Array>, Promise<void>>} connection - streaming iterable duplex that will be encrypted
     * @param {PeerId} remotePeer - PeerId of the remote peer. Used to validate the integrity of the remote peer.
     * @returns {Promise<SecuredConnection>}
     */
    async secureOutbound(localPeer, connection, remotePeer) {
        const wrappedConnection = lpStream(connection, {
            lengthEncoder: uint16BEEncode,
            lengthDecoder: uint16BEDecode,
            maxDataLength: NOISE_MSG_MAX_LENGTH_BYTES
        });
        const handshake = await this.performHandshake({
            connection: wrappedConnection,
            isInitiator: true,
            localPeer,
            remotePeer
        });
        const conn = await this.createSecureConnection(wrappedConnection, handshake);
        return {
            conn,
            remoteExtensions: handshake.remoteExtensions,
            remotePeer: handshake.remotePeer
        };
    }
    /**
     * Decrypt incoming data (handshake as responder).
     *
     * @param {PeerId} localPeer - PeerId of the receiving peer.
     * @param {Duplex<AsyncGenerator<Uint8Array>, AsyncIterable<Uint8Array>, Promise<void>>} connection - streaming iterable duplex that will be encryption.
     * @param {PeerId} remotePeer - optional PeerId of the initiating peer, if known. This may only exist during transport upgrades.
     * @returns {Promise<SecuredConnection>}
     */
    async secureInbound(localPeer, connection, remotePeer) {
        const wrappedConnection = lpStream(connection, {
            lengthEncoder: uint16BEEncode,
            lengthDecoder: uint16BEDecode,
            maxDataLength: NOISE_MSG_MAX_LENGTH_BYTES
        });
        const handshake = await this.performHandshake({
            connection: wrappedConnection,
            isInitiator: false,
            localPeer,
            remotePeer
        });
        const conn = await this.createSecureConnection(wrappedConnection, handshake);
        return {
            conn,
            remotePeer: handshake.remotePeer,
            remoteExtensions: handshake.remoteExtensions
        };
    }
    /**
     * If Noise pipes supported, tries IK handshake first with XX as fallback if it fails.
     * If noise pipes disabled or remote peer static key is unknown, use XX.
     *
     * @param {HandshakeParams} params
     */
    async performHandshake(params) {
        const payload = await getPayload(params.localPeer, this.staticKeys.publicKey, this.extensions);
        // run XX handshake
        return this.performXXHandshake(params, payload);
    }
    async performXXHandshake(params, payload) {
        const { isInitiator, remotePeer, connection } = params;
        const handshake = new XXHandshake(isInitiator, payload, this.prologue, this.crypto, this.staticKeys, connection, remotePeer);
        try {
            await handshake.propose();
            await handshake.exchange();
            await handshake.finish();
            this.metrics?.xxHandshakeSuccesses.increment();
        }
        catch (e) {
            this.metrics?.xxHandshakeErrors.increment();
            if (e instanceof Error) {
                e.message = `Error occurred during XX handshake: ${e.message}`;
                throw e;
            }
        }
        return handshake;
    }
    async createSecureConnection(connection, handshake) {
        // Create encryption box/unbox wrapper
        const [secure, user] = duplexPair();
        const network = connection.unwrap();
        await pipe(secure, // write to wrapper
        encryptStream(handshake, this.metrics), // encrypt data + prefix with message length
        network, // send to the remote peer
        (source) => decode$v(source, { lengthDecoder: uint16BEDecode }), // read message length prefix
        decryptStream(handshake, this.metrics), // decrypt the incoming data
        secure // pipe to the wrapper
        );
        return user;
    }
}

function noise(init = {}) {
    return () => new Noise(init);
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$b (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$a = base$b;

var _brrp__multiformats_scope_baseX$a = src$a;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$a = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$b = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$b = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$b(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$a = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$b(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$b = (left, right) => new ComposedDecoder$a(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$a = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$b(name, prefix, baseEncode);
    this.decoder = new Decoder$b(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$h = ({ name, prefix, encode, decode }) =>
  new Codec$a(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$a = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$a(alphabet, name);
  return from$h({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$a(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$n = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$t = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$a = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$h({
    prefix,
    name,
    encode (input) {
      return encode$t(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$n(input, alphabet, bitsPerChar, name)
    }
  })
};

const base32$a = rfc4648$a({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

rfc4648$a({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

rfc4648$a({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

rfc4648$a({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

rfc4648$a({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

rfc4648$a({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

rfc4648$a({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

rfc4648$a({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

rfc4648$a({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

const base58btc$9 = baseX$a({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$a({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

// @ts-check


const base64$a = rfc4648$a({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$a({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$a({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$a({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc$9.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$a.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64$a.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
debug.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger$6(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
function logger$8(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger$6(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (debug.enabled(`${name}:trace`) && debug.names.map(r => r.toString()).find(n => n.includes(':trace')) != null) {
        trace = debug(`${name}:trace`);
    }
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace
    });
}

let AbortError$4 = class AbortError extends Error {
    constructor(message, code) {
        super(message ?? 'The operation was aborted');
        this.type = 'aborted';
        this.code = code ?? 'ABORT_ERR';
    }
};

function getIterator(obj) {
    if (obj != null) {
        if (typeof obj[Symbol.iterator] === 'function') {
            return obj[Symbol.iterator]();
        }
        if (typeof obj[Symbol.asyncIterator] === 'function') {
            return obj[Symbol.asyncIterator]();
        }
        if (typeof obj.next === 'function') {
            return obj; // probably an iterator
        }
    }
    throw new Error('argument is not an iterator or iterable');
}

/**
 * @packageDocumentation
 *
 * @example
 *
 * ```js
 * import { abortableSource } from 'abortable-iterator'
 *
 * async function main () {
 *   // An example function that creates an async iterator that yields an increasing
 *   // number every x milliseconds and NEVER ENDS!
 *   const asyncCounter = async function * (start, delay) {
 *     let i = start
 *     while (true) {
 *       yield new Promise(resolve => setTimeout(() => resolve(i++), delay))
 *     }
 *   }
 *
 *   // Create a counter that'll yield numbers from 0 upwards every second
 *   const everySecond = asyncCounter(0, 1000)
 *
 *   // Make everySecond abortable!
 *   const controller = new AbortController()
 *   const abortableEverySecond = abortableSource(everySecond, controller.signal)
 *
 *   // Abort after 5 seconds
 *   setTimeout(() => controller.abort(), 5000)
 *
 *   try {
 *     // Start the iteration, which will throw after 5 seconds when it is aborted
 *     for await (const n of abortableEverySecond) {
 *       console.log(n)
 *     }
 *   } catch (err) {
 *     if (err.code === 'ERR_ABORTED') {
 *       // Expected - all ok :D
 *     } else {
 *       throw err
 *     }
 *   }
 * }
 *
 * main()
 * ```
 */
/**
 * Wrap an iterator to make it abortable, allow cleanup when aborted via onAbort
 */
function abortableSource(source, signal, options) {
    const opts = options ?? {};
    const iterator = getIterator(source);
    async function* abortable() {
        let nextAbortHandler;
        const abortHandler = () => {
            if (nextAbortHandler != null)
                nextAbortHandler();
        };
        signal.addEventListener('abort', abortHandler);
        while (true) {
            let result;
            try {
                if (signal.aborted) {
                    const { abortMessage, abortCode } = opts;
                    throw new AbortError$4(abortMessage, abortCode);
                }
                const abort = new Promise((resolve, reject) => {
                    nextAbortHandler = () => {
                        const { abortMessage, abortCode } = opts;
                        reject(new AbortError$4(abortMessage, abortCode));
                    };
                });
                // Race the iterator and the abort signals
                result = await Promise.race([abort, iterator.next()]);
                nextAbortHandler = null;
            }
            catch (err) {
                signal.removeEventListener('abort', abortHandler);
                // Might not have been aborted by a known signal
                const isKnownAborter = err.type === 'aborted' && signal.aborted;
                if (isKnownAborter && (opts.onAbort != null)) {
                    // Do any custom abort handling for the iterator
                    opts.onAbort(source);
                }
                // End the iterator if it is a generator
                if (typeof iterator.return === 'function') {
                    try {
                        const p = iterator.return();
                        if (p instanceof Promise) { // eslint-disable-line max-depth
                            p.catch(err => {
                                if (opts.onReturnError != null) {
                                    opts.onReturnError(err);
                                }
                            });
                        }
                    }
                    catch (err) {
                        if (opts.onReturnError != null) { // eslint-disable-line max-depth
                            opts.onReturnError(err);
                        }
                    }
                }
                if (isKnownAborter && opts.returnOnAbort === true) {
                    return;
                }
                throw err;
            }
            if (result.done === true) {
                break;
            }
            yield result.value;
        }
        signal.removeEventListener('abort', abortHandler);
    }
    return abortable();
}

var RateLimiterAbstract_1$1 = class RateLimiterAbstract {
  /**
   *
   * @param opts Object Defaults {
   *   points: 4, // Number of points
   *   duration: 1, // Per seconds
   *   blockDuration: 0, // Block if consumed more than points in current duration for blockDuration seconds
   *   execEvenly: false, // Execute allowed actions evenly over duration
   *   execEvenlyMinDelayMs: duration * 1000 / points, // ms, works with execEvenly=true option
   *   keyPrefix: 'rlflx',
   * }
   */
  constructor(opts = {}) {
    this.points = opts.points;
    this.duration = opts.duration;
    this.blockDuration = opts.blockDuration;
    this.execEvenly = opts.execEvenly;
    this.execEvenlyMinDelayMs = opts.execEvenlyMinDelayMs;
    this.keyPrefix = opts.keyPrefix;
  }

  get points() {
    return this._points;
  }

  set points(value) {
    this._points = value >= 0 ? value : 4;
  }

  get duration() {
    return this._duration;
  }

  set duration(value) {
    this._duration = typeof value === 'undefined' ? 1 : value;
  }

  get msDuration() {
    return this.duration * 1000;
  }

  get blockDuration() {
    return this._blockDuration;
  }

  set blockDuration(value) {
    this._blockDuration = typeof value === 'undefined' ? 0 : value;
  }

  get msBlockDuration() {
    return this.blockDuration * 1000;
  }

  get execEvenly() {
    return this._execEvenly;
  }

  set execEvenly(value) {
    this._execEvenly = typeof value === 'undefined' ? false : Boolean(value);
  }

  get execEvenlyMinDelayMs() {
    return this._execEvenlyMinDelayMs;
  }

  set execEvenlyMinDelayMs(value) {
    this._execEvenlyMinDelayMs = typeof value === 'undefined' ? Math.ceil(this.msDuration / this.points) : value;
  }

  get keyPrefix() {
    return this._keyPrefix;
  }

  set keyPrefix(value) {
    if (typeof value === 'undefined') {
      value = 'rlflx';
    }
    if (typeof value !== 'string') {
      throw new Error('keyPrefix must be string');
    }
    this._keyPrefix = value;
  }

  _getKeySecDuration(options = {}) {
    return options && options.customDuration >= 0
      ? options.customDuration
      : this.duration;
  }

  getKey(key) {
    return this.keyPrefix.length > 0 ? `${this.keyPrefix}:${key}` : key;
  }

  parseKey(rlKey) {
    return rlKey.substring(this.keyPrefix.length);
  }

  consume() {
    throw new Error("You have to implement the method 'consume'!");
  }

  penalty() {
    throw new Error("You have to implement the method 'penalty'!");
  }

  reward() {
    throw new Error("You have to implement the method 'reward'!");
  }

  get() {
    throw new Error("You have to implement the method 'get'!");
  }

  set() {
    throw new Error("You have to implement the method 'set'!");
  }

  block() {
    throw new Error("You have to implement the method 'block'!");
  }

  delete() {
    throw new Error("You have to implement the method 'delete'!");
  }
};

var BlockedKeys_1$3 = class BlockedKeys {
  constructor() {
    this._keys = {}; // {'key': 1526279430331}
    this._addedKeysAmount = 0;
  }

  collectExpired() {
    const now = Date.now();

    Object.keys(this._keys).forEach((key) => {
      if (this._keys[key] <= now) {
        delete this._keys[key];
      }
    });

    this._addedKeysAmount = Object.keys(this._keys).length;
  }

  /**
   * Add new blocked key
   *
   * @param key String
   * @param sec Number
   */
  add(key, sec) {
    this.addMs(key, sec * 1000);
  }

  /**
   * Add new blocked key for ms
   *
   * @param key String
   * @param ms Number
   */
  addMs(key, ms) {
    this._keys[key] = Date.now() + ms;
    this._addedKeysAmount++;
    if (this._addedKeysAmount > 999) {
      this.collectExpired();
    }
  }

  /**
   * 0 means not blocked
   *
   * @param key
   * @returns {number}
   */
  msBeforeExpire(key) {
    const expire = this._keys[key];

    if (expire && expire >= Date.now()) {
      this.collectExpired();
      const now = Date.now();
      return expire >= now ? expire - now : 0;
    }

    return 0;
  }

  /**
   * If key is not given, delete all data in memory
   * 
   * @param {string|undefined} key
   */
  delete(key) {
    if (key) {
      delete this._keys[key];
    } else {
      Object.keys(this._keys).forEach((key) => {
        delete this._keys[key];
      });
    }
  }
};

const BlockedKeys$3 = BlockedKeys_1$3;

var BlockedKeys_1$2 = BlockedKeys$3;

var RateLimiterRes_1$1 = class RateLimiterRes {
  constructor(remainingPoints, msBeforeNext, consumedPoints, isFirstInDuration) {
    this.remainingPoints = typeof remainingPoints === 'undefined' ? 0 : remainingPoints; // Remaining points in current duration
    this.msBeforeNext = typeof msBeforeNext === 'undefined' ? 0 : msBeforeNext; // Milliseconds before next action
    this.consumedPoints = typeof consumedPoints === 'undefined' ? 0 : consumedPoints; // Consumed points in current duration
    this.isFirstInDuration = typeof isFirstInDuration === 'undefined' ? false : isFirstInDuration;
  }

  get msBeforeNext() {
    return this._msBeforeNext;
  }

  set msBeforeNext(ms) {
    this._msBeforeNext = ms;
    return this;
  }

  get remainingPoints() {
    return this._remainingPoints;
  }

  set remainingPoints(p) {
    this._remainingPoints = p;
    return this;
  }

  get consumedPoints() {
    return this._consumedPoints;
  }

  set consumedPoints(p) {
    this._consumedPoints = p;
    return this;
  }

  get isFirstInDuration() {
    return this._isFirstInDuration;
  }

  set isFirstInDuration(value) {
    this._isFirstInDuration = Boolean(value);
  }

  _getDecoratedProperties() {
    return {
      remainingPoints: this.remainingPoints,
      msBeforeNext: this.msBeforeNext,
      consumedPoints: this.consumedPoints,
      isFirstInDuration: this.isFirstInDuration,
    };
  }

  [Symbol.for("nodejs.util.inspect.custom")]() {
    return this._getDecoratedProperties();
  }

  toString() {
    return JSON.stringify(this._getDecoratedProperties());
  }

  toJSON() {
    return this._getDecoratedProperties();
  }
};

const RateLimiterAbstract$7 = RateLimiterAbstract_1$1;
const BlockedKeys$2 = BlockedKeys_1$2;
const RateLimiterRes$n = RateLimiterRes_1$1;

var RateLimiterStoreAbstract_1$1 = class RateLimiterStoreAbstract extends RateLimiterAbstract$7 {
  /**
   *
   * @param opts Object Defaults {
   *   ... see other in RateLimiterAbstract
   *
   *   inMemoryBlockOnConsumed: 40, // Number of points when key is blocked
   *   inMemoryBlockDuration: 10, // Block duration in seconds
   *   insuranceLimiter: RateLimiterAbstract
   * }
   */
  constructor(opts = {}) {
    super(opts);

    this.inMemoryBlockOnConsumed = opts.inMemoryBlockOnConsumed || opts.inmemoryBlockOnConsumed;
    this.inMemoryBlockDuration = opts.inMemoryBlockDuration || opts.inmemoryBlockDuration;
    this.insuranceLimiter = opts.insuranceLimiter;
    this._inMemoryBlockedKeys = new BlockedKeys$2();
  }

  get client() {
    return this._client;
  }

  set client(value) {
    if (typeof value === 'undefined') {
      throw new Error('storeClient is not set');
    }
    this._client = value;
  }

  /**
   * Have to be launched after consume
   * It blocks key and execute evenly depending on result from store
   *
   * It uses _getRateLimiterRes function to prepare RateLimiterRes from store result
   *
   * @param resolve
   * @param reject
   * @param rlKey
   * @param changedPoints
   * @param storeResult
   * @param {Object} options
   * @private
   */
  _afterConsume(resolve, reject, rlKey, changedPoints, storeResult, options = {}) {
    const res = this._getRateLimiterRes(rlKey, changedPoints, storeResult);

    if (this.inMemoryBlockOnConsumed > 0 && !(this.inMemoryBlockDuration > 0)
      && res.consumedPoints >= this.inMemoryBlockOnConsumed
    ) {
      this._inMemoryBlockedKeys.addMs(rlKey, res.msBeforeNext);
      if (res.consumedPoints > this.points) {
        return reject(res);
      } else {
        return resolve(res)
      }
    } else if (res.consumedPoints > this.points) {
      let blockPromise = Promise.resolve();
      // Block only first time when consumed more than points
      if (this.blockDuration > 0 && res.consumedPoints <= (this.points + changedPoints)) {
        res.msBeforeNext = this.msBlockDuration;
        blockPromise = this._block(rlKey, res.consumedPoints, this.msBlockDuration, options);
      }

      if (this.inMemoryBlockOnConsumed > 0 && res.consumedPoints >= this.inMemoryBlockOnConsumed) {
        // Block key for this.inMemoryBlockDuration seconds
        this._inMemoryBlockedKeys.add(rlKey, this.inMemoryBlockDuration);
        res.msBeforeNext = this.msInMemoryBlockDuration;
      }

      blockPromise
        .then(() => {
          reject(res);
        })
        .catch((err) => {
          reject(err);
        });
    } else if (this.execEvenly && res.msBeforeNext > 0 && !res.isFirstInDuration) {
      let delay = Math.ceil(res.msBeforeNext / (res.remainingPoints + 2));
      if (delay < this.execEvenlyMinDelayMs) {
        delay = res.consumedPoints * this.execEvenlyMinDelayMs;
      }

      setTimeout(resolve, delay, res);
    } else {
      resolve(res);
    }
  }

  _handleError(err, funcName, resolve, reject, key, data = false, options = {}) {
    if (!(this.insuranceLimiter instanceof RateLimiterAbstract$7)) {
      reject(err);
    } else {
      this.insuranceLimiter[funcName](key, data, options)
        .then((res) => {
          resolve(res);
        })
        .catch((res) => {
          reject(res);
        });
    }
  }

  /**
   * @deprecated Use camelCase version
   * @returns {BlockedKeys}
   * @private
   */
  get _inmemoryBlockedKeys() {
    return this._inMemoryBlockedKeys
  }

  /**
   * @deprecated Use camelCase version
   * @param rlKey
   * @returns {number}
   */
  getInmemoryBlockMsBeforeExpire(rlKey) {
    return this.getInMemoryBlockMsBeforeExpire(rlKey)
  }

  /**
   * @deprecated Use camelCase version
   * @returns {number|number}
   */
  get inmemoryBlockOnConsumed() {
    return this.inMemoryBlockOnConsumed;
  }

  /**
   * @deprecated Use camelCase version
   * @param value
   */
  set inmemoryBlockOnConsumed(value) {
    this.inMemoryBlockOnConsumed = value;
  }

  /**
   * @deprecated Use camelCase version
   * @returns {number|number}
   */
  get inmemoryBlockDuration() {
    return this.inMemoryBlockDuration;
  }

  /**
   * @deprecated Use camelCase version
   * @param value
   */
  set inmemoryBlockDuration(value) {
    this.inMemoryBlockDuration = value;
  }

  /**
   * @deprecated Use camelCase version
   * @returns {number}
   */
  get msInmemoryBlockDuration() {
    return this.inMemoryBlockDuration * 1000;
  }

  getInMemoryBlockMsBeforeExpire(rlKey) {
    if (this.inMemoryBlockOnConsumed > 0) {
      return this._inMemoryBlockedKeys.msBeforeExpire(rlKey);
    }

    return 0;
  }

  get inMemoryBlockOnConsumed() {
    return this._inMemoryBlockOnConsumed;
  }

  set inMemoryBlockOnConsumed(value) {
    this._inMemoryBlockOnConsumed = value ? parseInt(value) : 0;
    if (this.inMemoryBlockOnConsumed > 0 && this.points > this.inMemoryBlockOnConsumed) {
      throw new Error('inMemoryBlockOnConsumed option must be greater or equal "points" option');
    }
  }

  get inMemoryBlockDuration() {
    return this._inMemoryBlockDuration;
  }

  set inMemoryBlockDuration(value) {
    this._inMemoryBlockDuration = value ? parseInt(value) : 0;
    if (this.inMemoryBlockDuration > 0 && this.inMemoryBlockOnConsumed === 0) {
      throw new Error('inMemoryBlockOnConsumed option must be set up');
    }
  }

  get msInMemoryBlockDuration() {
    return this._inMemoryBlockDuration * 1000;
  }

  get insuranceLimiter() {
    return this._insuranceLimiter;
  }

  set insuranceLimiter(value) {
    if (typeof value !== 'undefined' && !(value instanceof RateLimiterAbstract$7)) {
      throw new Error('insuranceLimiter must be instance of RateLimiterAbstract');
    }
    this._insuranceLimiter = value;
    if (this._insuranceLimiter) {
      this._insuranceLimiter.blockDuration = this.blockDuration;
      this._insuranceLimiter.execEvenly = this.execEvenly;
    }
  }

  /**
   * Block any key for secDuration seconds
   *
   * @param key
   * @param secDuration
   * @param {Object} options
   *
   * @return Promise<RateLimiterRes>
   */
  block(key, secDuration, options = {}) {
    const msDuration = secDuration * 1000;
    return this._block(this.getKey(key), this.points + 1, msDuration, options);
  }

  /**
   * Set points by key for any duration
   *
   * @param key
   * @param points
   * @param secDuration
   * @param {Object} options
   *
   * @return Promise<RateLimiterRes>
   */
  set(key, points, secDuration, options = {}) {
    const msDuration = (secDuration >= 0 ? secDuration : this.duration) * 1000;
    return this._block(this.getKey(key), points, msDuration, options);
  }

  /**
   *
   * @param key
   * @param pointsToConsume
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const rlKey = this.getKey(key);

      const inMemoryBlockMsBeforeExpire = this.getInMemoryBlockMsBeforeExpire(rlKey);
      if (inMemoryBlockMsBeforeExpire > 0) {
        return reject(new RateLimiterRes$n(0, inMemoryBlockMsBeforeExpire));
      }

      this._upsert(rlKey, pointsToConsume, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          this._afterConsume(resolve, reject, rlKey, pointsToConsume, res);
        })
        .catch((err) => {
          this._handleError(err, 'consume', resolve, reject, key, pointsToConsume, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param points
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  penalty(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, points, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          resolve(this._getRateLimiterRes(rlKey, points, res));
        })
        .catch((err) => {
          this._handleError(err, 'penalty', resolve, reject, key, points, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param points
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  reward(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, -points, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          resolve(this._getRateLimiterRes(rlKey, -points, res));
        })
        .catch((err) => {
          this._handleError(err, 'reward', resolve, reject, key, points, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param {Object} options
   * @returns Promise<RateLimiterRes>|null
   */
  get(key, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._get(rlKey, options)
        .then((res) => {
          if (res === null || typeof res === 'undefined') {
            resolve(null);
          } else {
            resolve(this._getRateLimiterRes(rlKey, 0, res));
          }
        })
        .catch((err) => {
          this._handleError(err, 'get', resolve, reject, key, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param {Object} options
   * @returns Promise<boolean>
   */
  delete(key, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._delete(rlKey, options)
        .then((res) => {
          this._inMemoryBlockedKeys.delete(rlKey);
          resolve(res);
        })
        .catch((err) => {
          this._handleError(err, 'delete', resolve, reject, key, options);
        });
    });
  }

  /**
   * Cleanup keys no-matter expired or not.
   */
  deleteInMemoryBlockedAll() {
    this._inMemoryBlockedKeys.delete();
  }

  /**
   * Get RateLimiterRes object filled depending on storeResult, which specific for exact store
   *
   * @param rlKey
   * @param changedPoints
   * @param storeResult
   * @private
   */
  _getRateLimiterRes(rlKey, changedPoints, storeResult) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_getRateLimiterRes'!");
  }

  /**
   * Block key for this.msBlockDuration milliseconds
   * Usually, it just prolongs lifetime of key
   *
   * @param rlKey
   * @param initPoints
   * @param msDuration
   * @param {Object} options
   *
   * @return Promise<any>
   */
  _block(rlKey, initPoints, msDuration, options = {}) {
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, initPoints, msDuration, true, options)
        .then(() => {
          resolve(new RateLimiterRes$n(0, msDuration > 0 ? msDuration : -1, initPoints));
        })
        .catch((err) => {
          this._handleError(err, 'block', resolve, reject, this.parseKey(rlKey), msDuration / 1000, options);
        });
    });
  }

  /**
   * Have to be implemented in every limiter
   * Resolve with raw result from Store OR null if rlKey is not set
   * or Reject with error
   *
   * @param rlKey
   * @param {Object} options
   * @private
   *
   * @return Promise<any>
   */
  _get(rlKey, options = {}) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_get'!");
  }

  /**
   * Have to be implemented
   * Resolve with true OR false if rlKey doesn't exist
   * or Reject with error
   *
   * @param rlKey
   * @param {Object} options
   * @private
   *
   * @return Promise<any>
   */
  _delete(rlKey, options = {}) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_delete'!");
  }

  /**
   * Have to be implemented
   * Resolve with object used for {@link _getRateLimiterRes} to generate {@link RateLimiterRes}
   *
   * @param {string} rlKey
   * @param {number} points
   * @param {number} msDuration
   * @param {boolean} forceExpire
   * @param {Object} options
   * @abstract
   *
   * @return Promise<Object>
   */
  _upsert(rlKey, points, msDuration, forceExpire = false, options = {}) {
    throw new Error("You have to implement the method '_upsert'!");
  }
};

const RateLimiterStoreAbstract$9 = RateLimiterStoreAbstract_1$1;
const RateLimiterRes$m = RateLimiterRes_1$1;

const incrTtlLuaScript$1 = `redis.call('set', KEYS[1], 0, 'EX', ARGV[2], 'NX') \
local consumed = redis.call('incrby', KEYS[1], ARGV[1]) \
local ttl = redis.call('pttl', KEYS[1]) \
if ttl == -1 then \
  redis.call('expire', KEYS[1], ARGV[2]) \
  ttl = 1000 * ARGV[2] \
end \
return {consumed, ttl} \
`;

let RateLimiterRedis$3 = class RateLimiterRedis extends RateLimiterStoreAbstract$9 {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   redis: RedisClient
   *   rejectIfRedisNotReady: boolean = false - reject / invoke insuranceLimiter immediately when redis connection is not "ready"
   * }
   */
  constructor(opts) {
    super(opts);
    if (opts.redis) {
      this.client = opts.redis;
    } else {
      this.client = opts.storeClient;
    }

    this._rejectIfRedisNotReady = !!opts.rejectIfRedisNotReady;

    if (typeof this.client.defineCommand === 'function') {
      this.client.defineCommand("rlflxIncr", {
        numberOfKeys: 1,
        lua: incrTtlLuaScript$1,
      });
    }
  }

  /**
   * Prevent actual redis call if redis connection is not ready
   * Because of different connection state checks for ioredis and node-redis, only this clients would be actually checked.
   * For any other clients all the requests would be passed directly to redis client
   * @return {boolean}
   * @private
   */
  _isRedisReady() {
    if (!this._rejectIfRedisNotReady) {
      return true;
    }
    // ioredis client
    if (this.client.status && this.client.status !== 'ready') {
      return false;
    }
    // node-redis client
    if (typeof this.client.isReady === 'function' && !this.client.isReady()) {
      return false;
    }
    return true;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    let [consumed, resTtlMs] = result;
    // Support ioredis results format
    if (Array.isArray(consumed)) {
      [, consumed] = consumed;
      [, resTtlMs] = resTtlMs;
    }

    const res = new RateLimiterRes$m();
    res.consumedPoints = parseInt(consumed);
    res.isFirstInDuration = res.consumedPoints === changedPoints;
    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = resTtlMs;

    return res;
  }

  _upsert(rlKey, points, msDuration, forceExpire = false) {
    return new Promise((resolve, reject) => {
      if (!this._isRedisReady()) {
        return reject(new Error('Redis connection is not ready'));
      }

      const secDuration = Math.floor(msDuration / 1000);
      const multi = this.client.multi();
      if (forceExpire) {
        if (secDuration > 0) {
          multi.set(rlKey, points, 'EX', secDuration);
        } else {
          multi.set(rlKey, points);
        }

        multi.pttl(rlKey)
          .exec((err, res) => {
            if (err) {
              return reject(err);
            }

            return resolve(res);
          });
      } else {
        if (secDuration > 0) {
          const incrCallback = function(err, result) {
            if (err) {
              return reject(err);
            }

            return resolve(result);
          };

          if (typeof this.client.rlflxIncr === 'function') {
            this.client.rlflxIncr(rlKey, points, secDuration, incrCallback);
          } else {
            this.client.eval(incrTtlLuaScript$1, 1, rlKey, points, secDuration, incrCallback);
          }
        } else {
          multi.incrby(rlKey, points)
            .pttl(rlKey)
            .exec((err, res) => {
              if (err) {
                return reject(err);
              }

              return resolve(res);
            });
        }
      }
    });
  }

  _get(rlKey) {
    return new Promise((resolve, reject) => {
      if (!this._isRedisReady()) {
        return reject(new Error('Redis connection is not ready'));
      }

      this.client
        .multi()
        .get(rlKey)
        .pttl(rlKey)
        .exec((err, res) => {
          if (err) {
            reject(err);
          } else {
            const [points] = res;
            if (points === null) {
              return resolve(null)
            }

            resolve(res);
          }
        });
    });
  }

  _delete(rlKey) {
    return new Promise((resolve, reject) => {
      this.client.del(rlKey, (err, res) => {
        if (err) {
          reject(err);
        } else {
          resolve(res > 0);
        }
      });
    });
  }
};

var RateLimiterRedis_1$1 = RateLimiterRedis$3;

const RateLimiterStoreAbstract$8 = RateLimiterStoreAbstract_1$1;
const RateLimiterRes$l = RateLimiterRes_1$1;

/**
 * Get MongoDB driver version as upsert options differ
 * @params {Object} Client instance
 * @returns {Object} Version Object containing major, feature & minor versions.
 */
function getDriverVersion$1(client) {
  try {
    const _client = client.client ? client.client : client;

    const { version } = _client.topology.s.options.metadata.driver;
    const _v = version.split('.').map(v => parseInt(v));

    return {
      major: _v[0],
      feature: _v[1],
      patch: _v[2],
    };
  } catch (err) {
    return { major: 0, feature: 0, patch: 0 };
  }
}

let RateLimiterMongo$3 = class RateLimiterMongo extends RateLimiterStoreAbstract$8 {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   indexKeyPrefix: {attr1: 1, attr2: 1}
   *   ... see other in RateLimiterStoreAbstract
   *
   *   mongo: MongoClient
   * }
   */
  constructor(opts) {
    super(opts);

    this.dbName = opts.dbName;
    this.tableName = opts.tableName;
    this.indexKeyPrefix = opts.indexKeyPrefix;

    if (opts.mongo) {
      this.client = opts.mongo;
    } else {
      this.client = opts.storeClient;
    }
    if (typeof this.client.then === 'function') {
      // If Promise
      this.client
        .then((conn) => {
          this.client = conn;
          this._initCollection();
          this._driverVersion = getDriverVersion$1(this.client);
        });
    } else {
      this._initCollection();
      this._driverVersion = getDriverVersion$1(this.client);
    }
  }

  get dbName() {
    return this._dbName;
  }

  set dbName(value) {
    this._dbName = typeof value === 'undefined' ? RateLimiterMongo.getDbName() : value;
  }

  static getDbName() {
    return 'node-rate-limiter-flexible';
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get client() {
    return this._client;
  }

  set client(value) {
    if (typeof value === 'undefined') {
      throw new Error('mongo is not set');
    }
    this._client = value;
  }

  get indexKeyPrefix() {
    return this._indexKeyPrefix;
  }

  set indexKeyPrefix(obj) {
    this._indexKeyPrefix = obj || {};
  }

  _initCollection() {
    const db = typeof this.client.db === 'function'
      ? this.client.db(this.dbName)
      : this.client;

    const collection = db.collection(this.tableName);
    collection.createIndex({ expire: -1 }, { expireAfterSeconds: 0 });
    collection.createIndex(Object.assign({}, this.indexKeyPrefix, { key: 1 }), { unique: true });

    this._collection = collection;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$l();

    let doc;
    if (typeof result.value === 'undefined') {
      doc = result;
    } else {
      doc = result.value;
    }

    res.isFirstInDuration = doc.points === changedPoints;
    res.consumedPoints = doc.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = doc.expire !== null
      ? Math.max(new Date(doc.expire).getTime() - Date.now(), 0)
      : -1;

    return res;
  }

  _upsert(key, points, msDuration, forceExpire = false, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};

    let where;
    let upsertData;
    if (forceExpire) {
      where = { key };
      where = Object.assign(where, docAttrs);
      upsertData = {
        $set: {
          key,
          points,
          expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
        },
      };
      upsertData.$set = Object.assign(upsertData.$set, docAttrs);
    } else {
      where = {
        $or: [
          { expire: { $gt: new Date() } },
          { expire: { $eq: null } },
        ],
        key,
      };
      where = Object.assign(where, docAttrs);
      upsertData = {
        $setOnInsert: {
          key,
          expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
        },
        $inc: { points },
      };
      upsertData.$setOnInsert = Object.assign(upsertData.$setOnInsert, docAttrs);
    }

    // Options for collection updates differ between driver versions
    const upsertOptions = {
      upsert: true,
    };
    if ((this._driverVersion.major >= 4) ||
        (this._driverVersion.major === 3 &&
          (this._driverVersion.feature >=7) || 
          (this._driverVersion.feature >= 6 && 
              this._driverVersion.patch >= 7 ))) 
    {
      upsertOptions.returnDocument = 'after';
    } else {
      upsertOptions.returnOriginal = false;
    }

    /*
     * 1. Find actual limit and increment points
     * 2. If limit expired, but Mongo doesn't clean doc by TTL yet, try to replace limit doc completely
     * 3. If 2 or more Mongo threads try to insert the new limit doc, only the first succeed
     * 4. Try to upsert from step 1. Actual limit is created now, points are incremented without problems
     */
    return new Promise((resolve, reject) => {
      this._collection.findOneAndUpdate(
        where,
        upsertData,
        upsertOptions
      ).then((res) => {
        resolve(res);
      }).catch((errUpsert) => {
        if (errUpsert && errUpsert.code === 11000) { // E11000 duplicate key error collection
          const replaceWhere = Object.assign({ // try to replace OLD limit doc
            $or: [
              { expire: { $lte: new Date() } },
              { expire: { $eq: null } },
            ],
            key,
          }, docAttrs);

          const replaceTo = {
            $set: Object.assign({
              key,
              points,
              expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
            }, docAttrs)
          };

          this._collection.findOneAndUpdate(
            replaceWhere,
            replaceTo,
            upsertOptions
          ).then((res) => {
            resolve(res);
          }).catch((errReplace) => {
            if (errReplace && errReplace.code === 11000) { // E11000 duplicate key error collection
              this._upsert(key, points, msDuration, forceExpire)
                .then(res => resolve(res))
                .catch(err => reject(err));
            } else {
              reject(errReplace);
            }
          });
        } else {
          reject(errUpsert);
        }
      });
    });
  }

  _get(rlKey, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};

    const where = Object.assign({
      key: rlKey,
      $or: [
        { expire: { $gt: new Date() } },
        { expire: { $eq: null } },
      ],
    }, docAttrs);

    return this._collection.findOne(where);
  }

  _delete(rlKey, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};
    const where = Object.assign({ key: rlKey }, docAttrs);

    return this._collection.deleteOne(where)
      .then(res => res.deletedCount > 0);
  }
};

var RateLimiterMongo_1$1 = RateLimiterMongo$3;

const RateLimiterStoreAbstract$7 = RateLimiterStoreAbstract_1$1;
const RateLimiterRes$k = RateLimiterRes_1$1;

let RateLimiterMySQL$3 = class RateLimiterMySQL extends RateLimiterStoreAbstract$7 {
  /**
   * @callback callback
   * @param {Object} err
   *
   * @param {Object} opts
   * @param {callback} cb
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: anySqlClient,
   *   storeType: 'knex', // required only for Knex instance
   *   dbName: 'string',
   *   tableName: 'string',
   * }
   */
  constructor(opts, cb = null) {
    super(opts);

    this.client = opts.storeClient;
    this.clientType = opts.storeType;

    this.dbName = opts.dbName;
    this.tableName = opts.tableName;

    this.clearExpiredByTimeout = opts.clearExpiredByTimeout;

    this.tableCreated = opts.tableCreated;
    if (!this.tableCreated) {
      this._createDbAndTable()
        .then(() => {
          this.tableCreated = true;
          if (this.clearExpiredByTimeout) {
            this._clearExpiredHourAgo();
          }
          if (typeof cb === 'function') {
            cb();
          }
        })
        .catch((err) => {
          if (typeof cb === 'function') {
            cb(err);
          } else {
            throw err;
          }
        });
    } else {
      if (this.clearExpiredByTimeout) {
        this._clearExpiredHourAgo();
      }
      if (typeof cb === 'function') {
        cb();
      }
    }
  }

  clearExpired(expire) {
    return new Promise((resolve) => {
      this._getConnection()
        .then((conn) => {
          conn.query(`DELETE FROM ??.?? WHERE expire < ?`, [this.dbName, this.tableName, expire], () => {
            this._releaseConnection(conn);
            resolve();
          });
        })
        .catch(() => {
          resolve();
        });
    });
  }

  _clearExpiredHourAgo() {
    if (this._clearExpiredTimeoutId) {
      clearTimeout(this._clearExpiredTimeoutId);
    }
    this._clearExpiredTimeoutId = setTimeout(() => {
      this.clearExpired(Date.now() - 3600000) // Never rejected
        .then(() => {
          this._clearExpiredHourAgo();
        });
    }, 300000);
    this._clearExpiredTimeoutId.unref();
  }

  /**
   *
   * @return Promise<any>
   * @private
   */
  _getConnection() {
    switch (this.clientType) {
      case 'pool':
        return new Promise((resolve, reject) => {
          this.client.getConnection((errConn, conn) => {
            if (errConn) {
              return reject(errConn);
            }

            resolve(conn);
          });
        });
      case 'sequelize':
        return this.client.connectionManager.getConnection();
      case 'knex':
        return this.client.client.acquireConnection();
      default:
        return Promise.resolve(this.client);
    }
  }

  _releaseConnection(conn) {
    switch (this.clientType) {
      case 'pool':
        return conn.release();
      case 'sequelize':
        return this.client.connectionManager.releaseConnection(conn);
      case 'knex':
        return this.client.client.releaseConnection(conn);
      default:
        return true;
    }
  }

  /**
   *
   * @returns {Promise<any>}
   * @private
   */
  _createDbAndTable() {
    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(`CREATE DATABASE IF NOT EXISTS \`${this.dbName}\`;`, (errDb) => {
            if (errDb) {
              this._releaseConnection(conn);
              return reject(errDb);
            }
            conn.query(this._getCreateTableStmt(), (err) => {
              if (err) {
                this._releaseConnection(conn);
                return reject(err);
              }
              this._releaseConnection(conn);
              resolve();
            });
          });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _getCreateTableStmt() {
    return `CREATE TABLE IF NOT EXISTS \`${this.dbName}\`.\`${this.tableName}\` (` +
      '`key` VARCHAR(255) CHARACTER SET utf8 NOT NULL,' +
      '`points` INT(9) NOT NULL default 0,' +
      '`expire` BIGINT UNSIGNED,' +
      'PRIMARY KEY (`key`)' +
      ') ENGINE = INNODB;';
  }

  get clientType() {
    return this._clientType;
  }

  set clientType(value) {
    if (typeof value === 'undefined') {
      if (this.client.constructor.name === 'Connection') {
        value = 'connection';
      } else if (this.client.constructor.name === 'Pool') {
        value = 'pool';
      } else if (this.client.constructor.name === 'Sequelize') {
        value = 'sequelize';
      } else {
        throw new Error('storeType is not defined');
      }
    }
    this._clientType = value.toLowerCase();
  }

  get dbName() {
    return this._dbName;
  }

  set dbName(value) {
    this._dbName = typeof value === 'undefined' ? 'rtlmtrflx' : value;
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get tableCreated() {
    return this._tableCreated
  }

  set tableCreated(value) {
    this._tableCreated = typeof value === 'undefined' ? false : !!value;
  }

  get clearExpiredByTimeout() {
    return this._clearExpiredByTimeout;
  }

  set clearExpiredByTimeout(value) {
    this._clearExpiredByTimeout = typeof value === 'undefined' ? true : Boolean(value);
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$k();
    const [row] = result;

    res.isFirstInDuration = changedPoints === row.points;
    res.consumedPoints = res.isFirstInDuration ? changedPoints : row.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = row.expire
      ? Math.max(row.expire - Date.now(), 0)
      : -1;

    return res;
  }

  _upsertTransaction(conn, key, points, msDuration, forceExpire) {
    return new Promise((resolve, reject) => {
      conn.query('BEGIN', (errBegin) => {
        if (errBegin) {
          conn.rollback();

          return reject(errBegin);
        }

        const dateNow = Date.now();
        const newExpire = msDuration > 0 ? dateNow + msDuration : null;

        let q;
        let values;
        if (forceExpire) {
          q = `INSERT INTO ??.?? VALUES (?, ?, ?)
          ON DUPLICATE KEY UPDATE 
            points = ?, 
            expire = ?;`;
          values = [
            this.dbName, this.tableName, key, points, newExpire,
            points,
            newExpire,
          ];
        } else {
          q = `INSERT INTO ??.?? VALUES (?, ?, ?)
          ON DUPLICATE KEY UPDATE 
            points = IF(expire <= ?, ?, points + (?)), 
            expire = IF(expire <= ?, ?, expire);`;
          values = [
            this.dbName, this.tableName, key, points, newExpire,
            dateNow, points, points,
            dateNow, newExpire,
          ];
        }

        conn.query(q, values, (errUpsert) => {
          if (errUpsert) {
            conn.rollback();

            return reject(errUpsert);
          }
          conn.query('SELECT points, expire FROM ??.?? WHERE `key` = ?;', [this.dbName, this.tableName, key], (errSelect, res) => {
            if (errSelect) {
              conn.rollback();

              return reject(errSelect);
            }

            conn.query('COMMIT', (err) => {
              if (err) {
                conn.rollback();

                return reject(err);
              }

              resolve(res);
            });
          });
        });
      });
    });
  }

  _upsert(key, points, msDuration, forceExpire = false) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          this._upsertTransaction(conn, key, points, msDuration, forceExpire)
            .then((res) => {
              resolve(res);
              this._releaseConnection(conn);
            })
            .catch((err) => {
              reject(err);
              this._releaseConnection(conn);
            });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _get(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(
            'SELECT points, expire FROM ??.?? WHERE `key` = ? AND (`expire` > ? OR `expire` IS NULL)',
            [this.dbName, this.tableName, rlKey, Date.now()],
            (err, res) => {
              if (err) {
                reject(err);
              } else if (res.length === 0) {
                resolve(null);
              } else {
                resolve(res);
              }

              this._releaseConnection(conn);
            } // eslint-disable-line
          );
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _delete(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(
            'DELETE FROM ??.?? WHERE `key` = ?',
            [this.dbName, this.tableName, rlKey],
            (err, res) => {
              if (err) {
                reject(err);
              } else {
                resolve(res.affectedRows > 0);
              }

              this._releaseConnection(conn);
            } // eslint-disable-line
          );
        })
        .catch((err) => {
          reject(err);
        });
    });
  }
};

var RateLimiterMySQL_1$1 = RateLimiterMySQL$3;

const RateLimiterStoreAbstract$6 = RateLimiterStoreAbstract_1$1;
const RateLimiterRes$j = RateLimiterRes_1$1;

let RateLimiterPostgres$3 = class RateLimiterPostgres extends RateLimiterStoreAbstract$6 {
  /**
   * @callback callback
   * @param {Object} err
   *
   * @param {Object} opts
   * @param {callback} cb
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: postgresClient,
   *   storeType: 'knex', // required only for Knex instance
   *   tableName: 'string',
   * }
   */
  constructor(opts, cb = null) {
    super(opts);

    this.client = opts.storeClient;
    this.clientType = opts.storeType;

    this.tableName = opts.tableName;

    this.clearExpiredByTimeout = opts.clearExpiredByTimeout;

    this.tableCreated = opts.tableCreated;
    if (!this.tableCreated) {
      this._createTable()
        .then(() => {
          this.tableCreated = true;
          if (this.clearExpiredByTimeout) {
            this._clearExpiredHourAgo();
          }
          if (typeof cb === 'function') {
            cb();
          }
        })
        .catch((err) => {
          if (typeof cb === 'function') {
            cb(err);
          } else {
            throw err;
          }
        });
    } else {
      if (typeof cb === 'function') {
        cb();
      }
    }
  }

  clearExpired(expire) {
    return new Promise((resolve) => {
      const q = {
        name: 'rlflx-clear-expired',
        text: `DELETE FROM ${this.tableName} WHERE expire < $1`,
        values: [expire],
      };
      this._query(q)
        .then(() => {
          resolve();
        })
        .catch(() => {
          // Deleting expired query is not critical
          resolve();
        });
    });
  }

  /**
   * Delete all rows expired 1 hour ago once per 5 minutes
   *
   * @private
   */
  _clearExpiredHourAgo() {
    if (this._clearExpiredTimeoutId) {
      clearTimeout(this._clearExpiredTimeoutId);
    }
    this._clearExpiredTimeoutId = setTimeout(() => {
      this.clearExpired(Date.now() - 3600000) // Never rejected
        .then(() => {
          this._clearExpiredHourAgo();
        });
    }, 300000);
    this._clearExpiredTimeoutId.unref();
  }

  /**
   *
   * @return Promise<any>
   * @private
   */
  _getConnection() {
    switch (this.clientType) {
      case 'pool':
        return Promise.resolve(this.client);
      case 'sequelize':
        return this.client.connectionManager.getConnection();
      case 'knex':
        return this.client.client.acquireConnection();
      case 'typeorm':
        return Promise.resolve(this.client.driver.master);
      default:
        return Promise.resolve(this.client);
    }
  }

  _releaseConnection(conn) {
    switch (this.clientType) {
      case 'pool':
        return true;
      case 'sequelize':
        return this.client.connectionManager.releaseConnection(conn);
      case 'knex':
        return this.client.client.releaseConnection(conn);
      case 'typeorm':
        return true;
      default:
        return true;
    }
  }

  /**
   *
   * @returns {Promise<any>}
   * @private
   */
  _createTable() {
    return new Promise((resolve, reject) => {
      this._query({
        text: this._getCreateTableStmt(),
      })
        .then(() => {
          resolve();
        })
        .catch((err) => {
          if (err.code === '23505') {
            // Error: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
            // Postgres doesn't handle concurrent table creation
            // It is supposed, that table is created by another worker
            resolve();
          } else {
            reject(err);
          }
        });
    });
  }

  _getCreateTableStmt() {
    return `CREATE TABLE IF NOT EXISTS ${this.tableName} ( 
      key varchar(255) PRIMARY KEY,
      points integer NOT NULL DEFAULT 0,
      expire bigint
    );`;
  }

  get clientType() {
    return this._clientType;
  }

  set clientType(value) {
    const constructorName = this.client.constructor.name;

    if (typeof value === 'undefined') {
      if (constructorName === 'Client') {
        value = 'client';
      } else if (
        constructorName === 'Pool' ||
        constructorName === 'BoundPool'
      ) {
        value = 'pool';
      } else if (constructorName === 'Sequelize') {
        value = 'sequelize';
      } else {
        throw new Error('storeType is not defined');
      }
    }

    this._clientType = value.toLowerCase();
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get tableCreated() {
    return this._tableCreated
  }

  set tableCreated(value) {
    this._tableCreated = typeof value === 'undefined' ? false : !!value;
  }

  get clearExpiredByTimeout() {
    return this._clearExpiredByTimeout;
  }

  set clearExpiredByTimeout(value) {
    this._clearExpiredByTimeout = typeof value === 'undefined' ? true : Boolean(value);
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$j();
    const row = result.rows[0];

    res.isFirstInDuration = changedPoints === row.points;
    res.consumedPoints = res.isFirstInDuration ? changedPoints : row.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = row.expire
      ? Math.max(row.expire - Date.now(), 0)
      : -1;

    return res;
  }

  _query(q) {
    const prefix = this.tableName.toLowerCase();
    const queryObj = { name: `${prefix}:${q.name}`, text: q.text, values: q.values };
    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(queryObj)
            .then((res) => {
              resolve(res);
              this._releaseConnection(conn);
            })
            .catch((err) => {
              reject(err);
              this._releaseConnection(conn);
            });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _upsert(key, points, msDuration, forceExpire = false) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    const newExpire = msDuration > 0 ? Date.now() + msDuration : null;
    const expireQ = forceExpire
      ? ' $3 '
      : ` CASE
             WHEN ${this.tableName}.expire <= $4 THEN $3
             ELSE ${this.tableName}.expire
            END `;

    return this._query({
      name: forceExpire ? 'rlflx-upsert-force' : 'rlflx-upsert',
      text: `
            INSERT INTO ${this.tableName} VALUES ($1, $2, $3)
              ON CONFLICT(key) DO UPDATE SET
                points = CASE
                          WHEN (${this.tableName}.expire <= $4 OR 1=${forceExpire ? 1 : 0}) THEN $2
                          ELSE ${this.tableName}.points + ($2)
                         END,
                expire = ${expireQ}
            RETURNING points, expire;`,
      values: [key, points, newExpire, Date.now()],
    });
  }

  _get(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._query({
        name: 'rlflx-get',
        text: `
            SELECT points, expire FROM ${this.tableName} WHERE key = $1 AND (expire > $2 OR expire IS NULL);`,
        values: [rlKey, Date.now()],
      })
        .then((res) => {
          if (res.rowCount === 0) {
            res = null;
          }
          resolve(res);
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _delete(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return this._query({
      name: 'rlflx-delete',
      text: `DELETE FROM ${this.tableName} WHERE key = $1`,
      values: [rlKey],
    })
      .then(res => res.rowCount > 0);
  }
};

var RateLimiterPostgres_1$1 = RateLimiterPostgres$3;

var Record_1$1 = class Record {
  /**
   *
   * @param value int
   * @param expiresAt Date|int
   * @param timeoutId
   */
  constructor(value, expiresAt, timeoutId = null) {
    this.value = value;
    this.expiresAt = expiresAt;
    this.timeoutId = timeoutId;
  }

  get value() {
    return this._value;
  }

  set value(value) {
    this._value = parseInt(value);
  }

  get expiresAt() {
    return this._expiresAt;
  }

  set expiresAt(value) {
    if (!(value instanceof Date) && Number.isInteger(value)) {
      value = new Date(value);
    }
    this._expiresAt = value;
  }

  get timeoutId() {
    return this._timeoutId;
  }

  set timeoutId(value) {
    this._timeoutId = value;
  }
};

const Record$1 = Record_1$1;
const RateLimiterRes$i = RateLimiterRes_1$1;

var MemoryStorage_1$1 = class MemoryStorage {
  constructor() {
    /**
     * @type {Object.<string, Record>}
     * @private
     */
    this._storage = {};
  }

  incrby(key, value, durationSec) {
    if (this._storage[key]) {
      const msBeforeExpires = this._storage[key].expiresAt
        ? this._storage[key].expiresAt.getTime() - new Date().getTime()
        : -1;
      if (msBeforeExpires !== 0) {
        // Change value
        this._storage[key].value = this._storage[key].value + value;

        return new RateLimiterRes$i(0, msBeforeExpires, this._storage[key].value, false);
      }

      return this.set(key, value, durationSec);
    }
    return this.set(key, value, durationSec);
  }

  set(key, value, durationSec) {
    const durationMs = durationSec * 1000;

    if (this._storage[key] && this._storage[key].timeoutId) {
      clearTimeout(this._storage[key].timeoutId);
    }

    this._storage[key] = new Record$1(
      value,
      durationMs > 0 ? new Date(Date.now() + durationMs) : null
    );
    if (durationMs > 0) {
      this._storage[key].timeoutId = setTimeout(() => {
        delete this._storage[key];
      }, durationMs);
      if (this._storage[key].timeoutId.unref) {
        this._storage[key].timeoutId.unref();
      }
    }

    return new RateLimiterRes$i(0, durationMs === 0 ? -1 : durationMs, this._storage[key].value, true);
  }

  /**
   *
   * @param key
   * @returns {*}
   */
  get(key) {
    if (this._storage[key]) {
      const msBeforeExpires = this._storage[key].expiresAt
        ? this._storage[key].expiresAt.getTime() - new Date().getTime()
        : -1;
      return new RateLimiterRes$i(0, msBeforeExpires, this._storage[key].value, false);
    }
    return null;
  }

  /**
   *
   * @param key
   * @returns {boolean}
   */
  delete(key) {
    if (this._storage[key]) {
      if (this._storage[key].timeoutId) {
        clearTimeout(this._storage[key].timeoutId);
      }
      delete this._storage[key];
      return true;
    }
    return false;
  }
};

const RateLimiterAbstract$6 = RateLimiterAbstract_1$1;
const MemoryStorage$1 = MemoryStorage_1$1;
const RateLimiterRes$h = RateLimiterRes_1$1;

let RateLimiterMemory$5 = class RateLimiterMemory extends RateLimiterAbstract$6 {
  constructor(opts = {}) {
    super(opts);

    this._memoryStorage = new MemoryStorage$1();
  }
  /**
   *
   * @param key
   * @param pointsToConsume
   * @param {Object} options
   * @returns {Promise<RateLimiterRes>}
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const rlKey = this.getKey(key);
      const secDuration = this._getKeySecDuration(options);
      let res = this._memoryStorage.incrby(rlKey, pointsToConsume, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);

      if (res.consumedPoints > this.points) {
        // Block only first time when consumed more than points
        if (this.blockDuration > 0 && res.consumedPoints <= (this.points + pointsToConsume)) {
          // Block key
          res = this._memoryStorage.set(rlKey, res.consumedPoints, this.blockDuration);
        }
        reject(res);
      } else if (this.execEvenly && res.msBeforeNext > 0 && !res.isFirstInDuration) {
        // Execute evenly
        let delay = Math.ceil(res.msBeforeNext / (res.remainingPoints + 2));
        if (delay < this.execEvenlyMinDelayMs) {
          delay = res.consumedPoints * this.execEvenlyMinDelayMs;
        }

        setTimeout(resolve, delay, res);
      } else {
        resolve(res);
      }
    });
  }

  penalty(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve) => {
      const secDuration = this._getKeySecDuration(options);
      const res = this._memoryStorage.incrby(rlKey, points, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
      resolve(res);
    });
  }

  reward(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve) => {
      const secDuration = this._getKeySecDuration(options);
      const res = this._memoryStorage.incrby(rlKey, -points, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
      resolve(res);
    });
  }

  /**
   * Block any key for secDuration seconds
   *
   * @param key
   * @param secDuration
   */
  block(key, secDuration) {
    const msDuration = secDuration * 1000;
    const initPoints = this.points + 1;

    this._memoryStorage.set(this.getKey(key), initPoints, secDuration);
    return Promise.resolve(
      new RateLimiterRes$h(0, msDuration === 0 ? -1 : msDuration, initPoints)
    );
  }

  set(key, points, secDuration) {
    const msDuration = (secDuration >= 0 ? secDuration : this.duration) * 1000;

    this._memoryStorage.set(this.getKey(key), points, secDuration);
    return Promise.resolve(
      new RateLimiterRes$h(0, msDuration === 0 ? -1 : msDuration, points)
    );
  }

  get(key) {
    const res = this._memoryStorage.get(this.getKey(key));
    if (res !== null) {
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    }

    return Promise.resolve(res);
  }

  delete(key) {
    return Promise.resolve(this._memoryStorage.delete(this.getKey(key)));
  }
};

var RateLimiterMemory_1$1 = RateLimiterMemory$5;

/**
 * Implements rate limiting in cluster using built-in IPC
 *
 * Two classes are described here: master and worker
 * Master have to be create in the master process without any options.
 * Any number of rate limiters can be created in workers, but each rate limiter must be with unique keyPrefix
 *
 * Workflow:
 * 1. master rate limiter created in master process
 * 2. worker rate limiter sends 'init' message with necessary options during creating
 * 3. master receives options and adds new rate limiter by keyPrefix if it isn't created yet
 * 4. master sends 'init' back to worker's rate limiter
 * 5. worker can process requests immediately,
 *    but they will be postponed by 'workerWaitInit' until master sends 'init' to worker
 * 6. every request to worker rate limiter creates a promise
 * 7. if master doesn't response for 'timeout', promise is rejected
 * 8. master sends 'resolve' or 'reject' command to worker
 * 9. worker resolves or rejects promise depending on message from master
 *
 */

const cluster$1 = require$$1;
const crypto$2 = require$$1;
const RateLimiterAbstract$5 = RateLimiterAbstract_1$1;
const RateLimiterMemory$4 = RateLimiterMemory_1$1;
const RateLimiterRes$g = RateLimiterRes_1$1;

const channel$1 = 'rate_limiter_flexible';
let masterInstance$1 = null;

const masterSendToWorker$1 = function (worker, msg, type, res) {
  let data;
  if (res === null || res === true || res === false) {
    data = res;
  } else {
    data = {
      remainingPoints: res.remainingPoints,
      msBeforeNext: res.msBeforeNext,
      consumedPoints: res.consumedPoints,
      isFirstInDuration: res.isFirstInDuration,
    };
  }
  worker.send({
    channel: channel$1,
    keyPrefix: msg.keyPrefix, // which rate limiter exactly
    promiseId: msg.promiseId,
    type,
    data,
  });
};

const workerWaitInit$1 = function (payload) {
  setTimeout(() => {
    if (this._initiated) {
      process.send(payload);
      // Promise will be removed by timeout if too long
    } else if (typeof this._promises[payload.promiseId] !== 'undefined') {
      workerWaitInit$1.call(this, payload);
    }
  }, 30);
};

const workerSendToMaster$1 = function (func, promiseId, key, arg, opts) {
  const payload = {
    channel: channel$1,
    keyPrefix: this.keyPrefix,
    func,
    promiseId,
    data: {
      key,
      arg,
      opts,
    },
  };

  if (!this._initiated) {
    // Wait init before sending messages to master
    workerWaitInit$1.call(this, payload);
  } else {
    process.send(payload);
  }
};

const masterProcessMsg$1 = function (worker, msg) {
  if (!msg || msg.channel !== channel$1 || typeof this._rateLimiters[msg.keyPrefix] === 'undefined') {
    return false;
  }

  let promise;

  switch (msg.func) {
    case 'consume':
      promise = this._rateLimiters[msg.keyPrefix].consume(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'penalty':
      promise = this._rateLimiters[msg.keyPrefix].penalty(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'reward':
      promise = this._rateLimiters[msg.keyPrefix].reward(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'block':
      promise = this._rateLimiters[msg.keyPrefix].block(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'get':
      promise = this._rateLimiters[msg.keyPrefix].get(msg.data.key, msg.data.opts);
      break;
    case 'delete':
      promise = this._rateLimiters[msg.keyPrefix].delete(msg.data.key, msg.data.opts);
      break;
    default:
      return false;
  }

  if (promise) {
    promise
      .then((res) => {
        masterSendToWorker$1(worker, msg, 'resolve', res);
      })
      .catch((rejRes) => {
        masterSendToWorker$1(worker, msg, 'reject', rejRes);
      });
  }
};

const workerProcessMsg$1 = function (msg) {
  if (!msg || msg.channel !== channel$1 || msg.keyPrefix !== this.keyPrefix) {
    return false;
  }

  if (this._promises[msg.promiseId]) {
    clearTimeout(this._promises[msg.promiseId].timeoutId);
    let res;
    if (msg.data === null || msg.data === true || msg.data === false) {
      res = msg.data;
    } else {
      res = new RateLimiterRes$g(
        msg.data.remainingPoints,
        msg.data.msBeforeNext,
        msg.data.consumedPoints,
        msg.data.isFirstInDuration // eslint-disable-line comma-dangle
      );
    }

    switch (msg.type) {
      case 'resolve':
        this._promises[msg.promiseId].resolve(res);
        break;
      case 'reject':
        this._promises[msg.promiseId].reject(res);
        break;
      default:
        throw new Error(`RateLimiterCluster: no such message type '${msg.type}'`);
    }

    delete this._promises[msg.promiseId];
  }
};
/**
 * Prepare options to send to master
 * Master will create rate limiter depending on options
 *
 * @returns {{points: *, duration: *, blockDuration: *, execEvenly: *, execEvenlyMinDelayMs: *, keyPrefix: *}}
 */
const getOpts$1 = function () {
  return {
    points: this.points,
    duration: this.duration,
    blockDuration: this.blockDuration,
    execEvenly: this.execEvenly,
    execEvenlyMinDelayMs: this.execEvenlyMinDelayMs,
    keyPrefix: this.keyPrefix,
  };
};

const savePromise$1 = function (resolve, reject) {
  const hrtime = process.hrtime();
  let promiseId = hrtime[0].toString() + hrtime[1].toString();

  if (typeof this._promises[promiseId] !== 'undefined') {
    promiseId += crypto$2.randomBytes(12).toString('base64');
  }

  this._promises[promiseId] = {
    resolve,
    reject,
    timeoutId: setTimeout(() => {
      delete this._promises[promiseId];
      reject(new Error('RateLimiterCluster timeout: no answer from master in time'));
    }, this.timeoutMs),
  };

  return promiseId;
};

let RateLimiterClusterMaster$3 = class RateLimiterClusterMaster {
  constructor() {
    if (masterInstance$1) {
      return masterInstance$1;
    }

    this._rateLimiters = {};

    cluster$1.setMaxListeners(0);

    cluster$1.on('message', (worker, msg) => {
      if (msg && msg.channel === channel$1 && msg.type === 'init') {
        // If init request, check or create rate limiter by key prefix and send 'init' back to worker
        if (typeof this._rateLimiters[msg.opts.keyPrefix] === 'undefined') {
          this._rateLimiters[msg.opts.keyPrefix] = new RateLimiterMemory$4(msg.opts);
        }

        worker.send({
          channel: channel$1,
          type: 'init',
          keyPrefix: msg.opts.keyPrefix,
        });
      } else {
        masterProcessMsg$1.call(this, worker, msg);
      }
    });

    masterInstance$1 = this;
  }
};

let RateLimiterClusterMasterPM2$3 = class RateLimiterClusterMasterPM2 {
  constructor(pm2) {
    if (masterInstance$1) {
      return masterInstance$1;
    }

    this._rateLimiters = {};

    pm2.launchBus((err, pm2Bus) => {
      pm2Bus.on('process:msg', (packet) => {
        const msg = packet.raw;
        if (msg && msg.channel === channel$1 && msg.type === 'init') {
          // If init request, check or create rate limiter by key prefix and send 'init' back to worker
          if (typeof this._rateLimiters[msg.opts.keyPrefix] === 'undefined') {
            this._rateLimiters[msg.opts.keyPrefix] = new RateLimiterMemory$4(msg.opts);
          }

          pm2.sendDataToProcessId(packet.process.pm_id, {
            data: {},
            topic: channel$1,
            channel: channel$1,
            type: 'init',
            keyPrefix: msg.opts.keyPrefix,
          }, (sendErr, res) => {
            if (sendErr) {
              console.log(sendErr, res);
            }
          });
        } else {
          const worker = {
            send: (msgData) => {
              const pm2Message = msgData;
              pm2Message.topic = channel$1;
              if (typeof pm2Message.data === 'undefined') {
                pm2Message.data = {};
              }
              pm2.sendDataToProcessId(packet.process.pm_id, pm2Message, (sendErr, res) => {
                if (sendErr) {
                  console.log(sendErr, res);
                }
              });
            },
          };
          masterProcessMsg$1.call(this, worker, msg);
        }
      });
    });

    masterInstance$1 = this;
  }
};

let RateLimiterClusterWorker$1 = class RateLimiterClusterWorker extends RateLimiterAbstract$5 {
  get timeoutMs() {
    return this._timeoutMs;
  }

  set timeoutMs(value) {
    this._timeoutMs = typeof value === 'undefined' ? 5000 : Math.abs(parseInt(value));
  }

  constructor(opts = {}) {
    super(opts);

    process.setMaxListeners(0);

    this.timeoutMs = opts.timeoutMs;

    this._initiated = false;

    process.on('message', (msg) => {
      if (msg && msg.channel === channel$1 && msg.type === 'init' && msg.keyPrefix === this.keyPrefix) {
        this._initiated = true;
      } else {
        workerProcessMsg$1.call(this, msg);
      }
    });

    // Create limiter on master with specific options
    process.send({
      channel: channel$1,
      type: 'init',
      opts: getOpts$1.call(this),
    });

    this._promises = {};
  }

  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise$1.call(this, resolve, reject);

      workerSendToMaster$1.call(this, 'consume', promiseId, key, pointsToConsume, options);
    });
  }

  penalty(key, points = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise$1.call(this, resolve, reject);

      workerSendToMaster$1.call(this, 'penalty', promiseId, key, points, options);
    });
  }

  reward(key, points = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise$1.call(this, resolve, reject);

      workerSendToMaster$1.call(this, 'reward', promiseId, key, points, options);
    });
  }

  block(key, secDuration, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise$1.call(this, resolve, reject);

      workerSendToMaster$1.call(this, 'block', promiseId, key, secDuration, options);
    });
  }

  get(key, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise$1.call(this, resolve, reject);

      workerSendToMaster$1.call(this, 'get', promiseId, key, options);
    });
  }

  delete(key, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise$1.call(this, resolve, reject);

      workerSendToMaster$1.call(this, 'delete', promiseId, key, options);
    });
  }
};

var RateLimiterCluster$3 = {
  RateLimiterClusterMaster: RateLimiterClusterMaster$3,
  RateLimiterClusterMasterPM2: RateLimiterClusterMasterPM2$3,
  RateLimiterCluster: RateLimiterClusterWorker$1,
};

const RateLimiterStoreAbstract$5 = RateLimiterStoreAbstract_1$1;
const RateLimiterRes$f = RateLimiterRes_1$1;

let RateLimiterMemcache$3 = class RateLimiterMemcache extends RateLimiterStoreAbstract$5 {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: memcacheClient
   * }
   */
  constructor(opts) {
    super(opts);

    this.client = opts.storeClient;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$f();
    res.consumedPoints = parseInt(result.consumedPoints);
    res.isFirstInDuration = result.consumedPoints === changedPoints;
    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = result.msBeforeNext;

    return res;
  }

  _upsert(rlKey, points, msDuration, forceExpire = false, options = {}) {
    return new Promise((resolve, reject) => {
      const nowMs = Date.now();
      const secDuration = Math.floor(msDuration / 1000);

      if (forceExpire) {
        this.client.set(rlKey, points, secDuration, (err) => {
          if (!err) {
            this.client.set(
              `${rlKey}_expire`,
              secDuration > 0 ? nowMs + (secDuration * 1000) : -1,
              secDuration,
              () => {
                const res = {
                  consumedPoints: points,
                  msBeforeNext: secDuration > 0 ? secDuration * 1000 : -1,
                };
                resolve(res);
              }
            );
          } else {
            reject(err);
          }
        });
      } else {
        this.client.incr(rlKey, points, (err, consumedPoints) => {
          if (err || consumedPoints === false) {
            this.client.add(rlKey, points, secDuration, (errAddKey, createdNew) => {
              if (errAddKey || !createdNew) {
                // Try to upsert again in case of race condition
                if (typeof options.attemptNumber === 'undefined' || options.attemptNumber < 3) {
                  const nextOptions = Object.assign({}, options);
                  nextOptions.attemptNumber = nextOptions.attemptNumber ? (nextOptions.attemptNumber + 1) : 1;

                  this._upsert(rlKey, points, msDuration, forceExpire, nextOptions)
                    .then(resUpsert => resolve(resUpsert))
                    .catch(errUpsert => reject(errUpsert));
                } else {
                  reject(new Error('Can not add key'));
                }
              } else {
                this.client.add(
                  `${rlKey}_expire`,
                  secDuration > 0 ? nowMs + (secDuration * 1000) : -1,
                  secDuration,
                  () => {
                    const res = {
                      consumedPoints: points,
                      msBeforeNext: secDuration > 0 ? secDuration * 1000 : -1,
                    };
                    resolve(res);
                  }
                );
              }
            });
          } else {
            this.client.get(`${rlKey}_expire`, (errGetExpire, resGetExpireMs) => {
              if (errGetExpire) {
                reject(errGetExpire);
              } else {
                const expireMs = resGetExpireMs === false ? 0 : resGetExpireMs;
                const res = {
                  consumedPoints,
                  msBeforeNext: expireMs >= 0 ? Math.max(expireMs - nowMs, 0) : -1,
                };
                resolve(res);
              }
            });
          }
        });
      }
    });
  }

  _get(rlKey) {
    return new Promise((resolve, reject) => {
      const nowMs = Date.now();

      this.client.get(rlKey, (err, consumedPoints) => {
        if (!consumedPoints) {
          resolve(null);
        } else {
          this.client.get(`${rlKey}_expire`, (errGetExpire, resGetExpireMs) => {
            if (errGetExpire) {
              reject(errGetExpire);
            } else {
              const expireMs = resGetExpireMs === false ? 0 : resGetExpireMs;
              const res = {
                consumedPoints,
                msBeforeNext: expireMs >= 0 ? Math.max(expireMs - nowMs, 0) : -1,
              };
              resolve(res);
            }
          });
        }
      });
    });
  }

  _delete(rlKey) {
    return new Promise((resolve, reject) => {
      this.client.del(rlKey, (err, res) => {
        if (err) {
          reject(err);
        } else if (res === false) {
          resolve(res);
        } else {
          this.client.del(`${rlKey}_expire`, (errDelExpire) => {
            if (errDelExpire) {
              reject(errDelExpire);
            } else {
              resolve(res);
            }
          });
        }
      });
    });
  }
};

var RateLimiterMemcache_1$1 = RateLimiterMemcache$3;

const RateLimiterRes$e = RateLimiterRes_1$1;

var RLWrapperBlackAndWhite_1$1 = class RLWrapperBlackAndWhite {
  constructor(opts = {}) {
    this.limiter = opts.limiter;
    this.blackList = opts.blackList;
    this.whiteList = opts.whiteList;
    this.isBlackListed = opts.isBlackListed;
    this.isWhiteListed = opts.isWhiteListed;
    this.runActionAnyway = opts.runActionAnyway;
  }

  get limiter() {
    return this._limiter;
  }

  set limiter(value) {
    if (typeof value === 'undefined') {
      throw new Error('limiter is not set');
    }

    this._limiter = value;
  }

  get runActionAnyway() {
    return this._runActionAnyway;
  }

  set runActionAnyway(value) {
    this._runActionAnyway = typeof value === 'undefined' ? false : value;
  }

  get blackList() {
    return this._blackList;
  }

  set blackList(value) {
    this._blackList = Array.isArray(value) ? value : [];
  }

  get isBlackListed() {
    return this._isBlackListed;
  }

  set isBlackListed(func) {
    if (typeof func === 'undefined') {
      func = () => false;
    }
    if (typeof func !== 'function') {
      throw new Error('isBlackListed must be function');
    }
    this._isBlackListed = func;
  }

  get whiteList() {
    return this._whiteList;
  }

  set whiteList(value) {
    this._whiteList = Array.isArray(value) ? value : [];
  }

  get isWhiteListed() {
    return this._isWhiteListed;
  }

  set isWhiteListed(func) {
    if (typeof func === 'undefined') {
      func = () => false;
    }
    if (typeof func !== 'function') {
      throw new Error('isWhiteListed must be function');
    }
    this._isWhiteListed = func;
  }

  isBlackListedSomewhere(key) {
    return this.blackList.indexOf(key) >= 0 || this.isBlackListed(key);
  }

  isWhiteListedSomewhere(key) {
    return this.whiteList.indexOf(key) >= 0 || this.isWhiteListed(key);
  }

  getBlackRes() {
    return new RateLimiterRes$e(0, Number.MAX_SAFE_INTEGER, 0, false);
  }

  getWhiteRes() {
    return new RateLimiterRes$e(Number.MAX_SAFE_INTEGER, 0, 0, false);
  }

  rejectBlack() {
    return Promise.reject(this.getBlackRes());
  }

  resolveBlack() {
    return Promise.resolve(this.getBlackRes());
  }

  resolveWhite() {
    return Promise.resolve(this.getWhiteRes());
  }

  consume(key, pointsToConsume = 1) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.rejectBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.consume(key, pointsToConsume);
    }

    if (this.runActionAnyway) {
      this.limiter.consume(key, pointsToConsume).catch(() => {});
    }
    return res;
  }

  block(key, secDuration) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.block(key, secDuration);
    }

    if (this.runActionAnyway) {
      this.limiter.block(key, secDuration).catch(() => {});
    }
    return res;
  }

  penalty(key, points) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.penalty(key, points);
    }

    if (this.runActionAnyway) {
      this.limiter.penalty(key, points).catch(() => {});
    }
    return res;
  }

  reward(key, points) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.reward(key, points);
    }

    if (this.runActionAnyway) {
      this.limiter.reward(key, points).catch(() => {});
    }
    return res;
  }

  get(key) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined' || this.runActionAnyway) {
      return this.limiter.get(key);
    }

    return res;
  }

  delete(key) {
    return this.limiter.delete(key);
  }
};

const RateLimiterAbstract$4 = RateLimiterAbstract_1$1;

var RateLimiterUnion_1$1 = class RateLimiterUnion {
  constructor(...limiters) {
    if (limiters.length < 1) {
      throw new Error('RateLimiterUnion: at least one limiter have to be passed');
    }
    limiters.forEach((limiter) => {
      if (!(limiter instanceof RateLimiterAbstract$4)) {
        throw new Error('RateLimiterUnion: all limiters have to be instance of RateLimiterAbstract');
      }
    });

    this._limiters = limiters;
  }

  consume(key, points = 1) {
    return new Promise((resolve, reject) => {
      const promises = [];
      this._limiters.forEach((limiter) => {
        promises.push(limiter.consume(key, points).catch(rej => ({ rejected: true, rej })));
      });

      Promise.all(promises)
        .then((res) => {
          const resObj = {};
          let rejected = false;

          res.forEach((item) => {
            if (item.rejected === true) {
              rejected = true;
            }
          });

          for (let i = 0; i < res.length; i++) {
            if (rejected && res[i].rejected === true) {
              resObj[this._limiters[i].keyPrefix] = res[i].rej;
            } else if (!rejected) {
              resObj[this._limiters[i].keyPrefix] = res[i];
            }
          }

          if (rejected) {
            reject(resObj);
          } else {
            resolve(resObj);
          }
        });
    });
  }
};

var RateLimiterQueueError_1$1 = class RateLimiterQueueError extends Error {
  constructor(message, extra) {
    super();
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, this.constructor);
    }
    this.name = 'CustomError';
    this.message = message;
    if (extra) {
      this.extra = extra;
    }
  }
};

const RateLimiterQueueError$1 = RateLimiterQueueError_1$1;
const MAX_QUEUE_SIZE$1 = 4294967295;
const KEY_DEFAULT$1 = 'limiter';

var RateLimiterQueue_1$1 = class RateLimiterQueue {
  constructor(limiterFlexible, opts = {
    maxQueueSize: MAX_QUEUE_SIZE$1,
  }) {
    this._queueLimiters = {
      KEY_DEFAULT: new RateLimiterQueueInternal$1(limiterFlexible, opts)
    };
    this._limiterFlexible = limiterFlexible;
    this._maxQueueSize = opts.maxQueueSize;
  }

  getTokensRemaining(key = KEY_DEFAULT$1) {
    if (this._queueLimiters[key]) {
      return this._queueLimiters[key].getTokensRemaining()
    } else {
      return Promise.resolve(this._limiterFlexible.points)
    }
  }

  removeTokens(tokens, key = KEY_DEFAULT$1) {
    if (!this._queueLimiters[key]) {
      this._queueLimiters[key] = new RateLimiterQueueInternal$1(
        this._limiterFlexible, {
          key,
          maxQueueSize: this._maxQueueSize,
        });
    }

    return this._queueLimiters[key].removeTokens(tokens)
  }
};

let RateLimiterQueueInternal$1 = class RateLimiterQueueInternal {

  constructor(limiterFlexible, opts = {
    maxQueueSize: MAX_QUEUE_SIZE$1,
    key: KEY_DEFAULT$1,
  }) {
    this._key = opts.key;
    this._waitTimeout = null;
    this._queue = [];
    this._limiterFlexible = limiterFlexible;

    this._maxQueueSize = opts.maxQueueSize;
  }

  getTokensRemaining() {
    return this._limiterFlexible.get(this._key)
      .then((rlRes) => {
        return rlRes !== null ? rlRes.remainingPoints : this._limiterFlexible.points;
      })
  }

  removeTokens(tokens) {
    const _this = this;

    return new Promise((resolve, reject) => {
      if (tokens > _this._limiterFlexible.points) {
        reject(new RateLimiterQueueError$1(`Requested tokens ${tokens} exceeds maximum ${_this._limiterFlexible.points} tokens per interval`));
        return
      }

      if (_this._queue.length > 0) {
        _this._queueRequest.call(_this, resolve, reject, tokens);
      } else {
        _this._limiterFlexible.consume(_this._key, tokens)
          .then((res) => {
            resolve(res.remainingPoints);
          })
          .catch((rej) => {
            if (rej instanceof Error) {
              reject(rej);
            } else {
              _this._queueRequest.call(_this, resolve, reject, tokens);
              if (_this._waitTimeout === null) {
                _this._waitTimeout = setTimeout(_this._processFIFO.bind(_this), rej.msBeforeNext);
              }
            }
          });
      }
    })
  }

  _queueRequest(resolve, reject, tokens) {
    const _this = this;
    if (_this._queue.length < _this._maxQueueSize) {
      _this._queue.push({resolve, reject, tokens});
    } else {
      reject(new RateLimiterQueueError$1(`Number of requests reached it's maximum ${_this._maxQueueSize}`));
    }
  }

  _processFIFO() {
    const _this = this;

    if (_this._waitTimeout !== null) {
      clearTimeout(_this._waitTimeout);
      _this._waitTimeout = null;
    }

    if (_this._queue.length === 0) {
      return;
    }

    const item = _this._queue.shift();
    _this._limiterFlexible.consume(_this._key, item.tokens)
      .then((res) => {
        item.resolve(res.remainingPoints);
        _this._processFIFO.call(_this);
      })
      .catch((rej) => {
        if (rej instanceof Error) {
          item.reject(rej);
          _this._processFIFO.call(_this);
        } else {
          _this._queue.unshift(item);
          if (_this._waitTimeout === null) {
            _this._waitTimeout = setTimeout(_this._processFIFO.bind(_this), rej.msBeforeNext);
          }
        }
      });
  }
};

const RateLimiterRes$d = RateLimiterRes_1$1;

/**
 * Bursty rate limiter exposes only msBeforeNext time and doesn't expose points from bursty limiter by default
 * @type {BurstyRateLimiter}
 */
var BurstyRateLimiter_1$1 = class BurstyRateLimiter {
  constructor(rateLimiter, burstLimiter) {
    this._rateLimiter = rateLimiter;
    this._burstLimiter = burstLimiter;
  }

  /**
   * Merge rate limiter response objects. Responses can be null
   *
   * @param {RateLimiterRes} [rlRes] Rate limiter response
   * @param {RateLimiterRes} [blRes] Bursty limiter response
   */
  _combineRes(rlRes, blRes) {
    return new RateLimiterRes$d(
      rlRes.remainingPoints,
      Math.min(rlRes.msBeforeNext, blRes.msBeforeNext),
      rlRes.consumedPoints,
      rlRes.isFirstInDuration
    )
  }

  /**
   * @param key
   * @param pointsToConsume
   * @param options
   * @returns {Promise<any>}
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return this._rateLimiter.consume(key, pointsToConsume, options)
      .catch((rlRej) => {
        if (rlRej instanceof RateLimiterRes$d) {
          return this._burstLimiter.consume(key, pointsToConsume, options)
            .then((blRes) => {
              return Promise.resolve(this._combineRes(rlRej, blRes))
            })
            .catch((blRej) => {
                if (blRej instanceof RateLimiterRes$d) {
                  return Promise.reject(this._combineRes(rlRej, blRej))
                } else {
                  return Promise.reject(blRej)
                }
              }
            )
        } else {
          return Promise.reject(rlRej)
        }
      })
  }

  /**
   * It doesn't expose available points from burstLimiter
   *
   * @param key
   * @returns {Promise<RateLimiterRes>}
   */
  get(key) {
    return Promise.all([
      this._rateLimiter.get(key),
      this._burstLimiter.get(key),
    ]).then(([rlRes, blRes]) => {
      return this._combineRes(rlRes, blRes);
    });
  }

  get points() {
    return this._rateLimiter.points;
  }
};

const RateLimiterRedis$2 = RateLimiterRedis_1$1;
const RateLimiterMongo$2 = RateLimiterMongo_1$1;
const RateLimiterMySQL$2 = RateLimiterMySQL_1$1;
const RateLimiterPostgres$2 = RateLimiterPostgres_1$1;
const {RateLimiterClusterMaster: RateLimiterClusterMaster$2, RateLimiterClusterMasterPM2: RateLimiterClusterMasterPM2$2, RateLimiterCluster: RateLimiterCluster$2} = RateLimiterCluster$3;
const RateLimiterMemory$3 = RateLimiterMemory_1$1;
const RateLimiterMemcache$2 = RateLimiterMemcache_1$1;
const RLWrapperBlackAndWhite$1 = RLWrapperBlackAndWhite_1$1;
const RateLimiterUnion$1 = RateLimiterUnion_1$1;
const RateLimiterQueue$1 = RateLimiterQueue_1$1;
const BurstyRateLimiter$1 = BurstyRateLimiter_1$1;
const RateLimiterRes$c = RateLimiterRes_1$1;

var rateLimiterFlexible$1 = {
  RateLimiterRedis: RateLimiterRedis$2,
  RateLimiterMongo: RateLimiterMongo$2,
  RateLimiterMySQL: RateLimiterMySQL$2,
  RateLimiterPostgres: RateLimiterPostgres$2,
  RateLimiterMemory: RateLimiterMemory$3,
  RateLimiterMemcache: RateLimiterMemcache$2,
  RateLimiterClusterMaster: RateLimiterClusterMaster$2,
  RateLimiterClusterMasterPM2: RateLimiterClusterMasterPM2$2,
  RateLimiterCluster: RateLimiterCluster$2,
  RLWrapperBlackAndWhite: RLWrapperBlackAndWhite$1,
  RateLimiterUnion: RateLimiterUnion$1,
  RateLimiterQueue: RateLimiterQueue$1,
  BurstyRateLimiter: BurstyRateLimiter$1,
  RateLimiterRes: RateLimiterRes$c,
};

var MessageTypes;
(function (MessageTypes) {
    MessageTypes[MessageTypes["NEW_STREAM"] = 0] = "NEW_STREAM";
    MessageTypes[MessageTypes["MESSAGE_RECEIVER"] = 1] = "MESSAGE_RECEIVER";
    MessageTypes[MessageTypes["MESSAGE_INITIATOR"] = 2] = "MESSAGE_INITIATOR";
    MessageTypes[MessageTypes["CLOSE_RECEIVER"] = 3] = "CLOSE_RECEIVER";
    MessageTypes[MessageTypes["CLOSE_INITIATOR"] = 4] = "CLOSE_INITIATOR";
    MessageTypes[MessageTypes["RESET_RECEIVER"] = 5] = "RESET_RECEIVER";
    MessageTypes[MessageTypes["RESET_INITIATOR"] = 6] = "RESET_INITIATOR";
})(MessageTypes || (MessageTypes = {}));
const MessageTypeNames = Object.freeze({
    0: 'NEW_STREAM',
    1: 'MESSAGE_RECEIVER',
    2: 'MESSAGE_INITIATOR',
    3: 'CLOSE_RECEIVER',
    4: 'CLOSE_INITIATOR',
    5: 'RESET_RECEIVER',
    6: 'RESET_INITIATOR'
});
const InitiatorMessageTypes = Object.freeze({
    NEW_STREAM: MessageTypes.NEW_STREAM,
    MESSAGE: MessageTypes.MESSAGE_INITIATOR,
    CLOSE: MessageTypes.CLOSE_INITIATOR,
    RESET: MessageTypes.RESET_INITIATOR
});
const ReceiverMessageTypes = Object.freeze({
    MESSAGE: MessageTypes.MESSAGE_RECEIVER,
    CLOSE: MessageTypes.CLOSE_RECEIVER,
    RESET: MessageTypes.RESET_RECEIVER
});

const MAX_MSG_SIZE = 1 << 20; // 1MB
const MAX_MSG_QUEUE_SIZE = 4 << 20; // 4MB
let Decoder$a = class Decoder {
    _buffer;
    _headerInfo;
    _maxMessageSize;
    _maxUnprocessedMessageQueueSize;
    constructor(maxMessageSize = MAX_MSG_SIZE, maxUnprocessedMessageQueueSize = MAX_MSG_QUEUE_SIZE) {
        this._buffer = new Uint8ArrayList();
        this._headerInfo = null;
        this._maxMessageSize = maxMessageSize;
        this._maxUnprocessedMessageQueueSize = maxUnprocessedMessageQueueSize;
    }
    write(chunk) {
        if (chunk == null || chunk.length === 0) {
            return [];
        }
        this._buffer.append(chunk);
        if (this._buffer.byteLength > this._maxUnprocessedMessageQueueSize) {
            throw Object.assign(new Error('unprocessed message queue size too large!'), { code: 'ERR_MSG_QUEUE_TOO_BIG' });
        }
        const msgs = [];
        while (this._buffer.length !== 0) {
            if (this._headerInfo == null) {
                try {
                    this._headerInfo = this._decodeHeader(this._buffer);
                }
                catch (err) {
                    if (err.code === 'ERR_MSG_TOO_BIG') {
                        throw err;
                    }
                    break; // We haven't received enough data yet
                }
            }
            const { id, type, length, offset } = this._headerInfo;
            const bufferedDataLength = this._buffer.length - offset;
            if (bufferedDataLength < length) {
                break; // not enough data yet
            }
            const msg = {
                id,
                type
            };
            if (type === MessageTypes.NEW_STREAM || type === MessageTypes.MESSAGE_INITIATOR || type === MessageTypes.MESSAGE_RECEIVER) {
                msg.data = this._buffer.sublist(offset, offset + length);
            }
            msgs.push(msg);
            this._buffer.consume(offset + length);
            this._headerInfo = null;
        }
        return msgs;
    }
    /**
     * Attempts to decode the message header from the buffer
     */
    _decodeHeader(data) {
        const { value: h, offset } = readVarInt(data);
        const { value: length, offset: end } = readVarInt(data, offset);
        const type = h & 7;
        // @ts-expect-error h is a number not a CODE
        if (MessageTypeNames[type] == null) {
            throw new Error(`Invalid type received: ${type}`);
        }
        // test message type varint + data length
        if (length > this._maxMessageSize) {
            throw Object.assign(new Error('message size too large!'), { code: 'ERR_MSG_TOO_BIG' });
        }
        // @ts-expect-error h is a number not a CODE
        return { id: h >> 3, type, offset: offset + end, length };
    }
};
const MSB$7 = 0x80;
const REST$7 = 0x7F;
function readVarInt(buf, offset = 0) {
    let res = 0;
    let shift = 0;
    let counter = offset;
    let b;
    const l = buf.length;
    do {
        if (counter >= l || shift > 49) {
            offset = 0;
            throw new RangeError('Could not decode varint');
        }
        b = buf.get(counter++);
        res += shift < 28
            ? (b & REST$7) << shift
            : (b & REST$7) * Math.pow(2, shift);
        shift += 7;
    } while (b >= MSB$7);
    offset = counter - offset;
    return {
        value: res,
        offset
    };
}

function isAsyncIterable$7(thing) {
    return thing[Symbol.asyncIterator] != null;
}
const DEFAULT_BATCH_SIZE = 1024 * 1024;
const DEFAULT_SERIALIZE = (buf, list) => { list.append(buf); };
function batchedBytes(source, options) {
    if (isAsyncIterable$7(source)) {
        return (async function* () {
            let buffer = new Uint8ArrayList();
            let ended = false;
            let deferred = pDefer();
            let size = Number(options?.size ?? DEFAULT_BATCH_SIZE);
            if (isNaN(size) || size === 0 || size < 0) {
                size = DEFAULT_BATCH_SIZE;
            }
            if (size !== Math.round(size)) {
                throw new Error('Batch size must be an integer');
            }
            const yieldAfter = options?.yieldAfter ?? 0;
            const serialize = options?.serialize ?? DEFAULT_SERIALIZE;
            void Promise.resolve().then(async () => {
                try {
                    let timeout;
                    for await (const buf of source) {
                        // @ts-expect-error - if buf is not `Uint8Array | Uint8ArrayList` we cannot use the default serializer
                        serialize(buf, buffer);
                        if (buffer.byteLength >= size) {
                            clearTimeout(timeout);
                            deferred.resolve();
                            continue;
                        }
                        timeout = setTimeout(() => {
                            deferred.resolve();
                        }, yieldAfter);
                    }
                    clearTimeout(timeout);
                    deferred.resolve();
                }
                catch (err) {
                    deferred.reject(err);
                }
                finally {
                    ended = true;
                }
            });
            while (!ended) { // eslint-disable-line no-unmodified-loop-condition
                await deferred.promise;
                deferred = pDefer();
                if (buffer.byteLength > 0) {
                    const b = buffer;
                    buffer = new Uint8ArrayList();
                    yield b.subarray();
                }
            }
        })();
    }
    return (function* () {
        const buffer = new Uint8ArrayList();
        let size = Number(options?.size ?? DEFAULT_BATCH_SIZE);
        if (isNaN(size) || size === 0 || size < 0) {
            size = DEFAULT_BATCH_SIZE;
        }
        if (size !== Math.round(size)) {
            throw new Error('Batch size must be an integer');
        }
        const serialize = options?.serialize ?? DEFAULT_SERIALIZE;
        for (const buf of source) {
            // @ts-expect-error - if buf is not `Uint8Array | Uint8ArrayList` we cannot use the default serializer
            serialize(buf, buffer);
            if (buffer.byteLength >= size) {
                yield buffer.subarray(0, size);
                buffer.consume(size);
            }
        }
        if (buffer.byteLength > 0) {
            yield buffer.subarray();
        }
    })();
}

function allocUnsafe(size) {
    return new Uint8Array(size);
}

const POOL_SIZE = 10 * 1024;
let Encoder$a = class Encoder {
    _pool;
    _poolOffset;
    constructor() {
        this._pool = allocUnsafe(POOL_SIZE);
        this._poolOffset = 0;
    }
    /**
     * Encodes the given message and adds it to the passed list
     */
    write(msg, list) {
        const pool = this._pool;
        let offset = this._poolOffset;
        varint$9.encode(msg.id << 3 | msg.type, pool, offset);
        offset += varint$9.encode.bytes ?? 0;
        if ((msg.type === MessageTypes.NEW_STREAM || msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) && msg.data != null) {
            varint$9.encode(msg.data.length, pool, offset);
        }
        else {
            varint$9.encode(0, pool, offset);
        }
        offset += varint$9.encode.bytes ?? 0;
        const header = pool.subarray(this._poolOffset, offset);
        if (POOL_SIZE - offset < 100) {
            this._pool = allocUnsafe(POOL_SIZE);
            this._poolOffset = 0;
        }
        else {
            this._poolOffset = offset;
        }
        list.append(header);
        if ((msg.type === MessageTypes.NEW_STREAM || msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) && msg.data != null) {
            list.append(msg.data);
        }
    }
};
const encoder = new Encoder$a();
/**
 * Encode and yield one or more messages
 */
async function* encode$s(source, minSendBytes = 0) {
    if (minSendBytes == null || minSendBytes === 0) {
        // just send the messages
        for await (const messages of source) {
            const list = new Uint8ArrayList();
            for (const msg of messages) {
                encoder.write(msg, list);
            }
            yield list.subarray();
        }
        return;
    }
    // batch messages up for sending
    yield* batchedBytes(source, {
        size: minSendBytes,
        serialize: (obj, list) => {
            for (const m of obj) {
                encoder.write(m, list);
            }
        }
    });
}

const ERR_STREAM_RESET = 'ERR_STREAM_RESET';
const ERR_SINK_INVALID_STATE = 'ERR_SINK_INVALID_STATE';
function isPromise$1(res) {
    return res != null && typeof res.then === 'function';
}
class AbstractStream {
    id;
    direction;
    timeline;
    protocol;
    metadata;
    source;
    status;
    readStatus;
    writeStatus;
    sinkController;
    sinkEnd;
    endErr;
    streamSource;
    onEnd;
    onCloseRead;
    onCloseWrite;
    onReset;
    onAbort;
    log;
    constructor(init) {
        this.sinkController = new AbortController();
        this.sinkEnd = pDefer();
        this.log = init.log;
        // stream status
        this.status = 'open';
        this.readStatus = 'ready';
        this.writeStatus = 'ready';
        this.id = init.id;
        this.metadata = init.metadata ?? {};
        this.direction = init.direction;
        this.timeline = {
            open: Date.now()
        };
        this.onEnd = init.onEnd;
        this.onCloseRead = init?.onCloseRead;
        this.onCloseWrite = init?.onCloseWrite;
        this.onReset = init?.onReset;
        this.onAbort = init?.onAbort;
        this.source = this.streamSource = pushable({
            onEnd: (err) => {
                if (err != null) {
                    this.log.trace('source ended with error', err);
                }
                else {
                    this.log.trace('source ended');
                }
                this.readStatus = 'closed';
                this.onSourceEnd(err);
            }
        });
        // necessary because the libp2p upgrader wraps the sink function
        this.sink = this.sink.bind(this);
    }
    async sink(source) {
        if (this.writeStatus !== 'ready') {
            throw new CodeError$3(`writable end state is "${this.writeStatus}" not "ready"`, ERR_SINK_INVALID_STATE);
        }
        try {
            this.writeStatus = 'writing';
            const options = {
                signal: this.sinkController.signal
            };
            if (this.direction === 'outbound') { // If initiator, open a new stream
                const res = this.sendNewStream(options);
                if (isPromise$1(res)) {
                    await res;
                }
            }
            source = abortableSource(source, this.sinkController.signal, {
                returnOnAbort: true
            });
            this.log.trace('sink reading from source');
            for await (let data of source) {
                data = data instanceof Uint8Array ? new Uint8ArrayList(data) : data;
                const res = this.sendData(data, options);
                if (isPromise$1(res)) { // eslint-disable-line max-depth
                    await res;
                }
            }
            this.log.trace('sink finished reading from source');
            this.writeStatus = 'done';
            this.log.trace('sink calling closeWrite');
            await this.closeWrite(options);
            this.onSinkEnd();
        }
        catch (err) {
            this.log.trace('sink ended with error, calling abort with error', err);
            this.abort(err);
            throw err;
        }
        finally {
            this.log.trace('resolve sink end');
            this.sinkEnd.resolve();
        }
    }
    onSourceEnd(err) {
        if (this.timeline.closeRead != null) {
            return;
        }
        this.timeline.closeRead = Date.now();
        if (err != null && this.endErr == null) {
            this.endErr = err;
        }
        this.onCloseRead?.();
        if (this.timeline.closeWrite != null) {
            this.log.trace('source and sink ended');
            this.timeline.close = Date.now();
            if (this.onEnd != null) {
                this.onEnd(this.endErr);
            }
        }
        else {
            this.log.trace('source ended, waiting for sink to end');
        }
    }
    onSinkEnd(err) {
        if (this.timeline.closeWrite != null) {
            return;
        }
        this.timeline.closeWrite = Date.now();
        if (err != null && this.endErr == null) {
            this.endErr = err;
        }
        this.onCloseWrite?.();
        if (this.timeline.closeRead != null) {
            this.log.trace('sink and source ended');
            this.timeline.close = Date.now();
            if (this.onEnd != null) {
                this.onEnd(this.endErr);
            }
        }
        else {
            this.log.trace('sink ended, waiting for source to end');
        }
    }
    // Close for both Reading and Writing
    async close(options) {
        this.log.trace('closing gracefully');
        this.status = 'closing';
        await Promise.all([
            this.closeRead(options),
            this.closeWrite(options)
        ]);
        this.status = 'closed';
        this.log.trace('closed gracefully');
    }
    async closeRead(options = {}) {
        if (this.readStatus === 'closing' || this.readStatus === 'closed') {
            return;
        }
        this.log.trace('closing readable end of stream with starting read status "%s"', this.readStatus);
        const readStatus = this.readStatus;
        this.readStatus = 'closing';
        if (readStatus === 'ready') {
            this.log.trace('ending internal source queue');
            this.streamSource.end();
        }
        if (this.status !== 'reset' && this.status !== 'aborted' && this.timeline.closeRead == null) {
            this.log.trace('send close read to remote');
            await this.sendCloseRead(options);
        }
        this.log.trace('closed readable end of stream');
    }
    async closeWrite(options = {}) {
        if (this.writeStatus === 'closing' || this.writeStatus === 'closed') {
            return;
        }
        this.log.trace('closing writable end of stream with starting write status "%s"', this.writeStatus);
        const writeStatus = this.writeStatus;
        if (this.writeStatus === 'ready') {
            this.log.trace('sink was never sunk, sink an empty array');
            await this.sink([]);
        }
        this.writeStatus = 'closing';
        if (writeStatus === 'writing') {
            // stop reading from the source passed to `.sink` in the microtask queue
            // - this lets any data queued by the user in the current tick get read
            // before we exit
            await new Promise((resolve, reject) => {
                queueMicrotask(() => {
                    this.log.trace('aborting source passed to .sink');
                    this.sinkController.abort();
                    this.sinkEnd.promise.then(resolve, reject);
                });
            });
        }
        if (this.status !== 'reset' && this.status !== 'aborted' && this.timeline.closeWrite == null) {
            this.log.trace('send close write to remote');
            await this.sendCloseWrite(options);
        }
        this.writeStatus = 'closed';
        this.log.trace('closed writable end of stream');
    }
    /**
     * Close immediately for reading and writing and send a reset message (local
     * error)
     */
    abort(err) {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            return;
        }
        this.log('abort with error', err);
        // try to send a reset message
        this.log('try to send reset to remote');
        const res = this.sendReset();
        if (isPromise$1(res)) {
            res.catch((err) => {
                this.log.error('error sending reset message', err);
            });
        }
        this.status = 'aborted';
        this.timeline.abort = Date.now();
        this._closeSinkAndSource(err);
        this.onAbort?.(err);
    }
    /**
     * Receive a reset message - close immediately for reading and writing (remote
     * error)
     */
    reset() {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            return;
        }
        const err = new CodeError$3('stream reset', ERR_STREAM_RESET);
        this.status = 'reset';
        this._closeSinkAndSource(err);
        this.onReset?.();
    }
    _closeSinkAndSource(err) {
        this._closeSink(err);
        this._closeSource(err);
    }
    _closeSink(err) {
        // if the sink function is running, cause it to end
        if (this.writeStatus === 'writing') {
            this.log.trace('end sink source');
            this.sinkController.abort();
        }
        this.onSinkEnd(err);
    }
    _closeSource(err) {
        // if the source is not ending, end it
        if (this.readStatus !== 'closing' && this.readStatus !== 'closed') {
            this.log.trace('ending source with %d bytes to be read by consumer', this.streamSource.readableLength);
            this.readStatus = 'closing';
            this.streamSource.end(err);
        }
    }
    /**
     * The remote closed for writing so we should expect to receive no more
     * messages
     */
    remoteCloseWrite() {
        if (this.readStatus === 'closing' || this.readStatus === 'closed') {
            this.log('received remote close write but local source is already closed');
            return;
        }
        this.log.trace('remote close write');
        this._closeSource();
    }
    /**
     * The remote closed for reading so we should not send any more
     * messages
     */
    remoteCloseRead() {
        if (this.writeStatus === 'closing' || this.writeStatus === 'closed') {
            this.log('received remote close read but local sink is already closed');
            return;
        }
        this.log.trace('remote close read');
        this._closeSink();
    }
    /**
     * The underlying muxer has closed, no more messages can be sent or will
     * be received, close immediately to free up resources
     */
    destroy() {
        if (this.status === 'closed' || this.status === 'aborted' || this.status === 'reset') {
            this.log('received destroy but we are already closed');
            return;
        }
        this.log.trace('muxer destroyed');
        this._closeSinkAndSource();
    }
    /**
     * When an extending class reads data from it's implementation-specific source,
     * call this method to allow the stream consumer to read the data.
     */
    sourcePush(data) {
        this.streamSource.push(data);
    }
    /**
     * Returns the amount of unread data - can be used to prevent large amounts of
     * data building up when the stream consumer is too slow.
     */
    sourceReadableLength() {
        return this.streamSource.readableLength;
    }
}

class MplexStream extends AbstractStream {
    name;
    streamId;
    send;
    types;
    maxDataSize;
    constructor(init) {
        super(init);
        this.types = init.direction === 'outbound' ? InitiatorMessageTypes : ReceiverMessageTypes;
        this.send = init.send;
        this.name = init.name;
        this.streamId = init.streamId;
        this.maxDataSize = init.maxDataSize;
    }
    async sendNewStream() {
        await this.send({ id: this.streamId, type: InitiatorMessageTypes.NEW_STREAM, data: new Uint8ArrayList(fromString$3(this.name)) });
    }
    async sendData(data) {
        data = data.sublist();
        while (data.byteLength > 0) {
            const toSend = Math.min(data.byteLength, this.maxDataSize);
            await this.send({
                id: this.streamId,
                type: this.types.MESSAGE,
                data: data.sublist(0, toSend)
            });
            data.consume(toSend);
        }
    }
    async sendReset() {
        await this.send({ id: this.streamId, type: this.types.RESET });
    }
    async sendCloseWrite() {
        await this.send({ id: this.streamId, type: this.types.CLOSE });
    }
    async sendCloseRead() {
        // mplex does not support close read, only close write
    }
}
function createStream(options) {
    const { id, name, send, onEnd, type = 'initiator', maxMsgSize = MAX_MSG_SIZE } = options;
    return new MplexStream({
        id: type === 'initiator' ? (`i${id}`) : `r${id}`,
        streamId: id,
        name: `${name == null ? id : name}`,
        direction: type === 'initiator' ? 'outbound' : 'inbound',
        maxDataSize: maxMsgSize,
        onEnd,
        send,
        log: logger$8(`libp2p:mplex:stream:${type}:${id}`)
    });
}

const log$y = logger$8('libp2p:mplex');
const MAX_STREAMS_INBOUND_STREAMS_PER_CONNECTION = 1024;
const MAX_STREAMS_OUTBOUND_STREAMS_PER_CONNECTION = 1024;
const MAX_STREAM_BUFFER_SIZE = 1024 * 1024 * 4; // 4MB
const DISCONNECT_THRESHOLD = 5;
const CLOSE_TIMEOUT$2 = 500;
function printMessage(msg) {
    const output = {
        ...msg,
        type: `${MessageTypeNames[msg.type]} (${msg.type})`
    };
    if (msg.type === MessageTypes.NEW_STREAM) {
        output.data = toString$9(msg.data instanceof Uint8Array ? msg.data : msg.data.subarray());
    }
    if (msg.type === MessageTypes.MESSAGE_INITIATOR || msg.type === MessageTypes.MESSAGE_RECEIVER) {
        output.data = toString$9(msg.data instanceof Uint8Array ? msg.data : msg.data.subarray(), 'base16');
    }
    return output;
}
class MplexStreamMuxer {
    protocol = '/mplex/6.7.0';
    sink;
    source;
    _streamId;
    _streams;
    _init;
    _source;
    closeController;
    rateLimiter;
    closeTimeout;
    constructor(init) {
        init = init ?? {};
        this._streamId = 0;
        this._streams = {
            /**
             * Stream to ids map
             */
            initiators: new Map(),
            /**
             * Stream to ids map
             */
            receivers: new Map()
        };
        this._init = init;
        this.closeTimeout = init.closeTimeout ?? CLOSE_TIMEOUT$2;
        /**
         * An iterable sink
         */
        this.sink = this._createSink();
        /**
         * An iterable source
         */
        this._source = pushableV({
            objectMode: true,
            onEnd: () => {
                // the source has ended, we can't write any more messages to gracefully
                // close streams so all we can do is destroy them
                for (const stream of this._streams.initiators.values()) {
                    stream.destroy();
                }
                for (const stream of this._streams.receivers.values()) {
                    stream.destroy();
                }
            }
        });
        this.source = pipe(this._source, source => encode$s(source, this._init.minSendBytes));
        /**
         * Close controller
         */
        this.closeController = new AbortController();
        this.rateLimiter = new rateLimiterFlexible$1.RateLimiterMemory({
            points: init.disconnectThreshold ?? DISCONNECT_THRESHOLD,
            duration: 1
        });
    }
    /**
     * Returns a Map of streams and their ids
     */
    get streams() {
        // Inbound and Outbound streams may have the same ids, so we need to make those unique
        const streams = [];
        for (const stream of this._streams.initiators.values()) {
            streams.push(stream);
        }
        for (const stream of this._streams.receivers.values()) {
            streams.push(stream);
        }
        return streams;
    }
    /**
     * Initiate a new stream with the given name. If no name is
     * provided, the id of the stream will be used.
     */
    newStream(name) {
        if (this.closeController.signal.aborted) {
            throw new Error('Muxer already closed');
        }
        const id = this._streamId++;
        name = name == null ? id.toString() : name.toString();
        const registry = this._streams.initiators;
        return this._newStream({ id, name, type: 'initiator', registry });
    }
    /**
     * Close or abort all tracked streams and stop the muxer
     */
    async close(options) {
        if (this.closeController.signal.aborted) {
            return;
        }
        const signal = options?.signal ?? AbortSignal.timeout(this.closeTimeout);
        try {
            // try to gracefully close all streams
            await Promise.all(this.streams.map(async (s) => s.close({
                signal
            })));
            this._source.end();
            // try to gracefully close the muxer
            await this._source.onEmpty({
                signal
            });
            this.closeController.abort();
        }
        catch (err) {
            this.abort(err);
        }
    }
    abort(err) {
        if (this.closeController.signal.aborted) {
            return;
        }
        this.streams.forEach(s => { s.abort(err); });
        this.closeController.abort(err);
    }
    /**
     * Called whenever an inbound stream is created
     */
    _newReceiverStream(options) {
        const { id, name } = options;
        const registry = this._streams.receivers;
        return this._newStream({ id, name, type: 'receiver', registry });
    }
    _newStream(options) {
        const { id, name, type, registry } = options;
        log$y('new %s stream %s', type, id);
        if (type === 'initiator' && this._streams.initiators.size === (this._init.maxOutboundStreams ?? MAX_STREAMS_OUTBOUND_STREAMS_PER_CONNECTION)) {
            throw new CodeError$3('Too many outbound streams open', 'ERR_TOO_MANY_OUTBOUND_STREAMS');
        }
        if (registry.has(id)) {
            throw new Error(`${type} stream ${id} already exists!`);
        }
        const send = async (msg) => {
            if (log$y.enabled) {
                log$y.trace('%s stream %s send', type, id, printMessage(msg));
            }
            this._source.push(msg);
        };
        const onEnd = () => {
            log$y('%s stream with id %s and protocol %s ended', type, id, stream.protocol);
            registry.delete(id);
            if (this._init.onStreamEnd != null) {
                this._init.onStreamEnd(stream);
            }
        };
        const stream = createStream({ id, name, send, type, onEnd, maxMsgSize: this._init.maxMsgSize });
        registry.set(id, stream);
        return stream;
    }
    /**
     * Creates a sink with an abortable source. Incoming messages will
     * also have their size restricted. All messages will be varint decoded.
     */
    _createSink() {
        const sink = async (source) => {
            try {
                source = abortableSource(source, this.closeController.signal, {
                    returnOnAbort: true
                });
                const decoder = new Decoder$a(this._init.maxMsgSize, this._init.maxUnprocessedMessageQueueSize);
                for await (const chunk of source) {
                    for (const msg of decoder.write(chunk)) {
                        await this._handleIncoming(msg);
                    }
                }
                this._source.end();
            }
            catch (err) {
                log$y('error in sink', err);
                this._source.end(err); // End the source with an error
            }
        };
        return sink;
    }
    async _handleIncoming(message) {
        const { id, type } = message;
        if (log$y.enabled) {
            log$y.trace('incoming message', printMessage(message));
        }
        // Create a new stream?
        if (message.type === MessageTypes.NEW_STREAM) {
            if (this._streams.receivers.size === (this._init.maxInboundStreams ?? MAX_STREAMS_INBOUND_STREAMS_PER_CONNECTION)) {
                log$y('too many inbound streams open');
                // not going to allow this stream, send the reset message manually
                // instead of setting it up just to tear it down
                this._source.push({
                    id,
                    type: MessageTypes.RESET_RECEIVER
                });
                // if we've hit our stream limit, and the remote keeps trying to open
                // more new streams, if they are doing this very quickly maybe they
                // are attacking us and we should close the connection
                try {
                    await this.rateLimiter.consume('new-stream', 1);
                }
                catch {
                    log$y('rate limit hit when opening too many new streams over the inbound stream limit - closing remote connection');
                    // since there's no backpressure in mplex, the only thing we can really do to protect ourselves is close the connection
                    this.abort(new Error('Too many open streams'));
                    return;
                }
                return;
            }
            const stream = this._newReceiverStream({ id, name: toString$9(message.data instanceof Uint8Array ? message.data : message.data.subarray()) });
            if (this._init.onIncomingStream != null) {
                this._init.onIncomingStream(stream);
            }
            return;
        }
        const list = (type & 1) === 1 ? this._streams.initiators : this._streams.receivers;
        const stream = list.get(id);
        if (stream == null) {
            log$y('missing stream %s for message type %s', id, MessageTypeNames[type]);
            // if the remote keeps sending us messages for streams that have been
            // closed or were never opened they may be attacking us so if they do
            // this very quickly all we can do is close the connection
            try {
                await this.rateLimiter.consume('missing-stream', 1);
            }
            catch {
                log$y('rate limit hit when receiving messages for streams that do not exist - closing remote connection');
                // since there's no backpressure in mplex, the only thing we can really do to protect ourselves is close the connection
                this.abort(new Error('Too many messages for missing streams'));
                return;
            }
            return;
        }
        const maxBufferSize = this._init.maxStreamBufferSize ?? MAX_STREAM_BUFFER_SIZE;
        try {
            switch (type) {
                case MessageTypes.MESSAGE_INITIATOR:
                case MessageTypes.MESSAGE_RECEIVER:
                    if (stream.sourceReadableLength() > maxBufferSize) {
                        // Stream buffer has got too large, reset the stream
                        this._source.push({
                            id: message.id,
                            type: type === MessageTypes.MESSAGE_INITIATOR ? MessageTypes.RESET_RECEIVER : MessageTypes.RESET_INITIATOR
                        });
                        // Inform the stream consumer they are not fast enough
                        throw new CodeError$3('Input buffer full - increase Mplex maxBufferSize to accommodate slow consumers', 'ERR_STREAM_INPUT_BUFFER_FULL');
                    }
                    // We got data from the remote, push it into our local stream
                    stream.sourcePush(message.data);
                    break;
                case MessageTypes.CLOSE_INITIATOR:
                case MessageTypes.CLOSE_RECEIVER:
                    // The remote has stopped writing, so we can stop reading
                    stream.remoteCloseWrite();
                    break;
                case MessageTypes.RESET_INITIATOR:
                case MessageTypes.RESET_RECEIVER:
                    // The remote has errored, stop reading and writing to the stream immediately
                    stream.reset();
                    break;
                default:
                    log$y('unknown message type %s', type);
            }
        }
        catch (err) {
            log$y.error('error while processing message', err);
            stream.abort(err);
        }
    }
}

class Mplex {
    protocol = '/mplex/6.7.0';
    _init;
    constructor(init = {}) {
        this._init = init;
    }
    createStreamMuxer(init = {}) {
        return new MplexStreamMuxer({
            ...init,
            ...this._init
        });
    }
}
function mplex(init = {}) {
    return () => new Mplex(init);
}

const symbol$2 = Symbol.for('@libp2p/transport');
/**
 * Enum Transport Manager Fault Tolerance values
 */
var FaultTolerance;
(function (FaultTolerance) {
    /**
     * should be used for failing in any listen circumstance
     */
    FaultTolerance[FaultTolerance["FATAL_ALL"] = 0] = "FATAL_ALL";
    /**
     * should be used for not failing when not listening
     */
    FaultTolerance[FaultTolerance["NO_FATAL"] = 1] = "NO_FATAL";
})(FaultTolerance || (FaultTolerance = {}));

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$a (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$9 = base$a;

var _brrp__multiformats_scope_baseX$9 = src$9;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$9 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$9 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$9 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$a(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$9 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$a(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$a = (left, right) => new ComposedDecoder$9(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$9 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$9(name, prefix, baseEncode);
    this.decoder = new Decoder$9(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$g = ({ name, prefix, encode, decode }) =>
  new Codec$9(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$9 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$9(alphabet, name);
  return from$g({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$9(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$m = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$r = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$9 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$g({
    prefix,
    name,
    encode (input) {
      return encode$r(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$m(input, alphabet, bitsPerChar, name)
    }
  })
};

const base32$9 = rfc4648$9({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

rfc4648$9({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

rfc4648$9({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

rfc4648$9({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

rfc4648$9({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

rfc4648$9({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

rfc4648$9({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

rfc4648$9({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

rfc4648$9({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

const base58btc$8 = baseX$9({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$9({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

// @ts-check


const base64$9 = rfc4648$9({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$9({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$9({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$9({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc$8.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$9.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64$9.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
debug.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger$5(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
function logger$7(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger$5(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (debug.enabled(`${name}:trace`) && debug.names.map(r => r.toString()).find(n => n.includes(':trace')) != null) {
        trace = debug(`${name}:trace`);
    }
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace
    });
}

const isV4 = isIPv4;
const isV6 = isIPv6;
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7
// but with buf/offset args removed because we don't use them
const toBytes = function (ip) {
    let offset = 0;
    ip = ip.toString().trim();
    if (isV4(ip)) {
        const bytes = new Uint8Array(offset + 4);
        ip.split(/\./g).forEach((byte) => {
            bytes[offset++] = parseInt(byte, 10) & 0xff;
        });
        return bytes;
    }
    if (isV6(ip)) {
        const sections = ip.split(':', 8);
        let i;
        for (i = 0; i < sections.length; i++) {
            const isv4 = isV4(sections[i]);
            let v4Buffer;
            if (isv4) {
                v4Buffer = toBytes(sections[i]);
                sections[i] = toString$9(v4Buffer.slice(0, 2), 'base16');
            }
            if (v4Buffer != null && ++i < 8) {
                sections.splice(i, 0, toString$9(v4Buffer.slice(2, 4), 'base16'));
            }
        }
        if (sections[0] === '') {
            while (sections.length < 8)
                sections.unshift('0');
        }
        else if (sections[sections.length - 1] === '') {
            while (sections.length < 8)
                sections.push('0');
        }
        else if (sections.length < 8) {
            for (i = 0; i < sections.length && sections[i] !== ''; i++)
                ;
            const argv = [i, 1];
            for (i = 9 - sections.length; i > 0; i--) {
                argv.push('0');
            }
            sections.splice.apply(sections, argv);
        }
        const bytes = new Uint8Array(offset + 16);
        for (i = 0; i < sections.length; i++) {
            const word = parseInt(sections[i], 16);
            bytes[offset++] = (word >> 8) & 0xff;
            bytes[offset++] = word & 0xff;
        }
        return bytes;
    }
    throw new Error('invalid ip address');
};
// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L63
const toString$6 = function (buf, offset = 0, length) {
    offset = ~~offset;
    length = length ?? (buf.length - offset);
    const view = new DataView(buf.buffer);
    if (length === 4) {
        const result = [];
        // IPv4
        for (let i = 0; i < length; i++) {
            result.push(buf[offset + i]);
        }
        return result.join('.');
    }
    if (length === 16) {
        const result = [];
        // IPv6
        for (let i = 0; i < length; i += 2) {
            result.push(view.getUint16(offset + i).toString(16));
        }
        return result.join(':')
            .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')
            .replace(/:{3,4}/, '::');
    }
    return '';
};

const V = -1;
const names = {};
const codes$4 = {};
const table = [
    [4, 32, 'ip4'],
    [6, 16, 'tcp'],
    [33, 16, 'dccp'],
    [41, 128, 'ip6'],
    [42, V, 'ip6zone'],
    [43, 8, 'ipcidr'],
    [53, V, 'dns', true],
    [54, V, 'dns4', true],
    [55, V, 'dns6', true],
    [56, V, 'dnsaddr', true],
    [132, 16, 'sctp'],
    [273, 16, 'udp'],
    [275, 0, 'p2p-webrtc-star'],
    [276, 0, 'p2p-webrtc-direct'],
    [277, 0, 'p2p-stardust'],
    [280, 0, 'webrtc'],
    [281, 0, 'webrtc-w3c'],
    [290, 0, 'p2p-circuit'],
    [301, 0, 'udt'],
    [302, 0, 'utp'],
    [400, V, 'unix', false, true],
    // `ipfs` is added before `p2p` for legacy support.
    // All text representations will default to `p2p`, but `ipfs` will
    // still be supported
    [421, V, 'ipfs'],
    // `p2p` is the preferred name for 421, and is now the default
    [421, V, 'p2p'],
    [443, 0, 'https'],
    [444, 96, 'onion'],
    [445, 296, 'onion3'],
    [446, V, 'garlic64'],
    [448, 0, 'tls'],
    [449, V, 'sni'],
    [460, 0, 'quic'],
    [461, 0, 'quic-v1'],
    [465, 0, 'webtransport'],
    [466, V, 'certhash'],
    [477, 0, 'ws'],
    [478, 0, 'wss'],
    [479, 0, 'p2p-websocket-star'],
    [480, 0, 'http'],
    [777, V, 'memory']
];
// populate tables
table.forEach(row => {
    const proto = createProtocol(...row);
    codes$4[proto.code] = proto;
    names[proto.name] = proto;
});
function createProtocol(code, size, name, resolvable, path) {
    return {
        code,
        size,
        name,
        resolvable: Boolean(resolvable),
        path: Boolean(path)
    };
}
/**
 * For the passed proto string or number, return a {@link Protocol}
 *
 * @example
 *
 * ```js
 * import { protocol } from '@multiformats/multiaddr'
 *
 * console.info(protocol(4))
 * // { code: 4, size: 32, name: 'ip4', resolvable: false, path: false }
 * ```
 */
function getProtocol(proto) {
    if (typeof proto === 'number') {
        if (codes$4[proto] != null) {
            return codes$4[proto];
        }
        throw new Error(`no protocol with code: ${proto}`);
    }
    else if (typeof proto === 'string') {
        if (names[proto] != null) {
            return names[proto];
        }
        throw new Error(`no protocol with name: ${proto}`);
    }
    throw new Error(`invalid protocol id type: ${typeof proto}`);
}

var encode_1$5 = encode$q;

var MSB$6 = 0x80
  , REST$6 = 0x7F
  , MSBALL$5 = ~REST$6
  , INT$5 = Math.pow(2, 31);

function encode$q(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$5) {
    out[offset++] = (num & 0xFF) | MSB$6;
    num /= 128;
  }
  while(num & MSBALL$5) {
    out[offset++] = (num & 0xFF) | MSB$6;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$q.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$l = read$6;

var MSB$1$5 = 0x80
  , REST$1$5 = 0x7F;

function read$6(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$6.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$5) << shift
      : (b & REST$1$5) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$5)

  read$6.bytes = counter - offset;

  return res
}

var N1$5 = Math.pow(2,  7);
var N2$5 = Math.pow(2, 14);
var N3$5 = Math.pow(2, 21);
var N4$5 = Math.pow(2, 28);
var N5$5 = Math.pow(2, 35);
var N6$5 = Math.pow(2, 42);
var N7$5 = Math.pow(2, 49);
var N8$5 = Math.pow(2, 56);
var N9$5 = Math.pow(2, 63);

var length$5 = function (value) {
  return (
    value < N1$5 ? 1
  : value < N2$5 ? 2
  : value < N3$5 ? 3
  : value < N4$5 ? 4
  : value < N5$5 ? 5
  : value < N6$5 ? 6
  : value < N7$5 ? 7
  : value < N8$5 ? 8
  : value < N9$5 ? 9
  :              10
  )
};

var varint$5 = {
    encode: encode_1$5
  , decode: decode$l
  , encodingLength: length$5
};

var _brrp_varint$5 = varint$5;

/**
 * @param {Uint8Array} data
 * @param {number} [offset=0]
 * @returns {[number, number]}
 */
const decode$k = (data, offset = 0) => {
  const code = _brrp_varint$5.decode(data, offset);
  return [code, _brrp_varint$5.decode.bytes]
};

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo$5 = (int, target, offset = 0) => {
  _brrp_varint$5.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$7 = (int) => {
  return _brrp_varint$5.encodingLength(int)
};

/**
 * @param {Uint8Array} aa
 * @param {Uint8Array} bb
 */
const equals$1 = (aa, bb) => {
  if (aa === bb) return true
  if (aa.byteLength !== bb.byteLength) {
    return false
  }

  for (let ii = 0; ii < aa.byteLength; ii++) {
    if (aa[ii] !== bb[ii]) {
      return false
    }
  }

  return true
};

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$8 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
const fromString$1 = str => (new TextEncoder()).encode(str);

/**
 * @param {Uint8Array} b
 * @returns {string}
 */
const toString$5 = b => (new TextDecoder()).decode(b);

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$b = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$7(code);
  const digestOffset = sizeOffset + encodingLength$7(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo$5(code, bytes, 0);
  encodeTo$5(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest$5(code, size, digest, bytes)
};

/**
 * Turns bytes representation of multihash digest into an instance.
 *
 * @param {Uint8Array} multihash
 * @returns {MultihashDigest}
 */
const decode$j = (multihash) => {
  const bytes = coerce$8(multihash);
  const [code, sizeOffset] = decode$k(bytes);
  const [size, digestOffset] = decode$k(bytes.subarray(sizeOffset));
  const digest = bytes.subarray(sizeOffset + digestOffset);

  if (digest.byteLength !== size) {
    throw new Error('Incorrect length')
  }

  return new Digest$5(code, size, digest, bytes)
};

/**
 * @param {MultihashDigest} a
 * @param {unknown} b
 * @returns {b is MultihashDigest}
 */
const equals = (a, b) => {
  if (a === b) {
    return true
  } else {
    const data = /** @type {{code?:unknown, size?:unknown, bytes?:unknown}} */(b);

    return (
      a.code === data.code &&
      a.size === data.size &&
      data.bytes instanceof Uint8Array &&
      equals$1(a.bytes, data.bytes)
    )
  }
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
let Digest$5 = class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
};

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$9 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$8 = base$9;

var _brrp__multiformats_scope_baseX$8 = src$8;

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$8 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$8 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$9(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$8 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$9(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$9 = (left, right) => new ComposedDecoder$8(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$8 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$8(name, prefix, baseEncode);
    this.decoder = new Decoder$8(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$f = ({ name, prefix, encode, decode }) =>
  new Codec$8(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$8 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$8(alphabet, name);
  return from$f({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$8(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$i = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$p = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$8 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$f({
    prefix,
    name,
    encode (input) {
      return encode$p(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$i(input, alphabet, bitsPerChar, name)
    }
  })
};

const base58btc$7 = baseX$8({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

const base58flickr = baseX$8({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var base58 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base58btc: base58btc$7,
    base58flickr: base58flickr
});

const base32$7 = rfc4648$8({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

const base32upper = rfc4648$8({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

const base32pad = rfc4648$8({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

const base32padupper = rfc4648$8({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

const base32hex = rfc4648$8({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

const base32hexupper = rfc4648$8({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

const base32hexpad = rfc4648$8({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

const base32hexpadupper = rfc4648$8({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

const base32z = rfc4648$8({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

var base32$8 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base32: base32$7,
    base32hex: base32hex,
    base32hexpad: base32hexpad,
    base32hexpadupper: base32hexpadupper,
    base32hexupper: base32hexupper,
    base32pad: base32pad,
    base32padupper: base32padupper,
    base32upper: base32upper,
    base32z: base32z
});

/**
 * @template {API.Link<unknown, number, number, API.Version>} T
 * @template {string} Prefix
 * @param {T} link
 * @param {API.MultibaseEncoder<Prefix>} [base]
 * @returns {API.ToString<T, Prefix>}
 */
const format$3 = (link, base) => {
  const { bytes, version } = link;
  switch (version) {
    case 0:
      return toStringV0(
        bytes,
        baseCache(link),
        /** @type {API.MultibaseEncoder<"z">} */ (base) || base58btc$7.encoder
      )
    default:
      return toStringV1(
        bytes,
        baseCache(link),
        /** @type {API.MultibaseEncoder<Prefix>} */ (base || base32$7.encoder)
      )
  }
};

/** @type {WeakMap<API.UnknownLink, Map<string, string>>} */
const cache$1 = new WeakMap();

/**
 * @param {API.UnknownLink} cid
 * @returns {Map<string, string>}
 */
const baseCache = cid => {
  const baseCache = cache$1.get(cid);
  if (baseCache == null) {
    const baseCache = new Map();
    cache$1.set(cid, baseCache);
    return baseCache
  }
  return baseCache
};

/**
 * @template {unknown} [Data=unknown]
 * @template {number} [Format=number]
 * @template {number} [Alg=number]
 * @template {API.Version} [Version=API.Version]
 * @implements {API.Link<Data, Format, Alg, Version>}
 */

class CID {
  /**
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} multihash - (Multi)hash of the of the content.
   * @param {Uint8Array} bytes
   *
   */
  constructor (version, code, multihash, bytes) {
    /** @readonly */
    this.code = code;
    /** @readonly */
    this.version = version;
    /** @readonly */
    this.multihash = multihash;
    /** @readonly */
    this.bytes = bytes;

    // flag to serializers that this is a CID and
    // should be treated specially
    /** @readonly */
    this['/'] = bytes;
  }

  /**
   * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`
   * please either use `CID.asCID(cid)` or switch to new signalling mechanism
   *
   * @deprecated
   */
  get asCID () {
    return this
  }

  // ArrayBufferView
  get byteOffset () {
    return this.bytes.byteOffset
  }

  // ArrayBufferView
  get byteLength () {
    return this.bytes.byteLength
  }

  /**
   * @returns {CID<Data, API.DAG_PB, API.SHA_256, 0>}
   */
  toV0 () {
    switch (this.version) {
      case 0: {
        return /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */ (this)
      }
      case 1: {
        const { code, multihash } = this;

        if (code !== DAG_PB_CODE) {
          throw new Error('Cannot convert a non dag-pb CID to CIDv0')
        }

        // sha2-256
        if (multihash.code !== SHA_256_CODE) {
          throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0')
        }

        return /** @type {CID<Data, API.DAG_PB, API.SHA_256, 0>} */ (
          CID.createV0(
            /** @type {API.MultihashDigest<API.SHA_256>} */ (multihash)
          )
        )
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 0. This is a bug please report`
        )
      }
    }
  }

  /**
   * @returns {CID<Data, Format, Alg, 1>}
   */
  toV1 () {
    switch (this.version) {
      case 0: {
        const { code, digest } = this.multihash;
        const multihash = create$b(code, digest);
        return /** @type {CID<Data, Format, Alg, 1>} */ (
          CID.createV1(this.code, multihash)
        )
      }
      case 1: {
        return /** @type {CID<Data, Format, Alg, 1>} */ (this)
      }
      default: {
        throw Error(
          `Can not convert CID version ${this.version} to version 1. This is a bug please report`
        )
      }
    }
  }

  /**
   * @param {unknown} other
   * @returns {other is CID<Data, Format, Alg, Version>}
   */
  equals (other) {
    return CID.equals(this, other)
  }

  /**
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {API.Link<Data, Format, Alg, Version>} self
   * @param {unknown} other
   * @returns {other is CID}
   */
  static equals (self, other) {
    const unknown =
      /** @type {{code?:unknown, version?:unknown, multihash?:unknown}} */ (
        other
      );
    return (
      unknown &&
      self.code === unknown.code &&
      self.version === unknown.version &&
      equals(self.multihash, unknown.multihash)
    )
  }

  /**
   * @param {API.MultibaseEncoder<string>} [base]
   * @returns {string}
   */
  toString (base) {
    return format$3(this, base)
  }

  toJSON () {
    return { '/': format$3(this) }
  }

  link () {
    return this
  }

  get [Symbol.toStringTag] () {
    return 'CID'
  }

  // Legacy

  [Symbol.for('nodejs.util.inspect.custom')] () {
    return `CID(${this.toString()})`
  }

  /**
   * Takes any input `value` and returns a `CID` instance if it was
   * a `CID` otherwise returns `null`. If `value` is instanceof `CID`
   * it will return value back. If `value` is not instance of this CID
   * class, but is compatible CID it will return new instance of this
   * `CID` class. Otherwise returns null.
   *
   * This allows two different incompatible versions of CID library to
   * co-exist and interop as long as binary interface is compatible.
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @template {unknown} U
   * @param {API.Link<Data, Format, Alg, Version>|U} input
   * @returns {CID<Data, Format, Alg, Version>|null}
   */
  static asCID (input) {
    if (input == null) {
      return null
    }

    const value = /** @type {any} */ (input);
    if (value instanceof CID) {
      // If value is instance of CID then we're all set.
      return value
    } else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {
      // If value isn't instance of this CID class but `this.asCID === this` or
      // `value['/'] === value.bytes` is true it is CID instance coming from a
      // different implementation (diff version or duplicate). In that case we
      // rebase it to this `CID` implementation so caller is guaranteed to get
      // instance with expected API.
      const { version, code, multihash, bytes } = value;
      return new CID(
        version,
        code,
        /** @type {API.MultihashDigest<Alg>} */ (multihash),
        bytes || encodeCID(version, code, multihash.bytes)
      )
    } else if (value[cidSymbol] === true) {
      // If value is a CID from older implementation that used to be tagged via
      // symbol we still rebase it to the this `CID` implementation by
      // delegating that to a constructor.
      const { version, multihash, code } = value;
      const digest =
        /** @type {API.MultihashDigest<Alg>} */
        (decode$j(multihash));
      return CID.create(version, code, digest)
    } else {
      // Otherwise value is not a CID (or an incompatible version of it) in
      // which case we return `null`.
      return null
    }
  }

  /**
   *
   * @template {unknown} Data
   * @template {number} Format
   * @template {number} Alg
   * @template {API.Version} Version
   * @param {Version} version - Version of the CID
   * @param {Format} code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv
   * @param {API.MultihashDigest<Alg>} digest - (Multi)hash of the of the content.
   * @returns {CID<Data, Format, Alg, Version>}
   */
  static create (version, code, digest) {
    if (typeof code !== 'number') {
      throw new Error('String codecs are no longer supported')
    }

    if (!(digest.bytes instanceof Uint8Array)) {
      throw new Error('Invalid digest')
    }

    switch (version) {
      case 0: {
        if (code !== DAG_PB_CODE) {
          throw new Error(
            `Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`
          )
        } else {
          return new CID(version, code, digest, digest.bytes)
        }
      }
      case 1: {
        const bytes = encodeCID(version, code, digest.bytes);
        return new CID(version, code, digest, bytes)
      }
      default: {
        throw new Error('Invalid version')
      }
    }
  }

  /**
   * Simplified version of `create` for CIDv0.
   *
   * @template {unknown} [T=unknown]
   * @param {API.MultihashDigest<typeof SHA_256_CODE>} digest - Multihash.
   * @returns {CID<T, typeof DAG_PB_CODE, typeof SHA_256_CODE, 0>}
   */
  static createV0 (digest) {
    return CID.create(0, DAG_PB_CODE, digest)
  }

  /**
   * Simplified version of `create` for CIDv1.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @param {Code} code - Content encoding format code.
   * @param {API.MultihashDigest<Alg>} digest - Miltihash of the content.
   * @returns {CID<Data, Code, Alg, 1>}
   */
  static createV1 (code, digest) {
    return CID.create(1, code, digest)
  }

  /**
   * Decoded a CID from its binary representation. The byte array must contain
   * only the CID with no additional bytes.
   *
   * An error will be thrown if the bytes provided do not contain a valid
   * binary representation of a CID.
   *
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ByteView<API.Link<Data, Code, Alg, Ver>>} bytes
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static decode (bytes) {
    const [cid, remainder] = CID.decodeFirst(bytes);
    if (remainder.length) {
      throw new Error('Incorrect length')
    }
    return cid
  }

  /**
   * Decoded a CID from its binary representation at the beginning of a byte
   * array.
   *
   * Returns an array with the first element containing the CID and the second
   * element containing the remainder of the original byte array. The remainder
   * will be a zero-length byte array if the provided bytes only contained a
   * binary CID representation.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} bytes
   * @returns {[CID<T, C, A, V>, Uint8Array]}
   */
  static decodeFirst (bytes) {
    const specs = CID.inspectBytes(bytes);
    const prefixSize = specs.size - specs.multihashSize;
    const multihashBytes = coerce$8(
      bytes.subarray(prefixSize, prefixSize + specs.multihashSize)
    );
    if (multihashBytes.byteLength !== specs.multihashSize) {
      throw new Error('Incorrect length')
    }
    const digestBytes = multihashBytes.subarray(
      specs.multihashSize - specs.digestSize
    );
    const digest = new Digest$5(
      specs.multihashCode,
      specs.digestSize,
      digestBytes,
      multihashBytes
    );
    const cid =
      specs.version === 0
        ? CID.createV0(/** @type {API.MultihashDigest<API.SHA_256>} */ (digest))
        : CID.createV1(specs.codec, digest);
    return [/** @type {CID<T, C, A, V>} */(cid), bytes.subarray(specs.size)]
  }

  /**
   * Inspect the initial bytes of a CID to determine its properties.
   *
   * Involves decoding up to 4 varints. Typically this will require only 4 to 6
   * bytes but for larger multicodec code values and larger multihash digest
   * lengths these varints can be quite large. It is recommended that at least
   * 10 bytes be made available in the `initialBytes` argument for a complete
   * inspection.
   *
   * @template {unknown} T
   * @template {number} C
   * @template {number} A
   * @template {API.Version} V
   * @param {API.ByteView<API.Link<T, C, A, V>>} initialBytes
   * @returns {{ version:V, codec:C, multihashCode:A, digestSize:number, multihashSize:number, size:number }}
   */
  static inspectBytes (initialBytes) {
    let offset = 0;
    const next = () => {
      const [i, length] = decode$k(initialBytes.subarray(offset));
      offset += length;
      return i
    };

    let version = /** @type {V} */ (next());
    let codec = /** @type {C} */ (DAG_PB_CODE);
    if (/** @type {number} */(version) === 18) {
      // CIDv0
      version = /** @type {V} */ (0);
      offset = 0;
    } else {
      codec = /** @type {C} */ (next());
    }

    if (version !== 0 && version !== 1) {
      throw new RangeError(`Invalid CID version ${version}`)
    }

    const prefixSize = offset;
    const multihashCode = /** @type {A} */ (next()); // multihash code
    const digestSize = next(); // multihash length
    const size = offset + digestSize;
    const multihashSize = size - prefixSize;

    return { version, codec, multihashCode, digestSize, multihashSize, size }
  }

  /**
   * Takes cid in a string representation and creates an instance. If `base`
   * decoder is not provided will use a default from the configuration. It will
   * throw an error if encoding of the CID is not compatible with supplied (or
   * a default decoder).
   *
   * @template {string} Prefix
   * @template {unknown} Data
   * @template {number} Code
   * @template {number} Alg
   * @template {API.Version} Ver
   * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
   * @param {API.MultibaseDecoder<Prefix>} [base]
   * @returns {CID<Data, Code, Alg, Ver>}
   */
  static parse (source, base) {
    const [prefix, bytes] = parseCIDtoBytes(source, base);

    const cid = CID.decode(bytes);

    if (cid.version === 0 && source[0] !== 'Q') {
      throw Error('Version 0 CID string must not include multibase prefix')
    }

    // Cache string representation to avoid computing it on `this.toString()`
    baseCache(cid).set(prefix, source);

    return cid
  }
}

/**
 * @template {string} Prefix
 * @template {unknown} Data
 * @template {number} Code
 * @template {number} Alg
 * @template {API.Version} Ver
 * @param {API.ToString<API.Link<Data, Code, Alg, Ver>, Prefix>} source
 * @param {API.MultibaseDecoder<Prefix>} [base]
 * @returns {[Prefix, API.ByteView<API.Link<Data, Code, Alg, Ver>>]}
 */
const parseCIDtoBytes = (source, base) => {
  switch (source[0]) {
    // CIDv0 is parsed differently
    case 'Q': {
      const decoder = base || base58btc$7;
      return [
        /** @type {Prefix} */ (base58btc$7.prefix),
        decoder.decode(`${base58btc$7.prefix}${source}`)
      ]
    }
    case base58btc$7.prefix: {
      const decoder = base || base58btc$7;
      return [/** @type {Prefix} */(base58btc$7.prefix), decoder.decode(source)]
    }
    case base32$7.prefix: {
      const decoder = base || base32$7;
      return [/** @type {Prefix} */(base32$7.prefix), decoder.decode(source)]
    }
    default: {
      if (base == null) {
        throw Error(
          'To parse non base32 or base58btc encoded CID multibase decoder must be provided'
        )
      }
      return [/** @type {Prefix} */(source[0]), base.decode(source)]
    }
  }
};

/**
 *
 * @param {Uint8Array} bytes
 * @param {Map<string, string>} cache
 * @param {API.MultibaseEncoder<'z'>} base
 */
const toStringV0 = (bytes, cache, base) => {
  const { prefix } = base;
  if (prefix !== base58btc$7.prefix) {
    throw Error(`Cannot string encode V0 in ${base.name} encoding`)
  }

  const cid = cache.get(prefix);
  if (cid == null) {
    const cid = base.encode(bytes).slice(1);
    cache.set(prefix, cid);
    return cid
  } else {
    return cid
  }
};

/**
 * @template {string} Prefix
 * @param {Uint8Array} bytes
 * @param {Map<string, string>} cache
 * @param {API.MultibaseEncoder<Prefix>} base
 */
const toStringV1 = (bytes, cache, base) => {
  const { prefix } = base;
  const cid = cache.get(prefix);
  if (cid == null) {
    const cid = base.encode(bytes);
    cache.set(prefix, cid);
    return cid
  } else {
    return cid
  }
};

const DAG_PB_CODE = 0x70;
const SHA_256_CODE = 0x12;

/**
 * @param {API.Version} version
 * @param {number} code
 * @param {Uint8Array} multihash
 * @returns {Uint8Array}
 */
const encodeCID = (version, code, multihash) => {
  const codeOffset = encodingLength$7(version);
  const hashOffset = codeOffset + encodingLength$7(code);
  const bytes = new Uint8Array(hashOffset + multihash.byteLength);
  encodeTo$5(version, bytes, 0);
  encodeTo$5(code, bytes, codeOffset);
  bytes.set(multihash, hashOffset);
  return bytes
};

const cidSymbol = Symbol.for('@ipld/js-cid/CID');

// @ts-check


const identity$6 = from$f({
  prefix: '\x00',
  name: 'identity',
  encode: (buf) => toString$5(buf),
  decode: (str) => fromString$1(str)
});

var identityBase = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identity: identity$6
});

// @ts-check


const base2 = rfc4648$8({
  prefix: '0',
  name: 'base2',
  alphabet: '01',
  bitsPerChar: 1
});

var base2$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base2: base2
});

// @ts-check


const base8 = rfc4648$8({
  prefix: '7',
  name: 'base8',
  alphabet: '01234567',
  bitsPerChar: 3
});

var base8$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base8: base8
});

const base10 = baseX$8({
  prefix: '9',
  name: 'base10',
  alphabet: '0123456789'
});

var base10$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base10: base10
});

// @ts-check


const base16 = rfc4648$8({
  prefix: 'f',
  name: 'base16',
  alphabet: '0123456789abcdef',
  bitsPerChar: 4
});

const base16upper = rfc4648$8({
  prefix: 'F',
  name: 'base16upper',
  alphabet: '0123456789ABCDEF',
  bitsPerChar: 4
});

var base16$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base16: base16,
    base16upper: base16upper
});

const base36 = baseX$8({
  prefix: 'k',
  name: 'base36',
  alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'
});

const base36upper = baseX$8({
  prefix: 'K',
  name: 'base36upper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
});

var base36$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base36: base36,
    base36upper: base36upper
});

// @ts-check


const base64$7 = rfc4648$8({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

const base64pad = rfc4648$8({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

const base64url = rfc4648$8({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

const base64urlpad = rfc4648$8({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

var base64$8 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base64: base64$7,
    base64pad: base64pad,
    base64url: base64url,
    base64urlpad: base64urlpad
});

const alphabet = Array.from('🚀🪐☄🛰🌌🌑🌒🌓🌔🌕🌖🌗🌘🌍🌏🌎🐉☀💻🖥💾💿😂❤😍🤣😊🙏💕😭😘👍😅👏😁🔥🥰💔💖💙😢🤔😆🙄💪😉☺👌🤗💜😔😎😇🌹🤦🎉💞✌✨🤷😱😌🌸🙌😋💗💚😏💛🙂💓🤩😄😀🖤😃💯🙈👇🎶😒🤭❣😜💋👀😪😑💥🙋😞😩😡🤪👊🥳😥🤤👉💃😳✋😚😝😴🌟😬🙃🍀🌷😻😓⭐✅🥺🌈😈🤘💦✔😣🏃💐☹🎊💘😠☝😕🌺🎂🌻😐🖕💝🙊😹🗣💫💀👑🎵🤞😛🔴😤🌼😫⚽🤙☕🏆🤫👈😮🙆🍻🍃🐶💁😲🌿🧡🎁⚡🌞🎈❌✊👋😰🤨😶🤝🚶💰🍓💢🤟🙁🚨💨🤬✈🎀🍺🤓😙💟🌱😖👶🥴▶➡❓💎💸⬇😨🌚🦋😷🕺⚠🙅😟😵👎🤲🤠🤧📌🔵💅🧐🐾🍒😗🤑🌊🤯🐷☎💧😯💆👆🎤🙇🍑❄🌴💣🐸💌📍🥀🤢👅💡💩👐📸👻🤐🤮🎼🥵🚩🍎🍊👼💍📣🥂');
const alphabetBytesToChars = /** @type {string[]} */ (alphabet.reduce((p, c, i) => { p[i] = c; return p }, /** @type {string[]} */([])));
const alphabetCharsToBytes = /** @type {number[]} */ (alphabet.reduce((p, c, i) => { p[/** @type {number} */ (c.codePointAt(0))] = i; return p }, /** @type {number[]} */([])));

/**
 * @param {Uint8Array} data
 * @returns {string}
 */
function encode$o (data) {
  return data.reduce((p, c) => {
    p += alphabetBytesToChars[c];
    return p
  }, '')
}

/**
 * @param {string} str
 * @returns {Uint8Array}
 */
function decode$h (str) {
  const byts = [];
  for (const char of str) {
    const byt = alphabetCharsToBytes[/** @type {number} */ (char.codePointAt(0))];
    if (byt === undefined) {
      throw new Error(`Non-base256emoji character: ${char}`)
    }
    byts.push(byt);
  }
  return new Uint8Array(byts)
}

const base256emoji = from$f({
  prefix: '🚀',
  name: 'base256emoji',
  encode: encode$o,
  decode: decode$h
});

var base256emoji$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    base256emoji: base256emoji
});

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$e = ({ name, code, encode }) => new Hasher$5(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
let Hasher$5 = class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$b(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$b(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
};

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */


/**
 * @param {AlgorithmIdentifier} name
 */
const sha$5 = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256$6 = from$e({
  name: 'sha2-256',
  code: 0x12,
  encode: sha$5('SHA-256')
});

const code$5 = 0x0;
const name$6 = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$n = coerce$8;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest$5 = (input) => create$b(code$5, encode$n(input));

const identity$5 = { code: code$5, name: name$6, encode: encode$n, digest: digest$5 };

// @ts-check

/**
 * @template T
 * @typedef {import('./interface.js').ByteView<T>} ByteView
 */

new TextEncoder();
new TextDecoder();

// @ts-check


const bases = { ...identityBase, ...base2$1, ...base8$1, ...base10$1, ...base16$1, ...base32$8, ...base36$1, ...base58, ...base64$8, ...base256emoji$1 };

/**
 * @packageDocumentation
 *
 * Provides methods for converting
 */
/**
 * Convert [code,Uint8Array] to string
 */
function convertToString(proto, buf) {
    const protocol = getProtocol(proto);
    switch (protocol.code) {
        case 4: // ipv4
        case 41: // ipv6
            return bytes2ip(buf);
        case 42: // ipv6zone
            return bytes2str(buf);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return bytes2port(buf).toString();
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return bytes2str(buf);
        case 421: // ipfs
            return bytes2mh(buf);
        case 444: // onion
            return bytes2onion(buf);
        case 445: // onion3
            return bytes2onion(buf);
        case 466: // certhash
            return bytes2mb(buf);
        default:
            return toString$9(buf, 'base16'); // no clue. convert to hex
    }
}
function convertToBytes(proto, str) {
    const protocol = getProtocol(proto);
    switch (protocol.code) {
        case 4: // ipv4
            return ip2bytes(str);
        case 41: // ipv6
            return ip2bytes(str);
        case 42: // ipv6zone
            return str2bytes(str);
        case 6: // tcp
        case 273: // udp
        case 33: // dccp
        case 132: // sctp
            return port2bytes(parseInt(str, 10));
        case 53: // dns
        case 54: // dns4
        case 55: // dns6
        case 56: // dnsaddr
        case 400: // unix
        case 449: // sni
        case 777: // memory
            return str2bytes(str);
        case 421: // ipfs
            return mh2bytes(str);
        case 444: // onion
            return onion2bytes(str);
        case 445: // onion3
            return onion32bytes(str);
        case 466: // certhash
            return mb2bytes(str);
        default:
            return fromString$3(str, 'base16'); // no clue. convert from hex
    }
}
const decoders = Object.values(bases).map((c) => c.decoder);
const anybaseDecoder = (function () {
    let acc = decoders[0].or(decoders[1]);
    decoders.slice(2).forEach((d) => (acc = acc.or(d)));
    return acc;
})();
function ip2bytes(ipString) {
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return toBytes(ipString);
}
function bytes2ip(ipBuff) {
    const ipString = toString$6(ipBuff, 0, ipBuff.length);
    if (ipString == null) {
        throw new Error('ipBuff is required');
    }
    if (!isIP(ipString)) {
        throw new Error('invalid ip address');
    }
    return ipString;
}
function port2bytes(port) {
    const buf = new ArrayBuffer(2);
    const view = new DataView(buf);
    view.setUint16(0, port);
    return new Uint8Array(buf);
}
function bytes2port(buf) {
    const view = new DataView(buf.buffer);
    return view.getUint16(buf.byteOffset);
}
function str2bytes(str) {
    const buf = fromString$3(str);
    const size = Uint8Array.from(varint$9.encode(buf.length));
    return concat$1([size, buf], size.length + buf.length);
}
function bytes2str(buf) {
    const size = varint$9.decode(buf);
    buf = buf.slice(varint$9.decode.bytes);
    if (buf.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$9(buf);
}
function mh2bytes(hash) {
    let mh;
    if (hash[0] === 'Q' || hash[0] === '1') {
        mh = decode$j(base58btc$7.decode(`z${hash}`)).bytes;
    }
    else {
        mh = CID.parse(hash).multihash.bytes;
    }
    // the address is a varint prefixed multihash string representation
    const size = Uint8Array.from(varint$9.encode(mh.length));
    return concat$1([size, mh], size.length + mh.length);
}
function mb2bytes(mbstr) {
    const mb = anybaseDecoder.decode(mbstr);
    const size = Uint8Array.from(varint$9.encode(mb.length));
    return concat$1([size, mb], size.length + mb.length);
}
function bytes2mb(buf) {
    const size = varint$9.decode(buf);
    const hash = buf.slice(varint$9.decode.bytes);
    if (hash.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return 'u' + toString$9(hash, 'base64url');
}
/**
 * Converts bytes to bas58btc string
 */
function bytes2mh(buf) {
    const size = varint$9.decode(buf);
    const address = buf.slice(varint$9.decode.bytes);
    if (address.length !== size) {
        throw new Error('inconsistent lengths');
    }
    return toString$9(address, 'base58btc');
}
function onion2bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 16) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$7.decode('b' + addr[0]);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat$1([buf, portBuf], buf.length + portBuf.length);
}
function onion32bytes(str) {
    const addr = str.split(':');
    if (addr.length !== 2) {
        throw new Error(`failed to parse onion addr: ["'${addr.join('", "')}'"]' does not contain a port number`);
    }
    if (addr[0].length !== 56) {
        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion3 address.`);
    }
    // onion addresses do not include the multibase prefix, add it before decoding
    const buf = base32$7.decode(`b${addr[0]}`);
    // onion port number
    const port = parseInt(addr[1], 10);
    if (port < 1 || port > 65536) {
        throw new Error('Port number is not in range(1, 65536)');
    }
    const portBuf = port2bytes(port);
    return concat$1([buf, portBuf], buf.length + portBuf.length);
}
function bytes2onion(buf) {
    const addrBytes = buf.slice(0, buf.length - 2);
    const portBytes = buf.slice(buf.length - 2);
    const addr = toString$9(addrBytes, 'base32');
    const port = bytes2port(portBytes);
    return `${addr}:${port}`;
}

/**
 * string -> [[str name, str addr]... ]
 */
function stringToStringTuples(str) {
    const tuples = [];
    const parts = str.split('/').slice(1); // skip first empty elem
    if (parts.length === 1 && parts[0] === '') {
        return [];
    }
    for (let p = 0; p < parts.length; p++) {
        const part = parts[p];
        const proto = getProtocol(part);
        if (proto.size === 0) {
            tuples.push([part]);
            // eslint-disable-next-line no-continue
            continue;
        }
        p++; // advance addr part
        if (p >= parts.length) {
            throw ParseError('invalid address: ' + str);
        }
        // if it's a path proto, take the rest
        if (proto.path === true) {
            tuples.push([
                part,
                // should we need to check each path part to see if it's a proto?
                // This would allow for other protocols to be added after a unix path,
                // however it would have issues if the path had a protocol name in the path
                cleanPath(parts.slice(p).join('/'))
            ]);
            break;
        }
        tuples.push([part, parts[p]]);
    }
    return tuples;
}
/**
 * [[str name, str addr]... ] -> string
 */
function stringTuplesToString(tuples) {
    const parts = [];
    tuples.map((tup) => {
        const proto = protoFromTuple(tup);
        parts.push(proto.name);
        if (tup.length > 1 && tup[1] != null) {
            parts.push(tup[1]);
        }
        return null;
    });
    return cleanPath(parts.join('/'));
}
/**
 * [[str name, str addr]... ] -> [[int code, Uint8Array]... ]
 */
function stringTuplesToTuples(tuples) {
    return tuples.map((tup) => {
        if (!Array.isArray(tup)) {
            tup = [tup];
        }
        const proto = protoFromTuple(tup);
        if (tup.length > 1) {
            return [proto.code, convertToBytes(proto.code, tup[1])];
        }
        return [proto.code];
    });
}
/**
 * Convert tuples to string tuples
 *
 * [[int code, Uint8Array]... ] -> [[int code, str addr]... ]
 */
function tuplesToStringTuples(tuples) {
    return tuples.map(tup => {
        const proto = protoFromTuple(tup);
        if (tup[1] != null) {
            return [proto.code, convertToString(proto.code, tup[1])];
        }
        return [proto.code];
    });
}
/**
 * [[int code, Uint8Array ]... ] -> Uint8Array
 */
function tuplesToBytes(tuples) {
    return fromBytes(concat$1(tuples.map((tup) => {
        const proto = protoFromTuple(tup);
        let buf = Uint8Array.from(varint$9.encode(proto.code));
        if (tup.length > 1 && tup[1] != null) {
            buf = concat$1([buf, tup[1]]); // add address buffer
        }
        return buf;
    })));
}
/**
 * For the passed address, return the serialized size
 */
function sizeForAddr(p, addr) {
    if (p.size > 0) {
        return p.size / 8;
    }
    else if (p.size === 0) {
        return 0;
    }
    else {
        const size = varint$9.decode(addr);
        return size + (varint$9.decode.bytes ?? 0);
    }
}
function bytesToTuples(buf) {
    const tuples = [];
    let i = 0;
    while (i < buf.length) {
        const code = varint$9.decode(buf, i);
        const n = varint$9.decode.bytes ?? 0;
        const p = getProtocol(code);
        const size = sizeForAddr(p, buf.slice(i + n));
        if (size === 0) {
            tuples.push([code]);
            i += n;
            // eslint-disable-next-line no-continue
            continue;
        }
        const addr = buf.slice(i + n, i + n + size);
        i += (size + n);
        if (i > buf.length) { // did not end _exactly_ at buffer.length
            throw ParseError('Invalid address Uint8Array: ' + toString$9(buf, 'base16'));
        }
        // ok, tuple seems good.
        tuples.push([code, addr]);
    }
    return tuples;
}
/**
 * Uint8Array -> String
 */
function bytesToString(buf) {
    const a = bytesToTuples(buf);
    const b = tuplesToStringTuples(a);
    return stringTuplesToString(b);
}
/**
 * String -> Uint8Array
 */
function stringToBytes(str) {
    str = cleanPath(str);
    const a = stringToStringTuples(str);
    const b = stringTuplesToTuples(a);
    return tuplesToBytes(b);
}
/**
 * String -> Uint8Array
 */
function fromString(str) {
    return stringToBytes(str);
}
/**
 * Uint8Array -> Uint8Array
 */
function fromBytes(buf) {
    const err = validateBytes(buf);
    if (err != null) {
        throw err;
    }
    return Uint8Array.from(buf); // copy
}
function validateBytes(buf) {
    try {
        bytesToTuples(buf); // try to parse. will throw if breaks
    }
    catch (err) {
        return err;
    }
}
function cleanPath(str) {
    return '/' + str.trim().split('/').filter((a) => a).join('/');
}
function ParseError(str) {
    return new Error('Error parsing address: ' + str);
}
function protoFromTuple(tup) {
    const proto = getProtocol(tup[0]);
    return proto;
}

/**
 * @packageDocumentation
 *
 * An implementation of a Multiaddr in JavaScript
 *
 * @example
 *
 * ```js
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const ma = multiaddr('/ip4/127.0.0.1/tcp/1234')
 * ```
 */
var __classPrivateFieldGet$2 = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var __classPrivateFieldSet$1 = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return (kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;
};
var _DefaultMultiaddr_string, _DefaultMultiaddr_tuples, _DefaultMultiaddr_stringTuples, _a;
const inspect = Symbol.for('nodejs.util.inspect.custom');
const DNS_CODES = [
    getProtocol('dns').code,
    getProtocol('dns4').code,
    getProtocol('dns6').code,
    getProtocol('dnsaddr').code
];
/**
 * All configured {@link Resolver}s
 */
const resolvers$1 = new Map();
const symbol$1 = Symbol.for('@multiformats/js-multiaddr/multiaddr');
/**
 * Check if object is a {@link Multiaddr} instance
 *
 * @example
 *
 * ```js
 * import { isMultiaddr, multiaddr } from '@multiformats/multiaddr'
 *
 * isMultiaddr(5)
 * // false
 * isMultiaddr(multiaddr('/ip4/127.0.0.1'))
 * // true
 * ```
 */
function isMultiaddr(value) {
    return Boolean(value?.[symbol$1]);
}
/**
 * Creates a {@link Multiaddr} from a {@link MultiaddrInput}
 */
class DefaultMultiaddr {
    constructor(addr) {
        _DefaultMultiaddr_string.set(this, void 0);
        _DefaultMultiaddr_tuples.set(this, void 0);
        _DefaultMultiaddr_stringTuples.set(this, void 0);
        this[_a] = true;
        // default
        if (addr == null) {
            addr = '';
        }
        if (addr instanceof Uint8Array) {
            this.bytes = fromBytes(addr);
        }
        else if (typeof addr === 'string') {
            if (addr.length > 0 && addr.charAt(0) !== '/') {
                throw new Error(`multiaddr "${addr}" must start with a "/"`);
            }
            this.bytes = fromString(addr);
        }
        else if (isMultiaddr(addr)) { // Multiaddr
            this.bytes = fromBytes(addr.bytes); // validate + copy buffer
        }
        else {
            throw new Error('addr must be a string, Buffer, or another Multiaddr');
        }
    }
    toString() {
        if (__classPrivateFieldGet$2(this, _DefaultMultiaddr_string, "f") == null) {
            __classPrivateFieldSet$1(this, _DefaultMultiaddr_string, bytesToString(this.bytes), "f");
        }
        return __classPrivateFieldGet$2(this, _DefaultMultiaddr_string, "f");
    }
    toJSON() {
        return this.toString();
    }
    toOptions() {
        let family;
        let transport;
        let host;
        let port;
        let zone = '';
        const tcp = getProtocol('tcp');
        const udp = getProtocol('udp');
        const ip4 = getProtocol('ip4');
        const ip6 = getProtocol('ip6');
        const dns6 = getProtocol('dns6');
        const ip6zone = getProtocol('ip6zone');
        for (const [code, value] of this.stringTuples()) {
            if (code === ip6zone.code) {
                zone = `%${value ?? ''}`;
            }
            // default to https when protocol & port are omitted from DNS addrs
            if (DNS_CODES.includes(code)) {
                transport = tcp.name;
                port = 443;
                host = `${value ?? ''}${zone}`;
                family = code === dns6.code ? 6 : 4;
            }
            if (code === tcp.code || code === udp.code) {
                transport = getProtocol(code).name;
                port = parseInt(value ?? '');
            }
            if (code === ip4.code || code === ip6.code) {
                transport = getProtocol(code).name;
                host = `${value ?? ''}${zone}`;
                family = code === ip6.code ? 6 : 4;
            }
        }
        if (family == null || transport == null || host == null || port == null) {
            throw new Error('multiaddr must have a valid format: "/{ip4, ip6, dns4, dns6, dnsaddr}/{address}/{tcp, udp}/{port}".');
        }
        const opts = {
            family,
            host,
            transport,
            port
        };
        return opts;
    }
    protos() {
        return this.protoCodes().map(code => Object.assign({}, getProtocol(code)));
    }
    protoCodes() {
        const codes = [];
        const buf = this.bytes;
        let i = 0;
        while (i < buf.length) {
            const code = varint$9.decode(buf, i);
            const n = varint$9.decode.bytes ?? 0;
            const p = getProtocol(code);
            const size = sizeForAddr(p, buf.slice(i + n));
            i += (size + n);
            codes.push(code);
        }
        return codes;
    }
    protoNames() {
        return this.protos().map(proto => proto.name);
    }
    tuples() {
        if (__classPrivateFieldGet$2(this, _DefaultMultiaddr_tuples, "f") == null) {
            __classPrivateFieldSet$1(this, _DefaultMultiaddr_tuples, bytesToTuples(this.bytes), "f");
        }
        return __classPrivateFieldGet$2(this, _DefaultMultiaddr_tuples, "f");
    }
    stringTuples() {
        if (__classPrivateFieldGet$2(this, _DefaultMultiaddr_stringTuples, "f") == null) {
            __classPrivateFieldSet$1(this, _DefaultMultiaddr_stringTuples, tuplesToStringTuples(this.tuples()), "f");
        }
        return __classPrivateFieldGet$2(this, _DefaultMultiaddr_stringTuples, "f");
    }
    encapsulate(addr) {
        addr = new DefaultMultiaddr(addr);
        return new DefaultMultiaddr(this.toString() + addr.toString());
    }
    decapsulate(addr) {
        const addrString = addr.toString();
        const s = this.toString();
        const i = s.lastIndexOf(addrString);
        if (i < 0) {
            throw new Error(`Address ${this.toString()} does not contain subaddress: ${addr.toString()}`);
        }
        return new DefaultMultiaddr(s.slice(0, i));
    }
    decapsulateCode(code) {
        const tuples = this.tuples();
        for (let i = tuples.length - 1; i >= 0; i--) {
            if (tuples[i][0] === code) {
                return new DefaultMultiaddr(tuplesToBytes(tuples.slice(0, i)));
            }
        }
        return this;
    }
    getPeerId() {
        try {
            const tuples = this.stringTuples().filter((tuple) => {
                if (tuple[0] === names.ipfs.code) {
                    return true;
                }
                return false;
            });
            // Get the last ipfs tuple ['ipfs', 'peerid string']
            const tuple = tuples.pop();
            if (tuple?.[1] != null) {
                const peerIdStr = tuple[1];
                // peer id is base58btc encoded string but not multibase encoded so add the `z`
                // prefix so we can validate that it is correctly encoded
                if (peerIdStr[0] === 'Q' || peerIdStr[0] === '1') {
                    return toString$9(base58btc$7.decode(`z${peerIdStr}`), 'base58btc');
                }
                // try to parse peer id as CID
                return toString$9(CID.parse(peerIdStr).multihash.bytes, 'base58btc');
            }
            return null;
        }
        catch (e) {
            return null;
        }
    }
    getPath() {
        let path = null;
        try {
            path = this.stringTuples().filter((tuple) => {
                const proto = getProtocol(tuple[0]);
                if (proto.path === true) {
                    return true;
                }
                return false;
            })[0][1];
            if (path == null) {
                path = null;
            }
        }
        catch {
            path = null;
        }
        return path;
    }
    equals(addr) {
        return equals$4(this.bytes, addr.bytes);
    }
    async resolve(options) {
        const resolvableProto = this.protos().find((p) => p.resolvable);
        // Multiaddr is not resolvable?
        if (resolvableProto == null) {
            return [this];
        }
        const resolver = resolvers$1.get(resolvableProto.name);
        if (resolver == null) {
            throw errCode$1(new Error(`no available resolver for ${resolvableProto.name}`), 'ERR_NO_AVAILABLE_RESOLVER');
        }
        const addresses = await resolver(this, options);
        return addresses.map((a) => new DefaultMultiaddr(a));
    }
    nodeAddress() {
        const options = this.toOptions();
        if (options.transport !== 'tcp' && options.transport !== 'udp') {
            throw new Error(`multiaddr must have a valid format - no protocol with name: "${options.transport}". Must have a valid transport protocol: "{tcp, udp}"`);
        }
        return {
            family: options.family,
            address: options.host,
            port: options.port
        };
    }
    isThinWaistAddress(addr) {
        const protos = (addr ?? this).protos();
        if (protos.length !== 2) {
            return false;
        }
        if (protos[0].code !== 4 && protos[0].code !== 41) {
            return false;
        }
        if (protos[1].code !== 6 && protos[1].code !== 273) {
            return false;
        }
        return true;
    }
    /**
     * Returns Multiaddr as a human-readable string
     * https://nodejs.org/api/util.html#utilinspectcustom
     *
     * @example
     * ```js
     * import { multiaddr } from '@multiformats/multiaddr'
     *
     * console.info(multiaddr('/ip4/127.0.0.1/tcp/4001'))
     * // 'Multiaddr(/ip4/127.0.0.1/tcp/4001)'
     * ```
     */
    [(_DefaultMultiaddr_string = new WeakMap(), _DefaultMultiaddr_tuples = new WeakMap(), _DefaultMultiaddr_stringTuples = new WeakMap(), _a = symbol$1, inspect)]() {
        return `Multiaddr(${bytesToString(this.bytes)})`;
    }
}
/**
 * A function that takes a {@link MultiaddrInput} and returns a {@link Multiaddr}
 *
 * @example
 * ```js
 * import { multiaddr } from '@libp2p/multiaddr'
 *
 * multiaddr('/ip4/127.0.0.1/tcp/4001')
 * // Multiaddr(/ip4/127.0.0.1/tcp/4001)
 * ```
 *
 * @param {MultiaddrInput} [addr] - If String or Uint8Array, needs to adhere to the address format of a [multiaddr](https://github.com/multiformats/multiaddr#string-format)
 */
function multiaddr(addr) {
    return new DefaultMultiaddr(addr);
}

const reduceValue = (_, v) => v;
const tcpUri = (str, port, parts, opts) => {
    // return tcp when explicitly requested
    if ((opts != null) && opts.assumeHttp === false)
        return `tcp://${str}:${port}`;
    // check if tcp is the last protocol in multiaddr
    let protocol = 'tcp';
    let explicitPort = `:${port}`;
    const last = parts[parts.length - 1];
    if (last.protocol === 'tcp') {
        // assume http and produce clean urls
        protocol = port === '443' ? 'https' : 'http';
        explicitPort = port === '443' || port === '80' ? '' : explicitPort;
    }
    return `${protocol}://${str}${explicitPort}`;
};
const Reducers = {
    ip4: reduceValue,
    ip6: (str, content, i, parts) => (parts.length === 1 && parts[0].protocol === 'ip6'
        ? content
        : `[${content}]`),
    tcp: (str, content, i, parts, opts) => (parts.some(p => ['http', 'https', 'ws', 'wss'].includes(p.protocol))
        ? `${str}:${content}`
        : tcpUri(str, content, parts, opts)),
    udp: (str, content) => `udp://${str}:${content}`,
    dnsaddr: reduceValue,
    dns4: reduceValue,
    dns6: reduceValue,
    ipfs: (str, content) => `${str}/ipfs/${content}`,
    p2p: (str, content) => `${str}/p2p/${content}`,
    http: str => `http://${str}`,
    https: str => `https://${str}`,
    ws: str => `ws://${str}`,
    wss: str => `wss://${str}`,
    'p2p-websocket-star': str => `${str}/p2p-websocket-star`,
    'p2p-webrtc-star': str => `${str}/p2p-webrtc-star`,
    'p2p-webrtc-direct': str => `${str}/p2p-webrtc-direct`
};
function multiaddrToUri(input, opts) {
    const ma = multiaddr(input);
    const parts = ma.toString().split('/').slice(1);
    return ma
        .tuples()
        .map(tuple => ({
        protocol: parts.shift() ?? '',
        content: (tuple[1] != null) ? parts.shift() ?? '' : ''
    }))
        .reduce((str, part, i, parts) => {
        const reduce = Reducers[part.protocol];
        if (reduce == null) {
            throw new Error(`Unsupported protocol ${part.protocol}`);
        }
        return reduce(str, part.content, i, parts, opts);
    }, '');
}

var ready = async (socket) => {
    // if the socket is closing or closed, return end
    if (socket.readyState >= 2) {
        throw new Error('socket closed');
    }
    // if open, return
    if (socket.readyState === 1) {
        return;
    }
    await new Promise((resolve, reject) => {
        function cleanup() {
            socket.removeEventListener('open', handleOpen);
            socket.removeEventListener('error', handleErr);
        }
        function handleOpen() {
            cleanup();
            resolve();
        }
        function handleErr(event) {
            cleanup();
            reject(event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`));
        }
        socket.addEventListener('open', handleOpen);
        socket.addEventListener('error', handleErr);
    });
};

var sink = (socket, options) => {
    options = options ?? {};
    options.closeOnEnd = options.closeOnEnd !== false;
    const sink = async (source) => {
        for await (const data of source) {
            try {
                await ready(socket);
            }
            catch (err) {
                if (err.message === 'socket closed')
                    break;
                throw err;
            }
            // the ready promise resolved without error but the socket was closing so
            // exit the loop and don't send data
            if (socket.readyState === socket.CLOSING || socket.readyState === socket.CLOSED) {
                break;
            }
            socket.send(data);
        }
        if (options.closeOnEnd != null && socket.readyState <= 1) {
            await new Promise((resolve, reject) => {
                socket.addEventListener('close', event => {
                    if (event.wasClean || event.code === 1006) {
                        resolve();
                    }
                    else {
                        const err = Object.assign(new Error('ws error'), { event });
                        reject(err);
                    }
                });
                setTimeout(() => { socket.close(); });
            });
        }
    };
    return sink;
};

var dom = {};

var eventIterator = {};

Object.defineProperty(eventIterator, "__esModule", { value: true });
class EventQueue {
    constructor() {
        this.pullQueue = [];
        this.pushQueue = [];
        this.eventHandlers = {};
        this.isPaused = false;
        this.isStopped = false;
    }
    push(value) {
        if (this.isStopped)
            return;
        const resolution = { value, done: false };
        if (this.pullQueue.length) {
            const placeholder = this.pullQueue.shift();
            if (placeholder)
                placeholder.resolve(resolution);
        }
        else {
            this.pushQueue.push(Promise.resolve(resolution));
            if (this.highWaterMark !== undefined &&
                this.pushQueue.length >= this.highWaterMark &&
                !this.isPaused) {
                this.isPaused = true;
                if (this.eventHandlers.highWater) {
                    this.eventHandlers.highWater();
                }
                else if (console) {
                    console.warn(`EventIterator queue reached ${this.pushQueue.length} items`);
                }
            }
        }
    }
    stop() {
        if (this.isStopped)
            return;
        this.isStopped = true;
        this.remove();
        for (const placeholder of this.pullQueue) {
            placeholder.resolve({ value: undefined, done: true });
        }
        this.pullQueue.length = 0;
    }
    fail(error) {
        if (this.isStopped)
            return;
        this.isStopped = true;
        this.remove();
        if (this.pullQueue.length) {
            for (const placeholder of this.pullQueue) {
                placeholder.reject(error);
            }
            this.pullQueue.length = 0;
        }
        else {
            const rejection = Promise.reject(error);
            /* Attach error handler to avoid leaking an unhandled promise rejection. */
            rejection.catch(() => { });
            this.pushQueue.push(rejection);
        }
    }
    remove() {
        Promise.resolve().then(() => {
            if (this.removeCallback)
                this.removeCallback();
        });
    }
    [Symbol.asyncIterator]() {
        return {
            next: (value) => {
                const result = this.pushQueue.shift();
                if (result) {
                    if (this.lowWaterMark !== undefined &&
                        this.pushQueue.length <= this.lowWaterMark &&
                        this.isPaused) {
                        this.isPaused = false;
                        if (this.eventHandlers.lowWater) {
                            this.eventHandlers.lowWater();
                        }
                    }
                    return result;
                }
                else if (this.isStopped) {
                    return Promise.resolve({ value: undefined, done: true });
                }
                else {
                    return new Promise((resolve, reject) => {
                        this.pullQueue.push({ resolve, reject });
                    });
                }
            },
            return: () => {
                this.isStopped = true;
                this.pushQueue.length = 0;
                this.remove();
                return Promise.resolve({ value: undefined, done: true });
            },
        };
    }
}
let EventIterator$1 = class EventIterator {
    constructor(listen, { highWaterMark = 100, lowWaterMark = 1 } = {}) {
        const queue = new EventQueue();
        queue.highWaterMark = highWaterMark;
        queue.lowWaterMark = lowWaterMark;
        queue.removeCallback =
            listen({
                push: value => queue.push(value),
                stop: () => queue.stop(),
                fail: error => queue.fail(error),
                on: (event, fn) => {
                    queue.eventHandlers[event] = fn;
                },
            }) || (() => { });
        this[Symbol.asyncIterator] = () => queue[Symbol.asyncIterator]();
        Object.freeze(this);
    }
};
eventIterator.EventIterator = EventIterator$1;
eventIterator.default = EventIterator$1;

Object.defineProperty(dom, "__esModule", { value: true });
const event_iterator_1 = eventIterator;
var EventIterator = dom.EventIterator = event_iterator_1.EventIterator;
function subscribe(event, options, evOptions) {
    return new event_iterator_1.EventIterator(({ push }) => {
        this.addEventListener(event, push, options);
        return () => this.removeEventListener(event, push, options);
    }, evOptions);
}
dom.subscribe = subscribe;
dom.default = event_iterator_1.EventIterator;

// copied from github.com/feross/buffer
// Some ArrayBuffers are not passing the instanceof check, so we need to do a bit more work :(
function isArrayBuffer(obj) {
    return (obj instanceof ArrayBuffer) ||
        (obj?.constructor?.name === 'ArrayBuffer' && typeof obj?.byteLength === 'number');
}
var source = (socket) => {
    socket.binaryType = 'arraybuffer';
    const connected = async () => {
        await new Promise((resolve, reject) => {
            if (isConnected) {
                resolve();
                return;
            }
            if (connError != null) {
                reject(connError);
                return;
            }
            const cleanUp = (cont) => {
                socket.removeEventListener('open', onOpen);
                socket.removeEventListener('error', onError);
                cont();
            };
            const onOpen = () => { cleanUp(resolve); };
            const onError = (event) => {
                cleanUp(() => { reject(event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`)); });
            };
            socket.addEventListener('open', onOpen);
            socket.addEventListener('error', onError);
        });
    };
    const source = (async function* () {
        const messages = new EventIterator(({ push, stop, fail }) => {
            const onMessage = (event) => {
                let data = null;
                if (typeof event.data === 'string') {
                    data = fromString$3(event.data);
                }
                if (isArrayBuffer(event.data)) {
                    data = new Uint8Array(event.data);
                }
                if (event.data instanceof Uint8Array) {
                    data = event.data;
                }
                if (data == null) {
                    return;
                }
                push(data);
            };
            const onError = (event) => { fail(event.error ?? new Error('Socket error')); };
            socket.addEventListener('message', onMessage);
            socket.addEventListener('error', onError);
            socket.addEventListener('close', stop);
            return () => {
                socket.removeEventListener('message', onMessage);
                socket.removeEventListener('error', onError);
                socket.removeEventListener('close', stop);
            };
        }, { highWaterMark: Infinity });
        await connected();
        for await (const chunk of messages) {
            yield isArrayBuffer(chunk) ? new Uint8Array(chunk) : chunk;
        }
    }());
    let isConnected = socket.readyState === 1;
    let connError;
    socket.addEventListener('open', () => {
        isConnected = true;
        connError = null;
    });
    socket.addEventListener('close', () => {
        isConnected = false;
        connError = null;
    });
    socket.addEventListener('error', event => {
        if (!isConnected) {
            connError = event.error ?? new Error(`connect ECONNREFUSED ${socket.url}`);
        }
    });
    return Object.assign(source, {
        connected
    });
};

var duplex = (socket, options) => {
    options = options ?? {};
    const connectedSource = source(socket);
    let remoteAddress = options.remoteAddress;
    let remotePort = options.remotePort;
    if (socket.url != null) {
        // only client->server sockets have urls, server->client connections do not
        try {
            const url = new URL(socket.url);
            remoteAddress = url.hostname;
            remotePort = parseInt(url.port, 10);
        }
        catch { }
    }
    if (remoteAddress == null || remotePort == null) {
        throw new Error('Remote connection did not have address and/or port');
    }
    const duplex = {
        sink: sink(socket, options),
        source: connectedSource,
        connected: async () => { await connectedSource.connected(); },
        close: async () => {
            if (socket.readyState === socket.CONNECTING || socket.readyState === socket.OPEN) {
                await new Promise((resolve) => {
                    socket.addEventListener('close', () => {
                        resolve();
                    });
                    socket.close();
                });
            }
        },
        destroy: () => {
            if (socket.terminate != null) {
                socket.terminate();
            }
            else {
                socket.close();
            }
        },
        remoteAddress,
        remotePort,
        socket
    };
    return duplex;
};

/* eslint-env browser */
var WebSocket$1 = WebSocket;

const isReactNative$1 =
    typeof navigator !== 'undefined' &&
    navigator.product === 'ReactNative';

function getDefaultBase () {
  if (isReactNative$1) {
    return 'http://localhost'
  }
  // in some environments i.e. cloudflare workers location is not available
  if (!self.location) {
    return ''
  }

  return self.location.protocol + '//' + self.location.host
}

const URL$2 = self.URL;
const defaultBase$1 = getDefaultBase();

let URLWithLegacySupport$2 = class URLWithLegacySupport {
  constructor (url = '', base = defaultBase$1) {
    this.super = new URL$2(url, base);
    this.path = this.pathname + this.search;
    this.auth =
            this.username && this.password
              ? this.username + ':' + this.password
              : null;

    this.query =
            this.search && this.search.startsWith('?')
              ? this.search.slice(1)
              : null;
  }

  get hash () {
    return this.super.hash
  }

  get host () {
    return this.super.host
  }

  get hostname () {
    return this.super.hostname
  }

  get href () {
    return this.super.href
  }

  get origin () {
    return this.super.origin
  }

  get password () {
    return this.super.password
  }

  get pathname () {
    return this.super.pathname
  }

  get port () {
    return this.super.port
  }

  get protocol () {
    return this.super.protocol
  }

  get search () {
    return this.super.search
  }

  get searchParams () {
    return this.super.searchParams
  }

  get username () {
    return this.super.username
  }

  set hash (hash) {
    this.super.hash = hash;
  }

  set host (host) {
    this.super.host = host;
  }

  set hostname (hostname) {
    this.super.hostname = hostname;
  }

  set href (href) {
    this.super.href = href;
  }

  set password (password) {
    this.super.password = password;
  }

  set pathname (pathname) {
    this.super.pathname = pathname;
  }

  set port (port) {
    this.super.port = port;
  }

  set protocol (protocol) {
    this.super.protocol = protocol;
  }

  set search (search) {
    this.super.search = search;
  }

  set username (username) {
    this.super.username = username;
  }

  /**
   * @param {any} o
   */
  static createObjectURL (o) {
    return URL$2.createObjectURL(o)
  }

  /**
   * @param {string} o
   */
  static revokeObjectURL (o) {
    URL$2.revokeObjectURL(o);
  }

  toJSON () {
    return this.super.toJSON()
  }

  toString () {
    return this.super.toString()
  }

  format () {
    return this.toString()
  }
};

/**
 * @param {string | import('url').UrlObject} obj
 */
function format$2 (obj) {
  if (typeof obj === 'string') {
    const url = new URL$2(obj);

    return url.toString()
  }

  if (!(obj instanceof URL$2)) {
    const userPass =
            // @ts-ignore its not supported in node but we normalise
            obj.username && obj.password
              // @ts-ignore its not supported in node but we normalise
              ? `${obj.username}:${obj.password}@`
              : '';
    const auth = obj.auth ? obj.auth + '@' : '';
    const port = obj.port ? ':' + obj.port : '';
    const protocol = obj.protocol ? obj.protocol + '//' : '';
    const host = obj.host || '';
    const hostname = obj.hostname || '';
    const search = obj.search || (obj.query ? '?' + obj.query : '');
    const hash = obj.hash || '';
    const pathname = obj.pathname || '';
    // @ts-ignore - path is not supported in node but we normalise
    const path = obj.path || pathname + search;

    return `${protocol}${userPass || auth}${
            host || hostname + port
        }${path}${hash}`
  }
}

var urlBrowser = {
  URLWithLegacySupport: URLWithLegacySupport$2,
  URLSearchParams: self.URLSearchParams,
  defaultBase: defaultBase$1,
  format: format$2
};

const { URLWithLegacySupport: URLWithLegacySupport$1, format: format$1 } = urlBrowser;

/**
 * @param {string | undefined} url
 * @param {any} [location]
 * @param {any} [protocolMap]
 * @param {any} [defaultProtocol]
 */
var relative$1 = (url, location = {}, protocolMap = {}, defaultProtocol) => {
  let protocol = location.protocol
    ? location.protocol.replace(':', '')
    : 'http';

  // Check protocol map
  protocol = (protocolMap[protocol] || defaultProtocol || protocol) + ':';
  let urlParsed;

  try {
    urlParsed = new URLWithLegacySupport$1(url);
  } catch (err) {
    urlParsed = {};
  }

  const base = Object.assign({}, location, {
    protocol: protocol || urlParsed.protocol,
    host: location.host || urlParsed.host
  });

  return new URLWithLegacySupport$1(url, format$1(base)).toString()
};

const {
  URLWithLegacySupport,
  format,
  URLSearchParams,
  defaultBase
} = urlBrowser;
const relative = relative$1;

var isoUrl = {
  URL: URLWithLegacySupport,
  URLSearchParams,
  format,
  relative,
  defaultBase
};

const map$1 = { http: 'ws', https: 'wss' };
const def = 'ws';
var wsurl = (url, location) => isoUrl.relative(url, location, map$1, def);

// load websocket library if we are not in the browser
function connect(addr, opts) {
    const location = typeof window === 'undefined' ? '' : window.location;
    opts = opts ?? {};
    const url = wsurl(addr, location.toString());
    const socket = new WebSocket$1(url, opts.websocket);
    return duplex(socket, opts);
}

// https://github.com/electron/electron/issues/2288
function isElectron$1() {
    // Renderer process
    if (typeof window !== 'undefined' && typeof window.process === 'object' && window.process.type === 'renderer') {
        return true;
    }

    // Main process
    if (typeof process !== 'undefined' && typeof process.versions === 'object' && !!process.versions.electron) {
        return true;
    }

    // Detect the user agent when the `nodeIntegration` option is set to false
    if (typeof navigator === 'object' && typeof navigator.userAgent === 'string' && navigator.userAgent.indexOf('Electron') >= 0) {
        return true;
    }

    return false;
}

var isElectron_1 = isElectron$1;

var detectElectron = /*@__PURE__*/getDefaultExportFromCjs(isElectron_1);

const isEnvWithDom = typeof window === 'object' && typeof document === 'object' && document.nodeType === 9;
const isElectron = detectElectron();

/**
 * Detects browser main thread  **NOT** web worker or service worker
 */
const isBrowser = isEnvWithDom && !isElectron;
const isElectronMain = isElectron && !isEnvWithDom;
const isElectronRenderer = isElectron && isEnvWithDom;
const isNode = typeof globalThis.process !== 'undefined' && typeof globalThis.process.release !== 'undefined' && globalThis.process.release.name === 'node' && !isElectron;
// @ts-ignore
// eslint-disable-next-line no-undef
const isWebWorker = typeof importScripts === 'function' && typeof self !== 'undefined' && typeof WorkerGlobalScope !== 'undefined' && self instanceof WorkerGlobalScope;

// defeat bundlers replacing process.env.NODE_ENV with "development" or whatever
typeof globalThis.process !== 'undefined' && typeof globalThis.process.env !== 'undefined' && globalThis.process.env['NODE' + (() => '_')() + 'ENV'] === 'test';
const isReactNative = typeof navigator !== 'undefined' && navigator.product === 'ReactNative';

/*
 * Valid combinations
 */
const DNS4 = base$8('dns4');
const DNS6 = base$8('dns6');
const DNSADDR = base$8('dnsaddr');
const DNS = or$8(base$8('dns'), DNSADDR, DNS4, DNS6);
const IP = or$8(base$8('ip4'), base$8('ip6'));
const TCP = or$8(and(IP, base$8('tcp')), and(DNS, base$8('tcp')));
const _WebSockets = or$8(and(TCP, base$8('ws')), and(DNS, base$8('ws')));
const WebSockets$1 = or$8(and(_WebSockets, base$8('p2p')), _WebSockets);
const _WebSocketsSecure = or$8(and(TCP, base$8('wss')), and(DNS, base$8('wss')), and(TCP, base$8('tls'), base$8('ws')), and(DNS, base$8('tls'), base$8('ws')));
const WebSocketsSecure = or$8(and(_WebSocketsSecure, base$8('p2p')), _WebSocketsSecure);
/*
 * Validation funcs
 */
function makeMatchesFunction(partialMatch) {
    function matches(a) {
        let ma;
        try {
            ma = multiaddr$1(a);
        }
        catch (err) { // catch error
            return false; // also if it's invalid it's probably not matching as well so return false
        }
        const out = partialMatch(ma.protoNames());
        if (out === null) {
            return false;
        }
        if (out === true || out === false) {
            return out;
        }
        return out.length === 0;
    }
    return matches;
}
function and(...args) {
    function partialMatch(a) {
        if (a.length < args.length) {
            return null;
        }
        let out = a;
        args.some((arg) => {
            out = typeof arg === 'function'
                ? arg().partialMatch(a)
                : arg.partialMatch(a);
            if (Array.isArray(out)) {
                a = out;
            }
            if (out === null) {
                return true;
            }
            return false;
        });
        return out;
    }
    return {
        toString: function () { return '{ ' + args.join(' ') + ' }'; },
        input: args,
        matches: makeMatchesFunction(partialMatch),
        partialMatch
    };
}
function or$8(...args) {
    function partialMatch(a) {
        let out = null;
        args.some((arg) => {
            const res = typeof arg === 'function'
                ? arg().partialMatch(a)
                : arg.partialMatch(a);
            if (res != null) {
                out = res;
                return true;
            }
            return false;
        });
        return out;
    }
    const result = {
        toString: function () { return '{ ' + args.join(' ') + ' }'; },
        input: args,
        matches: makeMatchesFunction(partialMatch),
        partialMatch
    };
    return result;
}
function base$8(n) {
    const name = n;
    function matches(a) {
        let ma;
        try {
            ma = multiaddr$1(a);
        }
        catch (err) { // catch error
            return false; // also if it's invalid it's probably not matching as well so return false
        }
        const pnames = ma.protoNames();
        if (pnames.length === 1 && pnames[0] === name) {
            return true;
        }
        return false;
    }
    function partialMatch(protos) {
        if (protos.length === 0) {
            return null;
        }
        if (protos[0] === name) {
            return protos.slice(1);
        }
        return null;
    }
    return {
        toString: function () { return name; },
        matches,
        partialMatch
    };
}

// p2p multi-address code
const CODE_P2P = 421;
const CODE_CIRCUIT = 290;
// Time to wait for a connection to close gracefully before destroying it manually
const CLOSE_TIMEOUT$1 = 500;

function all(multiaddrs) {
    return multiaddrs.filter((ma) => {
        if (ma.protoCodes().includes(CODE_CIRCUIT)) {
            return false;
        }
        const testMa = ma.decapsulateCode(CODE_P2P);
        return WebSockets$1.matches(testMa) ||
            WebSocketsSecure.matches(testMa);
    });
}
function wss(multiaddrs) {
    return multiaddrs.filter((ma) => {
        if (ma.protoCodes().includes(CODE_CIRCUIT)) {
            return false;
        }
        const testMa = ma.decapsulateCode(CODE_P2P);
        return WebSocketsSecure.matches(testMa);
    });
}

function createListener() {
    throw new Error('WebSocket Servers can not be created in the browser!');
}

const log$x = logger$7('libp2p:websockets:socket');
// Convert a stream into a MultiaddrConnection
// https://github.com/libp2p/interface-transport#multiaddrconnection
function socketToMaConn(stream, remoteAddr, options) {
    options = options ?? {};
    const maConn = {
        async sink(source) {
            if ((options?.signal) != null) {
                source = abortableSource(source, options.signal);
            }
            try {
                await stream.sink(source);
            }
            catch (err) {
                if (err.type !== 'aborted') {
                    log$x.error(err);
                }
            }
        },
        source: (options.signal != null) ? abortableSource(stream.source, options.signal) : stream.source,
        remoteAddr,
        timeline: { open: Date.now() },
        async close(options = {}) {
            const start = Date.now();
            options.signal = options.signal ?? AbortSignal.timeout(CLOSE_TIMEOUT$1);
            const listener = () => {
                const { host, port } = maConn.remoteAddr.toOptions();
                log$x('timeout closing stream to %s:%s after %dms, destroying it manually', host, port, Date.now() - start);
                this.abort(new CodeError$3('Socket close timeout', 'ERR_SOCKET_CLOSE_TIMEOUT'));
            };
            options.signal.addEventListener('abort', listener);
            try {
                await stream.close();
            }
            catch (err) {
                this.abort(err);
            }
            finally {
                options.signal.removeEventListener('abort', listener);
                maConn.timeline.close = Date.now();
            }
        },
        abort(err) {
            const { host, port } = maConn.remoteAddr.toOptions();
            log$x('timeout closing stream to %s:%s due to error', host, port, err);
            stream.destroy();
            maConn.timeline.close = Date.now();
        }
    };
    stream.socket.addEventListener('close', () => {
        // In instances where `close` was not explicitly called,
        // such as an iterable stream ending, ensure we have set the close
        // timeline
        if (maConn.timeline.close == null) {
            maConn.timeline.close = Date.now();
        }
    }, { once: true });
    return maConn;
}

const log$w = logger$7('libp2p:websockets');
class WebSockets {
    init;
    constructor(init) {
        this.init = init;
    }
    [Symbol.toStringTag] = '@libp2p/websockets';
    [symbol$2] = true;
    async dial(ma, options) {
        log$w('dialing %s', ma);
        options = options ?? {};
        const socket = await this._connect(ma, options);
        const maConn = socketToMaConn(socket, ma);
        log$w('new outbound connection %s', maConn.remoteAddr);
        const conn = await options.upgrader.upgradeOutbound(maConn);
        log$w('outbound connection %s upgraded', maConn.remoteAddr);
        return conn;
    }
    async _connect(ma, options) {
        if (options?.signal?.aborted === true) {
            throw new AbortError$8();
        }
        const cOpts = ma.toOptions();
        log$w('dialing %s:%s', cOpts.host, cOpts.port);
        const errorPromise = pDefer();
        const rawSocket = connect(multiaddrToUri(ma), this.init);
        rawSocket.socket.addEventListener('error', () => {
            // the WebSocket.ErrorEvent type doesn't actually give us any useful
            // information about what happened
            // https://developer.mozilla.org/en-US/docs/Web/API/WebSocket/error_event
            const err = new CodeError$3(`Could not connect to ${ma.toString()}`, 'ERR_CONNECTION_FAILED');
            log$w.error('connection error:', err);
            errorPromise.reject(err);
        });
        if (options.signal == null) {
            await Promise.race([rawSocket.connected(), errorPromise.promise]);
            log$w('connected %s', ma);
            return rawSocket;
        }
        // Allow abort via signal during connect
        let onAbort;
        const abort = new Promise((resolve, reject) => {
            onAbort = () => {
                reject(new AbortError$8());
                rawSocket.close().catch(err => {
                    log$w.error('error closing raw socket', err);
                });
            };
            // Already aborted?
            if (options?.signal?.aborted === true) {
                onAbort();
                return;
            }
            options?.signal?.addEventListener('abort', onAbort);
        });
        try {
            await Promise.race([abort, errorPromise.promise, rawSocket.connected()]);
        }
        finally {
            if (onAbort != null) {
                options?.signal?.removeEventListener('abort', onAbort);
            }
        }
        log$w('connected %s', ma);
        return rawSocket;
    }
    /**
     * Creates a Websockets listener. The provided `handler` function will be called
     * anytime a new incoming Connection has been successfully upgraded via
     * `upgrader.upgradeInbound`
     */
    createListener(options) {
        return createListener({ ...this.init, ...options });
    }
    /**
     * Takes a list of `Multiaddr`s and returns only valid Websockets addresses.
     * By default, in a browser environment only DNS+WSS multiaddr is accepted,
     * while in a Node.js environment DNS+{WS, WSS} multiaddrs are accepted.
     */
    filter(multiaddrs) {
        multiaddrs = Array.isArray(multiaddrs) ? multiaddrs : [multiaddrs];
        if (this.init?.filter != null) {
            return this.init?.filter(multiaddrs);
        }
        // Browser
        if (isBrowser || isWebWorker) {
            return wss(multiaddrs);
        }
        return all(multiaddrs);
    }
}
function webSockets(init = {}) {
    return () => {
        return new WebSockets(init);
    };
}

/**
 * Adds types to the EventTarget class. Hopefully this won't be necessary forever.
 *
 * https://github.com/microsoft/TypeScript/issues/28357
 * https://github.com/microsoft/TypeScript/issues/43477
 * https://github.com/microsoft/TypeScript/issues/299
 * etc
 */
let EventEmitter$2 = class EventEmitter extends EventTarget {
    #listeners = new Map();
    listenerCount(type) {
        const listeners = this.#listeners.get(type);
        if (listeners == null) {
            return 0;
        }
        return listeners.length;
    }
    addEventListener(type, listener, options) {
        super.addEventListener(type, listener, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            list = [];
            this.#listeners.set(type, list);
        }
        list.push({
            callback: listener,
            once: (options !== true && options !== false && options?.once) ?? false
        });
    }
    removeEventListener(type, listener, options) {
        super.removeEventListener(type.toString(), listener ?? null, options);
        let list = this.#listeners.get(type);
        if (list == null) {
            return;
        }
        list = list.filter(({ callback }) => callback !== listener);
        this.#listeners.set(type, list);
    }
    dispatchEvent(event) {
        const result = super.dispatchEvent(event);
        let list = this.#listeners.get(event.type);
        if (list == null) {
            return result;
        }
        list = list.filter(({ once }) => !once);
        this.#listeners.set(event.type, list);
        return result;
    }
    safeDispatchEvent(type, detail) {
        return this.dispatchEvent(new CustomEvent(type, detail));
    }
};
/**
 * CustomEvent is a standard event but it's not supported by node.
 *
 * Remove this when https://github.com/nodejs/node/issues/40678 is closed.
 *
 * Ref: https://developer.mozilla.org/en-US/docs/Web/API/CustomEvent
 */
class CustomEventPolyfill extends Event {
    /** Returns any custom data event was created with. Typically used for synthetic events. */
    detail;
    constructor(message, data) {
        super(message, data);
        // @ts-expect-error could be undefined
        this.detail = data?.detail;
    }
}
const CustomEvent = globalThis.CustomEvent ?? CustomEventPolyfill;

/**
 * Any object that implements this Symbol as a property should return a
 * PeerDiscovery instance as the property value, similar to how
 * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```js
 * import { peerDiscovery, PeerDiscovery } from '@libp2p/peer-discovery'
 *
 * class MyPeerDiscoverer implements PeerDiscovery {
 *   get [peerDiscovery] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const peerDiscovery = Symbol.for('@libp2p/peer-discovery');

const enrTree = {
    TEST: "enrtree://AOGECG2SPND25EEFMAJ5WF3KSGJNSGV356DSTL2YVLLZWIV6SAYBM@test.waku.nodes.status.im",
    PROD: "enrtree://AOGECG2SPND25EEFMAJ5WF3KSGJNSGV356DSTL2YVLLZWIV6SAYBM@prod.waku.nodes.status.im"
};
const DEFAULT_BOOTSTRAP_TAG_NAME = "bootstrap";
const DEFAULT_BOOTSTRAP_TAG_VALUE = 50;
const DEFAULT_BOOTSTRAP_TAG_TTL = 100000000;
const DEFAULT_NODE_REQUIREMENTS$1 = {
    store: 2,
    filter: 1,
    lightPush: 1
};

// Maximum encoded size of an ENR
const ERR_INVALID_ID = "Invalid record id";
// The maximum length of byte size of a multiaddr to encode in the `multiaddr` field
// The size is a big endian 16-bit unsigned integer
const MULTIADDR_LENGTH_SIZE = 2;

var sha3$1 = {exports: {}};

/**
 * [js-sha3]{@link https://github.com/emn178/js-sha3}
 *
 * @version 0.8.0
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2015-2018
 * @license MIT
 */

(function (module) {
	/*jslint bitwise: true */
	(function () {

	  var INPUT_ERROR = 'input is invalid type';
	  var FINALIZE_ERROR = 'finalize already called';
	  var WINDOW = typeof window === 'object';
	  var root = WINDOW ? window : {};
	  if (root.JS_SHA3_NO_WINDOW) {
	    WINDOW = false;
	  }
	  var WEB_WORKER = !WINDOW && typeof self === 'object';
	  var NODE_JS = !root.JS_SHA3_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
	  if (NODE_JS) {
	    root = commonjsGlobal;
	  } else if (WEB_WORKER) {
	    root = self;
	  }
	  var COMMON_JS = !root.JS_SHA3_NO_COMMON_JS && 'object' === 'object' && module.exports;
	  var ARRAY_BUFFER = !root.JS_SHA3_NO_ARRAY_BUFFER && typeof ArrayBuffer !== 'undefined';
	  var HEX_CHARS = '0123456789abcdef'.split('');
	  var SHAKE_PADDING = [31, 7936, 2031616, 520093696];
	  var CSHAKE_PADDING = [4, 1024, 262144, 67108864];
	  var KECCAK_PADDING = [1, 256, 65536, 16777216];
	  var PADDING = [6, 1536, 393216, 100663296];
	  var SHIFT = [0, 8, 16, 24];
	  var RC = [1, 0, 32898, 0, 32906, 2147483648, 2147516416, 2147483648, 32907, 0, 2147483649,
	    0, 2147516545, 2147483648, 32777, 2147483648, 138, 0, 136, 0, 2147516425, 0,
	    2147483658, 0, 2147516555, 0, 139, 2147483648, 32905, 2147483648, 32771,
	    2147483648, 32770, 2147483648, 128, 2147483648, 32778, 0, 2147483658, 2147483648,
	    2147516545, 2147483648, 32896, 2147483648, 2147483649, 0, 2147516424, 2147483648];
	  var BITS = [224, 256, 384, 512];
	  var SHAKE_BITS = [128, 256];
	  var OUTPUT_TYPES = ['hex', 'buffer', 'arrayBuffer', 'array', 'digest'];
	  var CSHAKE_BYTEPAD = {
	    '128': 168,
	    '256': 136
	  };

	  if (root.JS_SHA3_NO_NODE_JS || !Array.isArray) {
	    Array.isArray = function (obj) {
	      return Object.prototype.toString.call(obj) === '[object Array]';
	    };
	  }

	  if (ARRAY_BUFFER && (root.JS_SHA3_NO_ARRAY_BUFFER_IS_VIEW || !ArrayBuffer.isView)) {
	    ArrayBuffer.isView = function (obj) {
	      return typeof obj === 'object' && obj.buffer && obj.buffer.constructor === ArrayBuffer;
	    };
	  }

	  var createOutputMethod = function (bits, padding, outputType) {
	    return function (message) {
	      return new Keccak(bits, padding, bits).update(message)[outputType]();
	    };
	  };

	  var createShakeOutputMethod = function (bits, padding, outputType) {
	    return function (message, outputBits) {
	      return new Keccak(bits, padding, outputBits).update(message)[outputType]();
	    };
	  };

	  var createCshakeOutputMethod = function (bits, padding, outputType) {
	    return function (message, outputBits, n, s) {
	      return methods['cshake' + bits].update(message, outputBits, n, s)[outputType]();
	    };
	  };

	  var createKmacOutputMethod = function (bits, padding, outputType) {
	    return function (key, message, outputBits, s) {
	      return methods['kmac' + bits].update(key, message, outputBits, s)[outputType]();
	    };
	  };

	  var createOutputMethods = function (method, createMethod, bits, padding) {
	    for (var i = 0; i < OUTPUT_TYPES.length; ++i) {
	      var type = OUTPUT_TYPES[i];
	      method[type] = createMethod(bits, padding, type);
	    }
	    return method;
	  };

	  var createMethod = function (bits, padding) {
	    var method = createOutputMethod(bits, padding, 'hex');
	    method.create = function () {
	      return new Keccak(bits, padding, bits);
	    };
	    method.update = function (message) {
	      return method.create().update(message);
	    };
	    return createOutputMethods(method, createOutputMethod, bits, padding);
	  };

	  var createShakeMethod = function (bits, padding) {
	    var method = createShakeOutputMethod(bits, padding, 'hex');
	    method.create = function (outputBits) {
	      return new Keccak(bits, padding, outputBits);
	    };
	    method.update = function (message, outputBits) {
	      return method.create(outputBits).update(message);
	    };
	    return createOutputMethods(method, createShakeOutputMethod, bits, padding);
	  };

	  var createCshakeMethod = function (bits, padding) {
	    var w = CSHAKE_BYTEPAD[bits];
	    var method = createCshakeOutputMethod(bits, padding, 'hex');
	    method.create = function (outputBits, n, s) {
	      if (!n && !s) {
	        return methods['shake' + bits].create(outputBits);
	      } else {
	        return new Keccak(bits, padding, outputBits).bytepad([n, s], w);
	      }
	    };
	    method.update = function (message, outputBits, n, s) {
	      return method.create(outputBits, n, s).update(message);
	    };
	    return createOutputMethods(method, createCshakeOutputMethod, bits, padding);
	  };

	  var createKmacMethod = function (bits, padding) {
	    var w = CSHAKE_BYTEPAD[bits];
	    var method = createKmacOutputMethod(bits, padding, 'hex');
	    method.create = function (key, outputBits, s) {
	      return new Kmac(bits, padding, outputBits).bytepad(['KMAC', s], w).bytepad([key], w);
	    };
	    method.update = function (key, message, outputBits, s) {
	      return method.create(key, outputBits, s).update(message);
	    };
	    return createOutputMethods(method, createKmacOutputMethod, bits, padding);
	  };

	  var algorithms = [
	    { name: 'keccak', padding: KECCAK_PADDING, bits: BITS, createMethod: createMethod },
	    { name: 'sha3', padding: PADDING, bits: BITS, createMethod: createMethod },
	    { name: 'shake', padding: SHAKE_PADDING, bits: SHAKE_BITS, createMethod: createShakeMethod },
	    { name: 'cshake', padding: CSHAKE_PADDING, bits: SHAKE_BITS, createMethod: createCshakeMethod },
	    { name: 'kmac', padding: CSHAKE_PADDING, bits: SHAKE_BITS, createMethod: createKmacMethod }
	  ];

	  var methods = {}, methodNames = [];

	  for (var i = 0; i < algorithms.length; ++i) {
	    var algorithm = algorithms[i];
	    var bits = algorithm.bits;
	    for (var j = 0; j < bits.length; ++j) {
	      var methodName = algorithm.name + '_' + bits[j];
	      methodNames.push(methodName);
	      methods[methodName] = algorithm.createMethod(bits[j], algorithm.padding);
	      if (algorithm.name !== 'sha3') {
	        var newMethodName = algorithm.name + bits[j];
	        methodNames.push(newMethodName);
	        methods[newMethodName] = methods[methodName];
	      }
	    }
	  }

	  function Keccak(bits, padding, outputBits) {
	    this.blocks = [];
	    this.s = [];
	    this.padding = padding;
	    this.outputBits = outputBits;
	    this.reset = true;
	    this.finalized = false;
	    this.block = 0;
	    this.start = 0;
	    this.blockCount = (1600 - (bits << 1)) >> 5;
	    this.byteCount = this.blockCount << 2;
	    this.outputBlocks = outputBits >> 5;
	    this.extraBytes = (outputBits & 31) >> 3;

	    for (var i = 0; i < 50; ++i) {
	      this.s[i] = 0;
	    }
	  }

	  Keccak.prototype.update = function (message) {
	    if (this.finalized) {
	      throw new Error(FINALIZE_ERROR);
	    }
	    var notString, type = typeof message;
	    if (type !== 'string') {
	      if (type === 'object') {
	        if (message === null) {
	          throw new Error(INPUT_ERROR);
	        } else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) {
	          message = new Uint8Array(message);
	        } else if (!Array.isArray(message)) {
	          if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) {
	            throw new Error(INPUT_ERROR);
	          }
	        }
	      } else {
	        throw new Error(INPUT_ERROR);
	      }
	      notString = true;
	    }
	    var blocks = this.blocks, byteCount = this.byteCount, length = message.length,
	      blockCount = this.blockCount, index = 0, s = this.s, i, code;

	    while (index < length) {
	      if (this.reset) {
	        this.reset = false;
	        blocks[0] = this.block;
	        for (i = 1; i < blockCount + 1; ++i) {
	          blocks[i] = 0;
	        }
	      }
	      if (notString) {
	        for (i = this.start; index < length && i < byteCount; ++index) {
	          blocks[i >> 2] |= message[index] << SHIFT[i++ & 3];
	        }
	      } else {
	        for (i = this.start; index < length && i < byteCount; ++index) {
	          code = message.charCodeAt(index);
	          if (code < 0x80) {
	            blocks[i >> 2] |= code << SHIFT[i++ & 3];
	          } else if (code < 0x800) {
	            blocks[i >> 2] |= (0xc0 | (code >> 6)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          } else if (code < 0xd800 || code >= 0xe000) {
	            blocks[i >> 2] |= (0xe0 | (code >> 12)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          } else {
	            code = 0x10000 + (((code & 0x3ff) << 10) | (message.charCodeAt(++index) & 0x3ff));
	            blocks[i >> 2] |= (0xf0 | (code >> 18)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 12) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | ((code >> 6) & 0x3f)) << SHIFT[i++ & 3];
	            blocks[i >> 2] |= (0x80 | (code & 0x3f)) << SHIFT[i++ & 3];
	          }
	        }
	      }
	      this.lastByteIndex = i;
	      if (i >= byteCount) {
	        this.start = i - byteCount;
	        this.block = blocks[blockCount];
	        for (i = 0; i < blockCount; ++i) {
	          s[i] ^= blocks[i];
	        }
	        f(s);
	        this.reset = true;
	      } else {
	        this.start = i;
	      }
	    }
	    return this;
	  };

	  Keccak.prototype.encode = function (x, right) {
	    var o = x & 255, n = 1;
	    var bytes = [o];
	    x = x >> 8;
	    o = x & 255;
	    while (o > 0) {
	      bytes.unshift(o);
	      x = x >> 8;
	      o = x & 255;
	      ++n;
	    }
	    if (right) {
	      bytes.push(n);
	    } else {
	      bytes.unshift(n);
	    }
	    this.update(bytes);
	    return bytes.length;
	  };

	  Keccak.prototype.encodeString = function (str) {
	    var notString, type = typeof str;
	    if (type !== 'string') {
	      if (type === 'object') {
	        if (str === null) {
	          throw new Error(INPUT_ERROR);
	        } else if (ARRAY_BUFFER && str.constructor === ArrayBuffer) {
	          str = new Uint8Array(str);
	        } else if (!Array.isArray(str)) {
	          if (!ARRAY_BUFFER || !ArrayBuffer.isView(str)) {
	            throw new Error(INPUT_ERROR);
	          }
	        }
	      } else {
	        throw new Error(INPUT_ERROR);
	      }
	      notString = true;
	    }
	    var bytes = 0, length = str.length;
	    if (notString) {
	      bytes = length;
	    } else {
	      for (var i = 0; i < str.length; ++i) {
	        var code = str.charCodeAt(i);
	        if (code < 0x80) {
	          bytes += 1;
	        } else if (code < 0x800) {
	          bytes += 2;
	        } else if (code < 0xd800 || code >= 0xe000) {
	          bytes += 3;
	        } else {
	          code = 0x10000 + (((code & 0x3ff) << 10) | (str.charCodeAt(++i) & 0x3ff));
	          bytes += 4;
	        }
	      }
	    }
	    bytes += this.encode(bytes * 8);
	    this.update(str);
	    return bytes;
	  };

	  Keccak.prototype.bytepad = function (strs, w) {
	    var bytes = this.encode(w);
	    for (var i = 0; i < strs.length; ++i) {
	      bytes += this.encodeString(strs[i]);
	    }
	    var paddingBytes = w - bytes % w;
	    var zeros = [];
	    zeros.length = paddingBytes;
	    this.update(zeros);
	    return this;
	  };

	  Keccak.prototype.finalize = function () {
	    if (this.finalized) {
	      return;
	    }
	    this.finalized = true;
	    var blocks = this.blocks, i = this.lastByteIndex, blockCount = this.blockCount, s = this.s;
	    blocks[i >> 2] |= this.padding[i & 3];
	    if (this.lastByteIndex === this.byteCount) {
	      blocks[0] = blocks[blockCount];
	      for (i = 1; i < blockCount + 1; ++i) {
	        blocks[i] = 0;
	      }
	    }
	    blocks[blockCount - 1] |= 0x80000000;
	    for (i = 0; i < blockCount; ++i) {
	      s[i] ^= blocks[i];
	    }
	    f(s);
	  };

	  Keccak.prototype.toString = Keccak.prototype.hex = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var hex = '', block;
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        block = s[i];
	        hex += HEX_CHARS[(block >> 4) & 0x0F] + HEX_CHARS[block & 0x0F] +
	          HEX_CHARS[(block >> 12) & 0x0F] + HEX_CHARS[(block >> 8) & 0x0F] +
	          HEX_CHARS[(block >> 20) & 0x0F] + HEX_CHARS[(block >> 16) & 0x0F] +
	          HEX_CHARS[(block >> 28) & 0x0F] + HEX_CHARS[(block >> 24) & 0x0F];
	      }
	      if (j % blockCount === 0) {
	        f(s);
	        i = 0;
	      }
	    }
	    if (extraBytes) {
	      block = s[i];
	      hex += HEX_CHARS[(block >> 4) & 0x0F] + HEX_CHARS[block & 0x0F];
	      if (extraBytes > 1) {
	        hex += HEX_CHARS[(block >> 12) & 0x0F] + HEX_CHARS[(block >> 8) & 0x0F];
	      }
	      if (extraBytes > 2) {
	        hex += HEX_CHARS[(block >> 20) & 0x0F] + HEX_CHARS[(block >> 16) & 0x0F];
	      }
	    }
	    return hex;
	  };

	  Keccak.prototype.arrayBuffer = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var bytes = this.outputBits >> 3;
	    var buffer;
	    if (extraBytes) {
	      buffer = new ArrayBuffer((outputBlocks + 1) << 2);
	    } else {
	      buffer = new ArrayBuffer(bytes);
	    }
	    var array = new Uint32Array(buffer);
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        array[j] = s[i];
	      }
	      if (j % blockCount === 0) {
	        f(s);
	      }
	    }
	    if (extraBytes) {
	      array[i] = s[i];
	      buffer = buffer.slice(0, bytes);
	    }
	    return buffer;
	  };

	  Keccak.prototype.buffer = Keccak.prototype.arrayBuffer;

	  Keccak.prototype.digest = Keccak.prototype.array = function () {
	    this.finalize();

	    var blockCount = this.blockCount, s = this.s, outputBlocks = this.outputBlocks,
	      extraBytes = this.extraBytes, i = 0, j = 0;
	    var array = [], offset, block;
	    while (j < outputBlocks) {
	      for (i = 0; i < blockCount && j < outputBlocks; ++i, ++j) {
	        offset = j << 2;
	        block = s[i];
	        array[offset] = block & 0xFF;
	        array[offset + 1] = (block >> 8) & 0xFF;
	        array[offset + 2] = (block >> 16) & 0xFF;
	        array[offset + 3] = (block >> 24) & 0xFF;
	      }
	      if (j % blockCount === 0) {
	        f(s);
	      }
	    }
	    if (extraBytes) {
	      offset = j << 2;
	      block = s[i];
	      array[offset] = block & 0xFF;
	      if (extraBytes > 1) {
	        array[offset + 1] = (block >> 8) & 0xFF;
	      }
	      if (extraBytes > 2) {
	        array[offset + 2] = (block >> 16) & 0xFF;
	      }
	    }
	    return array;
	  };

	  function Kmac(bits, padding, outputBits) {
	    Keccak.call(this, bits, padding, outputBits);
	  }

	  Kmac.prototype = new Keccak();

	  Kmac.prototype.finalize = function () {
	    this.encode(this.outputBits, true);
	    return Keccak.prototype.finalize.call(this);
	  };

	  var f = function (s) {
	    var h, l, n, c0, c1, c2, c3, c4, c5, c6, c7, c8, c9,
	      b0, b1, b2, b3, b4, b5, b6, b7, b8, b9, b10, b11, b12, b13, b14, b15, b16, b17,
	      b18, b19, b20, b21, b22, b23, b24, b25, b26, b27, b28, b29, b30, b31, b32, b33,
	      b34, b35, b36, b37, b38, b39, b40, b41, b42, b43, b44, b45, b46, b47, b48, b49;
	    for (n = 0; n < 48; n += 2) {
	      c0 = s[0] ^ s[10] ^ s[20] ^ s[30] ^ s[40];
	      c1 = s[1] ^ s[11] ^ s[21] ^ s[31] ^ s[41];
	      c2 = s[2] ^ s[12] ^ s[22] ^ s[32] ^ s[42];
	      c3 = s[3] ^ s[13] ^ s[23] ^ s[33] ^ s[43];
	      c4 = s[4] ^ s[14] ^ s[24] ^ s[34] ^ s[44];
	      c5 = s[5] ^ s[15] ^ s[25] ^ s[35] ^ s[45];
	      c6 = s[6] ^ s[16] ^ s[26] ^ s[36] ^ s[46];
	      c7 = s[7] ^ s[17] ^ s[27] ^ s[37] ^ s[47];
	      c8 = s[8] ^ s[18] ^ s[28] ^ s[38] ^ s[48];
	      c9 = s[9] ^ s[19] ^ s[29] ^ s[39] ^ s[49];

	      h = c8 ^ ((c2 << 1) | (c3 >>> 31));
	      l = c9 ^ ((c3 << 1) | (c2 >>> 31));
	      s[0] ^= h;
	      s[1] ^= l;
	      s[10] ^= h;
	      s[11] ^= l;
	      s[20] ^= h;
	      s[21] ^= l;
	      s[30] ^= h;
	      s[31] ^= l;
	      s[40] ^= h;
	      s[41] ^= l;
	      h = c0 ^ ((c4 << 1) | (c5 >>> 31));
	      l = c1 ^ ((c5 << 1) | (c4 >>> 31));
	      s[2] ^= h;
	      s[3] ^= l;
	      s[12] ^= h;
	      s[13] ^= l;
	      s[22] ^= h;
	      s[23] ^= l;
	      s[32] ^= h;
	      s[33] ^= l;
	      s[42] ^= h;
	      s[43] ^= l;
	      h = c2 ^ ((c6 << 1) | (c7 >>> 31));
	      l = c3 ^ ((c7 << 1) | (c6 >>> 31));
	      s[4] ^= h;
	      s[5] ^= l;
	      s[14] ^= h;
	      s[15] ^= l;
	      s[24] ^= h;
	      s[25] ^= l;
	      s[34] ^= h;
	      s[35] ^= l;
	      s[44] ^= h;
	      s[45] ^= l;
	      h = c4 ^ ((c8 << 1) | (c9 >>> 31));
	      l = c5 ^ ((c9 << 1) | (c8 >>> 31));
	      s[6] ^= h;
	      s[7] ^= l;
	      s[16] ^= h;
	      s[17] ^= l;
	      s[26] ^= h;
	      s[27] ^= l;
	      s[36] ^= h;
	      s[37] ^= l;
	      s[46] ^= h;
	      s[47] ^= l;
	      h = c6 ^ ((c0 << 1) | (c1 >>> 31));
	      l = c7 ^ ((c1 << 1) | (c0 >>> 31));
	      s[8] ^= h;
	      s[9] ^= l;
	      s[18] ^= h;
	      s[19] ^= l;
	      s[28] ^= h;
	      s[29] ^= l;
	      s[38] ^= h;
	      s[39] ^= l;
	      s[48] ^= h;
	      s[49] ^= l;

	      b0 = s[0];
	      b1 = s[1];
	      b32 = (s[11] << 4) | (s[10] >>> 28);
	      b33 = (s[10] << 4) | (s[11] >>> 28);
	      b14 = (s[20] << 3) | (s[21] >>> 29);
	      b15 = (s[21] << 3) | (s[20] >>> 29);
	      b46 = (s[31] << 9) | (s[30] >>> 23);
	      b47 = (s[30] << 9) | (s[31] >>> 23);
	      b28 = (s[40] << 18) | (s[41] >>> 14);
	      b29 = (s[41] << 18) | (s[40] >>> 14);
	      b20 = (s[2] << 1) | (s[3] >>> 31);
	      b21 = (s[3] << 1) | (s[2] >>> 31);
	      b2 = (s[13] << 12) | (s[12] >>> 20);
	      b3 = (s[12] << 12) | (s[13] >>> 20);
	      b34 = (s[22] << 10) | (s[23] >>> 22);
	      b35 = (s[23] << 10) | (s[22] >>> 22);
	      b16 = (s[33] << 13) | (s[32] >>> 19);
	      b17 = (s[32] << 13) | (s[33] >>> 19);
	      b48 = (s[42] << 2) | (s[43] >>> 30);
	      b49 = (s[43] << 2) | (s[42] >>> 30);
	      b40 = (s[5] << 30) | (s[4] >>> 2);
	      b41 = (s[4] << 30) | (s[5] >>> 2);
	      b22 = (s[14] << 6) | (s[15] >>> 26);
	      b23 = (s[15] << 6) | (s[14] >>> 26);
	      b4 = (s[25] << 11) | (s[24] >>> 21);
	      b5 = (s[24] << 11) | (s[25] >>> 21);
	      b36 = (s[34] << 15) | (s[35] >>> 17);
	      b37 = (s[35] << 15) | (s[34] >>> 17);
	      b18 = (s[45] << 29) | (s[44] >>> 3);
	      b19 = (s[44] << 29) | (s[45] >>> 3);
	      b10 = (s[6] << 28) | (s[7] >>> 4);
	      b11 = (s[7] << 28) | (s[6] >>> 4);
	      b42 = (s[17] << 23) | (s[16] >>> 9);
	      b43 = (s[16] << 23) | (s[17] >>> 9);
	      b24 = (s[26] << 25) | (s[27] >>> 7);
	      b25 = (s[27] << 25) | (s[26] >>> 7);
	      b6 = (s[36] << 21) | (s[37] >>> 11);
	      b7 = (s[37] << 21) | (s[36] >>> 11);
	      b38 = (s[47] << 24) | (s[46] >>> 8);
	      b39 = (s[46] << 24) | (s[47] >>> 8);
	      b30 = (s[8] << 27) | (s[9] >>> 5);
	      b31 = (s[9] << 27) | (s[8] >>> 5);
	      b12 = (s[18] << 20) | (s[19] >>> 12);
	      b13 = (s[19] << 20) | (s[18] >>> 12);
	      b44 = (s[29] << 7) | (s[28] >>> 25);
	      b45 = (s[28] << 7) | (s[29] >>> 25);
	      b26 = (s[38] << 8) | (s[39] >>> 24);
	      b27 = (s[39] << 8) | (s[38] >>> 24);
	      b8 = (s[48] << 14) | (s[49] >>> 18);
	      b9 = (s[49] << 14) | (s[48] >>> 18);

	      s[0] = b0 ^ (~b2 & b4);
	      s[1] = b1 ^ (~b3 & b5);
	      s[10] = b10 ^ (~b12 & b14);
	      s[11] = b11 ^ (~b13 & b15);
	      s[20] = b20 ^ (~b22 & b24);
	      s[21] = b21 ^ (~b23 & b25);
	      s[30] = b30 ^ (~b32 & b34);
	      s[31] = b31 ^ (~b33 & b35);
	      s[40] = b40 ^ (~b42 & b44);
	      s[41] = b41 ^ (~b43 & b45);
	      s[2] = b2 ^ (~b4 & b6);
	      s[3] = b3 ^ (~b5 & b7);
	      s[12] = b12 ^ (~b14 & b16);
	      s[13] = b13 ^ (~b15 & b17);
	      s[22] = b22 ^ (~b24 & b26);
	      s[23] = b23 ^ (~b25 & b27);
	      s[32] = b32 ^ (~b34 & b36);
	      s[33] = b33 ^ (~b35 & b37);
	      s[42] = b42 ^ (~b44 & b46);
	      s[43] = b43 ^ (~b45 & b47);
	      s[4] = b4 ^ (~b6 & b8);
	      s[5] = b5 ^ (~b7 & b9);
	      s[14] = b14 ^ (~b16 & b18);
	      s[15] = b15 ^ (~b17 & b19);
	      s[24] = b24 ^ (~b26 & b28);
	      s[25] = b25 ^ (~b27 & b29);
	      s[34] = b34 ^ (~b36 & b38);
	      s[35] = b35 ^ (~b37 & b39);
	      s[44] = b44 ^ (~b46 & b48);
	      s[45] = b45 ^ (~b47 & b49);
	      s[6] = b6 ^ (~b8 & b0);
	      s[7] = b7 ^ (~b9 & b1);
	      s[16] = b16 ^ (~b18 & b10);
	      s[17] = b17 ^ (~b19 & b11);
	      s[26] = b26 ^ (~b28 & b20);
	      s[27] = b27 ^ (~b29 & b21);
	      s[36] = b36 ^ (~b38 & b30);
	      s[37] = b37 ^ (~b39 & b31);
	      s[46] = b46 ^ (~b48 & b40);
	      s[47] = b47 ^ (~b49 & b41);
	      s[8] = b8 ^ (~b0 & b2);
	      s[9] = b9 ^ (~b1 & b3);
	      s[18] = b18 ^ (~b10 & b12);
	      s[19] = b19 ^ (~b11 & b13);
	      s[28] = b28 ^ (~b20 & b22);
	      s[29] = b29 ^ (~b21 & b23);
	      s[38] = b38 ^ (~b30 & b32);
	      s[39] = b39 ^ (~b31 & b33);
	      s[48] = b48 ^ (~b40 & b42);
	      s[49] = b49 ^ (~b41 & b43);

	      s[0] ^= RC[n];
	      s[1] ^= RC[n + 1];
	    }
	  };

	  if (COMMON_JS) {
	    module.exports = methods;
	  } else {
	    for (i = 0; i < methodNames.length; ++i) {
	      root[methodNames[i]] = methods[methodNames[i]];
	    }
	  }
	})(); 
} (sha3$1));

var sha3Exports = sha3$1.exports;
var sha3 = /*@__PURE__*/getDefaultExportFromCjs(sha3Exports);

function keccak256(input) {
    return new Uint8Array(sha3.keccak256.arrayBuffer(input));
}
/**
 * Verify an ECDSA signature.
 */
function verifySignature(signature, message, publicKey) {
    try {
        const _signature = Signature.fromCompact(signature.slice(0, 64));
        return verify(_signature, message, publicKey);
    }
    catch {
        return false;
    }
}

function multiaddrFromFields(ipFamily, protocol, ipBytes, protocolBytes) {
    let ma = multiaddr$1("/" + ipFamily + "/" + convertToString$1(ipFamily, ipBytes));
    ma = ma.encapsulate(multiaddr$1("/" + protocol + "/" + convertToString$1(protocol, protocolBytes)));
    return ma;
}

function locationMultiaddrFromEnrFields(enr, protocol) {
    switch (protocol) {
        case "udp":
            return (locationMultiaddrFromEnrFields(enr, "udp4") ||
                locationMultiaddrFromEnrFields(enr, "udp6"));
        case "tcp":
            return (locationMultiaddrFromEnrFields(enr, "tcp4") ||
                locationMultiaddrFromEnrFields(enr, "tcp6"));
    }
    const isIpv6 = protocol.endsWith("6");
    const ipVal = enr.get(isIpv6 ? "ip6" : "ip");
    if (!ipVal)
        return;
    const protoName = protocol.slice(0, 3);
    let protoVal;
    switch (protoName) {
        case "udp":
            protoVal = isIpv6 ? enr.get("udp6") : enr.get("udp");
            break;
        case "tcp":
            protoVal = isIpv6 ? enr.get("tcp6") : enr.get("tcp");
            break;
        default:
            return;
    }
    if (!protoVal)
        return;
    return multiaddrFromFields(isIpv6 ? "ip6" : "ip4", protoName, ipVal, protoVal);
}

/**
 * When this error is thrown it means an operation was aborted,
 * usually in response to the `abort` event being emitted by an
 * AbortSignal.
 */
class CodeError extends Error {
    code;
    props;
    constructor(message, code, props) {
        super(message);
        this.code = code;
        this.name = props?.name ?? 'CodeError';
        this.props = props ?? {}; // eslint-disable-line @typescript-eslint/consistent-type-assertions
    }
}

const PUBLIC_KEY_BYTE_LENGTH$5 = 32;
const PRIVATE_KEY_BYTE_LENGTH$5 = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH$5 = 32;
async function generateKey$h() {
    // the actual private key (32 bytes)
    const privateKeyRaw = utils$1.randomPrivateKey();
    const publicKey = await getPublicKey$1(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys$5(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
async function generateKeyFromSeed$5(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH$5) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = await getPublicKey$1(privateKeyRaw);
    const privateKey = concatKeys$5(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSign$h(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH$5);
    return sign$2(msg, privateKeyRaw);
}
async function hashAndVerify$h(publicKey, sig, msg) {
    return verify$1(sig, msg, publicKey);
}
function concatKeys$5(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH$5);
    for (let i = 0; i < KEYS_BYTE_LENGTH$5; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH$5 + i] = publicKey[i];
    }
    return privateKey;
}

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto$5 = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto == null || nativeCrypto.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p-crypto/blob/master/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

// WebKit on Linux does not support deriving a key from an empty PBKDF2 key.
// So, as a workaround, we provide the generated key as a constant. We test that
// this generated key is accurate in test/workaround.spec.ts
// Generated via:
// await crypto.subtle.exportKey('jwk',
//   await crypto.subtle.deriveKey(
//     { name: 'PBKDF2', salt: new Uint8Array(16), iterations: 32767, hash: { name: 'SHA-256' } },
//     await crypto.subtle.importKey('raw', new Uint8Array(0), { name: 'PBKDF2' }, false, ['deriveKey']),
//     { name: 'AES-GCM', length: 128 }, true, ['encrypt', 'decrypt'])
// )
const derivedEmptyPasswordKey$5 = { alg: 'A128GCM', ext: true, k: 'scm9jmO_4BJAgdwWGVulLg', key_ops: ['encrypt', 'decrypt'], kty: 'oct' };
// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create$a(opts) {
    const algorithm = opts?.algorithm ?? 'AES-GCM';
    let keyLength = opts?.keyLength ?? 16;
    const nonceLength = opts?.nonceLength ?? 12;
    const digest = opts?.digest ?? 'SHA-256';
    const saltLength = opts?.saltLength ?? 16;
    const iterations = opts?.iterations ?? 32767;
    const crypto = webcrypto$5.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$5, { name: 'AES-GCM' }, true, ['encrypt']);
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['encrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$5, { name: 'AES-GCM' }, true, ['encrypt']);
            }
        }
        else {
            // Derive a key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        }
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat$1([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['decrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$5, { name: 'AES-GCM' }, true, ['decrypt']);
            }
        }
        else {
            // Derive the key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        }
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter$5(privateKey, password) {
    const cipher = create$a();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64$7.encode(encryptedKey);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType$6;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType$6 || (KeyType$6 = {}));
var __KeyTypeValues$6;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues$6 || (__KeyTypeValues$6 = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues$6);
    };
})(KeyType$6 || (KeyType$6 = {}));
var PublicKey$6;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$6.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$6.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$1(buf, PublicKey.codec());
    };
})(PublicKey$6 || (PublicKey$6 = {}));
var PrivateKey$6;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$6.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$6.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$1(buf, PrivateKey.codec());
    };
})(PrivateKey$6 || (PrivateKey$6 = {}));

let Ed25519PublicKey$5 = class Ed25519PublicKey {
    _key;
    constructor(key) {
        this._key = ensureKey$5(key, PUBLIC_KEY_BYTE_LENGTH$5);
    }
    async verify(data, sig) {
        return hashAndVerify$h(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey$6.encode({
            Type: KeyType$6.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$6.digest(this.bytes);
        return bytes;
    }
};
let Ed25519PrivateKey$5 = class Ed25519PrivateKey {
    _key;
    _publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey$5(key, PRIVATE_KEY_BYTE_LENGTH$5);
        this._publicKey = ensureKey$5(publicKey, PUBLIC_KEY_BYTE_LENGTH$5);
    }
    async sign(message) {
        return hashAndSign$h(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey$5(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$6.encode({
            Type: KeyType$6.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$6.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity$5.digest(this.public.bytes);
        return base58btc$7.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$5(this.bytes, password);
        }
        else {
            throw new CodeError(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalEd25519PrivateKey$5(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH$5) {
        bytes = ensureKey$5(bytes, PRIVATE_KEY_BYTE_LENGTH$5 + PUBLIC_KEY_BYTE_LENGTH$5);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$5);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH$5, bytes.length);
        return new Ed25519PrivateKey$5(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey$5(bytes, PRIVATE_KEY_BYTE_LENGTH$5);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$5);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH$5);
    return new Ed25519PrivateKey$5(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey$5(bytes) {
    bytes = ensureKey$5(bytes, PUBLIC_KEY_BYTE_LENGTH$5);
    return new Ed25519PublicKey$5(bytes);
}
async function generateKeyPair$j() {
    const { privateKey, publicKey } = await generateKey$h();
    return new Ed25519PrivateKey$5(privateKey, publicKey);
}
async function generateKeyPairFromSeed$5(seed) {
    const { privateKey, publicKey } = await generateKeyFromSeed$5(seed);
    return new Ed25519PrivateKey$5(privateKey, publicKey);
}
function ensureKey$5(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey$5,
    Ed25519PublicKey: Ed25519PublicKey$5,
    generateKeyPair: generateKeyPair$j,
    generateKeyPairFromSeed: generateKeyPairFromSeed$5,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey$5,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey$5
});

function bigIntegerToUintBase64url$5(num, len) {
    // Call `.abs()` to convert to unsigned
    let buf = Uint8Array.from(num.abs().toByteArray()); // toByteArray converts to big endian
    // toByteArray() gives us back a signed array, which will include a leading 0
    // byte if the most significant bit of the number is 1:
    // https://docs.microsoft.com/en-us/windows/win32/seccertenroll/about-integer
    // Our number will always be positive so we should remove the leading padding.
    buf = buf[0] === 0 ? buf.subarray(1) : buf;
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return toString$9(buf, 'base64url');
}
// Convert a base64url encoded string to a BigInteger
function base64urlToBigInteger$5(str) {
    const buf = base64urlToBuffer$5(str);
    return new forge$n.jsbn.BigInteger(toString$9(buf, 'base16'), 16);
}
function base64urlToBuffer$5(str, len) {
    let buf = fromString$3(str, 'base64urlpad');
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return buf;
}

const bits$6 = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes$6 = Object.keys(bits$6);
curveTypes$6.join(' / ');

function randomBytes$5(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return utils.randomBytes(length);
}

function convert$5(key, types) {
    return types.map(t => base64urlToBigInteger$5(key[t]));
}
function jwk2priv$5(key) {
    return forge$n.pki.setRsaPrivateKey(...convert$5(key, ['n', 'e', 'd', 'p', 'q', 'dp', 'dq', 'qi']));
}
function jwk2pub$5(key) {
    return forge$n.pki.setRsaPublicKey(...convert$5(key, ['n', 'e']));
}

// Convert a PKCS#1 in ASN1 DER format to a JWK key
function pkcs1ToJwk$5(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
    // https://tools.ietf.org/html/rfc7518#section-6.3.1
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$5(privateKey.n),
        e: bigIntegerToUintBase64url$5(privateKey.e),
        d: bigIntegerToUintBase64url$5(privateKey.d),
        p: bigIntegerToUintBase64url$5(privateKey.p),
        q: bigIntegerToUintBase64url$5(privateKey.q),
        dp: bigIntegerToUintBase64url$5(privateKey.dP),
        dq: bigIntegerToUintBase64url$5(privateKey.dQ),
        qi: bigIntegerToUintBase64url$5(privateKey.qInv),
        alg: 'RS256'
    };
}
// Convert a JWK key into PKCS#1 in ASN1 DER format
function jwkToPkcs1$5(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.privateKeyToAsn1({
        n: base64urlToBigInteger$5(jwk.n),
        e: base64urlToBigInteger$5(jwk.e),
        d: base64urlToBigInteger$5(jwk.d),
        p: base64urlToBigInteger$5(jwk.p),
        q: base64urlToBigInteger$5(jwk.q),
        dP: base64urlToBigInteger$5(jwk.dp),
        dQ: base64urlToBigInteger$5(jwk.dq),
        qInv: base64urlToBigInteger$5(jwk.qi)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}
// Convert a PKCIX in ASN1 DER format to a JWK key
function pkixToJwk$5(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const publicKey = forge$n.pki.publicKeyFromAsn1(asn1);
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$5(publicKey.n),
        e: bigIntegerToUintBase64url$5(publicKey.e)
    };
}
// Convert a JWK key to PKCIX in ASN1 DER format
function jwkToPkix$5(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.publicKeyToAsn1({
        n: base64urlToBigInteger$5(jwk.n),
        e: base64urlToBigInteger$5(jwk.e)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}

async function generateKey$g(bits) {
    const pair = await webcrypto$5.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey$5(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$8(key) {
    const privateKey = await webcrypto$5.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate$5(key)
    ];
    const keys = await exportKey$5({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$g(key, msg) {
    const privateKey = await webcrypto$5.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto$5.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, Uint8Array.from(msg));
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$g(key, sig, msg) {
    const publicKey = await webcrypto$5.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return webcrypto$5.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg);
}
async function exportKey$5(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return Promise.all([
        webcrypto$5.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto$5.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate$5(jwKey) {
    return webcrypto$5.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
/*

RSA encryption/decryption for the browser with webcrypto workaround
"bloody dark magic. webcrypto's why."

Explanation:
  - Convert JWK to nodeForge
  - Convert msg Uint8Array to nodeForge buffer: ByteBuffer is a "binary-string backed buffer", so let's make our Uint8Array a binary string
  - Convert resulting nodeForge buffer to Uint8Array: it returns a binary string, turn that into a Uint8Array

*/
function convertKey$5(key, pub, msg, handle) {
    const fkey = pub ? jwk2pub$5(key) : jwk2priv$5(key);
    const fmsg = toString$9(Uint8Array.from(msg), 'ascii');
    const fomsg = handle(fmsg, fkey);
    return fromString$3(fomsg, 'ascii');
}
function encrypt$5(key, msg) {
    return convertKey$5(key, true, msg, (msg, key) => key.encrypt(msg));
}
function decrypt$5(key, msg) {
    return convertKey$5(key, false, msg, (msg, key) => key.decrypt(msg));
}

let RsaPublicKey$5 = class RsaPublicKey {
    _key;
    constructor(key) {
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$g(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix$5(this._key);
    }
    get bytes() {
        return PublicKey$6.encode({
            Type: KeyType$6.RSA,
            Data: this.marshal()
        }).subarray();
    }
    encrypt(bytes) {
        return encrypt$5(this._key, bytes);
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$6.digest(this.bytes);
        return bytes;
    }
};
let RsaPrivateKey$5 = class RsaPrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes$5(16);
    }
    async sign(message) {
        return hashAndSign$g(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey$5(this._publicKey);
    }
    decrypt(bytes) {
        return decrypt$5(this._key, bytes);
    }
    marshal() {
        return jwkToPkcs1$5(this._key);
    }
    get bytes() {
        return PrivateKey$6.encode({
            Type: KeyType$6.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$6.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected PEM format
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            const buffer = new forge$n.util.ByteBuffer(this.marshal());
            const asn1 = forge$n.asn1.fromDer(buffer);
            const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
            const options = {
                algorithm: 'aes256',
                count: 10000,
                saltSize: 128 / 8,
                prfAlgorithm: 'sha512'
            };
            return forge$n.pki.encryptRsaPrivateKey(privateKey, password, options);
        }
        else if (format === 'libp2p-key') {
            return exporter$5(this.bytes, password);
        }
        else {
            throw new CodeError(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
async function unmarshalRsaPrivateKey$5(bytes) {
    const jwk = pkcs1ToJwk$5(bytes);
    const keys = await unmarshalPrivateKey$8(jwk);
    return new RsaPrivateKey$5(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey$5(bytes) {
    const jwk = pkixToJwk$5(bytes);
    return new RsaPublicKey$5(jwk);
}
async function fromJwk$5(jwk) {
    const keys = await unmarshalPrivateKey$8(jwk);
    return new RsaPrivateKey$5(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$i(bits) {
    const keys = await generateKey$g(bits);
    return new RsaPrivateKey$5(keys.privateKey, keys.publicKey);
}

var RSA$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    RsaPrivateKey: RsaPrivateKey$5,
    RsaPublicKey: RsaPublicKey$5,
    fromJwk: fromJwk$5,
    generateKeyPair: generateKeyPair$i,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey$5,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey$5
});

function generateKey$f() {
    return utils.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
async function hashAndSign$f(key, msg) {
    const { digest } = await sha256$6.digest(msg);
    try {
        return await sign$1(digest, key);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
async function hashAndVerify$f(key, sig, msg) {
    try {
        const { digest } = await sha256$6.digest(msg);
        return verify(sig, digest, key);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey$5(key) {
    const point = Point.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey$5(key) {
    try {
        getPublicKey(key, true);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey$5(key) {
    try {
        Point.fromHex(key);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey$5(privateKey) {
    try {
        return getPublicKey(privateKey, true);
    }
    catch (err) {
        throw new CodeError(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

let Secp256k1PublicKey$5 = class Secp256k1PublicKey {
    _key;
    constructor(key) {
        validatePublicKey$5(key);
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$f(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey$5(this._key);
    }
    get bytes() {
        return PublicKey$6.encode({
            Type: KeyType$6.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$6.digest(this.bytes);
        return bytes;
    }
};
let Secp256k1PrivateKey$5 = class Secp256k1PrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey$5(key);
        validatePrivateKey$5(this._key);
        validatePublicKey$5(this._publicKey);
    }
    async sign(message) {
        return hashAndSign$f(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey$5(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$6.encode({
            Type: KeyType$6.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$6.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$5(this.bytes, password);
        }
        else {
            throw new CodeError(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalSecp256k1PrivateKey$5(bytes) {
    return new Secp256k1PrivateKey$5(bytes);
}
function unmarshalSecp256k1PublicKey$5(bytes) {
    return new Secp256k1PublicKey$5(bytes);
}
async function generateKeyPair$h() {
    const privateKeyBytes = generateKey$f();
    return new Secp256k1PrivateKey$5(privateKeyBytes);
}

var Secp256k1$5 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey$5,
    Secp256k1PublicKey: Secp256k1PublicKey$5,
    generateKeyPair: generateKeyPair$h,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey$5,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey$5
});

const supportedKeys$5 = {
    rsa: RSA$5,
    ed25519: Ed25519$5,
    secp256k1: Secp256k1$5
};

function createPeerIdFromPublicKey(publicKey) {
    const _publicKey = new supportedKeys$5.secp256k1.Secp256k1PublicKey(publicKey);
    return peerIdFromKeys(_publicKey.bytes, undefined);
}

function decodeMultiaddrs(bytes) {
    const multiaddrs = [];
    let index = 0;
    while (index < bytes.length) {
        const sizeDataView = new DataView(bytes.buffer, index, MULTIADDR_LENGTH_SIZE);
        const size = sizeDataView.getUint16(0);
        index += MULTIADDR_LENGTH_SIZE;
        const multiaddrBytes = bytes.slice(index, index + size);
        index += size;
        multiaddrs.push(multiaddr$1(multiaddrBytes));
    }
    return multiaddrs;
}
function encodeMultiaddrs(multiaddrs) {
    const totalLength = multiaddrs.reduce((acc, ma) => acc + MULTIADDR_LENGTH_SIZE + ma.bytes.length, 0);
    const bytes = new Uint8Array(totalLength);
    const dataView = new DataView(bytes.buffer);
    let index = 0;
    multiaddrs.forEach((multiaddr) => {
        if (multiaddr.getPeerId())
            throw new Error("`multiaddr` field MUST not contain peer id");
        // Prepend the size of the next entry
        dataView.setUint16(index, multiaddr.bytes.length);
        index += MULTIADDR_LENGTH_SIZE;
        bytes.set(multiaddr.bytes, index);
        index += multiaddr.bytes.length;
    });
    return bytes;
}

function encodeWaku2(protocols) {
    let byte = 0;
    if (protocols.lightPush)
        byte += 1;
    byte = byte << 1;
    if (protocols.filter)
        byte += 1;
    byte = byte << 1;
    if (protocols.store)
        byte += 1;
    byte = byte << 1;
    if (protocols.relay)
        byte += 1;
    return byte;
}
function decodeWaku2(byte) {
    const waku2 = {
        relay: false,
        store: false,
        filter: false,
        lightPush: false
    };
    if (byte % 2)
        waku2.relay = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.store = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.filter = true;
    byte = byte >> 1;
    if (byte % 2)
        waku2.lightPush = true;
    return waku2;
}

class RawEnr extends Map {
    seq;
    signature;
    constructor(kvs = {}, seq = BigInt(1), signature) {
        super(Object.entries(kvs));
        this.seq = seq;
        this.signature = signature;
    }
    set(k, v) {
        this.signature = undefined;
        this.seq++;
        return super.set(k, v);
    }
    get id() {
        const id = this.get("id");
        if (!id)
            throw new Error("id not found.");
        return bytesToUtf8(id);
    }
    get publicKey() {
        switch (this.id) {
            case "v4":
                return this.get("secp256k1");
            default:
                throw new Error(ERR_INVALID_ID);
        }
    }
    get ip() {
        return getStringValue(this, "ip", "ip4");
    }
    set ip(ip) {
        setStringValue(this, "ip", "ip4", ip);
    }
    get tcp() {
        return getNumberAsStringValue(this, "tcp", "tcp");
    }
    set tcp(port) {
        setNumberAsStringValue(this, "tcp", "tcp", port);
    }
    get udp() {
        return getNumberAsStringValue(this, "udp", "udp");
    }
    set udp(port) {
        setNumberAsStringValue(this, "udp", "udp", port);
    }
    get ip6() {
        return getStringValue(this, "ip6", "ip6");
    }
    set ip6(ip) {
        setStringValue(this, "ip6", "ip6", ip);
    }
    get tcp6() {
        return getNumberAsStringValue(this, "tcp6", "tcp");
    }
    set tcp6(port) {
        setNumberAsStringValue(this, "tcp6", "tcp", port);
    }
    get udp6() {
        return getNumberAsStringValue(this, "udp6", "udp");
    }
    set udp6(port) {
        setNumberAsStringValue(this, "udp6", "udp", port);
    }
    /**
     * Get the `multiaddrs` field from ENR.
     *
     * This field is used to store multiaddresses that cannot be stored with the current ENR pre-defined keys.
     * These can be a multiaddresses that include encapsulation (e.g. wss) or do not use `ip4` nor `ip6` for the host
     * address (e.g. `dns4`, `dnsaddr`, etc)..
     *
     * If the peer information only contains information that can be represented with the ENR pre-defined keys
     * (ip, tcp, etc) then the usage of { @link ENR.getLocationMultiaddr } should be preferred.
     *
     * The multiaddresses stored in this field are expected to be location multiaddresses, ie, peer id less.
     */
    get multiaddrs() {
        const raw = this.get("multiaddrs");
        if (raw)
            return decodeMultiaddrs(raw);
        return;
    }
    /**
     * Set the `multiaddrs` field on the ENR.
     *
     * This field is used to store multiaddresses that cannot be stored with the current ENR pre-defined keys.
     * These can be a multiaddresses that include encapsulation (e.g. wss) or do not use `ip4` nor `ip6` for the host
     * address (e.g. `dns4`, `dnsaddr`, etc)..
     *
     * If the peer information only contains information that can be represented with the ENR pre-defined keys
     * (ip, tcp, etc) then the usage of { @link ENR.setLocationMultiaddr } should be preferred.
     * The multiaddresses stored in this field must be location multiaddresses,
     * ie, without a peer id.
     */
    set multiaddrs(multiaddrs) {
        deleteUndefined(this, "multiaddrs", multiaddrs, encodeMultiaddrs);
    }
    /**
     * Get the `waku2` field from ENR.
     */
    get waku2() {
        const raw = this.get("waku2");
        if (raw)
            return decodeWaku2(raw[0]);
        return;
    }
    /**
     * Set the `waku2` field on the ENR.
     */
    set waku2(waku2) {
        deleteUndefined(this, "waku2", waku2, (w) => new Uint8Array([encodeWaku2(w)]));
    }
}
function getStringValue(map, key, proto) {
    const raw = map.get(key);
    if (!raw)
        return;
    return convertToString$1(proto, raw);
}
function getNumberAsStringValue(map, key, proto) {
    const raw = map.get(key);
    if (!raw)
        return;
    return Number(convertToString$1(proto, raw));
}
function setStringValue(map, key, proto, value) {
    deleteUndefined(map, key, value, convertToBytes$1.bind({}, proto));
}
function setNumberAsStringValue(map, key, proto, value) {
    setStringValue(map, key, proto, value?.toString(10));
}
function deleteUndefined(map, key, value, transform) {
    if (value !== undefined) {
        map.set(key, transform(value));
    }
    else {
        map.delete(key);
    }
}

async function sign(privKey, msg) {
    return sign$1(keccak256(msg), privKey, {
        der: false
    });
}
function nodeId(pubKey) {
    const publicKey = Point.fromHex(pubKey);
    const uncompressedPubkey = publicKey.toRawBytes(false);
    return bytesToHex$3(keccak256(uncompressedPubkey.slice(1)));
}

const log$v = debug("waku:enr");
var TransportProtocol;
(function (TransportProtocol) {
    TransportProtocol["TCP"] = "tcp";
    TransportProtocol["UDP"] = "udp";
})(TransportProtocol || (TransportProtocol = {}));
var TransportProtocolPerIpVersion;
(function (TransportProtocolPerIpVersion) {
    TransportProtocolPerIpVersion["TCP4"] = "tcp4";
    TransportProtocolPerIpVersion["UDP4"] = "udp4";
    TransportProtocolPerIpVersion["TCP6"] = "tcp6";
    TransportProtocolPerIpVersion["UDP6"] = "udp6";
})(TransportProtocolPerIpVersion || (TransportProtocolPerIpVersion = {}));
class ENR extends RawEnr {
    static RECORD_PREFIX = "enr:";
    peerId;
    static async create(kvs = {}, seq = BigInt(1), signature) {
        const enr = new ENR(kvs, seq, signature);
        try {
            const publicKey = enr.publicKey;
            if (publicKey) {
                enr.peerId = await createPeerIdFromPublicKey(publicKey);
            }
        }
        catch (e) {
            log$v("Could not calculate peer id for ENR", e);
        }
        return enr;
    }
    get nodeId() {
        switch (this.id) {
            case "v4":
                return this.publicKey ? nodeId(this.publicKey) : undefined;
            default:
                throw new Error(ERR_INVALID_ID);
        }
    }
    getLocationMultiaddr = locationMultiaddrFromEnrFields.bind({}, this);
    setLocationMultiaddr(multiaddr) {
        const protoNames = multiaddr.protoNames();
        if (protoNames.length !== 2 &&
            protoNames[1] !== "udp" &&
            protoNames[1] !== "tcp") {
            throw new Error("Invalid multiaddr");
        }
        const tuples = multiaddr.tuples();
        if (!tuples[0][1] || !tuples[1][1]) {
            throw new Error("Invalid multiaddr");
        }
        // IPv4
        if (tuples[0][0] === 4) {
            this.set("ip", tuples[0][1]);
            this.set(protoNames[1], tuples[1][1]);
        }
        else {
            this.set("ip6", tuples[0][1]);
            this.set(protoNames[1] + "6", tuples[1][1]);
        }
    }
    getAllLocationMultiaddrs() {
        const multiaddrs = [];
        for (const protocol of Object.values(TransportProtocolPerIpVersion)) {
            const ma = this.getLocationMultiaddr(protocol);
            if (ma)
                multiaddrs.push(ma);
        }
        const _multiaddrs = this.multiaddrs ?? [];
        return multiaddrs.concat(_multiaddrs);
    }
    get peerInfo() {
        const id = this.peerId;
        if (!id)
            return;
        return {
            id,
            multiaddrs: this.getAllLocationMultiaddrs(),
            protocols: []
        };
    }
    /**
     * Returns the full multiaddr from the ENR fields matching the provided
     * `protocol` parameter.
     * To return full multiaddrs from the `multiaddrs` ENR field,
     * use { @link ENR.getFullMultiaddrs }.
     *
     * @param protocol
     */
    getFullMultiaddr(protocol) {
        if (this.peerId) {
            const locationMultiaddr = this.getLocationMultiaddr(protocol);
            if (locationMultiaddr) {
                return locationMultiaddr.encapsulate(`/p2p/${this.peerId.toString()}`);
            }
        }
        return;
    }
    /**
     * Returns the full multiaddrs from the `multiaddrs` ENR field.
     */
    getFullMultiaddrs() {
        if (this.peerId && this.multiaddrs) {
            const peerId = this.peerId;
            return this.multiaddrs.map((ma) => {
                return ma.encapsulate(`/p2p/${peerId.toString()}`);
            });
        }
        return [];
    }
    verify(data, signature) {
        if (!this.get("id") || this.id !== "v4") {
            throw new Error(ERR_INVALID_ID);
        }
        if (!this.publicKey) {
            throw new Error("Failed to verify ENR: No public key");
        }
        return verifySignature(signature, keccak256(data), this.publicKey);
    }
    async sign(data, privateKey) {
        switch (this.id) {
            case "v4":
                this.signature = await sign(privateKey, data);
                break;
            default:
                throw new Error(ERR_INVALID_ID);
        }
        return this.signature;
    }
}

const version$3 = "logger/5.7.0";

let _permanentCensorErrors = false;
let _censorErrors = false;
const LogLevels = { debug: 1, "default": 2, info: 2, warning: 3, error: 4, off: 5 };
let _logLevel = LogLevels["default"];
let _globalLogger = null;
function _checkNormalize() {
    try {
        const missing = [];
        // Make sure all forms of normalization are supported
        ["NFD", "NFC", "NFKD", "NFKC"].forEach((form) => {
            try {
                if ("test".normalize(form) !== "test") {
                    throw new Error("bad normalize");
                }
                ;
            }
            catch (error) {
                missing.push(form);
            }
        });
        if (missing.length) {
            throw new Error("missing " + missing.join(", "));
        }
        if (String.fromCharCode(0xe9).normalize("NFD") !== String.fromCharCode(0x65, 0x0301)) {
            throw new Error("broken implementation");
        }
    }
    catch (error) {
        return error.message;
    }
    return null;
}
const _normalizeError = _checkNormalize();
var LogLevel;
(function (LogLevel) {
    LogLevel["DEBUG"] = "DEBUG";
    LogLevel["INFO"] = "INFO";
    LogLevel["WARNING"] = "WARNING";
    LogLevel["ERROR"] = "ERROR";
    LogLevel["OFF"] = "OFF";
})(LogLevel || (LogLevel = {}));
var ErrorCode;
(function (ErrorCode) {
    ///////////////////
    // Generic Errors
    // Unknown Error
    ErrorCode["UNKNOWN_ERROR"] = "UNKNOWN_ERROR";
    // Not Implemented
    ErrorCode["NOT_IMPLEMENTED"] = "NOT_IMPLEMENTED";
    // Unsupported Operation
    //   - operation
    ErrorCode["UNSUPPORTED_OPERATION"] = "UNSUPPORTED_OPERATION";
    // Network Error (i.e. Ethereum Network, such as an invalid chain ID)
    //   - event ("noNetwork" is not re-thrown in provider.ready; otherwise thrown)
    ErrorCode["NETWORK_ERROR"] = "NETWORK_ERROR";
    // Some sort of bad response from the server
    ErrorCode["SERVER_ERROR"] = "SERVER_ERROR";
    // Timeout
    ErrorCode["TIMEOUT"] = "TIMEOUT";
    ///////////////////
    // Operational  Errors
    // Buffer Overrun
    ErrorCode["BUFFER_OVERRUN"] = "BUFFER_OVERRUN";
    // Numeric Fault
    //   - operation: the operation being executed
    //   - fault: the reason this faulted
    ErrorCode["NUMERIC_FAULT"] = "NUMERIC_FAULT";
    ///////////////////
    // Argument Errors
    // Missing new operator to an object
    //  - name: The name of the class
    ErrorCode["MISSING_NEW"] = "MISSING_NEW";
    // Invalid argument (e.g. value is incompatible with type) to a function:
    //   - argument: The argument name that was invalid
    //   - value: The value of the argument
    ErrorCode["INVALID_ARGUMENT"] = "INVALID_ARGUMENT";
    // Missing argument to a function:
    //   - count: The number of arguments received
    //   - expectedCount: The number of arguments expected
    ErrorCode["MISSING_ARGUMENT"] = "MISSING_ARGUMENT";
    // Too many arguments
    //   - count: The number of arguments received
    //   - expectedCount: The number of arguments expected
    ErrorCode["UNEXPECTED_ARGUMENT"] = "UNEXPECTED_ARGUMENT";
    ///////////////////
    // Blockchain Errors
    // Call exception
    //  - transaction: the transaction
    //  - address?: the contract address
    //  - args?: The arguments passed into the function
    //  - method?: The Solidity method signature
    //  - errorSignature?: The EIP848 error signature
    //  - errorArgs?: The EIP848 error parameters
    //  - reason: The reason (only for EIP848 "Error(string)")
    ErrorCode["CALL_EXCEPTION"] = "CALL_EXCEPTION";
    // Insufficient funds (< value + gasLimit * gasPrice)
    //   - transaction: the transaction attempted
    ErrorCode["INSUFFICIENT_FUNDS"] = "INSUFFICIENT_FUNDS";
    // Nonce has already been used
    //   - transaction: the transaction attempted
    ErrorCode["NONCE_EXPIRED"] = "NONCE_EXPIRED";
    // The replacement fee for the transaction is too low
    //   - transaction: the transaction attempted
    ErrorCode["REPLACEMENT_UNDERPRICED"] = "REPLACEMENT_UNDERPRICED";
    // The gas limit could not be estimated
    //   - transaction: the transaction passed to estimateGas
    ErrorCode["UNPREDICTABLE_GAS_LIMIT"] = "UNPREDICTABLE_GAS_LIMIT";
    // The transaction was replaced by one with a higher gas price
    //   - reason: "cancelled", "replaced" or "repriced"
    //   - cancelled: true if reason == "cancelled" or reason == "replaced")
    //   - hash: original transaction hash
    //   - replacement: the full TransactionsResponse for the replacement
    //   - receipt: the receipt of the replacement
    ErrorCode["TRANSACTION_REPLACED"] = "TRANSACTION_REPLACED";
    ///////////////////
    // Interaction Errors
    // The user rejected the action, such as signing a message or sending
    // a transaction
    ErrorCode["ACTION_REJECTED"] = "ACTION_REJECTED";
})(ErrorCode || (ErrorCode = {}));
const HEX = "0123456789abcdef";
class Logger {
    constructor(version) {
        Object.defineProperty(this, "version", {
            enumerable: true,
            value: version,
            writable: false
        });
    }
    _log(logLevel, args) {
        const level = logLevel.toLowerCase();
        if (LogLevels[level] == null) {
            this.throwArgumentError("invalid log level name", "logLevel", logLevel);
        }
        if (_logLevel > LogLevels[level]) {
            return;
        }
        console.log.apply(console, args);
    }
    debug(...args) {
        this._log(Logger.levels.DEBUG, args);
    }
    info(...args) {
        this._log(Logger.levels.INFO, args);
    }
    warn(...args) {
        this._log(Logger.levels.WARNING, args);
    }
    makeError(message, code, params) {
        // Errors are being censored
        if (_censorErrors) {
            return this.makeError("censored error", code, {});
        }
        if (!code) {
            code = Logger.errors.UNKNOWN_ERROR;
        }
        if (!params) {
            params = {};
        }
        const messageDetails = [];
        Object.keys(params).forEach((key) => {
            const value = params[key];
            try {
                if (value instanceof Uint8Array) {
                    let hex = "";
                    for (let i = 0; i < value.length; i++) {
                        hex += HEX[value[i] >> 4];
                        hex += HEX[value[i] & 0x0f];
                    }
                    messageDetails.push(key + "=Uint8Array(0x" + hex + ")");
                }
                else {
                    messageDetails.push(key + "=" + JSON.stringify(value));
                }
            }
            catch (error) {
                messageDetails.push(key + "=" + JSON.stringify(params[key].toString()));
            }
        });
        messageDetails.push(`code=${code}`);
        messageDetails.push(`version=${this.version}`);
        const reason = message;
        let url = "";
        switch (code) {
            case ErrorCode.NUMERIC_FAULT: {
                url = "NUMERIC_FAULT";
                const fault = message;
                switch (fault) {
                    case "overflow":
                    case "underflow":
                    case "division-by-zero":
                        url += "-" + fault;
                        break;
                    case "negative-power":
                    case "negative-width":
                        url += "-unsupported";
                        break;
                    case "unbound-bitwise-result":
                        url += "-unbound-result";
                        break;
                }
                break;
            }
            case ErrorCode.CALL_EXCEPTION:
            case ErrorCode.INSUFFICIENT_FUNDS:
            case ErrorCode.MISSING_NEW:
            case ErrorCode.NONCE_EXPIRED:
            case ErrorCode.REPLACEMENT_UNDERPRICED:
            case ErrorCode.TRANSACTION_REPLACED:
            case ErrorCode.UNPREDICTABLE_GAS_LIMIT:
                url = code;
                break;
        }
        if (url) {
            message += " [ See: https:/\/links.ethers.org/v5-errors-" + url + " ]";
        }
        if (messageDetails.length) {
            message += " (" + messageDetails.join(", ") + ")";
        }
        // @TODO: Any??
        const error = new Error(message);
        error.reason = reason;
        error.code = code;
        Object.keys(params).forEach(function (key) {
            error[key] = params[key];
        });
        return error;
    }
    throwError(message, code, params) {
        throw this.makeError(message, code, params);
    }
    throwArgumentError(message, name, value) {
        return this.throwError(message, Logger.errors.INVALID_ARGUMENT, {
            argument: name,
            value: value
        });
    }
    assert(condition, message, code, params) {
        if (!!condition) {
            return;
        }
        this.throwError(message, code, params);
    }
    assertArgument(condition, message, name, value) {
        if (!!condition) {
            return;
        }
        this.throwArgumentError(message, name, value);
    }
    checkNormalize(message) {
        if (_normalizeError) {
            this.throwError("platform missing String.prototype.normalize", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "String.prototype.normalize", form: _normalizeError
            });
        }
    }
    checkSafeUint53(value, message) {
        if (typeof (value) !== "number") {
            return;
        }
        if (message == null) {
            message = "value not safe";
        }
        if (value < 0 || value >= 0x1fffffffffffff) {
            this.throwError(message, Logger.errors.NUMERIC_FAULT, {
                operation: "checkSafeInteger",
                fault: "out-of-safe-range",
                value: value
            });
        }
        if (value % 1) {
            this.throwError(message, Logger.errors.NUMERIC_FAULT, {
                operation: "checkSafeInteger",
                fault: "non-integer",
                value: value
            });
        }
    }
    checkArgumentCount(count, expectedCount, message) {
        if (message) {
            message = ": " + message;
        }
        else {
            message = "";
        }
        if (count < expectedCount) {
            this.throwError("missing argument" + message, Logger.errors.MISSING_ARGUMENT, {
                count: count,
                expectedCount: expectedCount
            });
        }
        if (count > expectedCount) {
            this.throwError("too many arguments" + message, Logger.errors.UNEXPECTED_ARGUMENT, {
                count: count,
                expectedCount: expectedCount
            });
        }
    }
    checkNew(target, kind) {
        if (target === Object || target == null) {
            this.throwError("missing new", Logger.errors.MISSING_NEW, { name: kind.name });
        }
    }
    checkAbstract(target, kind) {
        if (target === kind) {
            this.throwError("cannot instantiate abstract class " + JSON.stringify(kind.name) + " directly; use a sub-class", Logger.errors.UNSUPPORTED_OPERATION, { name: target.name, operation: "new" });
        }
        else if (target === Object || target == null) {
            this.throwError("missing new", Logger.errors.MISSING_NEW, { name: kind.name });
        }
    }
    static globalLogger() {
        if (!_globalLogger) {
            _globalLogger = new Logger(version$3);
        }
        return _globalLogger;
    }
    static setCensorship(censorship, permanent) {
        if (!censorship && permanent) {
            this.globalLogger().throwError("cannot permanently disable censorship", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "setCensorship"
            });
        }
        if (_permanentCensorErrors) {
            if (!censorship) {
                return;
            }
            this.globalLogger().throwError("error censorship permanent", Logger.errors.UNSUPPORTED_OPERATION, {
                operation: "setCensorship"
            });
        }
        _censorErrors = !!censorship;
        _permanentCensorErrors = !!permanent;
    }
    static setLogLevel(logLevel) {
        const level = LogLevels[logLevel.toLowerCase()];
        if (level == null) {
            Logger.globalLogger().warn("invalid log level - " + logLevel);
            return;
        }
        _logLevel = level;
    }
    static from(version) {
        return new Logger(version);
    }
}
Logger.errors = ErrorCode;
Logger.levels = LogLevel;

const version$2 = "bytes/5.7.0";

const logger$6 = new Logger(version$2);
///////////////////////////////
function isHexable(value) {
    return !!(value.toHexString);
}
function addSlice(array) {
    if (array.slice) {
        return array;
    }
    array.slice = function () {
        const args = Array.prototype.slice.call(arguments);
        return addSlice(new Uint8Array(Array.prototype.slice.apply(array, args)));
    };
    return array;
}
function isBytesLike(value) {
    return ((isHexString(value) && !(value.length % 2)) || isBytes(value));
}
function isInteger(value) {
    return (typeof (value) === "number" && value == value && (value % 1) === 0);
}
function isBytes(value) {
    if (value == null) {
        return false;
    }
    if (value.constructor === Uint8Array) {
        return true;
    }
    if (typeof (value) === "string") {
        return false;
    }
    if (!isInteger(value.length) || value.length < 0) {
        return false;
    }
    for (let i = 0; i < value.length; i++) {
        const v = value[i];
        if (!isInteger(v) || v < 0 || v >= 256) {
            return false;
        }
    }
    return true;
}
function arrayify(value, options) {
    if (!options) {
        options = {};
    }
    if (typeof (value) === "number") {
        logger$6.checkSafeUint53(value, "invalid arrayify value");
        const result = [];
        while (value) {
            result.unshift(value & 0xff);
            value = parseInt(String(value / 256));
        }
        if (result.length === 0) {
            result.push(0);
        }
        return addSlice(new Uint8Array(result));
    }
    if (options.allowMissingPrefix && typeof (value) === "string" && value.substring(0, 2) !== "0x") {
        value = "0x" + value;
    }
    if (isHexable(value)) {
        value = value.toHexString();
    }
    if (isHexString(value)) {
        let hex = value.substring(2);
        if (hex.length % 2) {
            if (options.hexPad === "left") {
                hex = "0" + hex;
            }
            else if (options.hexPad === "right") {
                hex += "0";
            }
            else {
                logger$6.throwArgumentError("hex data is odd-length", "value", value);
            }
        }
        const result = [];
        for (let i = 0; i < hex.length; i += 2) {
            result.push(parseInt(hex.substring(i, i + 2), 16));
        }
        return addSlice(new Uint8Array(result));
    }
    if (isBytes(value)) {
        return addSlice(new Uint8Array(value));
    }
    return logger$6.throwArgumentError("invalid arrayify value", "value", value);
}
function isHexString(value, length) {
    if (typeof (value) !== "string" || !value.match(/^0x[0-9A-Fa-f]*$/)) {
        return false;
    }
    if (length && value.length !== 2 + 2 * length) {
        return false;
    }
    return true;
}
const HexCharacters = "0123456789abcdef";
function hexlify(value, options) {
    if (!options) {
        options = {};
    }
    if (typeof (value) === "number") {
        logger$6.checkSafeUint53(value, "invalid hexlify value");
        let hex = "";
        while (value) {
            hex = HexCharacters[value & 0xf] + hex;
            value = Math.floor(value / 16);
        }
        if (hex.length) {
            if (hex.length % 2) {
                hex = "0" + hex;
            }
            return "0x" + hex;
        }
        return "0x00";
    }
    if (typeof (value) === "bigint") {
        value = value.toString(16);
        if (value.length % 2) {
            return ("0x0" + value);
        }
        return "0x" + value;
    }
    if (options.allowMissingPrefix && typeof (value) === "string" && value.substring(0, 2) !== "0x") {
        value = "0x" + value;
    }
    if (isHexable(value)) {
        return value.toHexString();
    }
    if (isHexString(value)) {
        if (value.length % 2) {
            if (options.hexPad === "left") {
                value = "0x0" + value.substring(2);
            }
            else if (options.hexPad === "right") {
                value += "0";
            }
            else {
                logger$6.throwArgumentError("hex data is odd-length", "value", value);
            }
        }
        return value.toLowerCase();
    }
    if (isBytes(value)) {
        let result = "0x";
        for (let i = 0; i < value.length; i++) {
            let v = value[i];
            result += HexCharacters[(v & 0xf0) >> 4] + HexCharacters[v & 0x0f];
        }
        return result;
    }
    return logger$6.throwArgumentError("invalid hexlify value", "value", value);
}

const version$1 = "rlp/5.7.0";

const logger$5 = new Logger(version$1);
function arrayifyInteger(value) {
    const result = [];
    while (value) {
        result.unshift(value & 0xff);
        value >>= 8;
    }
    return result;
}
function unarrayifyInteger(data, offset, length) {
    let result = 0;
    for (let i = 0; i < length; i++) {
        result = (result * 256) + data[offset + i];
    }
    return result;
}
function _encode(object) {
    if (Array.isArray(object)) {
        let payload = [];
        object.forEach(function (child) {
            payload = payload.concat(_encode(child));
        });
        if (payload.length <= 55) {
            payload.unshift(0xc0 + payload.length);
            return payload;
        }
        const length = arrayifyInteger(payload.length);
        length.unshift(0xf7 + length.length);
        return length.concat(payload);
    }
    if (!isBytesLike(object)) {
        logger$5.throwArgumentError("RLP object must be BytesLike", "object", object);
    }
    const data = Array.prototype.slice.call(arrayify(object));
    if (data.length === 1 && data[0] <= 0x7f) {
        return data;
    }
    else if (data.length <= 55) {
        data.unshift(0x80 + data.length);
        return data;
    }
    const length = arrayifyInteger(data.length);
    length.unshift(0xb7 + length.length);
    return length.concat(data);
}
function encode$m(object) {
    return hexlify(_encode(object));
}
function _decodeChildren(data, offset, childOffset, length) {
    const result = [];
    while (childOffset < offset + 1 + length) {
        const decoded = _decode(data, childOffset);
        result.push(decoded.result);
        childOffset += decoded.consumed;
        if (childOffset > offset + 1 + length) {
            logger$5.throwError("child data too short", Logger.errors.BUFFER_OVERRUN, {});
        }
    }
    return { consumed: (1 + length), result: result };
}
// returns { consumed: number, result: Object }
function _decode(data, offset) {
    if (data.length === 0) {
        logger$5.throwError("data too short", Logger.errors.BUFFER_OVERRUN, {});
    }
    // Array with extra length prefix
    if (data[offset] >= 0xf8) {
        const lengthLength = data[offset] - 0xf7;
        if (offset + 1 + lengthLength > data.length) {
            logger$5.throwError("data short segment too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const length = unarrayifyInteger(data, offset + 1, lengthLength);
        if (offset + 1 + lengthLength + length > data.length) {
            logger$5.throwError("data long segment too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        return _decodeChildren(data, offset, offset + 1 + lengthLength, lengthLength + length);
    }
    else if (data[offset] >= 0xc0) {
        const length = data[offset] - 0xc0;
        if (offset + 1 + length > data.length) {
            logger$5.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        return _decodeChildren(data, offset, offset + 1, length);
    }
    else if (data[offset] >= 0xb8) {
        const lengthLength = data[offset] - 0xb7;
        if (offset + 1 + lengthLength > data.length) {
            logger$5.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const length = unarrayifyInteger(data, offset + 1, lengthLength);
        if (offset + 1 + lengthLength + length > data.length) {
            logger$5.throwError("data array too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const result = hexlify(data.slice(offset + 1 + lengthLength, offset + 1 + lengthLength + length));
        return { consumed: (1 + lengthLength + length), result: result };
    }
    else if (data[offset] >= 0x80) {
        const length = data[offset] - 0x80;
        if (offset + 1 + length > data.length) {
            logger$5.throwError("data too short", Logger.errors.BUFFER_OVERRUN, {});
        }
        const result = hexlify(data.slice(offset + 1, offset + 1 + length));
        return { consumed: (1 + length), result: result };
    }
    return { consumed: 1, result: hexlify(data[offset]) };
}
function decode$g(data) {
    const bytes = arrayify(data);
    const decoded = _decode(bytes, 0);
    if (decoded.consumed !== bytes.length) {
        logger$5.throwArgumentError("invalid rlp data", "data", data);
    }
    return decoded.result;
}

class EnrDecoder {
    static fromString(encoded) {
        if (!encoded.startsWith(ENR.RECORD_PREFIX)) {
            throw new Error(`"string encoded ENR must start with '${ENR.RECORD_PREFIX}'`);
        }
        return EnrDecoder.fromRLP(fromString$3(encoded.slice(4), "base64url"));
    }
    static fromRLP(encoded) {
        const decoded = decode$g(encoded).map(hexToBytes$3);
        return fromValues(decoded);
    }
}
async function fromValues(values) {
    const { signature, seq, kvs } = checkValues(values);
    const obj = {};
    for (let i = 0; i < kvs.length; i += 2) {
        try {
            obj[bytesToUtf8(kvs[i])] = kvs[i + 1];
        }
        catch (e) {
            browserExports.log("Failed to decode ENR key to UTF-8, skipping it", kvs[i], e);
        }
    }
    const _seq = decodeSeq(seq);
    const enr = await ENR.create(obj, _seq, signature);
    checkSignature(seq, kvs, enr, signature);
    return enr;
}
function decodeSeq(seq) {
    // If seq is an empty array, translate as value 0
    if (!seq.length)
        return BigInt(0);
    return BigInt("0x" + bytesToHex$3(seq));
}
function checkValues(values) {
    if (!Array.isArray(values)) {
        throw new Error("Decoded ENR must be an array");
    }
    if (values.length % 2 !== 0) {
        throw new Error("Decoded ENR must have an even number of elements");
    }
    const [signature, seq, ...kvs] = values;
    if (!signature || Array.isArray(signature)) {
        throw new Error("Decoded ENR invalid signature: must be a byte array");
    }
    if (!seq || Array.isArray(seq)) {
        throw new Error("Decoded ENR invalid sequence number: must be a byte array");
    }
    return { signature, seq, kvs };
}
function checkSignature(seq, kvs, enr, signature) {
    const rlpEncodedBytes = hexToBytes$3(encode$m([seq, ...kvs]));
    if (!enr.verify(rlpEncodedBytes, signature)) {
        throw new Error("Unable to verify ENR signature");
    }
}

const v4Regex$1 = /^(\d{1,3}\.){3,3}\d{1,3}$/;
const v4Size = 4;
const v6Regex$1 = /^(::)?(((\d{1,3}\.){3}(\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?$/i;
const v6Size = 16;

const v4$1 = {
  name: 'v4',
  size: v4Size,
  isFormat: ip => v4Regex$1.test(ip),
  encode (ip, buff, offset) {
    offset = ~~offset;
    buff = buff || new Uint8Array(offset + v4Size);
    const max = ip.length;
    let n = 0;
    for (let i = 0; i < max;) {
      const c = ip.charCodeAt(i++);
      if (c === 46) { // "."
        buff[offset++] = n;
        n = 0;
      } else {
        n = n * 10 + (c - 48);
      }
    }
    buff[offset] = n;
    return buff
  },
  decode (buff, offset) {
    offset = ~~offset;
    return `${buff[offset++]}.${buff[offset++]}.${buff[offset++]}.${buff[offset]}`
  }
};

const v6$1 = {
  name: 'v6',
  size: v6Size,
  isFormat: ip => ip.length > 0 && v6Regex$1.test(ip),
  encode (ip, buff, offset) {
    offset = ~~offset;
    let end = offset + v6Size;
    let fill = -1;
    let hexN = 0;
    let decN = 0;
    let prevColon = true;
    let useDec = false;
    buff = buff || new Uint8Array(offset + v6Size);
    // Note: This algorithm needs to check if the offset
    // could exceed the buffer boundaries as it supports
    // non-standard compliant encodings that may go beyond
    // the boundary limits. if (offset < end) checks should
    // not be necessary...
    for (let i = 0; i < ip.length; i++) {
      let c = ip.charCodeAt(i);
      if (c === 58) { // :
        if (prevColon) {
          if (fill !== -1) {
            // Not Standard! (standard doesn't allow multiple ::)
            // We need to treat
            if (offset < end) buff[offset] = 0;
            if (offset < end - 1) buff[offset + 1] = 0;
            offset += 2;
          } else if (offset < end) {
            // :: in the middle
            fill = offset;
          }
        } else {
          // : ends the previous number
          if (useDec === true) {
            // Non-standard! (ipv4 should be at end only)
            // A ipv4 address should not be found anywhere else but at
            // the end. This codec also support putting characters
            // after the ipv4 address..
            if (offset < end) buff[offset] = decN;
            offset++;
          } else {
            if (offset < end) buff[offset] = hexN >> 8;
            if (offset < end - 1) buff[offset + 1] = hexN & 0xff;
            offset += 2;
          }
          hexN = 0;
          decN = 0;
        }
        prevColon = true;
        useDec = false;
      } else if (c === 46) { // . indicates IPV4 notation
        if (offset < end) buff[offset] = decN;
        offset++;
        decN = 0;
        hexN = 0;
        prevColon = false;
        useDec = true;
      } else {
        prevColon = false;
        if (c >= 97) {
          c -= 87; // a-f ... 97~102 -87 => 10~15
        } else if (c >= 65) {
          c -= 55; // A-F ... 65~70 -55 => 10~15
        } else {
          c -= 48; // 0-9 ... starting from charCode 48
          decN = decN * 10 + c;
        }
        // We don't know yet if its a dec or hex number
        hexN = (hexN << 4) + c;
      }
    }
    if (prevColon === false) {
      // Commiting last number
      if (useDec === true) {
        if (offset < end) buff[offset] = decN;
        offset++;
      } else {
        if (offset < end) buff[offset] = hexN >> 8;
        if (offset < end - 1) buff[offset + 1] = hexN & 0xff;
        offset += 2;
      }
    } else if (fill === 0) {
      // Not Standard! (standard doesn't allow multiple ::)
      // This means that a : was found at the start AND end which means the
      // end needs to be treated as 0 entry...
      if (offset < end) buff[offset] = 0;
      if (offset < end - 1) buff[offset + 1] = 0;
      offset += 2;
    } else if (fill !== -1) {
      // Non-standard! (standard doens't allow multiple ::)
      // Here we find that there has been a :: somewhere in the middle
      // and the end. To treat the end with priority we need to move all
      // written data two bytes to the right.
      offset += 2;
      for (let i = Math.min(offset - 1, end - 1); i >= fill + 2; i--) {
        buff[i] = buff[i - 2];
      }
      buff[fill] = 0;
      buff[fill + 1] = 0;
      fill = offset;
    }
    if (fill !== offset && fill !== -1) {
      // Move the written numbers to the end while filling the everything
      // "fill" to the bytes with zeros.
      if (offset > end - 2) {
        // Non Standard support, when the cursor exceeds bounds.
        offset = end - 2;
      }
      while (end > fill) {
        buff[--end] = offset < end && offset > fill ? buff[--offset] : 0;
      }
    } else {
      // Fill the rest with zeros
      while (offset < end) {
        buff[offset++] = 0;
      }
    }
    return buff
  },
  decode (buff, offset) {
    offset = ~~offset;
    let result = '';
    for (let i = 0; i < v6Size; i += 2) {
      if (i !== 0) {
        result += ':';
      }
      result += (buff[offset + i] << 8 | buff[offset + i + 1]).toString(16);
    }
    return result
      .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')
      .replace(/:{3,4}/, '::')
  }
};
function sizeOf (ip) {
  if (v4$1.isFormat(ip)) return v4$1.size
  if (v6$1.isFormat(ip)) return v6$1.size
  throw Error(`Invalid ip address: ${ip}`)
}

function familyOf (string) {
  return sizeOf(string) === v4$1.size ? 1 : 2
}

function encode$l (ip, buff, offset) {
  offset = ~~offset;
  const size = sizeOf(ip);
  if (typeof buff === 'function') {
    buff = buff(offset + size);
  }
  if (size === v4$1.size) {
    return v4$1.encode(ip, buff, offset)
  }
  return v6$1.encode(ip, buff, offset)
}

function decode$f (buff, offset, length) {
  offset = ~~offset;
  length = length || (buff.length - offset);
  if (length === v4$1.size) {
    return v4$1.decode(buff, offset, length)
  }
  if (length === v6$1.size) {
    return v6$1.decode(buff, offset, length)
  }
  throw Error(`Invalid buffer size needs to be ${v4$1.size} for v4 or ${v6$1.size} for v6.`)
}

function toString$4 (type) {
  switch (type) {
    case 1: return 'A'
    case 10: return 'NULL'
    case 28: return 'AAAA'
    case 18: return 'AFSDB'
    case 42: return 'APL'
    case 257: return 'CAA'
    case 60: return 'CDNSKEY'
    case 59: return 'CDS'
    case 37: return 'CERT'
    case 5: return 'CNAME'
    case 49: return 'DHCID'
    case 32769: return 'DLV'
    case 39: return 'DNAME'
    case 48: return 'DNSKEY'
    case 43: return 'DS'
    case 55: return 'HIP'
    case 13: return 'HINFO'
    case 45: return 'IPSECKEY'
    case 25: return 'KEY'
    case 36: return 'KX'
    case 29: return 'LOC'
    case 15: return 'MX'
    case 35: return 'NAPTR'
    case 2: return 'NS'
    case 47: return 'NSEC'
    case 50: return 'NSEC3'
    case 51: return 'NSEC3PARAM'
    case 12: return 'PTR'
    case 46: return 'RRSIG'
    case 17: return 'RP'
    case 24: return 'SIG'
    case 6: return 'SOA'
    case 99: return 'SPF'
    case 33: return 'SRV'
    case 44: return 'SSHFP'
    case 32768: return 'TA'
    case 249: return 'TKEY'
    case 52: return 'TLSA'
    case 250: return 'TSIG'
    case 16: return 'TXT'
    case 252: return 'AXFR'
    case 251: return 'IXFR'
    case 41: return 'OPT'
    case 255: return 'ANY'
  }
  return 'UNKNOWN_' + type
}

function toType (name) {
  switch (name.toUpperCase()) {
    case 'A': return 1
    case 'NULL': return 10
    case 'AAAA': return 28
    case 'AFSDB': return 18
    case 'APL': return 42
    case 'CAA': return 257
    case 'CDNSKEY': return 60
    case 'CDS': return 59
    case 'CERT': return 37
    case 'CNAME': return 5
    case 'DHCID': return 49
    case 'DLV': return 32769
    case 'DNAME': return 39
    case 'DNSKEY': return 48
    case 'DS': return 43
    case 'HIP': return 55
    case 'HINFO': return 13
    case 'IPSECKEY': return 45
    case 'KEY': return 25
    case 'KX': return 36
    case 'LOC': return 29
    case 'MX': return 15
    case 'NAPTR': return 35
    case 'NS': return 2
    case 'NSEC': return 47
    case 'NSEC3': return 50
    case 'NSEC3PARAM': return 51
    case 'PTR': return 12
    case 'RRSIG': return 46
    case 'RP': return 17
    case 'SIG': return 24
    case 'SOA': return 6
    case 'SPF': return 99
    case 'SRV': return 33
    case 'SSHFP': return 44
    case 'TA': return 32768
    case 'TKEY': return 249
    case 'TLSA': return 52
    case 'TSIG': return 250
    case 'TXT': return 16
    case 'AXFR': return 252
    case 'IXFR': return 251
    case 'OPT': return 41
    case 'ANY': return 255
    case '*': return 255
  }
  if (name.toUpperCase().startsWith('UNKNOWN_')) return parseInt(name.slice(8))
  return 0
}

/*
 * Traditional DNS header RCODEs (4-bits) defined by IANA in
 * https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml
 */

function toString$3 (rcode) {
  switch (rcode) {
    case 0: return 'NOERROR'
    case 1: return 'FORMERR'
    case 2: return 'SERVFAIL'
    case 3: return 'NXDOMAIN'
    case 4: return 'NOTIMP'
    case 5: return 'REFUSED'
    case 6: return 'YXDOMAIN'
    case 7: return 'YXRRSET'
    case 8: return 'NXRRSET'
    case 9: return 'NOTAUTH'
    case 10: return 'NOTZONE'
    case 11: return 'RCODE_11'
    case 12: return 'RCODE_12'
    case 13: return 'RCODE_13'
    case 14: return 'RCODE_14'
    case 15: return 'RCODE_15'
  }
  return 'RCODE_' + rcode
}

/*
 * Traditional DNS header OPCODEs (4-bits) defined by IANA in
 * https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-5
 */

function toString$2 (opcode) {
  switch (opcode) {
    case 0: return 'QUERY'
    case 1: return 'IQUERY'
    case 2: return 'STATUS'
    case 3: return 'OPCODE_3'
    case 4: return 'NOTIFY'
    case 5: return 'UPDATE'
    case 6: return 'OPCODE_6'
    case 7: return 'OPCODE_7'
    case 8: return 'OPCODE_8'
    case 9: return 'OPCODE_9'
    case 10: return 'OPCODE_10'
    case 11: return 'OPCODE_11'
    case 12: return 'OPCODE_12'
    case 13: return 'OPCODE_13'
    case 14: return 'OPCODE_14'
    case 15: return 'OPCODE_15'
  }
  return 'OPCODE_' + opcode
}

function toString$1 (klass) {
  switch (klass) {
    case 1: return 'IN'
    case 2: return 'CS'
    case 3: return 'CH'
    case 4: return 'HS'
    case 255: return 'ANY'
  }
  return 'UNKNOWN_' + klass
}

function toClass (name) {
  switch (name.toUpperCase()) {
    case 'IN': return 1
    case 'CS': return 2
    case 'CH': return 3
    case 'HS': return 4
    case 'ANY': return 255
  }
  return 0
}

function toString (type) {
  switch (type) {
    // list at
    // https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-11
    case 1: return 'LLQ'
    case 2: return 'UL'
    case 3: return 'NSID'
    case 5: return 'DAU'
    case 6: return 'DHU'
    case 7: return 'N3U'
    case 8: return 'CLIENT_SUBNET'
    case 9: return 'EXPIRE'
    case 10: return 'COOKIE'
    case 11: return 'TCP_KEEPALIVE'
    case 12: return 'PADDING'
    case 13: return 'CHAIN'
    case 14: return 'KEY_TAG'
    case 26946: return 'DEVICEID'
  }
  if (type < 0) {
    return null
  }
  return `OPTION_${type}`
}

function toCode (name) {
  if (typeof name === 'number') {
    return name
  }
  if (!name) {
    return -1
  }
  switch (name.toUpperCase()) {
    case 'OPTION_0': return 0
    case 'LLQ': return 1
    case 'UL': return 2
    case 'NSID': return 3
    case 'OPTION_4': return 4
    case 'DAU': return 5
    case 'DHU': return 6
    case 'N3U': return 7
    case 'CLIENT_SUBNET': return 8
    case 'EXPIRE': return 9
    case 'COOKIE': return 10
    case 'TCP_KEEPALIVE': return 11
    case 'PADDING': return 12
    case 'CHAIN': return 13
    case 'KEY_TAG': return 14
    case 'DEVICEID': return 26946
    case 'OPTION_65535': return 65535
  }
  const m = name.match(/_(\d+)$/);
  if (m) {
    return parseInt(m[1], 10)
  }
  return -1
}

const SURROGATE_A = 0b1101100000000000;
const SURROGATE_B = 0b1101110000000000;

function encodingLength$6 (str) {
  let len = 0;
  const strLen = str.length;
  for (let i = 0; i < strLen; i += 1) {
    const code = str.charCodeAt(i);
    if (code <= 0x7F) {
      len += 1;
    } else if (code <= 0x07FF) {
      len += 2;
    } else if ((code & 0xF800) !== SURROGATE_A) {
      len += 3;
    } else {
      const next = i + 1;
      if (next === strLen || code >= SURROGATE_B) {
        len += 3;
      } else {
        const nextCode = str.charCodeAt(next);
        if ((nextCode & 0xFC00) !== SURROGATE_B) {
          len += 3;
        } else {
          i = next;
          len += 4;
        }
      }
    }
  }
  return len
}

function encode$k (str, buf, offset) {
  const strLen = str.length;
  if (offset === undefined || offset === null) {
    offset = 0;
  }
  if (buf === undefined) {
    buf = new Uint8Array(encodingLength$6(str) + offset);
  }
  let off = offset;
  for (let i = 0; i < strLen; i += 1) {
    let code = str.charCodeAt(i);
    if (code <= 0x7F) {
      buf[off++] = code;
    } else if (code <= 0x07FF) {
      buf[off++] = 0b11000000 | ((code & 0b11111000000) >> 6);
      buf[off++] = 0b10000000 | (code & 0b00000111111);
    } else if ((code & 0xF800) !== SURROGATE_A) {
      buf[off++] = 0b11100000 | ((code & 0b1111000000000000) >> 12);
      buf[off++] = 0b10000000 | ((code & 0b0000111111000000) >> 6);
      buf[off++] = 0b10000000 | (code & 0b0000000000111111);
    } else {
      const next = i + 1;
      if (next === strLen || code >= SURROGATE_B) {
        // Incorrectly started surrogate pair
        buf[off++] = 0xef;
        buf[off++] = 0xbf;
        buf[off++] = 0xbd;
      } else {
        const nextCode = str.charCodeAt(next);
        if ((nextCode & 0xFC00) !== SURROGATE_B) {
          // Incorrect surrogate pair
          buf[off++] = 0xef;
          buf[off++] = 0xbf;
          buf[off++] = 0xbd;
        } else {
          i = next;
          code = 0b000010000000000000000 |
            ((code & 0b1111111111) << 10) |
            (nextCode & 0b1111111111);
          buf[off++] = 0b11110000 | ((code & 0b111000000000000000000) >> 18);
          buf[off++] = 0b10000000 | ((code & 0b000111111000000000000) >> 12);
          buf[off++] = 0b10000000 | ((code & 0b000000000111111000000) >> 6);
          buf[off++] = 0b10000000 | (code & 0b000000000000000111111);
        }
      }
    }
  }
  encode$k.bytes = off - offset;
  return buf
}
encode$k.bytes = 0;

function decode$e (buf, start, end) {
  let result = '';
  if (start === undefined || start === null) {
    start = 0;
  }
  if (end === undefined || end === null) {
    end = buf.length;
  }
  for (let offset = start; offset < end;) {
    const code = buf[offset++];
    let num;
    if (code <= 128) {
      num = code;
    } else if (code > 191 && code < 224) {
      num = ((code & 0b11111) << 6) | (buf[offset++] & 0b111111);
    } else if (code > 239 && code < 365) {
      num = (
        ((code & 0b111) << 18) |
        ((buf[offset++] & 0b111111) << 12) |
        ((buf[offset++] & 0b111111) << 6) |
        (buf[offset++] & 0b111111)
      ) - 0x10000;
      const numA = SURROGATE_A | ((num >> 10) & 0b1111111111);
      result += String.fromCharCode(numA);
      num = SURROGATE_B | (num & 0b1111111111);
    } else {
      num = ((code & 0b1111) << 12) |
        ((buf[offset++] & 0b111111) << 6) |
        (buf[offset++] & 0b111111);
    }
    result += String.fromCharCode(num);
  }
  decode$e.bytes = end - start;
  return result
}
decode$e.bytes = 0;

const isU8Arr = input => input instanceof Uint8Array;

function bytelength (input) {
  return typeof input === 'string' ? encodingLength$6(input) : input.byteLength
}

function from$d (input) {
  if (input instanceof Uint8Array) {
    return input
  }
  if (Array.isArray(input)) {
    return new Uint8Array(input)
  }
  return encode$k(input)
}

function write$1 (arr, str, start) {
  if (typeof str !== 'string') {
    throw new Error('unknown input type')
  }
  encode$k(str, arr, start);
  return encode$k.bytes
}

const P_24 = Math.pow(2, 24);
const P_16 = Math.pow(2, 16);
const P_8 = Math.pow(2, 8);
const readUInt32BE = (buf, offset) => buf[offset] * P_24 +
  buf[offset + 1] * P_16 +
  buf[offset + 2] * P_8 +
  buf[offset + 3];

const readUInt16BE = (buf, offset) => (buf[offset] << 8) | buf[offset + 1];
const writeUInt32BE = (buf, value, offset) => {
  value = +value;
  buf[offset + 3] = value;
  value = value >>> 8;
  buf[offset + 2] = value;
  value = value >>> 8;
  buf[offset + 1] = value;
  value = value >>> 8;
  buf[offset] = value;
  return offset + 4
};
const writeUInt16BE = (buf, value, offset) => {
  buf[offset] = value >> 8;
  buf[offset + 1] = value & 0xFF;
  return offset + 2
};

function copy (source, target, targetStart, sourceStart, sourceEnd) {
  if (targetStart < 0) {
    sourceStart -= targetStart;
    targetStart = 0;
  }

  if (sourceStart < 0) {
    sourceStart = 0;
  }

  if (sourceEnd < 0) {
    return new Uint8Array(0)
  }

  if (targetStart >= target.length || sourceStart >= sourceEnd) {
    return 0
  }

  return _copyActual(source, target, targetStart, sourceStart, sourceEnd)
}

function _copyActual (source, target, targetStart, sourceStart, sourceEnd) {
  if (sourceEnd - sourceStart > target.length - targetStart) {
    sourceEnd = sourceStart + target.length - targetStart;
  }

  let nb = sourceEnd - sourceStart;
  const sourceLen = source.length - sourceStart;
  if (nb > sourceLen) {
    nb = sourceLen;
  }

  if (sourceStart !== 0 || sourceEnd < source.length) {
    source = new Uint8Array(source.buffer, source.byteOffset + sourceStart, nb);
  }

  target.set(source, targetStart);

  return nb
}

const QUERY_FLAG = 0;
const RESPONSE_FLAG = 1 << 15;
const FLUSH_MASK = 1 << 15;
const NOT_FLUSH_MASK = ~FLUSH_MASK;
const QU_MASK = 1 << 15;
const NOT_QU_MASK = ~QU_MASK;

function codec ({ bytes = 0, encode, decode, encodingLength }) {
  encode.bytes = bytes;
  decode.bytes = bytes;
  return {
    encode,
    decode,
    encodingLength: encodingLength || (() => bytes)
  }
}

const name$5 = codec({
  encode (str, buf, offset) {
    if (!buf) buf = new Uint8Array(name$5.encodingLength(str));
    if (!offset) offset = 0;
    const oldOffset = offset;

    // strip leading and trailing .
    const n = str.replace(/^\.|\.$/gm, '');
    if (n.length) {
      const list = n.split('.');

      for (let i = 0; i < list.length; i++) {
        const len = write$1(buf, list[i], offset + 1);
        buf[offset] = len;
        offset += len + 1;
      }
    }

    buf[offset++] = 0;

    name$5.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const list = [];
    let oldOffset = offset;
    let totalLength = 0;
    let consumedBytes = 0;
    let jumped = false;

    while (true) {
      if (offset >= buf.length) {
        throw new Error('Cannot decode name (buffer overflow)')
      }
      const len = buf[offset++];
      consumedBytes += jumped ? 0 : 1;

      if (len === 0) {
        break
      } else if ((len & 0xc0) === 0) {
        if (offset + len > buf.length) {
          throw new Error('Cannot decode name (buffer overflow)')
        }
        totalLength += len + 1;
        if (totalLength > 254) {
          throw new Error('Cannot decode name (name too long)')
        }
        list.push(decode$e(buf, offset, offset + len));
        offset += len;
        consumedBytes += jumped ? 0 : len;
      } else if ((len & 0xc0) === 0xc0) {
        if (offset + 1 > buf.length) {
          throw new Error('Cannot decode name (buffer overflow)')
        }
        const jumpOffset = readUInt16BE(buf, offset - 1) - 0xc000;
        if (jumpOffset >= oldOffset) {
          // Allow only pointers to prior data. RFC 1035, section 4.1.4 states:
          // "[...] an entire domain name or a list of labels at the end of a domain name
          // is replaced with a pointer to a prior occurance (sic) of the same name."
          throw new Error('Cannot decode name (bad pointer)')
        }
        offset = jumpOffset;
        oldOffset = jumpOffset;
        consumedBytes += jumped ? 0 : 1;
        jumped = true;
      } else {
        throw new Error('Cannot decode name (bad label)')
      }
    }

    name$5.decode.bytes = consumedBytes;
    return list.length === 0 ? '.' : list.join('.')
  },
  encodingLength (n) {
    if (n === '.' || n === '..') return 1
    return bytelength(n.replace(/^\.|\.$/gm, '')) + 2
  }
});

const string = codec({
  encode (s, buf, offset) {
    if (!buf) buf = new Uint8Array(string.encodingLength(s));
    if (!offset) offset = 0;

    const len = write$1(buf, s, offset + 1);
    buf[offset] = len;
    string.encode.bytes = len + 1;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = buf[offset];
    const s = decode$e(buf, offset + 1, offset + 1 + len);
    string.decode.bytes = len + 1;
    return s
  },
  encodingLength (s) {
    return bytelength(s) + 1
  }
});

const header = codec({
  bytes: 12,
  encode (h, buf, offset) {
    if (!buf) buf = new Uint8Array(header.encodingLength(h));
    if (!offset) offset = 0;

    const flags = (h.flags || 0) & 32767;
    const type = h.type === 'response' ? RESPONSE_FLAG : QUERY_FLAG;

    writeUInt16BE(buf, h.id || 0, offset);
    writeUInt16BE(buf, flags | type, offset + 2);
    writeUInt16BE(buf, h.questions.length, offset + 4);
    writeUInt16BE(buf, h.answers.length, offset + 6);
    writeUInt16BE(buf, h.authorities.length, offset + 8);
    writeUInt16BE(buf, h.additionals.length, offset + 10);

    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    if (buf.length < 12) throw new Error('Header must be 12 bytes')
    const flags = readUInt16BE(buf, offset + 2);

    return {
      id: readUInt16BE(buf, offset),
      type: flags & RESPONSE_FLAG ? 'response' : 'query',
      flags: flags & 32767,
      flag_qr: ((flags >> 15) & 0x1) === 1,
      opcode: toString$2((flags >> 11) & 0xf),
      flag_aa: ((flags >> 10) & 0x1) === 1,
      flag_tc: ((flags >> 9) & 0x1) === 1,
      flag_rd: ((flags >> 8) & 0x1) === 1,
      flag_ra: ((flags >> 7) & 0x1) === 1,
      flag_z: ((flags >> 6) & 0x1) === 1,
      flag_ad: ((flags >> 5) & 0x1) === 1,
      flag_cd: ((flags >> 4) & 0x1) === 1,
      rcode: toString$3(flags & 0xf),
      questions: new Array(readUInt16BE(buf, offset + 4)),
      answers: new Array(readUInt16BE(buf, offset + 6)),
      authorities: new Array(readUInt16BE(buf, offset + 8)),
      additionals: new Array(readUInt16BE(buf, offset + 10))
    }
  },
  encodingLength () {
    return 12
  }
});

const runknown = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(runknown.encodingLength(data));
    if (!offset) offset = 0;

    const dLen = data.length;
    writeUInt16BE(buf, dLen, offset);
    copy(data, buf, offset + 2, 0, dLen);

    runknown.encode.bytes = dLen + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    const data = buf.slice(offset + 2, offset + 2 + len);
    runknown.decode.bytes = len + 2;
    return data
  },
  encodingLength (data) {
    return data.length + 2
  }
});

const rns = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rns.encodingLength(data));
    if (!offset) offset = 0;

    name$5.encode(data, buf, offset + 2);
    writeUInt16BE(buf, name$5.encode.bytes, offset);
    rns.encode.bytes = name$5.encode.bytes + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    const dd = name$5.decode(buf, offset + 2);

    rns.decode.bytes = len + 2;
    return dd
  },
  encodingLength (data) {
    return name$5.encodingLength(data) + 2
  }
});

const rsoa = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rsoa.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    name$5.encode(data.mname, buf, offset);
    offset += name$5.encode.bytes;
    name$5.encode(data.rname, buf, offset);
    offset += name$5.encode.bytes;
    writeUInt32BE(buf, data.serial || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.refresh || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.retry || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.expire || 0, offset);
    offset += 4;
    writeUInt32BE(buf, data.minimum || 0, offset);
    offset += 4;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rsoa.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.mname = name$5.decode(buf, offset);
    offset += name$5.decode.bytes;
    data.rname = name$5.decode(buf, offset);
    offset += name$5.decode.bytes;
    data.serial = readUInt32BE(buf, offset);
    offset += 4;
    data.refresh = readUInt32BE(buf, offset);
    offset += 4;
    data.retry = readUInt32BE(buf, offset);
    offset += 4;
    data.expire = readUInt32BE(buf, offset);
    offset += 4;
    data.minimum = readUInt32BE(buf, offset);
    offset += 4;

    rsoa.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 22 + name$5.encodingLength(data.mname) + name$5.encodingLength(data.rname)
  }
});

const rtxt = codec({
  encode (data, buf, offset) {
    if (!Array.isArray(data)) data = [data];
    for (let i = 0; i < data.length; i++) {
      if (typeof data[i] === 'string') {
        data[i] = from$d(data[i]);
      }
      if (!isU8Arr(data[i])) {
        throw new Error('Must be a Buffer')
      }
    }

    if (!buf) buf = new Uint8Array(rtxt.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;

    data.forEach(function (d) {
      buf[offset++] = d.length;
      copy(d, buf, offset, 0, d.length);
      offset += d.length;
    });

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rtxt.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;
    let remaining = readUInt16BE(buf, offset);
    offset += 2;

    const data = [];
    while (remaining > 0) {
      const len = buf[offset++];
      --remaining;
      if (remaining < len) {
        throw new Error('Buffer overflow')
      }
      data.push(buf.slice(offset, offset + len));
      offset += len;
      remaining -= len;
    }

    rtxt.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    if (!Array.isArray(data)) data = [data];
    let length = 2;
    data.forEach(function (buf) {
      if (typeof buf === 'string') {
        length += bytelength(buf) + 1;
      } else {
        length += buf.length + 1;
      }
    });
    return length
  }
});

const rnull = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rnull.encodingLength(data));
    if (!offset) offset = 0;

    if (typeof data === 'string') data = from$d(data);
    if (!data) data = new Uint8Array(0);

    const oldOffset = offset;
    offset += 2;

    const len = data.length;
    copy(data, buf, offset, 0, len);
    offset += len;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rnull.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;
    const len = readUInt16BE(buf, offset);

    offset += 2;

    const data = buf.slice(offset, offset + len);
    offset += len;

    rnull.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    if (!data) return 2
    return (isU8Arr(data) ? data.length : bytelength(data)) + 2
  }
});

const rhinfo = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rhinfo.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    string.encode(data.cpu, buf, offset);
    offset += string.encode.bytes;
    string.encode(data.os, buf, offset);
    offset += string.encode.bytes;
    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rhinfo.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.cpu = string.decode(buf, offset);
    offset += string.decode.bytes;
    data.os = string.decode(buf, offset);
    offset += string.decode.bytes;
    rhinfo.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return string.encodingLength(data.cpu) + string.encodingLength(data.os) + 2
  }
});

const rptr = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rptr.encodingLength(data));
    if (!offset) offset = 0;

    name$5.encode(data, buf, offset + 2);
    writeUInt16BE(buf, name$5.encode.bytes, offset);
    rptr.encode.bytes = name$5.encode.bytes + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const data = name$5.decode(buf, offset + 2);
    rptr.decode.bytes = name$5.decode.bytes + 2;
    return data
  },
  encodingLength (data) {
    return name$5.encodingLength(data) + 2
  }
});

const rsrv = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rsrv.encodingLength(data));
    if (!offset) offset = 0;

    writeUInt16BE(buf, data.priority || 0, offset + 2);
    writeUInt16BE(buf, data.weight || 0, offset + 4);
    writeUInt16BE(buf, data.port || 0, offset + 6);
    name$5.encode(data.target, buf, offset + 8);

    const len = name$5.encode.bytes + 6;
    writeUInt16BE(buf, len, offset);

    rsrv.encode.bytes = len + 2;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);

    const data = {};
    data.priority = readUInt16BE(buf, offset + 2);
    data.weight = readUInt16BE(buf, offset + 4);
    data.port = readUInt16BE(buf, offset + 6);
    data.target = name$5.decode(buf, offset + 8);

    rsrv.decode.bytes = len + 2;
    return data
  },
  encodingLength (data) {
    return 8 + name$5.encodingLength(data.target)
  }
});

const rcaa = codec({
  encode (data, buf, offset) {
    const len = rcaa.encodingLength(data);

    if (!buf) buf = new Uint8Array(rcaa.encodingLength(data));
    if (!offset) offset = 0;

    if (data.issuerCritical) {
      data.flags = rcaa.ISSUER_CRITICAL;
    }

    writeUInt16BE(buf, len - 2, offset);
    offset += 2;
    buf[offset] = data.flags || 0;
    offset += 1;
    string.encode(data.tag, buf, offset);
    offset += string.encode.bytes;
    write$1(buf, data.value, offset);
    offset += bytelength(data.value);

    rcaa.encode.bytes = len;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const len = readUInt16BE(buf, offset);
    offset += 2;

    const oldOffset = offset;
    const data = {};
    data.flags = buf[offset];
    offset += 1;
    data.tag = string.decode(buf, offset);
    offset += string.decode.bytes;
    data.value = decode$e(buf, offset, oldOffset + len);

    data.issuerCritical = !!(data.flags & rcaa.ISSUER_CRITICAL);

    rcaa.decode.bytes = len + 2;

    return data
  },
  encodingLength (data) {
    return string.encodingLength(data.tag) + string.encodingLength(data.value) + 2
  }
});

rcaa.ISSUER_CRITICAL = 1 << 7;

const rmx = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rmx.encodingLength(data));
    if (!offset) offset = 0;

    const oldOffset = offset;
    offset += 2;
    writeUInt16BE(buf, data.preference || 0, offset);
    offset += 2;
    name$5.encode(data.exchange, buf, offset);
    offset += name$5.encode.bytes;

    writeUInt16BE(buf, offset - oldOffset - 2, oldOffset);
    rmx.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.preference = readUInt16BE(buf, offset);
    offset += 2;
    data.exchange = name$5.decode(buf, offset);
    offset += name$5.decode.bytes;

    rmx.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 4 + name$5.encodingLength(data.exchange)
  }
});

const ra = codec({
  encode (host, buf, offset) {
    if (!buf) buf = new Uint8Array(ra.encodingLength(host));
    if (!offset) offset = 0;

    writeUInt16BE(buf, 4, offset);
    offset += 2;
    v4$1.encode(host, buf, offset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    offset += 2;
    const host = v4$1.decode(buf, offset);
    return host
  },
  bytes: 6
});

const raaaa = codec({
  encode (host, buf, offset) {
    if (!buf) buf = new Uint8Array(raaaa.encodingLength(host));
    if (!offset) offset = 0;

    writeUInt16BE(buf, 16, offset);
    offset += 2;
    v6$1.encode(host, buf, offset);
    raaaa.encode.bytes = 18;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    offset += 2;
    const host = v6$1.decode(buf, offset);
    raaaa.decode.bytes = 18;
    return host
  },
  bytes: 18
});

const alloc = size => new Uint8Array(size);

const roption = codec({
  encode (option, buf, offset) {
    if (!buf) buf = new Uint8Array(roption.encodingLength(option));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const code = toCode(option.code);
    writeUInt16BE(buf, code, offset);
    offset += 2;
    if (option.data) {
      writeUInt16BE(buf, option.data.length, offset);
      offset += 2;
      copy(option.data, buf, offset);
      offset += option.data.length;
    } else {
      switch (code) {
        // case 3: NSID.  No encode makes sense.
        // case 5,6,7: Not implementable
        case 8: // ECS
          {
            // note: do IP math before calling
            const spl = option.sourcePrefixLength || 0;
            const fam = option.family || familyOf(option.ip);
            const ipBuf = encode$l(option.ip, alloc);
            const ipLen = Math.ceil(spl / 8);
            writeUInt16BE(buf, ipLen + 4, offset);
            offset += 2;
            writeUInt16BE(buf, fam, offset);
            offset += 2;
            buf[offset++] = spl;
            buf[offset++] = option.scopePrefixLength || 0;

            copy(ipBuf, buf, offset, 0, ipLen);
            offset += ipLen;
          }
          break
        // case 9: EXPIRE (experimental)
        // case 10: COOKIE.  No encode makes sense.
        case 11: // KEEP-ALIVE
          if (option.timeout) {
            writeUInt16BE(buf, 2, offset);
            offset += 2;
            writeUInt16BE(buf, option.timeout, offset);
            offset += 2;
          } else {
            writeUInt16BE(buf, 0, offset);
            offset += 2;
          }
          break
        case 12: // PADDING
          {
            const len = option.length || 0;
            writeUInt16BE(buf, len, offset);
            offset += 2;
            buf.fill(0, offset, offset + len);
            offset += len;
          }
          break
        // case 13:  CHAIN.  Experimental.
        case 14: // KEY-TAG
          {
            const tagsLen = option.tags.length * 2;
            writeUInt16BE(buf, tagsLen, offset);
            offset += 2;
            for (const tag of option.tags) {
              writeUInt16BE(buf, tag, offset);
              offset += 2;
            }
          }
          break
        default:
          throw new Error(`Unknown roption code: ${option.code}`)
      }
    }

    roption.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const option = {};
    option.code = readUInt16BE(buf, offset);
    option.type = toString(option.code);
    offset += 2;
    const len = readUInt16BE(buf, offset);
    offset += 2;
    option.data = buf.slice(offset, offset + len);
    switch (option.code) {
      // case 3: NSID.  No decode makes sense.
      case 8: // ECS
        option.family = readUInt16BE(buf, offset);
        offset += 2;
        option.sourcePrefixLength = buf[offset++];
        option.scopePrefixLength = buf[offset++];
        {
          const padded = new Uint8Array((option.family === 1) ? 4 : 16);
          copy(buf, padded, 0, offset, offset + len - 4);
          option.ip = decode$f(padded);
        }
        break
      // case 12: Padding.  No decode makes sense.
      case 11: // KEEP-ALIVE
        if (len > 0) {
          option.timeout = readUInt16BE(buf, offset);
          offset += 2;
        }
        break
      case 14:
        option.tags = [];
        for (let i = 0; i < len; i += 2) {
          option.tags.push(readUInt16BE(buf, offset));
          offset += 2;
        }
      // don't worry about default.  caller will use data if desired
    }

    roption.decode.bytes = len + 4;
    return option
  },
  encodingLength (option) {
    if (option.data) {
      return option.data.length + 4
    }
    const code = toCode(option.code);
    switch (code) {
      case 8: // ECS
      {
        const spl = option.sourcePrefixLength || 0;
        return Math.ceil(spl / 8) + 8
      }
      case 11: // KEEP-ALIVE
        return (typeof option.timeout === 'number') ? 6 : 4
      case 12: // PADDING
        return option.length + 4
      case 14: // KEY-TAG
        return 4 + (option.tags.length * 2)
    }
    throw new Error(`Unknown roption code: ${option.code}`)
  }
});

const ropt = codec({
  encode (options, buf, offset) {
    if (!buf) buf = new Uint8Array(ropt.encodingLength(options));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const rdlen = encodingLengthList(options, roption);
    writeUInt16BE(buf, rdlen, offset);
    offset = encodeList(options, roption, buf, offset + 2);

    ropt.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const options = [];
    let rdlen = readUInt16BE(buf, offset);
    offset += 2;
    let o = 0;
    while (rdlen > 0) {
      options[o++] = roption.decode(buf, offset);
      offset += roption.decode.bytes;
      rdlen -= roption.decode.bytes;
    }
    ropt.decode.bytes = offset - oldOffset;
    return options
  },
  encodingLength (options) {
    return 2 + encodingLengthList(options || [], roption)
  }
});

const rdnskey = codec({
  encode (key, buf, offset) {
    if (!buf) buf = new Uint8Array(rdnskey.encodingLength(key));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const keydata = key.key;
    if (!isU8Arr(keydata)) {
      throw new Error('Key must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, key.flags, offset);
    offset += 2;
    buf[offset] = rdnskey.PROTOCOL_DNSSEC;
    offset += 1;
    buf[offset] = key.algorithm;
    offset += 1;
    copy(keydata, buf, offset, 0, keydata.length);
    offset += keydata.length;

    rdnskey.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rdnskey.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const key = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    key.flags = readUInt16BE(buf, offset);
    offset += 2;
    if (buf[offset] !== rdnskey.PROTOCOL_DNSSEC) {
      throw new Error('Protocol must be 3')
    }
    offset += 1;
    key.algorithm = buf[offset];
    offset += 1;
    key.key = buf.slice(offset, oldOffset + length + 2);
    offset += key.key.length;
    rdnskey.decode.bytes = offset - oldOffset;
    return key
  },
  encodingLength (key) {
    return 6 + bytelength(key.key)
  }
});

rdnskey.PROTOCOL_DNSSEC = 3;
rdnskey.ZONE_KEY = 0x80;
rdnskey.SECURE_ENTRYPOINT = 0x8000;

const rrrsig = codec({
  encode (sig, buf, offset) {
    if (!buf) buf = new Uint8Array(rrrsig.encodingLength(sig));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const signature = sig.signature;
    if (!isU8Arr(signature)) {
      throw new Error('Signature must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, toType(sig.typeCovered), offset);
    offset += 2;
    buf[offset] = sig.algorithm;
    offset += 1;
    buf[offset] = sig.labels;
    offset += 1;
    writeUInt32BE(buf, sig.originalTTL, offset);
    offset += 4;
    writeUInt32BE(buf, sig.expiration, offset);
    offset += 4;
    writeUInt32BE(buf, sig.inception, offset);
    offset += 4;
    writeUInt16BE(buf, sig.keyTag, offset);
    offset += 2;
    name$5.encode(sig.signersName, buf, offset);
    offset += name$5.encode.bytes;
    copy(signature, buf, offset, 0, signature.length);
    offset += signature.length;

    rrrsig.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rrrsig.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const sig = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    sig.typeCovered = toString$4(readUInt16BE(buf, offset));
    offset += 2;
    sig.algorithm = buf[offset];
    offset += 1;
    sig.labels = buf[offset];
    offset += 1;
    sig.originalTTL = readUInt32BE(buf, offset);
    offset += 4;
    sig.expiration = readUInt32BE(buf, offset);
    offset += 4;
    sig.inception = readUInt32BE(buf, offset);
    offset += 4;
    sig.keyTag = readUInt16BE(buf, offset);
    offset += 2;
    sig.signersName = name$5.decode(buf, offset);
    offset += name$5.decode.bytes;
    sig.signature = buf.slice(offset, oldOffset + length + 2);
    offset += sig.signature.length;
    rrrsig.decode.bytes = offset - oldOffset;
    return sig
  },
  encodingLength (sig) {
    return 20 +
      name$5.encodingLength(sig.signersName) +
      bytelength(sig.signature)
  }
});
const rrp = codec({
  encode (data, buf, offset) {
    if (!buf) buf = new Uint8Array(rrp.encodingLength(data));
    if (!offset) offset = 0;
    const oldOffset = offset;

    offset += 2; // Leave space for length
    name$5.encode(data.mbox || '.', buf, offset);
    offset += name$5.encode.bytes;
    name$5.encode(data.txt || '.', buf, offset);
    offset += name$5.encode.bytes;
    rrp.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rrp.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const data = {};
    offset += 2;
    data.mbox = name$5.decode(buf, offset) || '.';
    offset += name$5.decode.bytes;
    data.txt = name$5.decode(buf, offset) || '.';
    offset += name$5.decode.bytes;
    rrp.decode.bytes = offset - oldOffset;
    return data
  },
  encodingLength (data) {
    return 2 + name$5.encodingLength(data.mbox || '.') + name$5.encodingLength(data.txt || '.')
  }
});

const typebitmap = codec({
  encode (typelist, buf, offset) {
    if (!buf) buf = new Uint8Array(typebitmap.encodingLength(typelist));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const typesByWindow = [];
    for (let i = 0; i < typelist.length; i++) {
      const typeid = toType(typelist[i]);
      if (typesByWindow[typeid >> 8] === undefined) {
        typesByWindow[typeid >> 8] = [];
      }
      typesByWindow[typeid >> 8][(typeid >> 3) & 0x1F] |= 1 << (7 - (typeid & 0x7));
    }

    for (let i = 0; i < typesByWindow.length; i++) {
      if (typesByWindow[i] !== undefined) {
        const windowBuf = from$d(typesByWindow[i]);
        buf[offset] = i;
        offset += 1;
        buf[offset] = windowBuf.length;
        offset += 1;
        copy(windowBuf, buf, offset, 0, windowBuf.length);
        offset += windowBuf.length;
      }
    }

    typebitmap.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset, length) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const typelist = [];
    while (offset - oldOffset < length) {
      const window = buf[offset];
      offset += 1;
      const windowLength = buf[offset];
      offset += 1;
      for (let i = 0; i < windowLength; i++) {
        const b = buf[offset + i];
        for (let j = 0; j < 8; j++) {
          if (b & (1 << (7 - j))) {
            const typeid = toString$4((window << 8) | (i << 3) | j);
            typelist.push(typeid);
          }
        }
      }
      offset += windowLength;
    }

    typebitmap.decode.bytes = offset - oldOffset;
    return typelist
  },
  encodingLength (typelist) {
    const extents = [];
    for (let i = 0; i < typelist.length; i++) {
      const typeid = toType(typelist[i]);
      extents[typeid >> 8] = Math.max(extents[typeid >> 8] || 0, typeid & 0xFF);
    }

    let len = 0;
    for (let i = 0; i < extents.length; i++) {
      if (extents[i] !== undefined) {
        len += 2 + Math.ceil((extents[i] + 1) / 8);
      }
    }

    return len
  }
});

const rnsec = codec({
  encode (record, buf, offset) {
    if (!buf) buf = new Uint8Array(rnsec.encodingLength(record));
    if (!offset) offset = 0;
    const oldOffset = offset;

    offset += 2; // Leave space for length
    name$5.encode(record.nextDomain, buf, offset);
    offset += name$5.encode.bytes;
    typebitmap.encode(record.rrtypes, buf, offset);
    offset += typebitmap.encode.bytes;

    rnsec.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rnsec.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const record = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    record.nextDomain = name$5.decode(buf, offset);
    offset += name$5.decode.bytes;
    record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset));
    offset += typebitmap.decode.bytes;

    rnsec.decode.bytes = offset - oldOffset;
    return record
  },
  encodingLength (record) {
    return 2 +
      name$5.encodingLength(record.nextDomain) +
      typebitmap.encodingLength(record.rrtypes)
  }
});

const rnsec3 = codec({
  encode (record, buf, offset) {
    if (!buf) buf = new Uint8Array(rnsec3.encodingLength(record));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const salt = record.salt;
    if (!isU8Arr(salt)) {
      throw new Error('salt must be a Buffer')
    }

    const nextDomain = record.nextDomain;
    if (!isU8Arr(nextDomain)) {
      throw new Error('nextDomain must be a Buffer')
    }

    offset += 2; // Leave space for length
    buf[offset] = record.algorithm;
    offset += 1;
    buf[offset] = record.flags;
    offset += 1;
    writeUInt16BE(buf, record.iterations, offset);
    offset += 2;
    buf[offset] = salt.length;
    offset += 1;
    copy(salt, buf, offset, 0, salt.length);
    offset += salt.length;
    buf[offset] = nextDomain.length;
    offset += 1;
    copy(nextDomain, buf, offset, 0, nextDomain.length);
    offset += nextDomain.length;
    typebitmap.encode(record.rrtypes, buf, offset);
    offset += typebitmap.encode.bytes;

    rnsec3.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rnsec3.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const record = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    record.algorithm = buf[offset];
    offset += 1;
    record.flags = buf[offset];
    offset += 1;
    record.iterations = readUInt16BE(buf, offset);
    offset += 2;
    const saltLength = buf[offset];
    offset += 1;
    record.salt = buf.slice(offset, offset + saltLength);
    offset += saltLength;
    const hashLength = buf[offset];
    offset += 1;
    record.nextDomain = buf.slice(offset, offset + hashLength);
    offset += hashLength;
    record.rrtypes = typebitmap.decode(buf, offset, length - (offset - oldOffset));
    offset += typebitmap.decode.bytes;

    rnsec3.decode.bytes = offset - oldOffset;
    return record
  },
  encodingLength (record) {
    return 8 +
      record.salt.length +
      record.nextDomain.length +
      typebitmap.encodingLength(record.rrtypes)
  }
});

const rds = codec({
  encode (digest, buf, offset) {
    if (!buf) buf = new Uint8Array(rds.encodingLength(digest));
    if (!offset) offset = 0;
    const oldOffset = offset;

    const digestdata = digest.digest;
    if (!isU8Arr(digestdata)) {
      throw new Error('Digest must be a Buffer')
    }

    offset += 2; // Leave space for length
    writeUInt16BE(buf, digest.keyTag, offset);
    offset += 2;
    buf[offset] = digest.algorithm;
    offset += 1;
    buf[offset] = digest.digestType;
    offset += 1;
    copy(digestdata, buf, offset, 0, digestdata.length);
    offset += digestdata.length;

    rds.encode.bytes = offset - oldOffset;
    writeUInt16BE(buf, rds.encode.bytes - 2, oldOffset);
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;
    const oldOffset = offset;

    const digest = {};
    const length = readUInt16BE(buf, offset);
    offset += 2;
    digest.keyTag = readUInt16BE(buf, offset);
    offset += 2;
    digest.algorithm = buf[offset];
    offset += 1;
    digest.digestType = buf[offset];
    offset += 1;
    digest.digest = buf.slice(offset, oldOffset + length + 2);
    offset += digest.digest.length;
    rds.decode.bytes = offset - oldOffset;
    return digest
  },
  encodingLength (digest) {
    return 6 + bytelength(digest.digest)
  }
});

function renc (type) {
  switch (type.toUpperCase()) {
    case 'A': return ra
    case 'PTR': return rptr
    case 'CNAME': return rptr
    case 'DNAME': return rptr
    case 'TXT': return rtxt
    case 'NULL': return rnull
    case 'AAAA': return raaaa
    case 'SRV': return rsrv
    case 'HINFO': return rhinfo
    case 'CAA': return rcaa
    case 'NS': return rns
    case 'SOA': return rsoa
    case 'MX': return rmx
    case 'OPT': return ropt
    case 'DNSKEY': return rdnskey
    case 'RRSIG': return rrrsig
    case 'RP': return rrp
    case 'NSEC': return rnsec
    case 'NSEC3': return rnsec3
    case 'DS': return rds
  }
  return runknown
}

const answer = codec({
  encode (a, buf, offset) {
    if (!buf) buf = new Uint8Array(answer.encodingLength(a));
    if (!offset) offset = 0;

    const oldOffset = offset;

    name$5.encode(a.name, buf, offset);
    offset += name$5.encode.bytes;

    writeUInt16BE(buf, toType(a.type), offset);

    if (a.type.toUpperCase() === 'OPT') {
      if (a.name !== '.') {
        throw new Error('OPT name must be root.')
      }
      writeUInt16BE(buf, a.udpPayloadSize || 4096, offset + 2);
      buf[offset + 4] = a.extendedRcode || 0;
      buf[offset + 5] = a.ednsVersion || 0;
      writeUInt16BE(buf, a.flags || 0, offset + 6);

      offset += 8;
      ropt.encode(a.options || [], buf, offset);
      offset += ropt.encode.bytes;
    } else {
      let klass = toClass(a.class === undefined ? 'IN' : a.class);
      if (a.flush) klass |= FLUSH_MASK; // the 1st bit of the class is the flush bit
      writeUInt16BE(buf, klass, offset + 2);
      writeUInt32BE(buf, a.ttl || 0, offset + 4);

      offset += 8;
      const enc = renc(a.type);
      enc.encode(a.data, buf, offset);
      offset += enc.encode.bytes;
    }

    answer.encode.bytes = offset - oldOffset;
    return buf
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const a = {};
    const oldOffset = offset;

    a.name = name$5.decode(buf, offset);
    offset += name$5.decode.bytes;
    a.type = toString$4(readUInt16BE(buf, offset));
    if (a.type === 'OPT') {
      a.udpPayloadSize = readUInt16BE(buf, offset + 2);
      a.extendedRcode = buf[offset + 4];
      a.ednsVersion = buf[offset + 5];
      a.flags = readUInt16BE(buf, offset + 6);
      a.flag_do = ((a.flags >> 15) & 0x1) === 1;
      a.options = ropt.decode(buf, offset + 8);
      offset += 8 + ropt.decode.bytes;
    } else {
      const klass = readUInt16BE(buf, offset + 2);
      a.ttl = readUInt32BE(buf, offset + 4);

      a.class = toString$1(klass & NOT_FLUSH_MASK);
      a.flush = !!(klass & FLUSH_MASK);

      const enc = renc(a.type);
      a.data = enc.decode(buf, offset + 8);
      offset += 8 + enc.decode.bytes;
    }

    answer.decode.bytes = offset - oldOffset;
    return a
  },
  encodingLength (a) {
    const data = (a.data !== null && a.data !== undefined) ? a.data : a.options;
    return name$5.encodingLength(a.name) + 8 + renc(a.type).encodingLength(data)
  }
});

const question = codec({
  encode (q, buf, offset) {
    if (!buf) buf = new Uint8Array(question.encodingLength(q));
    if (!offset) offset = 0;

    const oldOffset = offset;

    name$5.encode(q.name, buf, offset);
    offset += name$5.encode.bytes;

    writeUInt16BE(buf, toType(q.type), offset);
    offset += 2;

    writeUInt16BE(buf, toClass(q.class === undefined ? 'IN' : q.class), offset);
    offset += 2;

    question.encode.bytes = offset - oldOffset;
    return q
  },
  decode (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;
    const q = {};

    q.name = name$5.decode(buf, offset);
    offset += name$5.decode.bytes;

    q.type = toString$4(readUInt16BE(buf, offset));
    offset += 2;

    q.class = toString$1(readUInt16BE(buf, offset));
    offset += 2;

    const qu = !!(q.class & QU_MASK);
    if (qu) q.class &= NOT_QU_MASK;

    question.decode.bytes = offset - oldOffset;
    return q
  },
  encodingLength (q) {
    return name$5.encodingLength(q.name) + 4
  }
});
const RECURSION_DESIRED = 1 << 8;

const packet = {
  encode: function (result, buf, offset) {
    const allocing = !buf;

    if (allocing) buf = new Uint8Array(encodingLength$5(result));
    if (!offset) offset = 0;

    const oldOffset = offset;

    if (!result.questions) result.questions = [];
    if (!result.answers) result.answers = [];
    if (!result.authorities) result.authorities = [];
    if (!result.additionals) result.additionals = [];

    header.encode(result, buf, offset);
    offset += header.encode.bytes;

    offset = encodeList(result.questions, question, buf, offset);
    offset = encodeList(result.answers, answer, buf, offset);
    offset = encodeList(result.authorities, answer, buf, offset);
    offset = encodeList(result.additionals, answer, buf, offset);

    packet.encode.bytes = offset - oldOffset;

    // just a quick sanity check
    if (allocing && encode$j.bytes !== buf.length) {
      return buf.slice(0, encode$j.bytes)
    }

    return buf
  },
  decode: function (buf, offset) {
    if (!offset) offset = 0;

    const oldOffset = offset;
    const result = header.decode(buf, offset);
    offset += header.decode.bytes;

    offset = decodeList(result.questions, question, buf, offset);
    offset = decodeList(result.answers, answer, buf, offset);
    offset = decodeList(result.authorities, answer, buf, offset);
    offset = decodeList(result.additionals, answer, buf, offset);

    packet.decode.bytes = offset - oldOffset;

    return result
  },
  encodingLength: function (result) {
    return header.encodingLength(result) +
      encodingLengthList(result.questions || [], question) +
      encodingLengthList(result.answers || [], answer) +
      encodingLengthList(result.authorities || [], answer) +
      encodingLengthList(result.additionals || [], answer)
  }
};
packet.encode.bytes = 0;
packet.decode.bytes = 0;

const encode$j = packet.encode;
const decode$d = packet.decode;
const encodingLength$5 = packet.encodingLength;

function encodingLengthList (list, enc) {
  let len = 0;
  for (let i = 0; i < list.length; i++) len += enc.encodingLength(list[i]);
  return len
}

function encodeList (list, enc, buf, offset) {
  for (let i = 0; i < list.length; i++) {
    enc.encode(list[i], buf, offset);
    offset += enc.encode.bytes;
  }
  return offset
}

function decodeList (list, enc, buf, offset) {
  for (let i = 0; i < list.length; i++) {
    list[i] = enc.decode(buf, offset);
    offset += enc.decode.bytes;
  }
  return offset
}

const PREFERS_PADDING = 1;
const PREFERS_NO_PADDING = 2;

function make (name, charset, padding, paddingMode) {
  if (charset.length !== 64) {
    throw new Error(`Charset needs to be 64 characters long! (${charset.length})`)
  }
  const byCharCode = new Uint8Array(256);
  const byNum = new Uint8Array(64);
  for (let i = 0; i < 64; i += 1) {
    const code = charset.charCodeAt(i);
    if (code > 255) {
      throw new Error(`Character #${i} in charset [code=${code}, char=${charset.charAt(i)}] is too high! (max=255)`)
    }
    if (byCharCode[code] !== 0) {
      throw new Error(`Character [code=${code}, char=${charset.charAt(i)}] is more than once in the charset!`)
    }
    byCharCode[code] = i;
    byNum[i] = code;
  }
  const padCode = padding.charCodeAt(0);
  const codec = {
    name,
    encodingLength (str) {
      const strLen = str.length;
      const len = strLen * 0.75 | 0;
      if (str.charCodeAt(strLen - 1) === padCode) {
        if (str.charCodeAt(strLen - 2) === padCode) {
          return len - 2
        }
        return len - 1
      }
      return len
    },
    encode (str, buffer, offset) {
      if (buffer === null || buffer === undefined) {
        buffer = new Uint8Array(codec.encodingLength(str));
      }
      if (offset === null || offset === undefined) {
        offset = 0;
      }

      let strLen = str.length;
      if (str.charCodeAt(strLen - 1) === padCode) {
        if (str.charCodeAt(strLen - 2) === padCode) {
          strLen -= 2;
        } else {
          strLen -= 1;
        }
      }

      const padding = strLen % 4;
      const safeLen = strLen - padding;

      let off = offset;
      let i = 0;
      while (i < safeLen) {
        const code =
          (byCharCode[str.charCodeAt(i)] << 18) |
          (byCharCode[str.charCodeAt(i + 1)] << 12) |
          (byCharCode[str.charCodeAt(i + 2)] << 6) |
          byCharCode[str.charCodeAt(i + 3)];
        buffer[off++] = code >> 16;
        buffer[off++] = code >> 8;
        buffer[off++] = code;
        i += 4;
      }

      if (padding === 3) {
        const code =
          (byCharCode[str.charCodeAt(i)] << 10) |
          (byCharCode[str.charCodeAt(i + 1)] << 4) |
          (byCharCode[str.charCodeAt(i + 2)] >> 2);
        buffer[off++] = code >> 8;
        buffer[off++] = code;
      } else if (padding === 2) {
        buffer[off++] = (byCharCode[str.charCodeAt(i)] << 2) |
          (byCharCode[str.charCodeAt(i + 1)] >> 4);
      }

      codec.encode.bytes = off - offset;
      return buffer
    },
    decode (buffer, start, end) {
      if (start === null || start === undefined) {
        start = 0;
      }
      if (end === null || end === undefined) {
        end = buffer.length;
      }

      const length = end - start;
      const pad = length % 3;
      const safeEnd = start + length - pad;
      const codes = [];
      for (let off = start; off < safeEnd; off += 3) {
        const num = (buffer[off] << 16) | ((buffer[off + 1] << 8)) | buffer[off + 2];
        codes.push(
          byNum[num >> 18 & 0x3F],
          byNum[num >> 12 & 0x3F],
          byNum[num >> 6 & 0x3F],
          byNum[num & 0x3F]
        );
      }

      if (pad === 2) {
        const num = (buffer[end - 2] << 8) + buffer[end - 1];
        codes.push(
          byNum[num >> 10],
          byNum[(num >> 4) & 0x3F],
          byNum[(num << 2) & 0x3F]
        );
        if (paddingMode === PREFERS_PADDING) {
          codes.push(padCode);
        }
      } else if (pad === 1) {
        const num = buffer[end - 1];
        codes.push(
          byNum[num >> 2],
          byNum[(num << 4) & 0x3F]
        );
        if (paddingMode === PREFERS_PADDING) {
          codes.push(padCode, padCode);
        }
      }

      codec.decode.bytes = length;
      return String.fromCharCode.apply(String, codes)
    }
  };
  return codec
}

make('base64', 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/', '=', PREFERS_PADDING);
// https://datatracker.ietf.org/doc/html/rfc4648#section-5
const base64URL = make('base64-url', 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_', '=', PREFERS_NO_PADDING);

let AbortError$3 = typeof global !== 'undefined' ? global.AbortError : typeof window !== 'undefined' ? window.AbortError : null;
if (!AbortError$3) {
  AbortError$3 = class AbortError extends Error {
    constructor (message = 'Request aborted.') {
      super(message);
    }
  };
}
AbortError$3.prototype.name = 'AbortError';
AbortError$3.prototype.code = 'ABORT_ERR';

const URL$1 = (typeof globalThis !== 'undefined' && globalThis.URL) || require('url').URL;

class HTTPStatusError extends Error {
  constructor (uri, code, method) {
    super('status=' + code + ' while requesting ' + uri + ' [' + method + ']');
    this.uri = uri;
    this.status = code;
    this.method = method;
  }

  toJSON () {
    return {
      code: this.code,
      uri: this.uri,
      status: this.status,
      method: this.method,
      endpoint: this.endpoint
    }
  }
}
HTTPStatusError.prototype.name = 'HTTPStatusError';
HTTPStatusError.prototype.code = 'HTTP_STATUS';

class ResponseError extends Error {
  constructor (message, cause) {
    super(message);
    this.cause = cause;
  }

  toJSON () {
    return {
      message: this.message,
      endpoint: this.endpoint,
      code: this.code,
      cause: reduceError(this.cause)
    }
  }
}
ResponseError.prototype.name = 'ResponseError';
ResponseError.prototype.code = 'RESPONSE_ERR';

let TimeoutError$2 = class TimeoutError extends Error {
  constructor (timeout) {
    super('Timeout (t=' + timeout + ').');
    this.timeout = timeout;
  }

  toJSON () {
    return {
      code: this.code,
      endpoint: this.endpoint,
      timeout: this.timeout
    }
  }
};
TimeoutError$2.prototype.name = 'TimeoutError';
TimeoutError$2.prototype.code = 'ETIMEOUT';

const v4Regex = /^((\d{1,3}\.){3,3}\d{1,3})(:(\d{2,5}))?$/;
const v6Regex = /^((::)?(((\d{1,3}\.){3}(\d{1,3}){1})?([0-9a-f]){0,4}:{0,2}){1,8}(::)?)(:(\d{2,5}))?$/i;

function reduceError (err) {
  if (typeof err === 'string') {
    return {
      message: err
    }
  }
  try {
    const json = JSON.stringify(err);
    if (json !== '{}') {
      return JSON.parse(json)
    }
  } catch (e) {}
  const error = {
    message: String(err.message || err)
  };
  if (err.code !== undefined) {
    error.code = String(err.code);
  }
  return error
}

const baseParts = /^(([a-z0-9]+:)\/\/)?([^/[\s:]+|\[[^\]]+\])?(:([^/\s]+))?(\/[^\s]*)?(.*)$/;
const httpFlags = /\[(post|get|((ipv4|ipv6|name)=([^\]]+)))\]/ig;
const updFlags = /\[(((pk|name)=([^\]]+)))\]/ig;

function parseEndpoint (endpoint) {
  const parts = baseParts.exec(endpoint);
  const protocol = parts[2] || 'https:';
  const host = parts[3];
  const port = parts[5];
  const path = parts[6];
  const rest = parts[7];
  if (protocol === 'https:' || protocol === 'http:') {
    const flags = parseFlags(rest, httpFlags);
    return {
      name: flags.name,
      protocol,
      ipv4: flags.ipv4,
      ipv6: flags.ipv6,
      host,
      port,
      path,
      method: flags.post ? 'POST' : 'GET'
    }
  }
  if (protocol === 'udp:' || protocol === 'udp4:' || protocol === 'udp6:') {
    const flags = parseFlags(rest, updFlags);
    const v6Parts = /^\[(.*)\]$/.exec(host);
    if (v6Parts && protocol === 'udp4:') {
      throw new Error(`Endpoint parsing error: Cannot use ipv6 host with udp4: (endpoint=${endpoint})`)
    }
    if (!v6Parts && protocol === 'udp6:') {
      throw new Error(`Endpoint parsing error: Incorrectly formatted host for udp6: (endpoint=${endpoint})`)
    }
    if (v6Parts) {
      return new UDP6Endpoint({ protocol: 'udp6:', ipv6: v6Parts[1], port, pk: flags.pk, name: flags.name })
    }
    return new UDP4Endpoint({ protocol: 'udp4:', ipv4: host, port, pk: flags.pk, name: flags.name })
  }
  throw new InvalidProtocolError(protocol, endpoint)
}

function parseFlags (rest, regex) {
  regex.lastIndex = 0;
  const result = {};
  while (true) {
    const match = regex.exec(rest);
    if (!match) break
    if (match[2]) {
      result[match[3].toLowerCase()] = match[4];
    } else {
      result[match[1].toLowerCase()] = true;
    }
  }
  return result
}

class InvalidProtocolError extends Error {
  constructor (protocol, endpoint) {
    super(`Invalid Endpoint: unsupported protocol "${protocol}" for endpoint: ${endpoint}, supported protocols: ${supportedProtocols.join(', ')}`);
    this.protocol = protocol;
    this.endpoint = endpoint;
  }

  toJSON () {
    return {
      code: this.code,
      endpoint: this.endpoint,
      timeout: this.timeout
    }
  }
}
InvalidProtocolError.prototype.name = 'InvalidProtocolError';
InvalidProtocolError.prototype.code = 'EPROTOCOL';

const supportedProtocols = ['http:', 'https:', 'udp4:', 'udp6:'];

class BaseEndpoint {
  constructor (opts, isHTTP) {
    this.name = opts.name || null;
    this.protocol = opts.protocol;
    const port = typeof opts.port === 'string' ? opts.port = parseInt(opts.port, 10) : opts.port;
    if (port === undefined || port === null) {
      this.port = isHTTP
        ? (this.protocol === 'https:' ? 443 : 80)
        : (opts.pk ? 443 : 53);
    } else if (typeof port !== 'number' && !isNaN(port)) {
      throw new Error(`Invalid Endpoint: port "${opts.port}" needs to be a number: ${JSON.stringify(opts)}`)
    } else {
      this.port = port;
    }
  }

  toJSON () {
    return this.toString()
  }
}

class UDPEndpoint extends BaseEndpoint {
  constructor (opts) {
    super(opts, false);
    this.pk = opts.pk || null;
  }

  toString () {
    const port = this.port !== (this.pk ? 443 : 53) ? `:${this.port}` : '';
    const pk = this.pk ? ` [pk=${this.pk}]` : '';
    const name = this.name ? ` [name=${this.name}]` : '';
    return `udp://${this.ipv4 || `[${this.ipv6}]`}${port}${pk}${name}`
  }
}

class UDP4Endpoint extends UDPEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'udp4:' }, opts));
    if (!opts.ipv4 || typeof opts.ipv4 !== 'string') {
      throw new Error(`Invalid Endpoint: .ipv4 "${opts.ipv4}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.ipv4 = opts.ipv4;
  }
}

class UDP6Endpoint extends UDPEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'udp6:' }, opts));
    if (!opts.ipv6 || typeof opts.ipv6 !== 'string') {
      throw new Error(`Invalid Endpoint: .ipv6 "${opts.ipv6}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.ipv6 = opts.ipv6;
  }
}

function safeHost (host) {
  return v6Regex.test(host) && !v4Regex.test(host) ? `[${host}]` : host
}

class HTTPEndpoint extends BaseEndpoint {
  constructor (opts) {
    super(Object.assign({ protocol: 'https:' }, opts), true);
    if (!opts.host) {
      if (opts.ipv4) {
        opts.host = opts.ipv4;
      }
      if (opts.ipv6) {
        opts.host = `[${opts.ipv6}]`;
      }
    }
    if (!opts.host || typeof opts.host !== 'string') {
      throw new Error(`Invalid Endpoint: host "${opts.path}" needs to be set: ${JSON.stringify(opts)}`)
    }
    this.host = opts.host;
    this.path = opts.path || '/dns-query';
    this.method = /^post$/i.test(opts.method) ? 'POST' : 'GET';
    this.ipv4 = opts.ipv4;
    this.ipv6 = opts.ipv6;
    if (!this.ipv6) {
      const v6Parts = v6Regex.exec(this.host);
      if (v6Parts) {
        this.ipv6 = v6Parts[1];
      }
    }
    if (!this.ipv4) {
      if (v4Regex.test(this.host)) {
        this.ipv4 = this.host;
      }
    }
    const url = `${this.protocol}//${safeHost(this.host)}:${this.port}${this.path}`;
    try {
      this.url = new URL$1(url);
    } catch (err) {
      throw new Error(err.message + ` [${url}]`)
    }
  }

  toString () {
    const protocol = this.protocol === 'https:' ? '' : 'http://';
    const port = this.port !== (this.protocol === 'https:' ? 443 : 80) ? `:${this.port}` : '';
    const method = this.method !== 'GET' ? ' [post]' : '';
    const path = this.path === '/dns-query' ? '' : this.path;
    const name = this.name ? ` [name=${this.name}]` : '';
    const ipv4 = this.ipv4 && this.ipv4 !== this.host ? ` [ipv4=${this.ipv4}]` : '';
    const ipv6 = this.ipv6 && this.ipv6 !== this.host ? ` [ipv6=${this.ipv6}]` : '';
    return `${protocol}${safeHost(this.host)}${port}${path}${method}${ipv4}${ipv6}${name}`
  }
}

function toEndpoint (input) {
  let opts;
  if (typeof input === 'string') {
    opts = parseEndpoint(input);
  } else {
    if (typeof input !== 'object' || input === null || Array.isArray(input)) {
      throw new Error(`Can not convert ${input} to an endpoint`)
    } else if (input instanceof BaseEndpoint) {
      return input
    }
    opts = input;
  }
  if (opts.protocol === null || opts.protocol === undefined) {
    opts.protocol = 'https:';
  }
  const protocol = opts.protocol;
  if (protocol === 'udp4:') {
    return new UDP4Endpoint(opts)
  }
  if (protocol === 'udp6:') {
    return new UDP6Endpoint(opts)
  }
  if (protocol === 'https:' || protocol === 'http:') {
    return new HTTPEndpoint(opts)
  }
  throw new InvalidProtocolError(protocol, JSON.stringify(opts))
}

/* global XMLHttpRequest, localStorage */
const contentType = 'application/dns-message';

function noop () { }

function queryDns () {
  throw new Error('Only "doh" endpoints are supported in the browser')
}

async function loadJSON (url, cache, timeout, abortSignal) {
  const cacheKey = cache ? cache.localStoragePrefix + cache.name : null;
  if (cacheKey) {
    try {
      const cached = JSON.parse(localStorage.getItem(cacheKey));
      if (cached && cached.time > cache.maxTime) {
        return cached
      }
    } catch (err) {}
  }
  const { data } = await requestRaw(url, 'GET', null, timeout, abortSignal);
  const result = {
    time: Date.now(),
    data: JSON.parse(decode$e(data))
  };
  if (cacheKey) {
    try {
      localStorage.setItem(cacheKey, JSON.stringify(result));
    } catch (err) {
      result.time = null;
    }
  }
  return result
}

function requestRaw (url, method, data, timeout, abortSignal) {
  return new Promise((resolve, reject) => {
    const target = new URL$1(url);
    if (method === 'GET' && data) {
      target.search = '?dns=' + base64URL.decode(data);
    }
    const uri = target.toString();
    const xhr = new XMLHttpRequest();
    xhr.open(method, uri, true);
    xhr.setRequestHeader('Accept', contentType);
    if (method === 'POST') {
      xhr.setRequestHeader('Content-Type', contentType);
    }
    xhr.responseType = 'arraybuffer';
    xhr.timeout = timeout;
    xhr.ontimeout = ontimeout;
    xhr.onreadystatechange = onreadystatechange;
    xhr.onerror = onerror;
    xhr.onload = onload;
    if (method === 'POST') {
      xhr.send(data);
    } else {
      xhr.send();
    }

    if (abortSignal) {
      abortSignal.addEventListener('abort', onabort);
    }

    function ontimeout () {
      finish(new TimeoutError$2(timeout));
      try {
        xhr.abort();
      } catch (e) { }
    }

    function onload () {
      if (xhr.status !== 200) {
        finish(new HTTPStatusError(uri, xhr.status, method));
      } else {
        let buf;
        if (typeof xhr.response === 'string') {
          buf = encode$k(xhr.response);
        } else if (xhr.response instanceof Uint8Array) {
          buf = xhr.response;
        } else if (Array.isArray(xhr.response) || xhr.response instanceof ArrayBuffer) {
          buf = new Uint8Array(xhr.response);
        } else {
          throw new Error('Unprocessable response ' + xhr.response)
        }
        finish(null, buf);
      }
    }

    function onreadystatechange () {
      if (xhr.readyState > 1 && xhr.status !== 200 && xhr.status !== 0) {
        finish(new HTTPStatusError(uri, xhr.status, method));
        try {
          xhr.abort();
        } catch (e) { }
      }
    }

    let finish = function (error, data) {
      finish = noop;
      if (abortSignal) {
        abortSignal.removeEventListener('abort', onabort);
      }
      if (error) {
        resolve({
          error,
          response: xhr
        });
      } else {
        resolve({
          data,
          response: xhr
        });
      }
    };

    function onerror () {
      finish(xhr.status === 200 ? new Error('Inexplicable XHR Error') : new HTTPStatusError(uri, xhr.status, method));
    }

    function onabort () {
      finish(new AbortError$3());
      try {
        xhr.abort();
      } catch (e) { }
    }
  })
}

function request$1 (url, method, packet, timeout, abortSignal) {
  return requestRaw(url, method, packet, timeout, abortSignal)
}

function processResolvers$1 (resolvers) {
  return resolvers.filter(resolver => resolver.cors || resolver.endpoint.cors)
}

const resolvers = {
  data: [
    {
      name: 'adfree.usableprivacy.net',
      endpoint: {
        protocol: 'https:',
        host: 'adfree.usableprivacy.net'
      },
      description: 'Public updns DoH service with advertising, tracker and malware filters.\nHosted in Europe by @usableprivacy, details see: https://docs.usableprivacy.com',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      },
      filter: true
    },
    {
      name: 'adguard-dns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.adguard.com',
        ipv4: '94.140.15.15'
      },
      description: 'Remove ads and protect your computer from malware (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      },
      filter: true
    },
    {
      name: 'adguard-dns-family-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-family.adguard.com',
        ipv4: '94.140.15.16'
      },
      description: 'Adguard DNS with safesearch and adult content blocking (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      },
      filter: true
    },
    {
      name: 'adguard-dns-unfiltered-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-unfiltered.adguard.com',
        ipv4: '94.140.14.140'
      },
      description: 'AdGuard public DNS servers without filters (over DoH)',
      country: 'France',
      location: {
        lat: 48.8582,
        long: 2.3387
      }
    },
    {
      name: 'ahadns-doh-chi',
      endpoint: {
        protocol: 'https:',
        host: 'doh.chi.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Chicago, USA. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=chi',
      country: 'United States',
      location: {
        lat: 41.8483,
        long: -87.6517
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-in',
      endpoint: {
        protocol: 'https:',
        host: 'doh.in.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Mumbai, India. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=in',
      country: 'India',
      location: {
        lat: 19.0748,
        long: 72.8856
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-la',
      endpoint: {
        protocol: 'https:',
        host: 'doh.la.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Los Angeles, USA. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=la',
      country: 'United States',
      location: {
        lat: 34.0549,
        long: -118.2578
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'doh.nl.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Amsterdam, Netherlands. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=nl',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-ny',
      endpoint: {
        protocol: 'https:',
        host: 'doh.ny.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in New York. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=ny',
      country: 'United States',
      location: {
        lat: 40.7308,
        long: -73.9975
      },
      filter: true,
      cors: true
    },
    {
      name: 'ahadns-doh-pl',
      endpoint: {
        protocol: 'https:',
        host: 'doh.pl.ahadns.net',
        cors: true
      },
      description: 'A zero logging DNS with support for DNS-over-HTTPS (DoH) & DNS-over-TLS (DoT). Blocks ads, malware, trackers, viruses, ransomware, telemetry and more. No persistent logs. DNSSEC. Hosted in Poland. By https://ahadns.com/\nServer statistics can be seen at: https://statistics.ahadns.com/?server=pl',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'alidns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.alidns.com',
        ipv4: '223.5.5.5',
        cors: true
      },
      description: 'A public DNS resolver that supports DoH/DoT in mainland China, provided by Alibaba-Cloud.\nWarning: GFW filtering rules are applied by that resolver.\nHomepage: https://alidns.com/',
      country: 'China',
      location: {
        lat: 34.7725,
        long: 113.7266
      },
      filter: true,
      log: true,
      cors: true
    },
    {
      name: 'ams-ads-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'dnsnl-noads.alekberg.net'
      },
      description: 'Resolver in Amsterdam. DoH protocol. Non-logging. Blocks ads, malware and trackers. DNSSEC enabled.',
      country: 'Romania',
      location: {
        lat: 45.9968,
        long: 24.997
      },
      filter: true
    },
    {
      name: 'ams-doh-nl',
      endpoint: {
        protocol: 'https:',
        host: 'dnsnl.alekberg.net'
      },
      description: 'Resolver in Amsterdam. DoH protocol. Non-logging, non-filtering, DNSSEC.',
      country: 'Romania',
      location: {
        lat: 45.9968,
        long: 24.997
      }
    },
    {
      name: 'att',
      endpoint: {
        protocol: 'https:',
        host: 'dohtrial.att.net'
      },
      description: 'AT&T test DoH server.',
      log: true
    },
    {
      name: 'bcn-ads-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dnses-noads.alekberg.net'
      },
      description: 'Resolver in Spain. DoH protocol. Non-logging, remove ads and malware, DNSSEC.',
      country: 'Spain',
      location: {
        lat: 41.3891,
        long: 2.1611
      },
      filter: true
    },
    {
      name: 'bcn-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dnses.alekberg.net'
      },
      description: 'Resolver in Spain. DoH protocol. Non-logging, non-filtering, DNSSEC.',
      country: 'Spain',
      location: {
        lat: 41.3891,
        long: 2.1611
      }
    },
    {
      name: 'brahma-world',
      endpoint: {
        protocol: 'https:',
        host: 'dns.brahma.world'
      },
      description: 'DNS-over-HTTPS server. Non Logging, filters ads, trackers and malware. DNSSEC ready, QNAME Minimization, No EDNS Client-Subnet.\nHosted in Stockholm, Sweden. (https://dns.brahma.world)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'cisco-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.opendns.com',
        ipv4: '146.112.41.2'
      },
      description: 'Remove your DNS blind spot (DoH protocol)\nWarning: modifies your queries to include a copy of your network\naddress when forwarding them to a selection of companies and organizations.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true,
      log: true
    },
    {
      name: 'cloudflare',
      endpoint: {
        protocol: 'https:',
        host: 'dns.cloudflare.com',
        ipv4: '1.0.0.1',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) - aka 1.1.1.1 / 1.0.0.1',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      cors: true
    },
    {
      name: 'cloudflare-family',
      endpoint: {
        protocol: 'https:',
        host: 'family.cloudflare-dns.com',
        ipv4: '1.0.0.3',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) with malware protection and parental control - aka 1.1.1.3 / 1.0.0.3',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      filter: true,
      cors: true
    },
    {
      name: 'cloudflare-ipv6',
      endpoint: {
        protocol: 'https:',
        host: '1dot1dot1dot1.cloudflare-dns.com',
        cors: true
      },
      description: 'Cloudflare DNS over IPv6 (anycast)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'cloudflare-security',
      endpoint: {
        protocol: 'https:',
        host: 'security.cloudflare-dns.com',
        ipv4: '1.0.0.2',
        cors: true
      },
      description: 'Cloudflare DNS (anycast) with malware blocking - aka 1.1.1.2 / 1.0.0.2',
      country: 'Australia',
      location: {
        lat: -33.494,
        long: 143.2104
      },
      filter: true,
      cors: true
    },
    {
      name: 'controld-block-malware',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p1'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-block-malware-ad',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p2'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-block-malware-ad-social',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p3'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking and Social Networks domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-family-friendly',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/family'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS blocks Malware, Ads & Tracking, Adult Content and Drugs domains.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      },
      filter: true
    },
    {
      name: 'controld-uncensored',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/uncensored'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis DNS unblocks censored domains from various countries.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      }
    },
    {
      name: 'controld-unfiltered',
      endpoint: {
        protocol: 'https:',
        host: 'freedns.controld.com',
        path: '/p0'
      },
      description: 'ControlD Free DNS. Take CONTROL of your Internet. Block unwanted content, bypass geo-restrictions and be more productive. DoH protocol and No logging. - https://controld.com/free-dns\nThis is a Unfiltered DNS, no DNS record blocking or manipulation here, if you want to block Malware, Ads & Tracking or Social Network domains, use the other ControlD DNS configs.',
      country: 'Canada',
      location: {
        lat: 43.6319,
        long: -79.3716
      }
    },
    {
      name: 'dns.digitale-gesellschaft.ch',
      endpoint: {
        protocol: 'https:',
        host: 'dns.digitale-gesellschaft.ch'
      },
      description: 'Public DoH resolver operated by the Digital Society (https://www.digitale-gesellschaft.ch).\nHosted in Zurich, Switzerland.\nNon-logging, non-filtering, supports DNSSEC.',
      country: 'Switzerland',
      location: {
        lat: 47.1449,
        long: 8.1551
      }
    },
    {
      name: 'dns.ryan-palmer',
      endpoint: {
        protocol: 'https:',
        host: 'dns1.ryan-palmer.com'
      },
      description: 'Non-logging, non-filtering, DNSSEC DoH Server. Hosted in the UK.',
      country: 'United Kingdom',
      location: {
        lat: 51.5164,
        long: -0.093
      }
    },
    {
      name: 'dns.sb',
      endpoint: {
        protocol: 'https:',
        host: 'doh.sb',
        ipv4: '185.222.222.222',
        cors: true
      },
      description: 'DNSSEC-enabled DoH server by https://xtom.com/\nhttps://dns.sb/doh/',
      country: 'Unknown',
      location: {
        lat: 47,
        long: 8
      },
      cors: true
    },
    {
      name: 'dns.therifleman.name',
      endpoint: {
        protocol: 'https:',
        host: 'dns.therifleman.name'
      },
      description: 'DNS-over-HTTPS DNS forwarder from Mumbai, India. Blocks web and Android trackers and ads.\nIP addresses are not logged, but queries are logged for 24 hours for debugging.\nReport issues, send suggestions @ joker349 at protonmail.com.\nAlso supports DoT (for android) @ dns.therifleman.name and plain DNS @ 172.104.206.174',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'dnsforfamily-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns-doh.dnsforfamily.com'
      },
      description: '(DoH Protocol) (Now supports DNSSEC). Block adult websites, gambling websites, malwares and advertisements.\nIt also enforces safe search in: Google, YouTube, Bing, DuckDuckGo and Yandex.\nSocial websites like Facebook and Instagram are not blocked. No DNS queries are logged.\nAs of 26-May-2022 5.9 million websites are blocked and new websites are added to blacklist daily.\nCompletely free, no ads or any commercial motive. Operating for 4 years now.\nProvided by: https://dnsforfamily.com',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true
    },
    {
      name: 'dnsforfamily-doh-no-safe-search',
      endpoint: {
        protocol: 'https:',
        host: 'dns-doh-no-safe-search.dnsforfamily.com'
      },
      description: '(DoH Protocol) (Now supports DNSSEC) Block adult websites, gambling websites, malwares and advertisements.\nUnlike other dnsforfamily servers, this one does not enforces safe search. So Google, YouTube, Bing, DuckDuckGo and Yandex are completely accessible without any restriction.\nSocial websites like Facebook and Instagram are not blocked. No DNS queries are logged.\nAs of 26-May-2022 5.9 million websites are blocked and new websites are added to blacklist daily.\nCompletely free, no ads or any commercial motive. Operating for 4 years now.\nWarning: This server is incompatible with anonymization.\nProvided by: https://dnsforfamily.com',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true
    },
    {
      name: 'dnsforge.de',
      endpoint: {
        protocol: 'https:',
        host: 'dnsforge.de',
        cors: true
      },
      description: 'Public DoH resolver running with Pihole for Adblocking (https://dnsforge.de).\nNon-logging, AD-filtering, supports DNSSEC. Hosted in Germany.',
      country: 'Germany',
      location: {
        lat: 52.2998,
        long: 9.447
      },
      filter: true,
      cors: true
    },
    {
      name: 'dnshome-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.dnshome.de'
      },
      description: 'https://www.dnshome.de/ public resolver in Germany'
    },
    {
      name: 'dnspod-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.pub',
        cors: true
      },
      description: 'A public DNS resolver in mainland China provided by DNSPod (Tencent Cloud).\nhttps://www.dnspod.cn/Products/Public.DNS?lang=en',
      filter: true,
      log: true,
      cors: true
    },
    {
      name: 'dnswarden-asia-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/adblock'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'dnswarden-asia-adultfilter-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/adultfilter'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'dnswarden-asia-uncensor-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.asia.dnswarden.com',
        path: '/uncensored'
      },
      description: 'Hosted in Singapore. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      }
    },
    {
      name: 'dnswarden-eu-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.eu.dnswarden.com'
      },
      description: 'Hosted in Germany. For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'Germany',
      location: {
        lat: 50.1103,
        long: 8.7147
      },
      filter: true
    },
    {
      name: 'dnswarden-us-adblock-dohv4',
      endpoint: {
        protocol: 'https:',
        host: 'doh.us.dnswarden.com'
      },
      description: 'Hosted in USA (Dallas) . For more information look [here](https://github.com/bhanupratapys/dnswarden) or [here](https://dnswarden.com).',
      country: 'United States',
      location: {
        lat: 32.7889,
        long: -96.8021
      },
      filter: true
    },
    {
      name: 'doh-ch-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-ch.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Switzerland. By https://blahdns.com/',
      country: 'Netherlands',
      location: {
        lat: 52.3824,
        long: 4.8995
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-adult',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/adult-filter/',
        cors: true
      },
      description: 'Blocks access to all adult, pornographic and explicit sites. It does\nnot block proxy or VPNs, nor mixed-content sites. Sites like Reddit\nare allowed. Google and Bing are set to the Safe Mode.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-family',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/family-filter/',
        cors: true
      },
      description: 'Blocks access to all adult, pornographic and explicit sites. It also\nblocks proxy and VPN domains that are used to bypass the filters.\nMixed content sites (like Reddit) are also blocked. Google, Bing and\nYoutube are set to the Safe Mode.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-cleanbrowsing-security',
      endpoint: {
        protocol: 'https:',
        host: 'doh.cleanbrowsing.org',
        path: '/doh/security-filter/',
        cors: true
      },
      description: 'Block access to phishing, malware and malicious domains. It does not block adult content.\nBy https://cleanbrowsing.org/',
      filter: true,
      cors: true
    },
    {
      name: 'doh-crypto-sx',
      endpoint: {
        protocol: 'https:',
        host: 'doh.crypto.sx',
        cors: true
      },
      description: 'DNS-over-HTTPS server. Anycast, no logs, no censorship, DNSSEC.\nBackend hosted by Scaleway, globally cached via Cloudflare.\nMaintained by Frank Denis.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'doh-crypto-sx-ipv6',
      endpoint: {
        protocol: 'https:',
        host: 'doh-ipv6.crypto.sx',
        cors: true
      },
      description: 'DNS-over-HTTPS server accessible over IPv6. Anycast, no logs, no censorship, DNSSEC.\nBackend hosted by Scaleway, globally cached via Cloudflare.\nMaintained by Frank Denis.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'doh-de-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-de.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Germany. By https://blahdns.com/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-fi-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-fi.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Finland. By https://blahdns.com/',
      country: 'Finland',
      location: {
        lat: 60.1758,
        long: 24.9349
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh-ibksturm',
      endpoint: {
        protocol: 'https:',
        host: 'ibksturm.synology.me'
      },
      description: 'DoH & DoT Server, No Logging, No Filters, DNSSEC\nRunning privately by ibksturm in Thurgau, Switzerland'
    },
    {
      name: 'doh-jp-blahdns',
      endpoint: {
        protocol: 'https:',
        host: 'doh-jp.blahdns.com',
        cors: true
      },
      description: 'Blocks ad and Tracking, no Logging, DNSSEC, Hosted in Japan. By https://blahdns.com/',
      country: 'Japan',
      location: {
        lat: 35.6882,
        long: 139.7532
      },
      filter: true,
      cors: true
    },
    {
      name: 'doh.ffmuc.net',
      endpoint: {
        protocol: 'https:',
        host: 'doh.ffmuc.net'
      },
      description: 'An open (non-logging, non-filtering, non-censoring) DoH resolver operated by Freifunk Munich with nodes in DE.\nhttps://ffmuc.net/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      }
    },
    {
      name: 'doh.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiarap.org'
      },
      description: 'Non-Logging DNS-over-HTTPS server, cached via Cloudflare.\nFilters out ads, trackers and malware, NO ECS, supports DNSSEC.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'google',
      endpoint: {
        protocol: 'https:',
        host: 'dns.google',
        ipv4: '8.8.8.8',
        cors: true
      },
      description: 'Google DNS (anycast)',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      log: true,
      cors: true
    },
    {
      name: 'hdns',
      endpoint: {
        protocol: 'https:',
        host: 'query.hdns.io',
        cors: true
      },
      description: 'HDNS is a public DNS resolver that supports Handshake domains.\nhttps://www.hdns.io',
      country: 'United States',
      location: {
        lat: 37.7771,
        long: -122.406
      },
      cors: true
    },
    {
      name: 'he',
      endpoint: {
        protocol: 'https:',
        host: 'ordns.he.net'
      },
      description: 'Hurricane Electric DoH server (anycast)\nUnknown logging policy.',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      log: true
    },
    {
      name: 'id-gmail-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiar.app'
      },
      description: 'Non-Logging DNS-over-HTTPS server located in Singapore.\nFilters out ads, trackers and malware, supports DNSSEC, provided by id-gmail.',
      country: 'Singapore',
      location: {
        lat: 1.2929,
        long: 103.8547
      },
      filter: true
    },
    {
      name: 'iij',
      endpoint: {
        protocol: 'https:',
        host: 'public.dns.iij.jp'
      },
      description: 'DoH server operated by Internet Initiative Japan in Tokyo.\nhttps://www.iij.ad.jp/',
      country: 'Japan',
      location: {
        lat: 35.69,
        long: 139.69
      },
      log: true
    },
    {
      name: 'iqdns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'a.passcloud.xyz'
      },
      description: 'Non-logging DoH service runned by V2EX.com user johnsonwil.\nReturns "no such domain" for anti-Chinese government websites. Supports DNSSEC.\nFor more information: https://www.v2ex.com/t/785666',
      filter: true
    },
    {
      name: 'jp.tiar.app-doh',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiar.app'
      },
      description: 'Non-Logging, Non-Filtering DNS-over-HTTPS server in Japan.\nNo ECS, Support DNSSEC',
      country: 'Japan',
      location: {
        lat: 35.6882,
        long: 139.7532
      }
    },
    {
      name: 'jp.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiarap.org'
      },
      description: 'DNS-over-HTTPS Server. Non-Logging, Non-Filtering, No ECS, Support DNSSEC.\nCached via Cloudflare.'
    },
    {
      name: 'libredns',
      endpoint: {
        protocol: 'https:',
        host: 'doh.libredns.gr'
      },
      description: 'DoH server in Germany. No logging, but no DNS padding and no DNSSEC support.\nhttps://libredns.gr/',
      country: 'Germany',
      location: {
        lat: 51.2993,
        long: 9.491
      }
    },
    {
      name: 'nextdns',
      endpoint: {
        protocol: 'https:',
        host: 'anycsast.dns.nextdns.io'
      },
      description: 'NextDNS is a cloud-based private DNS service that gives you full control\nover what is allowed and what is blocked on the Internet.\nDNSSEC, Anycast, Non-logging, NoFilters\nhttps://www.nextdns.io/',
      country: 'Netherlands',
      location: {
        lat: 52.3891,
        long: 4.6563
      }
    },
    {
      name: 'nextdns-ultralow',
      endpoint: {
        protocol: 'https:',
        host: 'dns.nextdns.io',
        path: '/dnscrypt-proxy'
      },
      description: 'NextDNS is a cloud-based private DNS service that gives you full control\nover what is allowed and what is blocked on the Internet.\nhttps://www.nextdns.io/\nTo select the server location, the "-ultralow" variant relies on bootstrap servers\ninstead of anycast.'
    },
    {
      name: 'njalla-doh',
      endpoint: {
        protocol: 'https:',
        host: 'dns.njal.la',
        cors: true
      },
      description: 'Non-logging DoH server in Sweden operated by Njalla.\nhttps://dns.njal.la/',
      country: 'Sweden',
      location: {
        lat: 59.3247,
        long: 18.056
      },
      cors: true
    },
    {
      name: 'odoh-cloudflare',
      endpoint: {
        protocol: 'https:',
        host: 'odoh.cloudflare-dns.com',
        cors: true
      },
      description: 'Cloudflare ODoH server.\nhttps://cloudflare.com',
      cors: true
    },
    {
      name: 'odoh-crypto-sx',
      endpoint: {
        protocol: 'https:',
        host: 'odoh.crypto.sx',
        cors: true
      },
      description: 'ODoH target server. Anycast, no logs.\nBackend hosted by Scaleway. Maintained by Frank Denis.',
      cors: true
    },
    {
      name: 'odoh-id-gmail',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiar.app',
        path: '/odoh'
      },
      description: 'ODoH target server. Based in Singapore, no logs.\nFilter ads, trackers and malware.',
      filter: true
    },
    {
      name: 'odoh-jp.tiar.app',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiar.app',
        path: '/odoh'
      },
      description: 'ODoH target server. no logs.'
    },
    {
      name: 'odoh-jp.tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'jp.tiarap.org',
        path: '/odoh'
      },
      description: 'ODoH target server via Cloudflare, no logs.'
    },
    {
      name: 'odoh-resolver4.dns.openinternet.io',
      endpoint: {
        protocol: 'https:',
        host: 'resolver4.dns.openinternet.io'
      },
      description: "ODoH target server. no logs, no filter, DNSSEC.\nRunning on dedicated hardware colocated at Sonic.net in Santa Rosa, CA in the United States.\nUses Sonic's recusrive DNS servers as upstream resolvers (but is not affiliated with Sonic\nin any way). Provided by https://openinternet.io"
    },
    {
      name: 'odoh-tiarap.org',
      endpoint: {
        protocol: 'https:',
        host: 'doh.tiarap.org',
        path: '/odoh'
      },
      description: 'ODoH target server via Cloudflare, no logs.\nFilter ads, trackers and malware.',
      filter: true
    },
    {
      name: 'publicarray-au2-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh-2.seby.io',
        cors: true
      },
      description: 'DNSSEC • OpenNIC • Non-logging • Uncensored - hosted on ovh.com.au\nMaintained by publicarray - https://dns.seby.io',
      country: 'Australia',
      location: {
        lat: -33.8591,
        long: 151.2002
      },
      cors: true
    },
    {
      name: 'puredns-doh',
      endpoint: {
        protocol: 'https:',
        host: 'puredns.org',
        ipv4: '146.190.6.13',
        cors: true
      },
      description: 'Public uncensored DNS resolver in Singapore - https://puredns.org\n** Only available in Indonesia and Singapore **',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      cors: true
    },
    {
      name: 'quad101',
      endpoint: {
        protocol: 'https:',
        host: 'dns.twnic.tw',
        cors: true
      },
      description: 'DNSSEC-aware public resolver by the Taiwan Network Information Center (TWNIC)\nhttps://101.101.101.101/index_en.html',
      cors: true
    },
    {
      name: 'quad9-doh-ip4-port443-filter-ecs-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns11.quad9.net',
        ipv4: '149.112.112.11'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter/ecs 9.9.9.11 - 149.112.112.11',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'quad9-doh-ip4-port443-filter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns.quad9.net',
        ipv4: '149.112.112.112'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter 9.9.9.9 - 149.112.112.9 - 149.112.112.112',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'quad9-doh-ip4-port443-nofilter-ecs-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns12.quad9.net',
        ipv4: '9.9.9.12'
      },
      description: 'Quad9 (anycast) no-dnssec/no-log/no-filter/ecs 9.9.9.12 - 149.112.112.12',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      }
    },
    {
      name: 'quad9-doh-ip4-port443-nofilter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns10.quad9.net',
        ipv4: '149.112.112.10'
      },
      description: 'Quad9 (anycast) no-dnssec/no-log/no-filter 9.9.9.10 - 149.112.112.10',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      }
    },
    {
      name: 'quad9-doh-ip6-port5053-filter-pri',
      endpoint: {
        protocol: 'https:',
        host: 'dns9.quad9.net'
      },
      description: 'Quad9 (anycast) dnssec/no-log/filter 2620:fe::fe - 2620:fe::9 - 2620:fe::fe:9',
      country: 'United States',
      location: {
        lat: 37.751,
        long: -97.822
      },
      filter: true
    },
    {
      name: 'safesurfer-doh',
      endpoint: {
        protocol: 'https:',
        host: 'doh.safesurfer.io'
      },
      description: 'Family safety focused blocklist for over 2 million adult sites, as well as phishing and malware and more.\nFree to use, paid for customizing blocking for more categories+sites and viewing usage at my.safesurfer.io. Logs taken for viewing\nusage, data never sold - https://safesurfer.io',
      filter: true,
      log: true
    },
    {
      name: 'sth-ads-doh-se',
      endpoint: {
        protocol: 'https:',
        host: 'dnsse-noads.alekberg.net'
      },
      description: 'Resolver in Stockholm, Sweden. DoH server. Non-logging, remove ads and malware, DNSSEC.',
      country: 'Bulgaria',
      location: {
        lat: 42.696,
        long: 23.332
      },
      filter: true
    },
    {
      name: 'sth-doh-se',
      endpoint: {
        protocol: 'https:',
        host: 'dnsse.alekberg.net'
      },
      description: 'Resolver in Stockholm, Sweden. DoH server. Non-logging, non-filtering, DNSSEC.',
      country: 'Bulgaria',
      location: {
        lat: 42.696,
        long: 23.332
      }
    },
    {
      name: 'switch',
      endpoint: {
        protocol: 'https:',
        host: 'dns.switch.ch'
      },
      description: 'Public DoH service provided by SWITCH in Switzerland\nhttps://www.switch.ch\nProvides protection against malware, but does not block ads.',
      filter: true
    },
    {
      name: 'uncensoreddns-dk-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'unicast.uncensoreddns.org'
      },
      description: 'Also known as censurfridns.\nDoH, no logs, no filter, DNSSEC, unicast hosted in Denmark - https://blog.uncensoreddns.org',
      country: 'Denmark',
      location: {
        lat: 55.7123,
        long: 12.0564
      }
    },
    {
      name: 'uncensoreddns-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'anycast.uncensoreddns.org'
      },
      description: 'Also known as censurfridns.\nDoH, no logs, no filter, DNSSEC, anycast - https://blog.uncensoreddns.org',
      country: 'Denmark',
      location: {
        lat: 55.7123,
        long: 12.0564
      }
    },
    {
      name: 'v.dnscrypt.uk-doh-ipv4',
      endpoint: {
        protocol: 'https:',
        host: 'v.dnscrypt.uk'
      },
      description: 'DoH, no logs, uncensored, DNSSEC. Hosted in London UK on Digital Ocean\nhttps://www.dnscrypt.uk',
      country: 'United Kingdom',
      location: {
        lat: 51.4964,
        long: -0.1224
      }
    }
  ],
  time: 1654187067783
};

function processResolvers (res) {
  const time = (res.time === null || res.time === undefined) ? Date.now() : res.time;
  const resolvers = processResolvers$1(res.data.map(resolver => {
    resolver.endpoint = toEndpoint(Object.assign({ name: resolver.name }, resolver.endpoint));
    return resolver
  }));
  const endpoints = resolvers.map(resolver => resolver.endpoint);
  return {
    data: {
      resolvers,
      resolverByName: resolvers.reduce((byName, resolver) => {
        byName[resolver.name] = resolver;
        return byName
      }, {}),
      endpoints,
      endpointByName: endpoints.reduce((byName, endpoint) => {
        byName[endpoint.name] = endpoint;
        return byName
      }, {})
    },
    time
  }
}

const backup = processResolvers(resolvers);

function toMultiQuery (singleQuery) {
  const query = Object.assign({
    type: 'query'
  }, singleQuery);
  delete query.question;
  query.questions = [];
  if (singleQuery.question) {
    query.questions.push(singleQuery.question);
  }
  return query
}

function queryOne (endpoint, query, timeout, abortSignal) {
  if (abortSignal && abortSignal.aborted) {
    return Promise.reject(new AbortError$3())
  }
  if (endpoint.protocol === 'udp4:' || endpoint.protocol === 'udp6:') {
    return queryDns()
  }
  return queryDoh(endpoint, query, timeout, abortSignal)
}

function queryDoh (endpoint, query, timeout, abortSignal) {
  return request$1(
    endpoint.url,
    endpoint.method,
    encode$j(Object.assign({
      flags: RECURSION_DESIRED
    }, query)),
    timeout,
    abortSignal
  ).then(
    function (res) {
      const data = res.data;
      const response = res.response;
      let error = res.error;
      if (error === undefined) {
        if (data.length === 0) {
          error = new ResponseError('Empty.');
        } else {
          try {
            const decoded = decode$d(data);
            decoded.response = response;
            return decoded
          } catch (err) {
            error = new ResponseError('Invalid packet (cause=' + err.message + ')', err);
          }
        }
      }
      throw Object.assign(error, { response })
    }
  )
}

const UPDATE_URL = new URL$1('https://martinheidegger.github.io/dns-query/resolvers.json');

function isNameString (entry) {
  return /^@/.test(entry)
}

class Wellknown {
  constructor (opts) {
    this.opts = Object.assign({
      timeout: 5000,
      update: true,
      updateURL: UPDATE_URL,
      persist: false,
      localStoragePrefix: 'dnsquery_',
      maxAge: 300000 // 5 minutes
    }, opts);
    this._dataP = null;
  }

  _data (force, outdated) {
    if (!force && this._dataP !== null) {
      return this._dataP.then(res => {
        if (res.time < Date.now() - this.opts.maxAge) {
          return this._data(true, res)
        }
        return res
      })
    }
    this._dataP = (!this.opts.update
      ? Promise.resolve(backup)
      : loadJSON(
        this.opts.updateURL,
        this.opts.persist
          ? {
              name: 'resolvers.json',
              localStoragePrefix: this.opts.localStoragePrefix,
              maxTime: Date.now() - this.opts.maxAge
            }
          : null,
        this.opts.timeout
      )
        .then(res => processResolvers({
          data: res.data.resolvers,
          time: res.time
        }))
        .catch(() => outdated || backup)
    );
    return this._dataP
  }

  data () {
    return this._data(false).then(data => data.data)
  }

  endpoints (input) {
    if (input === null || input === undefined) {
      return this.data().then(data => data.endpoints)
    }
    if (input === 'doh') {
      input = filterDoh;
    }
    if (input === 'dns') {
      input = filterDns;
    }
    if (typeof input === 'function') {
      return this.data().then(data => data.endpoints.filter(input))
    }
    if (typeof input === 'string' || typeof input[Symbol.iterator] !== 'function') {
      return Promise.reject(new Error(`Endpoints (${input}) needs to be iterable (array).`))
    }
    input = Array.from(input).filter(Boolean);
    if (input.findIndex(isNameString) === -1) {
      try {
        return Promise.resolve(input.map(toEndpoint))
      } catch (err) {
        return Promise.reject(err)
      }
    }
    return this.data().then(data =>
      input.map(entry => {
        if (isNameString(entry)) {
          const found = data.endpointByName[entry.substring(1)];
          if (!found) {
            throw new Error(`Endpoint ${entry} is not known.`)
          }
          return found
        }
        return toEndpoint(entry)
      })
    )
  }
}

const wellknown = new Wellknown();

function isPromise (input) {
  if (input === null) {
    return false
  }
  if (typeof input !== 'object') {
    return false
  }
  return typeof input.then === 'function'
}

function toPromise (input) {
  return isPromise(input) ? input : Promise.resolve(input)
}

function query (q, opts) {
  opts = Object.assign({
    retries: 5,
    timeout: 30000 // 30 seconds
  }, opts);
  if (!q.question) return Promise.reject(new Error('To request data you need to specify a .question!'))
  return toPromise(opts.endpoints)
    .then(endpoints => {
      if (!Array.isArray(endpoints) || endpoints.length === 0) {
        throw new Error('No endpoints defined to lookup dns records.')
      }
      return queryN(endpoints.map(toEndpoint), toMultiQuery(q), opts)
    })
    .then(data => {
      data.question = data.questions[0];
      delete data.questions;
      return data
    })
}

function queryN (endpoints, q, opts) {
  const endpoint = endpoints.length === 1
    ? endpoints[0]
    : endpoints[Math.floor(Math.random() * endpoints.length) % endpoints.length];
  return queryOne(endpoint, q, opts.timeout, opts.signal)
    .then(
      data => {
        // Add the endpoint to give a chance to identify which endpoint returned the result
        data.endpoint = endpoint.toString();
        return data
      },
      err => {
        if (err.name === 'AbortError' || opts.retries === 0) {
          err.endpoint = endpoint.toString();
          throw err
        }
        if (opts.retries > 0) {
          opts.retries -= 1;
        }
        return queryN(endpoints, q, opts)
      }
    )
}

function filterDoh (endpoint) {
  return endpoint.protocol === 'https:' || endpoint.protocol === 'http:'
}

function filterDns (endpoint) {
  return endpoint.protocol === 'udp4:' || endpoint.protocol === 'udp6:'
}

const log$u = debug("waku:dns-over-https");
class DnsOverHttps {
    endpoints;
    retries;
    /**
     * Create new Dns-Over-Http DNS client.
     *
     * @param endpoints The endpoints for Dns-Over-Https queries;
     * Defaults to using dns-query's API..
     * @param retries Retries if a given endpoint fails.
     *
     * @throws {code: string} If DNS query fails.
     */
    static async create(endpoints, retries) {
        const _endpoints = endpoints ?? (await wellknown.endpoints("doh"));
        return new DnsOverHttps(_endpoints, retries);
    }
    constructor(endpoints, retries = 3) {
        this.endpoints = endpoints;
        this.retries = retries;
    }
    /**
     * Resolves a TXT record
     *
     * @param domain The domain name
     *
     * @throws if the query fails
     */
    async resolveTXT(domain) {
        let answers;
        try {
            const res = await query({
                question: { type: "TXT", name: domain }
            }, {
                endpoints: this.endpoints,
                retries: this.retries
            });
            answers = res.answers;
        }
        catch (error) {
            log$u("query failed: ", error);
            throw new Error("DNS query failed");
        }
        if (!answers)
            throw new Error(`Could not resolve ${domain}`);
        const data = answers.map((a) => a.data);
        const result = [];
        data.forEach((d) => {
            if (typeof d === "string") {
                result.push(d);
            }
            else if (Array.isArray(d)) {
                d.forEach((sd) => {
                    if (typeof sd === "string") {
                        result.push(sd);
                    }
                    else {
                        result.push(bytesToUtf8(sd));
                    }
                });
            }
            else {
                result.push(bytesToUtf8(d));
            }
        });
        return result;
    }
}

var base32$6 = {exports: {}};

/*
 * [hi-base32]{@link https://github.com/emn178/hi-base32}
 *
 * @version 0.5.0
 * @author Chen, Yi-Cyuan [emn178@gmail.com]
 * @copyright Chen, Yi-Cyuan 2015-2018
 * @license MIT
 */

(function (module) {
	/*jslint bitwise: true */
	(function () {

	  var root = typeof window === 'object' ? window : {};
	  var NODE_JS = !root.HI_BASE32_NO_NODE_JS && typeof process === 'object' && process.versions && process.versions.node;
	  if (NODE_JS) {
	    root = commonjsGlobal;
	  }
	  var COMMON_JS = !root.HI_BASE32_NO_COMMON_JS && 'object' === 'object' && module.exports;
	  var BASE32_ENCODE_CHAR = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'.split('');
	  var BASE32_DECODE_CHAR = {
	    'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8,
	    'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16,
	    'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24,
	    'Z': 25, '2': 26, '3': 27, '4': 28, '5': 29, '6': 30, '7': 31
	  };

	  var blocks = [0, 0, 0, 0, 0, 0, 0, 0];

	  var throwInvalidUtf8 = function (position, partial) {
	    if (partial.length > 10) {
	      partial = '...' + partial.substr(-10);
	    }
	    var err = new Error('Decoded data is not valid UTF-8.'
	      + ' Maybe try base32.decode.asBytes()?'
	      + ' Partial data after reading ' + position + ' bytes: ' + partial + ' <-');
	    err.position = position;
	    throw err;
	  };

	  var toUtf8String = function (bytes) {
	    var str = '', length = bytes.length, i = 0, followingChars = 0, b, c;
	    while (i < length) {
	      b = bytes[i++];
	      if (b <= 0x7F) {
	        str += String.fromCharCode(b);
	        continue;
	      } else if (b > 0xBF && b <= 0xDF) {
	        c = b & 0x1F;
	        followingChars = 1;
	      } else if (b <= 0xEF) {
	        c = b & 0x0F;
	        followingChars = 2;
	      } else if (b <= 0xF7) {
	        c = b & 0x07;
	        followingChars = 3;
	      } else {
	        throwInvalidUtf8(i, str);
	      }

	      for (var j = 0; j < followingChars; ++j) {
	        b = bytes[i++];
	        if (b < 0x80 || b > 0xBF) {
	          throwInvalidUtf8(i, str);
	        }
	        c <<= 6;
	        c += b & 0x3F;
	      }
	      if (c >= 0xD800 && c <= 0xDFFF) {
	        throwInvalidUtf8(i, str);
	      }
	      if (c > 0x10FFFF) {
	        throwInvalidUtf8(i, str);
	      }

	      if (c <= 0xFFFF) {
	        str += String.fromCharCode(c);
	      } else {
	        c -= 0x10000;
	        str += String.fromCharCode((c >> 10) + 0xD800);
	        str += String.fromCharCode((c & 0x3FF) + 0xDC00);
	      }
	    }
	    return str;
	  };

	  var decodeAsBytes = function (base32Str) {
	    if (base32Str === '') {
	      return [];
	    } else if (!/^[A-Z2-7=]+$/.test(base32Str)) {
	      throw new Error('Invalid base32 characters');
	    }
	    base32Str = base32Str.replace(/=/g, '');
	    var v1, v2, v3, v4, v5, v6, v7, v8, bytes = [], index = 0, length = base32Str.length;

	    // 4 char to 3 bytes
	    for (var i = 0, count = length >> 3 << 3; i < count;) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v8 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	      bytes[index++] = (v5 << 7 | v6 << 2 | v7 >>> 3) & 255;
	      bytes[index++] = (v7 << 5 | v8) & 255;
	    }

	    // remain bytes
	    var remain = length - count;
	    if (remain === 2) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	    } else if (remain === 4) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	    } else if (remain === 5) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	    } else if (remain === 7) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      bytes[index++] = (v1 << 3 | v2 >>> 2) & 255;
	      bytes[index++] = (v2 << 6 | v3 << 1 | v4 >>> 4) & 255;
	      bytes[index++] = (v4 << 4 | v5 >>> 1) & 255;
	      bytes[index++] = (v5 << 7 | v6 << 2 | v7 >>> 3) & 255;
	    }
	    return bytes;
	  };

	  var encodeAscii = function (str) {
	    var v1, v2, v3, v4, v5, base32Str = '', length = str.length;
	    for (var i = 0, count = parseInt(length / 5) * 5; i < count;) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i++);
	      v4 = str.charCodeAt(i++);
	      v5 = str.charCodeAt(i++);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	        BASE32_ENCODE_CHAR[v5 & 31];
	    }

	    // remain char
	    var remain = length - count;
	    if (remain === 1) {
	      v1 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	        '======';
	    } else if (remain === 2) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	        '====';
	    } else if (remain === 3) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	        '===';
	    } else if (remain === 4) {
	      v1 = str.charCodeAt(i++);
	      v2 = str.charCodeAt(i++);
	      v3 = str.charCodeAt(i++);
	      v4 = str.charCodeAt(i);
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	        '=';
	    }
	    return base32Str;
	  };

	  var encodeUtf8 = function (str) {
	    var v1, v2, v3, v4, v5, code, end = false, base32Str = '',
	      index = 0, i, start = 0, length = str.length;
	      if (str === '') {
	        return base32Str;
	      }
	    do {
	      blocks[0] = blocks[5];
	      blocks[1] = blocks[6];
	      blocks[2] = blocks[7];
	      for (i = start; index < length && i < 5; ++index) {
	        code = str.charCodeAt(index);
	        if (code < 0x80) {
	          blocks[i++] = code;
	        } else if (code < 0x800) {
	          blocks[i++] = 0xc0 | (code >> 6);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        } else if (code < 0xd800 || code >= 0xe000) {
	          blocks[i++] = 0xe0 | (code >> 12);
	          blocks[i++] = 0x80 | ((code >> 6) & 0x3f);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        } else {
	          code = 0x10000 + (((code & 0x3ff) << 10) | (str.charCodeAt(++index) & 0x3ff));
	          blocks[i++] = 0xf0 | (code >> 18);
	          blocks[i++] = 0x80 | ((code >> 12) & 0x3f);
	          blocks[i++] = 0x80 | ((code >> 6) & 0x3f);
	          blocks[i++] = 0x80 | (code & 0x3f);
	        }
	      }
	      start = i - 5;
	      if (index === length) {
	        ++index;
	      }
	      if (index > length && i < 6) {
	        end = true;
	      }
	      v1 = blocks[0];
	      if (i > 4) {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        v4 = blocks[3];
	        v5 = blocks[4];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	          BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	          BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	          BASE32_ENCODE_CHAR[v5 & 31];
	      } else if (i === 1) {
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	          '======';
	      } else if (i === 2) {
	        v2 = blocks[1];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	          '====';
	      } else if (i === 3) {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	          '===';
	      } else {
	        v2 = blocks[1];
	        v3 = blocks[2];
	        v4 = blocks[3];
	        base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	          BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	          BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	          BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	          BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	          BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	          BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	          '=';
	      }
	    } while (!end);
	    return base32Str;
	  };

	  var encodeBytes = function (bytes) {
	    var v1, v2, v3, v4, v5, base32Str = '', length = bytes.length;
	    for (var i = 0, count = parseInt(length / 5) * 5; i < count;) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i++];
	      v4 = bytes[i++];
	      v5 = bytes[i++];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3 | v5 >>> 5) & 31] +
	        BASE32_ENCODE_CHAR[v5 & 31];
	    }

	    // remain char
	    var remain = length - count;
	    if (remain === 1) {
	      v1 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2) & 31] +
	        '======';
	    } else if (remain === 2) {
	      v1 = bytes[i++];
	      v2 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4) & 31] +
	        '====';
	    } else if (remain === 3) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1) & 31] +
	        '===';
	    } else if (remain === 4) {
	      v1 = bytes[i++];
	      v2 = bytes[i++];
	      v3 = bytes[i++];
	      v4 = bytes[i];
	      base32Str += BASE32_ENCODE_CHAR[v1 >>> 3] +
	        BASE32_ENCODE_CHAR[(v1 << 2 | v2 >>> 6) & 31] +
	        BASE32_ENCODE_CHAR[(v2 >>> 1) & 31] +
	        BASE32_ENCODE_CHAR[(v2 << 4 | v3 >>> 4) & 31] +
	        BASE32_ENCODE_CHAR[(v3 << 1 | v4 >>> 7) & 31] +
	        BASE32_ENCODE_CHAR[(v4 >>> 2) & 31] +
	        BASE32_ENCODE_CHAR[(v4 << 3) & 31] +
	        '=';
	    }
	    return base32Str;
	  };

	  var encode = function (input, asciiOnly) {
	    var notString = typeof(input) !== 'string';
	    if (notString && input.constructor === ArrayBuffer) {
	      input = new Uint8Array(input);
	    }
	    if (notString) {
	      return encodeBytes(input);
	    } else if (asciiOnly) {
	      return encodeAscii(input);
	    } else {
	      return encodeUtf8(input);
	    }
	  };

	  var decode = function (base32Str, asciiOnly) {
	    if (!asciiOnly) {
	      return toUtf8String(decodeAsBytes(base32Str));
	    }
	    if (base32Str === '') {
	      return '';
	    } else if (!/^[A-Z2-7=]+$/.test(base32Str)) {
	      throw new Error('Invalid base32 characters');
	    }
	    var v1, v2, v3, v4, v5, v6, v7, v8, str = '', length = base32Str.indexOf('=');
	    if (length === -1) {
	      length = base32Str.length;
	    }

	    // 8 char to 5 bytes
	    for (var i = 0, count = length >> 3 << 3; i < count;) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v8 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255) +
	        String.fromCharCode((v5 << 7 | v6 << 2 | v7 >>> 3) & 255) +
	        String.fromCharCode((v7 << 5 | v8) & 255);
	    }

	    // remain bytes
	    var remain = length - count;
	    if (remain === 2) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255);
	    } else if (remain === 4) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255);
	    } else if (remain === 5) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255);
	    } else if (remain === 7) {
	      v1 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v2 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v3 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v4 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v5 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v6 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      v7 = BASE32_DECODE_CHAR[base32Str.charAt(i++)];
	      str += String.fromCharCode((v1 << 3 | v2 >>> 2) & 255) +
	        String.fromCharCode((v2 << 6 | v3 << 1 | v4 >>> 4) & 255) +
	        String.fromCharCode((v4 << 4 | v5 >>> 1) & 255) +
	        String.fromCharCode((v5 << 7 | v6 << 2 | v7 >>> 3) & 255);
	    }
	    return str;
	  };

	  var exports = {
	    encode: encode,
	    decode: decode
	  };
	  decode.asBytes = decodeAsBytes;

	  if (COMMON_JS) {
	    module.exports = exports;
	  } else {
	    root.base32 = exports;
	  }
	})(); 
} (base32$6));

var base32Exports = base32$6.exports;
var base32$5 = /*@__PURE__*/getDefaultExportFromCjs(base32Exports);

class ENRTree {
    static RECORD_PREFIX = ENR.RECORD_PREFIX;
    static TREE_PREFIX = "enrtree:";
    static BRANCH_PREFIX = "enrtree-branch:";
    static ROOT_PREFIX = "enrtree-root:";
    /**
     * Extracts the branch subdomain referenced by a DNS tree root string after verifying
     * the root record signature with its base32 compressed public key.
     */
    static parseAndVerifyRoot(root, publicKey) {
        if (!root.startsWith(this.ROOT_PREFIX))
            throw new Error(`ENRTree root entry must start with '${this.ROOT_PREFIX}'`);
        const rootValues = ENRTree.parseRootValues(root);
        const decodedPublicKey = base32$5.decode.asBytes(publicKey);
        // The signature is a 65-byte secp256k1 over the keccak256 hash
        // of the record content, excluding the `sig=` part, encoded as URL-safe base64 string
        // (Trailing recovery bit must be trimmed to pass `ecdsaVerify` method)
        const signedComponent = root.split(" sig")[0];
        const signedComponentBuffer = utf8ToBytes$4(signedComponent);
        const signatureBuffer = fromString$3(rootValues.signature, "base64url").slice(0, 64);
        const isVerified = verifySignature(signatureBuffer, keccak256(signedComponentBuffer), new Uint8Array(decodedPublicKey));
        if (!isVerified)
            throw new Error("Unable to verify ENRTree root signature");
        return rootValues.eRoot;
    }
    static parseRootValues(txt) {
        const matches = txt.match(/^enrtree-root:v1 e=([^ ]+) l=([^ ]+) seq=(\d+) sig=([^ ]+)$/);
        if (!Array.isArray(matches))
            throw new Error("Could not parse ENRTree root entry");
        matches.shift(); // The first entry is the full match
        const [eRoot, lRoot, seq, signature] = matches;
        if (!eRoot)
            throw new Error("Could not parse 'e' value from ENRTree root entry");
        if (!lRoot)
            throw new Error("Could not parse 'l' value from ENRTree root entry");
        if (!seq)
            throw new Error("Could not parse 'seq' value from ENRTree root entry");
        if (!signature)
            throw new Error("Could not parse 'sig' value from ENRTree root entry");
        return { eRoot, lRoot, seq: Number(seq), signature };
    }
    /**
     * Returns the public key and top level domain of an ENR tree entry.
     * The domain is the starting point for traversing a set of linked DNS TXT records
     * and the public key is used to verify the root entry record
     */
    static parseTree(tree) {
        if (!tree.startsWith(this.TREE_PREFIX))
            throw new Error(`ENRTree tree entry must start with '${this.TREE_PREFIX}'`);
        const matches = tree.match(/^enrtree:\/\/([^@]+)@(.+)$/);
        if (!Array.isArray(matches))
            throw new Error("Could not parse ENRTree tree entry");
        matches.shift(); // The first entry is the full match
        const [publicKey, domain] = matches;
        if (!publicKey)
            throw new Error("Could not parse public key from ENRTree tree entry");
        if (!domain)
            throw new Error("Could not parse domain from ENRTree tree entry");
        return { publicKey, domain };
    }
    /**
     * Returns subdomains listed in an ENR branch entry. These in turn lead to
     * either further branch entries or ENR records.
     */
    static parseBranch(branch) {
        if (!branch.startsWith(this.BRANCH_PREFIX))
            throw new Error(`ENRTree branch entry must start with '${this.BRANCH_PREFIX}'`);
        return branch.split(this.BRANCH_PREFIX)[1].split(",");
    }
}

const log$t = debug("waku:discovery:fetch_nodes");
/**
 * Fetch nodes using passed [[getNode]] until all wanted capabilities are
 * fulfilled or the number of [[getNode]] call exceeds the sum of
 * [[wantedNodeCapabilityCount]] plus [[errorTolerance]].
 */
async function fetchNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, errorTolerance, getNode) {
    const wanted = {
        relay: wantedNodeCapabilityCount.relay ?? 0,
        store: wantedNodeCapabilityCount.store ?? 0,
        filter: wantedNodeCapabilityCount.filter ?? 0,
        lightPush: wantedNodeCapabilityCount.lightPush ?? 0
    };
    const maxSearches = wanted.relay + wanted.store + wanted.filter + wanted.lightPush;
    const actual = {
        relay: 0,
        store: 0,
        filter: 0,
        lightPush: 0
    };
    let totalSearches = 0;
    const peers = [];
    while (!isSatisfied(wanted, actual) &&
        totalSearches < maxSearches + errorTolerance) {
        const peer = await getNode();
        if (peer && isNewPeer(peer, peers)) {
            // ENRs without a waku2 key are ignored.
            if (peer.waku2) {
                if (helpsSatisfyCapabilities(peer.waku2, wanted, actual)) {
                    addCapabilities(peer.waku2, actual);
                    peers.push(peer);
                }
            }
            log$t(`got new peer candidate from DNS address=${peer.nodeId}@${peer.ip}`);
        }
        totalSearches++;
    }
    return peers;
}
/**
 * Fetch nodes using passed [[getNode]] until all wanted capabilities are
 * fulfilled or the number of [[getNode]] call exceeds the sum of
 * [[wantedNodeCapabilityCount]] plus [[errorTolerance]].
 */
async function* yieldNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, errorTolerance, getNode) {
    const wanted = {
        relay: wantedNodeCapabilityCount.relay ?? 0,
        store: wantedNodeCapabilityCount.store ?? 0,
        filter: wantedNodeCapabilityCount.filter ?? 0,
        lightPush: wantedNodeCapabilityCount.lightPush ?? 0
    };
    const maxSearches = wanted.relay + wanted.store + wanted.filter + wanted.lightPush;
    const actual = {
        relay: 0,
        store: 0,
        filter: 0,
        lightPush: 0
    };
    let totalSearches = 0;
    const peerNodeIds = new Set();
    while (!isSatisfied(wanted, actual) &&
        totalSearches < maxSearches + errorTolerance) {
        const peer = await getNode();
        if (peer && peer.nodeId && !peerNodeIds.has(peer.nodeId)) {
            peerNodeIds.add(peer.nodeId);
            // ENRs without a waku2 key are ignored.
            if (peer.waku2) {
                if (helpsSatisfyCapabilities(peer.waku2, wanted, actual)) {
                    addCapabilities(peer.waku2, actual);
                    yield peer;
                }
            }
            log$t(`got new peer candidate from DNS address=${peer.nodeId}@${peer.ip}`);
        }
        totalSearches++;
    }
}
function isSatisfied(wanted, actual) {
    return (actual.relay >= wanted.relay &&
        actual.store >= wanted.store &&
        actual.filter >= wanted.filter &&
        actual.lightPush >= wanted.lightPush);
}
function isNewPeer(peer, peers) {
    if (!peer.nodeId)
        return false;
    for (const existingPeer of peers) {
        if (peer.nodeId === existingPeer.nodeId) {
            return false;
        }
    }
    return true;
}
function addCapabilities(node, total) {
    if (node.relay)
        total.relay += 1;
    if (node.store)
        total.store += 1;
    if (node.filter)
        total.filter += 1;
    if (node.lightPush)
        total.lightPush += 1;
}
/**
 * Checks if the proposed ENR [[node]] helps satisfy the [[wanted]] capabilities,
 * considering the [[actual]] capabilities of nodes retrieved so far..
 *
 * @throws If the function is called when the wanted capabilities are already fulfilled.
 */
function helpsSatisfyCapabilities(node, wanted, actual) {
    if (isSatisfied(wanted, actual)) {
        throw "Internal Error: Waku2 wanted capabilities are already fulfilled";
    }
    const missing = missingCapabilities(wanted, actual);
    return ((missing.relay && node.relay) ||
        (missing.store && node.store) ||
        (missing.filter && node.filter) ||
        (missing.lightPush && node.lightPush));
}
/**
 * Return a [[Waku2]] Object for which capabilities are set to true if they are
 * [[wanted]] yet missing from [[actual]].
 */
function missingCapabilities(wanted, actual) {
    return {
        relay: actual.relay < wanted.relay,
        store: actual.store < wanted.store,
        filter: actual.filter < wanted.filter,
        lightPush: actual.lightPush < wanted.lightPush
    };
}

const log$s = debug("waku:discovery:dns");
class DnsNodeDiscovery {
    dns;
    _DNSTreeCache;
    _errorTolerance = 10;
    static async dnsOverHttp(dnsClient) {
        if (!dnsClient) {
            dnsClient = await DnsOverHttps.create();
        }
        return new DnsNodeDiscovery(dnsClient);
    }
    /**
     * Returns a list of verified peers listed in an EIP-1459 DNS tree. Method may
     * return fewer peers than requested if @link wantedNodeCapabilityCount requires
     * larger quantity of peers than available or the number of errors/duplicate
     * peers encountered by randomized search exceeds the sum of the fields of
     * @link wantedNodeCapabilityCount plus the @link _errorTolerance factor.
     */
    async getPeers(enrTreeUrls, wantedNodeCapabilityCount) {
        const networkIndex = Math.floor(Math.random() * enrTreeUrls.length);
        const { publicKey, domain } = ENRTree.parseTree(enrTreeUrls[networkIndex]);
        const context = {
            domain,
            publicKey,
            visits: {}
        };
        const peers = await fetchNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, this._errorTolerance, () => this._search(domain, context));
        log$s("retrieved peers: ", peers.map((peer) => {
            return {
                id: peer.peerId?.toString(),
                multiaddrs: peer.multiaddrs?.map((ma) => ma.toString())
            };
        }));
        return peers;
    }
    constructor(dns) {
        this._DNSTreeCache = {};
        this.dns = dns;
    }
    /**
     * {@inheritDoc getPeers}
     */
    async *getNextPeer(enrTreeUrls, wantedNodeCapabilityCount) {
        const networkIndex = Math.floor(Math.random() * enrTreeUrls.length);
        const { publicKey, domain } = ENRTree.parseTree(enrTreeUrls[networkIndex]);
        const context = {
            domain,
            publicKey,
            visits: {}
        };
        for await (const peer of yieldNodesUntilCapabilitiesFulfilled(wantedNodeCapabilityCount, this._errorTolerance, () => this._search(domain, context))) {
            yield peer;
        }
    }
    /**
     * Runs a recursive, randomized descent of the DNS tree to retrieve a single
     * ENR record as an ENR. Returns null if parsing or DNS resolution fails.
     */
    async _search(subdomain, context) {
        try {
            const entry = await this._getTXTRecord(subdomain, context);
            context.visits[subdomain] = true;
            let next;
            let branches;
            const entryType = getEntryType(entry);
            try {
                switch (entryType) {
                    case ENRTree.ROOT_PREFIX:
                        next = ENRTree.parseAndVerifyRoot(entry, context.publicKey);
                        return await this._search(next, context);
                    case ENRTree.BRANCH_PREFIX:
                        branches = ENRTree.parseBranch(entry);
                        next = selectRandomPath(branches, context);
                        return await this._search(next, context);
                    case ENRTree.RECORD_PREFIX:
                        return EnrDecoder.fromString(entry);
                    default:
                        return null;
                }
            }
            catch (error) {
                log$s(`Failed to search DNS tree ${entryType} at subdomain ${subdomain}: ${error}`);
                return null;
            }
        }
        catch (error) {
            log$s(`Failed to retrieve TXT record at subdomain ${subdomain}: ${error}`);
            return null;
        }
    }
    /**
     * Retrieves the TXT record stored at a location from either
     * this DNS tree cache or via DNS query.
     *
     * @throws if the TXT Record contains non-UTF-8 values.
     */
    async _getTXTRecord(subdomain, context) {
        if (this._DNSTreeCache[subdomain]) {
            return this._DNSTreeCache[subdomain];
        }
        // Location is either the top level tree entry host or a subdomain of it.
        const location = subdomain !== context.domain
            ? `${subdomain}.${context.domain}`
            : context.domain;
        const response = await this.dns.resolveTXT(location);
        if (!response.length)
            throw new Error("Received empty result array while fetching TXT record");
        if (!response[0].length)
            throw new Error("Received empty TXT record");
        // Branch entries can be an array of strings of comma delimited subdomains, with
        // some subdomain strings split across the array elements
        const result = response.join("");
        this._DNSTreeCache[subdomain] = result;
        return result;
    }
}
function getEntryType(entry) {
    if (entry.startsWith(ENRTree.ROOT_PREFIX))
        return ENRTree.ROOT_PREFIX;
    if (entry.startsWith(ENRTree.BRANCH_PREFIX))
        return ENRTree.BRANCH_PREFIX;
    if (entry.startsWith(ENRTree.RECORD_PREFIX))
        return ENRTree.RECORD_PREFIX;
    return "";
}
/**
 * Returns a randomly selected subdomain string from the list provided by a branch
 * entry record.
 *
 * The client must track subdomains which are already resolved to avoid
 * going into an infinite loop b/c branch entries can contain
 * circular references. It’s in the client’s best interest to traverse the
 * tree in random order.
 */
function selectRandomPath(branches, context) {
    // Identify domains already visited in this traversal of the DNS tree.
    // Then filter against them to prevent cycles.
    const circularRefs = {};
    for (const [idx, subdomain] of branches.entries()) {
        if (context.visits[subdomain]) {
            circularRefs[idx] = true;
        }
    }
    // If all possible paths are circular...
    if (Object.keys(circularRefs).length === branches.length) {
        throw new Error("Unresolvable circular path detected");
    }
    // Randomly select a viable path
    let index;
    do {
        index = Math.floor(Math.random() * branches.length);
    } while (circularRefs[index]);
    return branches[index];
}

const log$r = debug("waku:peer-discovery-dns");
/**
 * Parse options and expose function to return bootstrap peer addresses.
 */
class PeerDiscoveryDns extends EventEmitter$2 {
    nextPeer;
    _started;
    _components;
    _options;
    constructor(components, options) {
        super();
        this._started = false;
        this._components = components;
        this._options = options;
        const { enrUrls } = options;
        log$r("Use following EIP-1459 ENR Tree URLs: ", enrUrls);
    }
    /**
     * Start discovery process
     */
    async start() {
        log$r("Starting peer discovery via dns");
        this._started = true;
        if (this.nextPeer === undefined) {
            let { enrUrls } = this._options;
            if (!Array.isArray(enrUrls))
                enrUrls = [enrUrls];
            const { wantedNodeCapabilityCount } = this._options;
            const dns = await DnsNodeDiscovery.dnsOverHttp();
            this.nextPeer = dns.getNextPeer.bind(dns, enrUrls, wantedNodeCapabilityCount);
        }
        for await (const peerEnr of this.nextPeer()) {
            if (!this._started) {
                return;
            }
            const peerInfo = peerEnr.peerInfo;
            if (!peerInfo) {
                continue;
            }
            const tagsToUpdate = {
                tags: {
                    [DEFAULT_BOOTSTRAP_TAG_NAME]: {
                        value: this._options.tagValue ?? DEFAULT_BOOTSTRAP_TAG_VALUE,
                        ttl: this._options.tagTTL ?? DEFAULT_BOOTSTRAP_TAG_TTL
                    }
                }
            };
            let isPeerChanged = false;
            const isPeerExists = await this._components.peerStore.has(peerInfo.id);
            if (isPeerExists) {
                const peer = await this._components.peerStore.get(peerInfo.id);
                const hasBootstrapTag = peer.tags.has(DEFAULT_BOOTSTRAP_TAG_NAME);
                if (!hasBootstrapTag) {
                    isPeerChanged = true;
                    await this._components.peerStore.merge(peerInfo.id, tagsToUpdate);
                }
            }
            else {
                isPeerChanged = true;
                await this._components.peerStore.save(peerInfo.id, tagsToUpdate);
            }
            if (isPeerChanged) {
                this.dispatchEvent(new CustomEvent("peer", { detail: peerInfo }));
            }
        }
    }
    /**
     * Stop emitting events
     */
    stop() {
        this._started = false;
    }
    get [peerDiscovery]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return "@waku/bootstrap";
    }
}
function wakuDnsDiscovery(enrUrls, wantedNodeCapabilityCount = DEFAULT_NODE_REQUIREMENTS$1) {
    return (components) => new PeerDiscoveryDns(components, { enrUrls, wantedNodeCapabilityCount });
}

/**
 * PeerExchangeRPC represents a message conforming to the Waku Peer Exchange protocol
 */
class PeerExchangeRPC {
    proto;
    constructor(proto) {
        this.proto = proto;
    }
    static createRequest(params) {
        const { numPeers } = params;
        return new PeerExchangeRPC({
            query: {
                numPeers: numPeers
            },
            response: undefined
        });
    }
    /**
     * Encode the current PeerExchangeRPC request to bytes
     * @returns Uint8Array
     */
    encode() {
        return PeerExchangeRPC$1.encode(this.proto);
    }
    /**
     * Decode the current PeerExchangeRPC request to bytes
     * @returns Uint8Array
     */
    static decode(bytes) {
        const res = PeerExchangeRPC$1.decode(bytes);
        return new PeerExchangeRPC(res);
    }
    get query() {
        return this.proto.query;
    }
    get response() {
        return this.proto.response;
    }
}

const PeerExchangeCodec = "/vac/waku/peer-exchange/2.0.0-alpha1";
const log$q = debug("waku:peer-exchange");
/**
 * Implementation of the Peer Exchange protocol (https://rfc.vac.dev/spec/34/)
 */
class WakuPeerExchange extends BaseProtocol {
    /**
     * @param components - libp2p components
     */
    constructor(components) {
        super(PeerExchangeCodec, components);
    }
    /**
     * Make a peer exchange query to a peer
     */
    async query(params) {
        const { numPeers } = params;
        const rpcQuery = PeerExchangeRPC.createRequest({
            numPeers: BigInt(numPeers)
        });
        const peer = await this.getPeer(params.peerId);
        const stream = await this.getStream(peer);
        const res = await pipe([rpcQuery.encode()], encode$B, stream, decode$v, async (source) => await all$1(source));
        try {
            const bytes = new Uint8ArrayList();
            res.forEach((chunk) => {
                bytes.append(chunk);
            });
            const { response } = PeerExchangeRPC.decode(bytes);
            if (!response) {
                log$q("PeerExchangeRPC message did not contains a `response` field");
                return;
            }
            return Promise.all(response.peerInfos
                .map((peerInfo) => peerInfo.enr)
                .filter(isDefined)
                .map(async (enr) => {
                return { ENR: await EnrDecoder.fromRLP(enr) };
            }));
        }
        catch (err) {
            log$q("Failed to decode push reply", err);
            return;
        }
    }
}

const log$p = debug("waku:peer-exchange-discovery");
const DEFAULT_PEER_EXCHANGE_REQUEST_NODES = 10;
const DEFAULT_PEER_EXCHANGE_QUERY_INTERVAL_MS = 10 * 1000;
const DEFAULT_MAX_RETRIES = 3;
const DEFAULT_PEER_EXCHANGE_TAG_NAME = Tags.PEER_EXCHANGE;
const DEFAULT_PEER_EXCHANGE_TAG_VALUE = 50;
const DEFAULT_PEER_EXCHANGE_TAG_TTL = 100000000;
class PeerExchangeDiscovery extends EventEmitter$2 {
    components;
    peerExchange;
    options;
    isStarted;
    queryingPeers = new Set();
    queryAttempts = new Map();
    handleDiscoveredPeer = (event) => {
        const { protocols, peerId } = event.detail;
        if (!protocols.includes(PeerExchangeCodec) ||
            this.queryingPeers.has(peerId.toString()))
            return;
        this.queryingPeers.add(peerId.toString());
        this.startRecurringQueries(peerId).catch((error) => log$p(`Error querying peer ${error}`));
    };
    constructor(components, options = {}) {
        super();
        this.components = components;
        this.peerExchange = new WakuPeerExchange(components);
        this.options = options;
        this.isStarted = false;
    }
    /**
     * Start emitting events
     */
    start() {
        if (this.isStarted) {
            return;
        }
        log$p("Starting peer exchange node discovery, discovering peers");
        // might be better to use "peer:identify" or "peer:update"
        this.components.events.addEventListener("peer:identify", this.handleDiscoveredPeer);
    }
    /**
     * Remove event listener
     */
    stop() {
        if (!this.isStarted)
            return;
        log$p("Stopping peer exchange node discovery");
        this.isStarted = false;
        this.queryingPeers.clear();
        this.components.events.removeEventListener("peer:identify", this.handleDiscoveredPeer);
    }
    get [peerDiscovery]() {
        return true;
    }
    get [Symbol.toStringTag]() {
        return "@waku/peer-exchange";
    }
    startRecurringQueries = async (peerId) => {
        const peerIdStr = peerId.toString();
        const { queryInterval = DEFAULT_PEER_EXCHANGE_QUERY_INTERVAL_MS, maxRetries = DEFAULT_MAX_RETRIES } = this.options;
        log$p(`Querying peer: ${peerIdStr} (attempt ${this.queryAttempts.get(peerIdStr) ?? 1})`);
        await this.query(peerId);
        const currentAttempt = this.queryAttempts.get(peerIdStr) ?? 1;
        if (currentAttempt > maxRetries) {
            this.abortQueriesForPeer(peerIdStr);
            return;
        }
        setTimeout(() => {
            this.queryAttempts.set(peerIdStr, currentAttempt + 1);
            this.startRecurringQueries(peerId).catch((error) => {
                log$p(`Error in startRecurringQueries: ${error}`);
            });
        }, queryInterval * currentAttempt);
    };
    async query(peerId) {
        const peerInfos = await this.peerExchange.query({
            numPeers: DEFAULT_PEER_EXCHANGE_REQUEST_NODES,
            peerId
        });
        if (!peerInfos) {
            log$p("Peer exchange query failed, no peer info returned");
            return;
        }
        for (const _peerInfo of peerInfos) {
            const { ENR } = _peerInfo;
            if (!ENR) {
                log$p("No ENR in peerInfo object, skipping");
                continue;
            }
            const { peerId, peerInfo } = ENR;
            if (!peerId || !peerInfo) {
                continue;
            }
            const hasPeer = await this.components.peerStore.has(peerId);
            if (hasPeer) {
                continue;
            }
            // update the tags for the peer
            await this.components.peerStore.save(peerId, {
                tags: {
                    [DEFAULT_PEER_EXCHANGE_TAG_NAME]: {
                        value: this.options.tagValue ?? DEFAULT_PEER_EXCHANGE_TAG_VALUE,
                        ttl: this.options.tagTTL ?? DEFAULT_PEER_EXCHANGE_TAG_TTL
                    }
                }
            });
            log$p(`Discovered peer: ${peerId.toString()}`);
            this.dispatchEvent(new CustomEvent("peer", {
                detail: {
                    id: peerId,
                    protocols: [],
                    multiaddrs: peerInfo.multiaddrs
                }
            }));
        }
    }
    abortQueriesForPeer(peerIdStr) {
        log$p(`Aborting queries for peer: ${peerIdStr}`);
        this.queryingPeers.delete(peerIdStr);
        this.queryAttempts.delete(peerIdStr);
    }
}
function wakuPeerExchangeDiscovery() {
    return (components) => new PeerExchangeDiscovery(components);
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$7 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$7 = base$7;

var _brrp__multiformats_scope_baseX$7 = src$7;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$7 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$7 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$7 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$7(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$7 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$7(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$7 = (left, right) => new ComposedDecoder$7(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$7 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$7(name, prefix, baseEncode);
    this.decoder = new Decoder$7(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$c = ({ name, prefix, encode, decode }) =>
  new Codec$7(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$7 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$7(alphabet, name);
  return from$c({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$7(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$c = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$i = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$7 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$c({
    prefix,
    name,
    encode (input) {
      return encode$i(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$c(input, alphabet, bitsPerChar, name)
    }
  })
};

const base32$4 = rfc4648$7({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

rfc4648$7({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

rfc4648$7({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

rfc4648$7({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

rfc4648$7({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

rfc4648$7({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

rfc4648$7({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

rfc4648$7({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

rfc4648$7({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

const base58btc$6 = baseX$7({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$7({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

// @ts-check


const base64$6 = rfc4648$7({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$7({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$7({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$7({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc$6.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$4.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64$6.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
debug.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger$4(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
function logger$4(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger$4(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (debug.enabled(`${name}:trace`) && debug.names.map(r => r.toString()).find(n => n.includes(':trace')) != null) {
        trace = debug(`${name}:trace`);
    }
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace
    });
}

class MessageCache {
    gossip;
    msgs = new Map();
    msgIdToStrFn;
    history = [];
    /** Track with accounting of messages in the mcache that are not yet validated */
    notValidatedCount = 0;
    /**
     * Holds history of messages in timebounded history arrays
     */
    constructor(
    /**
     * The number of indices in the cache history used for gossiping. That means that a message
     * won't get gossiped anymore when shift got called `gossip` many times after inserting the
     * message in the cache.
     */
    gossip, historyCapacity, msgIdToStrFn) {
        this.gossip = gossip;
        this.msgIdToStrFn = msgIdToStrFn;
        for (let i = 0; i < historyCapacity; i++) {
            this.history[i] = [];
        }
    }
    get size() {
        return this.msgs.size;
    }
    /**
     * Adds a message to the current window and the cache
     * Returns true if the message is not known and is inserted in the cache
     */
    put(messageId, msg, validated = false) {
        const { msgIdStr } = messageId;
        // Don't add duplicate entries to the cache.
        if (this.msgs.has(msgIdStr)) {
            return false;
        }
        this.msgs.set(msgIdStr, {
            message: msg,
            validated,
            originatingPeers: new Set(),
            iwantCounts: new Map()
        });
        this.history[0].push({ ...messageId, topic: msg.topic });
        if (!validated) {
            this.notValidatedCount++;
        }
        return true;
    }
    observeDuplicate(msgId, fromPeerIdStr) {
        const entry = this.msgs.get(msgId);
        if (entry &&
            // if the message is already validated, we don't need to store extra peers sending us
            // duplicates as the message has already been forwarded
            !entry.validated) {
            entry.originatingPeers.add(fromPeerIdStr);
        }
    }
    /**
     * Retrieves a message from the cache by its ID, if it is still present
     */
    get(msgId) {
        return this.msgs.get(this.msgIdToStrFn(msgId))?.message;
    }
    /**
     * Increases the iwant count for the given message by one and returns the message together
     * with the iwant if the message exists.
     */
    getWithIWantCount(msgIdStr, p) {
        const msg = this.msgs.get(msgIdStr);
        if (!msg) {
            return null;
        }
        const count = (msg.iwantCounts.get(p) ?? 0) + 1;
        msg.iwantCounts.set(p, count);
        return { msg: msg.message, count };
    }
    /**
     * Retrieves a list of message IDs for a set of topics
     */
    getGossipIDs(topics) {
        const msgIdsByTopic = new Map();
        for (let i = 0; i < this.gossip; i++) {
            this.history[i].forEach((entry) => {
                const msg = this.msgs.get(entry.msgIdStr);
                if (msg && msg.validated && topics.has(entry.topic)) {
                    let msgIds = msgIdsByTopic.get(entry.topic);
                    if (!msgIds) {
                        msgIds = [];
                        msgIdsByTopic.set(entry.topic, msgIds);
                    }
                    msgIds.push(entry.msgId);
                }
            });
        }
        return msgIdsByTopic;
    }
    /**
     * Gets a message with msgId and tags it as validated.
     * This function also returns the known peers that have sent us this message. This is used to
     * prevent us sending redundant messages to peers who have already propagated it.
     */
    validate(msgId) {
        const entry = this.msgs.get(msgId);
        if (!entry) {
            return null;
        }
        if (!entry.validated) {
            this.notValidatedCount--;
        }
        const { message, originatingPeers } = entry;
        entry.validated = true;
        // Clear the known peers list (after a message is validated, it is forwarded and we no
        // longer need to store the originating peers).
        entry.originatingPeers = new Set();
        return { message, originatingPeers };
    }
    /**
     * Shifts the current window, discarding messages older than this.history.length of the cache
     */
    shift() {
        const lastCacheEntries = this.history[this.history.length - 1];
        lastCacheEntries.forEach((cacheEntry) => {
            const entry = this.msgs.get(cacheEntry.msgIdStr);
            if (entry) {
                this.msgs.delete(cacheEntry.msgIdStr);
                if (!entry.validated) {
                    this.notValidatedCount--;
                }
            }
        });
        this.history.pop();
        this.history.unshift([]);
    }
    remove(msgId) {
        const entry = this.msgs.get(msgId);
        if (!entry) {
            return null;
        }
        // Keep the message on the history vector, it will be dropped on a shift()
        this.msgs.delete(msgId);
        return entry;
    }
}

function commonjsRequire(path) {
	throw new Error('Could not dynamically require "' + path + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}

var rpc$1 = {exports: {}};

var indexMinimal = {};

var rpc = {};

var service = Service;

var util = requireMinimal();

// Extends EventEmitter
(Service.prototype = Object.create(util.EventEmitter.prototype)).constructor = Service;

/**
 * A service method callback as used by {@link rpc.ServiceMethod|ServiceMethod}.
 *
 * Differs from {@link RPCImplCallback} in that it is an actual callback of a service method which may not return `response = null`.
 * @typedef rpc.ServiceMethodCallback
 * @template TRes extends Message<TRes>
 * @type {function}
 * @param {Error|null} error Error, if any
 * @param {TRes} [response] Response message
 * @returns {undefined}
 */

/**
 * A service method part of a {@link rpc.Service} as created by {@link Service.create}.
 * @typedef rpc.ServiceMethod
 * @template TReq extends Message<TReq>
 * @template TRes extends Message<TRes>
 * @type {function}
 * @param {TReq|Properties<TReq>} request Request message or plain object
 * @param {rpc.ServiceMethodCallback<TRes>} [callback] Node-style callback called with the error, if any, and the response message
 * @returns {Promise<Message<TRes>>} Promise if `callback` has been omitted, otherwise `undefined`
 */

/**
 * Constructs a new RPC service instance.
 * @classdesc An RPC service as returned by {@link Service#create}.
 * @exports rpc.Service
 * @extends util.EventEmitter
 * @constructor
 * @param {RPCImpl} rpcImpl RPC implementation
 * @param {boolean} [requestDelimited=false] Whether requests are length-delimited
 * @param {boolean} [responseDelimited=false] Whether responses are length-delimited
 */
function Service(rpcImpl, requestDelimited, responseDelimited) {

    if (typeof rpcImpl !== "function")
        throw TypeError("rpcImpl must be a function");

    util.EventEmitter.call(this);

    /**
     * RPC implementation. Becomes `null` once the service is ended.
     * @type {RPCImpl|null}
     */
    this.rpcImpl = rpcImpl;

    /**
     * Whether requests are length-delimited.
     * @type {boolean}
     */
    this.requestDelimited = Boolean(requestDelimited);

    /**
     * Whether responses are length-delimited.
     * @type {boolean}
     */
    this.responseDelimited = Boolean(responseDelimited);
}

/**
 * Calls a service method through {@link rpc.Service#rpcImpl|rpcImpl}.
 * @param {Method|rpc.ServiceMethod<TReq,TRes>} method Reflected or static method
 * @param {Constructor<TReq>} requestCtor Request constructor
 * @param {Constructor<TRes>} responseCtor Response constructor
 * @param {TReq|Properties<TReq>} request Request message or plain object
 * @param {rpc.ServiceMethodCallback<TRes>} callback Service callback
 * @returns {undefined}
 * @template TReq extends Message<TReq>
 * @template TRes extends Message<TRes>
 */
Service.prototype.rpcCall = function rpcCall(method, requestCtor, responseCtor, request, callback) {

    if (!request)
        throw TypeError("request must be specified");

    var self = this;
    if (!callback)
        return util.asPromise(rpcCall, self, method, requestCtor, responseCtor, request);

    if (!self.rpcImpl) {
        setTimeout(function() { callback(Error("already ended")); }, 0);
        return undefined;
    }

    try {
        return self.rpcImpl(
            method,
            requestCtor[self.requestDelimited ? "encodeDelimited" : "encode"](request).finish(),
            function rpcCallback(err, response) {

                if (err) {
                    self.emit("error", err, method);
                    return callback(err);
                }

                if (response === null) {
                    self.end(/* endedByRPC */ true);
                    return undefined;
                }

                if (!(response instanceof responseCtor)) {
                    try {
                        response = responseCtor[self.responseDelimited ? "decodeDelimited" : "decode"](response);
                    } catch (err) {
                        self.emit("error", err, method);
                        return callback(err);
                    }
                }

                self.emit("data", response, method);
                return callback(null, response);
            }
        );
    } catch (err) {
        self.emit("error", err, method);
        setTimeout(function() { callback(err); }, 0);
        return undefined;
    }
};

/**
 * Ends this service and emits the `end` event.
 * @param {boolean} [endedByRPC=false] Whether the service has been ended by the RPC implementation.
 * @returns {rpc.Service} `this`
 */
Service.prototype.end = function end(endedByRPC) {
    if (this.rpcImpl) {
        if (!endedByRPC) // signal end to rpcImpl
            this.rpcImpl(null, null, null);
        this.rpcImpl = null;
        this.emit("end").off();
    }
    return this;
};

(function (exports) {

	/**
	 * Streaming RPC helpers.
	 * @namespace
	 */
	var rpc = exports;

	/**
	 * RPC implementation passed to {@link Service#create} performing a service request on network level, i.e. by utilizing http requests or websockets.
	 * @typedef RPCImpl
	 * @type {function}
	 * @param {Method|rpc.ServiceMethod<Message<{}>,Message<{}>>} method Reflected or static method being called
	 * @param {Uint8Array} requestData Request data
	 * @param {RPCImplCallback} callback Callback function
	 * @returns {undefined}
	 * @example
	 * function rpcImpl(method, requestData, callback) {
	 *     if (protobuf.util.lcFirst(method.name) !== "myMethod") // compatible with static code
	 *         throw Error("no such method");
	 *     asynchronouslyObtainAResponse(requestData, function(err, responseData) {
	 *         callback(err, responseData);
	 *     });
	 * }
	 */

	/**
	 * Node-style callback as used by {@link RPCImpl}.
	 * @typedef RPCImplCallback
	 * @type {function}
	 * @param {Error|null} error Error, if any, otherwise `null`
	 * @param {Uint8Array|null} [response] Response data or `null` to signal end of stream, if there hasn't been an error
	 * @returns {undefined}
	 */

	rpc.Service = service; 
} (rpc));

var roots = {};

(function (exports) {
	var protobuf = exports;

	/**
	 * Build type, one of `"full"`, `"light"` or `"minimal"`.
	 * @name build
	 * @type {string}
	 * @const
	 */
	protobuf.build = "minimal";

	// Serialization
	protobuf.Writer       = writer$1;
	protobuf.BufferWriter = writer_buffer;
	protobuf.Reader       = reader$2;
	protobuf.BufferReader = reader_buffer;

	// Utility
	protobuf.util         = requireMinimal();
	protobuf.rpc          = rpc;
	protobuf.roots        = roots;
	protobuf.configure    = configure;

	/* istanbul ignore next */
	/**
	 * Reconfigures the library according to the environment.
	 * @returns {undefined}
	 */
	function configure() {
	    protobuf.util._configure();
	    protobuf.Writer._configure(protobuf.BufferWriter);
	    protobuf.Reader._configure(protobuf.BufferReader);
	}

	// Set up buffer utility according to the environment
	configure(); 
} (indexMinimal));

var minimal = indexMinimal;

var protobuf = /*@__PURE__*/getDefaultExportFromCjs(minimal);

(function (module) {
	// @ts-nocheck
	/*eslint-disable*/
	(function(global, factory) { /* global define, require, module */

	    /* AMD */ if (typeof commonjsRequire === 'function' && 'object' === 'object' && module && module.exports)
	        module.exports = factory(minimal);

	})(commonjsGlobal, function($protobuf) {

	    // Common aliases
	    var $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;

	    // Exported root namespace
	    var $root = $protobuf.roots["default"] || ($protobuf.roots["default"] = {});

	    $root.RPC = (function() {

	        /**
	         * Properties of a RPC.
	         * @exports IRPC
	         * @interface IRPC
	         * @property {Array.<RPC.ISubOpts>|null} [subscriptions] RPC subscriptions
	         * @property {Array.<RPC.IMessage>|null} [messages] RPC messages
	         * @property {RPC.IControlMessage|null} [control] RPC control
	         */

	        /**
	         * Constructs a new RPC.
	         * @exports RPC
	         * @classdesc Represents a RPC.
	         * @implements IRPC
	         * @constructor
	         * @param {IRPC=} [p] Properties to set
	         */
	        function RPC(p) {
	            this.subscriptions = [];
	            this.messages = [];
	            if (p)
	                for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                    if (p[ks[i]] != null)
	                        this[ks[i]] = p[ks[i]];
	        }

	        /**
	         * RPC subscriptions.
	         * @member {Array.<RPC.ISubOpts>} subscriptions
	         * @memberof RPC
	         * @instance
	         */
	        RPC.prototype.subscriptions = $util.emptyArray;

	        /**
	         * RPC messages.
	         * @member {Array.<RPC.IMessage>} messages
	         * @memberof RPC
	         * @instance
	         */
	        RPC.prototype.messages = $util.emptyArray;

	        /**
	         * RPC control.
	         * @member {RPC.IControlMessage|null|undefined} control
	         * @memberof RPC
	         * @instance
	         */
	        RPC.prototype.control = null;

	        // OneOf field names bound to virtual getters and setters
	        var $oneOfFields;

	        /**
	         * RPC _control.
	         * @member {"control"|undefined} _control
	         * @memberof RPC
	         * @instance
	         */
	        Object.defineProperty(RPC.prototype, "_control", {
	            get: $util.oneOfGetter($oneOfFields = ["control"]),
	            set: $util.oneOfSetter($oneOfFields)
	        });

	        /**
	         * Encodes the specified RPC message. Does not implicitly {@link RPC.verify|verify} messages.
	         * @function encode
	         * @memberof RPC
	         * @static
	         * @param {IRPC} m RPC message or plain object to encode
	         * @param {$protobuf.Writer} [w] Writer to encode to
	         * @returns {$protobuf.Writer} Writer
	         */
	        RPC.encode = function encode(m, w) {
	            if (!w)
	                w = $Writer.create();
	            if (m.subscriptions != null && m.subscriptions.length) {
	                for (var i = 0; i < m.subscriptions.length; ++i)
	                    $root.RPC.SubOpts.encode(m.subscriptions[i], w.uint32(10).fork()).ldelim();
	            }
	            if (m.messages != null && m.messages.length) {
	                for (var i = 0; i < m.messages.length; ++i)
	                    $root.RPC.Message.encode(m.messages[i], w.uint32(18).fork()).ldelim();
	            }
	            if (m.control != null && Object.hasOwnProperty.call(m, "control"))
	                $root.RPC.ControlMessage.encode(m.control, w.uint32(26).fork()).ldelim();
	            return w;
	        };

	        /**
	         * Decodes a RPC message from the specified reader or buffer.
	         * @function decode
	         * @memberof RPC
	         * @static
	         * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	         * @param {number} [l] Message length if known beforehand
	         * @returns {RPC} RPC
	         * @throws {Error} If the payload is not a reader or valid buffer
	         * @throws {$protobuf.util.ProtocolError} If required fields are missing
	         */
	        RPC.decode = function decode(r, l) {
	            if (!(r instanceof $Reader))
	                r = $Reader.create(r);
	            var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC();
	            while (r.pos < c) {
	                var t = r.uint32();
	                switch (t >>> 3) {
	                case 1:
	                    if (!(m.subscriptions && m.subscriptions.length))
	                        m.subscriptions = [];
	                    m.subscriptions.push($root.RPC.SubOpts.decode(r, r.uint32()));
	                    break;
	                case 2:
	                    if (!(m.messages && m.messages.length))
	                        m.messages = [];
	                    m.messages.push($root.RPC.Message.decode(r, r.uint32()));
	                    break;
	                case 3:
	                    m.control = $root.RPC.ControlMessage.decode(r, r.uint32());
	                    break;
	                default:
	                    r.skipType(t & 7);
	                    break;
	                }
	            }
	            return m;
	        };

	        /**
	         * Creates a RPC message from a plain object. Also converts values to their respective internal types.
	         * @function fromObject
	         * @memberof RPC
	         * @static
	         * @param {Object.<string,*>} d Plain object
	         * @returns {RPC} RPC
	         */
	        RPC.fromObject = function fromObject(d) {
	            if (d instanceof $root.RPC)
	                return d;
	            var m = new $root.RPC();
	            if (d.subscriptions) {
	                if (!Array.isArray(d.subscriptions))
	                    throw TypeError(".RPC.subscriptions: array expected");
	                m.subscriptions = [];
	                for (var i = 0; i < d.subscriptions.length; ++i) {
	                    if (typeof d.subscriptions[i] !== "object")
	                        throw TypeError(".RPC.subscriptions: object expected");
	                    m.subscriptions[i] = $root.RPC.SubOpts.fromObject(d.subscriptions[i]);
	                }
	            }
	            if (d.messages) {
	                if (!Array.isArray(d.messages))
	                    throw TypeError(".RPC.messages: array expected");
	                m.messages = [];
	                for (var i = 0; i < d.messages.length; ++i) {
	                    if (typeof d.messages[i] !== "object")
	                        throw TypeError(".RPC.messages: object expected");
	                    m.messages[i] = $root.RPC.Message.fromObject(d.messages[i]);
	                }
	            }
	            if (d.control != null) {
	                if (typeof d.control !== "object")
	                    throw TypeError(".RPC.control: object expected");
	                m.control = $root.RPC.ControlMessage.fromObject(d.control);
	            }
	            return m;
	        };

	        /**
	         * Creates a plain object from a RPC message. Also converts values to other types if specified.
	         * @function toObject
	         * @memberof RPC
	         * @static
	         * @param {RPC} m RPC
	         * @param {$protobuf.IConversionOptions} [o] Conversion options
	         * @returns {Object.<string,*>} Plain object
	         */
	        RPC.toObject = function toObject(m, o) {
	            if (!o)
	                o = {};
	            var d = {};
	            if (o.arrays || o.defaults) {
	                d.subscriptions = [];
	                d.messages = [];
	            }
	            if (m.subscriptions && m.subscriptions.length) {
	                d.subscriptions = [];
	                for (var j = 0; j < m.subscriptions.length; ++j) {
	                    d.subscriptions[j] = $root.RPC.SubOpts.toObject(m.subscriptions[j], o);
	                }
	            }
	            if (m.messages && m.messages.length) {
	                d.messages = [];
	                for (var j = 0; j < m.messages.length; ++j) {
	                    d.messages[j] = $root.RPC.Message.toObject(m.messages[j], o);
	                }
	            }
	            if (m.control != null && m.hasOwnProperty("control")) {
	                d.control = $root.RPC.ControlMessage.toObject(m.control, o);
	                if (o.oneofs)
	                    d._control = "control";
	            }
	            return d;
	        };

	        /**
	         * Converts this RPC to JSON.
	         * @function toJSON
	         * @memberof RPC
	         * @instance
	         * @returns {Object.<string,*>} JSON object
	         */
	        RPC.prototype.toJSON = function toJSON() {
	            return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	        };

	        RPC.SubOpts = (function() {

	            /**
	             * Properties of a SubOpts.
	             * @memberof RPC
	             * @interface ISubOpts
	             * @property {boolean|null} [subscribe] SubOpts subscribe
	             * @property {string|null} [topic] SubOpts topic
	             */

	            /**
	             * Constructs a new SubOpts.
	             * @memberof RPC
	             * @classdesc Represents a SubOpts.
	             * @implements ISubOpts
	             * @constructor
	             * @param {RPC.ISubOpts=} [p] Properties to set
	             */
	            function SubOpts(p) {
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * SubOpts subscribe.
	             * @member {boolean|null|undefined} subscribe
	             * @memberof RPC.SubOpts
	             * @instance
	             */
	            SubOpts.prototype.subscribe = null;

	            /**
	             * SubOpts topic.
	             * @member {string|null|undefined} topic
	             * @memberof RPC.SubOpts
	             * @instance
	             */
	            SubOpts.prototype.topic = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * SubOpts _subscribe.
	             * @member {"subscribe"|undefined} _subscribe
	             * @memberof RPC.SubOpts
	             * @instance
	             */
	            Object.defineProperty(SubOpts.prototype, "_subscribe", {
	                get: $util.oneOfGetter($oneOfFields = ["subscribe"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * SubOpts _topic.
	             * @member {"topic"|undefined} _topic
	             * @memberof RPC.SubOpts
	             * @instance
	             */
	            Object.defineProperty(SubOpts.prototype, "_topic", {
	                get: $util.oneOfGetter($oneOfFields = ["topic"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified SubOpts message. Does not implicitly {@link RPC.SubOpts.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.SubOpts
	             * @static
	             * @param {RPC.ISubOpts} m SubOpts message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            SubOpts.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.subscribe != null && Object.hasOwnProperty.call(m, "subscribe"))
	                    w.uint32(8).bool(m.subscribe);
	                if (m.topic != null && Object.hasOwnProperty.call(m, "topic"))
	                    w.uint32(18).string(m.topic);
	                return w;
	            };

	            /**
	             * Decodes a SubOpts message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.SubOpts
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.SubOpts} SubOpts
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            SubOpts.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.SubOpts();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.subscribe = r.bool();
	                        break;
	                    case 2:
	                        m.topic = r.string();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a SubOpts message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.SubOpts
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.SubOpts} SubOpts
	             */
	            SubOpts.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.SubOpts)
	                    return d;
	                var m = new $root.RPC.SubOpts();
	                if (d.subscribe != null) {
	                    m.subscribe = Boolean(d.subscribe);
	                }
	                if (d.topic != null) {
	                    m.topic = String(d.topic);
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a SubOpts message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.SubOpts
	             * @static
	             * @param {RPC.SubOpts} m SubOpts
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            SubOpts.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (m.subscribe != null && m.hasOwnProperty("subscribe")) {
	                    d.subscribe = m.subscribe;
	                    if (o.oneofs)
	                        d._subscribe = "subscribe";
	                }
	                if (m.topic != null && m.hasOwnProperty("topic")) {
	                    d.topic = m.topic;
	                    if (o.oneofs)
	                        d._topic = "topic";
	                }
	                return d;
	            };

	            /**
	             * Converts this SubOpts to JSON.
	             * @function toJSON
	             * @memberof RPC.SubOpts
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            SubOpts.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return SubOpts;
	        })();

	        RPC.Message = (function() {

	            /**
	             * Properties of a Message.
	             * @memberof RPC
	             * @interface IMessage
	             * @property {Uint8Array|null} [from] Message from
	             * @property {Uint8Array|null} [data] Message data
	             * @property {Uint8Array|null} [seqno] Message seqno
	             * @property {string} topic Message topic
	             * @property {Uint8Array|null} [signature] Message signature
	             * @property {Uint8Array|null} [key] Message key
	             */

	            /**
	             * Constructs a new Message.
	             * @memberof RPC
	             * @classdesc Represents a Message.
	             * @implements IMessage
	             * @constructor
	             * @param {RPC.IMessage=} [p] Properties to set
	             */
	            function Message(p) {
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * Message from.
	             * @member {Uint8Array|null|undefined} from
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.from = null;

	            /**
	             * Message data.
	             * @member {Uint8Array|null|undefined} data
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.data = null;

	            /**
	             * Message seqno.
	             * @member {Uint8Array|null|undefined} seqno
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.seqno = null;

	            /**
	             * Message topic.
	             * @member {string} topic
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.topic = "";

	            /**
	             * Message signature.
	             * @member {Uint8Array|null|undefined} signature
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.signature = null;

	            /**
	             * Message key.
	             * @member {Uint8Array|null|undefined} key
	             * @memberof RPC.Message
	             * @instance
	             */
	            Message.prototype.key = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * Message _from.
	             * @member {"from"|undefined} _from
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_from", {
	                get: $util.oneOfGetter($oneOfFields = ["from"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Message _data.
	             * @member {"data"|undefined} _data
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_data", {
	                get: $util.oneOfGetter($oneOfFields = ["data"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Message _seqno.
	             * @member {"seqno"|undefined} _seqno
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_seqno", {
	                get: $util.oneOfGetter($oneOfFields = ["seqno"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Message _signature.
	             * @member {"signature"|undefined} _signature
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_signature", {
	                get: $util.oneOfGetter($oneOfFields = ["signature"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Message _key.
	             * @member {"key"|undefined} _key
	             * @memberof RPC.Message
	             * @instance
	             */
	            Object.defineProperty(Message.prototype, "_key", {
	                get: $util.oneOfGetter($oneOfFields = ["key"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified Message message. Does not implicitly {@link RPC.Message.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.Message
	             * @static
	             * @param {RPC.IMessage} m Message message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            Message.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.from != null && Object.hasOwnProperty.call(m, "from"))
	                    w.uint32(10).bytes(m.from);
	                if (m.data != null && Object.hasOwnProperty.call(m, "data"))
	                    w.uint32(18).bytes(m.data);
	                if (m.seqno != null && Object.hasOwnProperty.call(m, "seqno"))
	                    w.uint32(26).bytes(m.seqno);
	                w.uint32(34).string(m.topic);
	                if (m.signature != null && Object.hasOwnProperty.call(m, "signature"))
	                    w.uint32(42).bytes(m.signature);
	                if (m.key != null && Object.hasOwnProperty.call(m, "key"))
	                    w.uint32(50).bytes(m.key);
	                return w;
	            };

	            /**
	             * Decodes a Message message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.Message
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.Message} Message
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            Message.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.Message();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.from = r.bytes();
	                        break;
	                    case 2:
	                        m.data = r.bytes();
	                        break;
	                    case 3:
	                        m.seqno = r.bytes();
	                        break;
	                    case 4:
	                        m.topic = r.string();
	                        break;
	                    case 5:
	                        m.signature = r.bytes();
	                        break;
	                    case 6:
	                        m.key = r.bytes();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                if (!m.hasOwnProperty("topic"))
	                    throw $util.ProtocolError("missing required 'topic'", { instance: m });
	                return m;
	            };

	            /**
	             * Creates a Message message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.Message
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.Message} Message
	             */
	            Message.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.Message)
	                    return d;
	                var m = new $root.RPC.Message();
	                if (d.from != null) {
	                    if (typeof d.from === "string")
	                        $util.base64.decode(d.from, m.from = $util.newBuffer($util.base64.length(d.from)), 0);
	                    else if (d.from.length)
	                        m.from = d.from;
	                }
	                if (d.data != null) {
	                    if (typeof d.data === "string")
	                        $util.base64.decode(d.data, m.data = $util.newBuffer($util.base64.length(d.data)), 0);
	                    else if (d.data.length)
	                        m.data = d.data;
	                }
	                if (d.seqno != null) {
	                    if (typeof d.seqno === "string")
	                        $util.base64.decode(d.seqno, m.seqno = $util.newBuffer($util.base64.length(d.seqno)), 0);
	                    else if (d.seqno.length)
	                        m.seqno = d.seqno;
	                }
	                if (d.topic != null) {
	                    m.topic = String(d.topic);
	                }
	                if (d.signature != null) {
	                    if (typeof d.signature === "string")
	                        $util.base64.decode(d.signature, m.signature = $util.newBuffer($util.base64.length(d.signature)), 0);
	                    else if (d.signature.length)
	                        m.signature = d.signature;
	                }
	                if (d.key != null) {
	                    if (typeof d.key === "string")
	                        $util.base64.decode(d.key, m.key = $util.newBuffer($util.base64.length(d.key)), 0);
	                    else if (d.key.length)
	                        m.key = d.key;
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a Message message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.Message
	             * @static
	             * @param {RPC.Message} m Message
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            Message.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.defaults) {
	                    d.topic = "";
	                }
	                if (m.from != null && m.hasOwnProperty("from")) {
	                    d.from = o.bytes === String ? $util.base64.encode(m.from, 0, m.from.length) : o.bytes === Array ? Array.prototype.slice.call(m.from) : m.from;
	                    if (o.oneofs)
	                        d._from = "from";
	                }
	                if (m.data != null && m.hasOwnProperty("data")) {
	                    d.data = o.bytes === String ? $util.base64.encode(m.data, 0, m.data.length) : o.bytes === Array ? Array.prototype.slice.call(m.data) : m.data;
	                    if (o.oneofs)
	                        d._data = "data";
	                }
	                if (m.seqno != null && m.hasOwnProperty("seqno")) {
	                    d.seqno = o.bytes === String ? $util.base64.encode(m.seqno, 0, m.seqno.length) : o.bytes === Array ? Array.prototype.slice.call(m.seqno) : m.seqno;
	                    if (o.oneofs)
	                        d._seqno = "seqno";
	                }
	                if (m.topic != null && m.hasOwnProperty("topic")) {
	                    d.topic = m.topic;
	                }
	                if (m.signature != null && m.hasOwnProperty("signature")) {
	                    d.signature = o.bytes === String ? $util.base64.encode(m.signature, 0, m.signature.length) : o.bytes === Array ? Array.prototype.slice.call(m.signature) : m.signature;
	                    if (o.oneofs)
	                        d._signature = "signature";
	                }
	                if (m.key != null && m.hasOwnProperty("key")) {
	                    d.key = o.bytes === String ? $util.base64.encode(m.key, 0, m.key.length) : o.bytes === Array ? Array.prototype.slice.call(m.key) : m.key;
	                    if (o.oneofs)
	                        d._key = "key";
	                }
	                return d;
	            };

	            /**
	             * Converts this Message to JSON.
	             * @function toJSON
	             * @memberof RPC.Message
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            Message.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return Message;
	        })();

	        RPC.ControlMessage = (function() {

	            /**
	             * Properties of a ControlMessage.
	             * @memberof RPC
	             * @interface IControlMessage
	             * @property {Array.<RPC.IControlIHave>|null} [ihave] ControlMessage ihave
	             * @property {Array.<RPC.IControlIWant>|null} [iwant] ControlMessage iwant
	             * @property {Array.<RPC.IControlGraft>|null} [graft] ControlMessage graft
	             * @property {Array.<RPC.IControlPrune>|null} [prune] ControlMessage prune
	             */

	            /**
	             * Constructs a new ControlMessage.
	             * @memberof RPC
	             * @classdesc Represents a ControlMessage.
	             * @implements IControlMessage
	             * @constructor
	             * @param {RPC.IControlMessage=} [p] Properties to set
	             */
	            function ControlMessage(p) {
	                this.ihave = [];
	                this.iwant = [];
	                this.graft = [];
	                this.prune = [];
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlMessage ihave.
	             * @member {Array.<RPC.IControlIHave>} ihave
	             * @memberof RPC.ControlMessage
	             * @instance
	             */
	            ControlMessage.prototype.ihave = $util.emptyArray;

	            /**
	             * ControlMessage iwant.
	             * @member {Array.<RPC.IControlIWant>} iwant
	             * @memberof RPC.ControlMessage
	             * @instance
	             */
	            ControlMessage.prototype.iwant = $util.emptyArray;

	            /**
	             * ControlMessage graft.
	             * @member {Array.<RPC.IControlGraft>} graft
	             * @memberof RPC.ControlMessage
	             * @instance
	             */
	            ControlMessage.prototype.graft = $util.emptyArray;

	            /**
	             * ControlMessage prune.
	             * @member {Array.<RPC.IControlPrune>} prune
	             * @memberof RPC.ControlMessage
	             * @instance
	             */
	            ControlMessage.prototype.prune = $util.emptyArray;

	            /**
	             * Encodes the specified ControlMessage message. Does not implicitly {@link RPC.ControlMessage.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlMessage
	             * @static
	             * @param {RPC.IControlMessage} m ControlMessage message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlMessage.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.ihave != null && m.ihave.length) {
	                    for (var i = 0; i < m.ihave.length; ++i)
	                        $root.RPC.ControlIHave.encode(m.ihave[i], w.uint32(10).fork()).ldelim();
	                }
	                if (m.iwant != null && m.iwant.length) {
	                    for (var i = 0; i < m.iwant.length; ++i)
	                        $root.RPC.ControlIWant.encode(m.iwant[i], w.uint32(18).fork()).ldelim();
	                }
	                if (m.graft != null && m.graft.length) {
	                    for (var i = 0; i < m.graft.length; ++i)
	                        $root.RPC.ControlGraft.encode(m.graft[i], w.uint32(26).fork()).ldelim();
	                }
	                if (m.prune != null && m.prune.length) {
	                    for (var i = 0; i < m.prune.length; ++i)
	                        $root.RPC.ControlPrune.encode(m.prune[i], w.uint32(34).fork()).ldelim();
	                }
	                return w;
	            };

	            /**
	             * Decodes a ControlMessage message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlMessage
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlMessage} ControlMessage
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlMessage.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlMessage();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        if (!(m.ihave && m.ihave.length))
	                            m.ihave = [];
	                        m.ihave.push($root.RPC.ControlIHave.decode(r, r.uint32()));
	                        break;
	                    case 2:
	                        if (!(m.iwant && m.iwant.length))
	                            m.iwant = [];
	                        m.iwant.push($root.RPC.ControlIWant.decode(r, r.uint32()));
	                        break;
	                    case 3:
	                        if (!(m.graft && m.graft.length))
	                            m.graft = [];
	                        m.graft.push($root.RPC.ControlGraft.decode(r, r.uint32()));
	                        break;
	                    case 4:
	                        if (!(m.prune && m.prune.length))
	                            m.prune = [];
	                        m.prune.push($root.RPC.ControlPrune.decode(r, r.uint32()));
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlMessage message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlMessage
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlMessage} ControlMessage
	             */
	            ControlMessage.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlMessage)
	                    return d;
	                var m = new $root.RPC.ControlMessage();
	                if (d.ihave) {
	                    if (!Array.isArray(d.ihave))
	                        throw TypeError(".RPC.ControlMessage.ihave: array expected");
	                    m.ihave = [];
	                    for (var i = 0; i < d.ihave.length; ++i) {
	                        if (typeof d.ihave[i] !== "object")
	                            throw TypeError(".RPC.ControlMessage.ihave: object expected");
	                        m.ihave[i] = $root.RPC.ControlIHave.fromObject(d.ihave[i]);
	                    }
	                }
	                if (d.iwant) {
	                    if (!Array.isArray(d.iwant))
	                        throw TypeError(".RPC.ControlMessage.iwant: array expected");
	                    m.iwant = [];
	                    for (var i = 0; i < d.iwant.length; ++i) {
	                        if (typeof d.iwant[i] !== "object")
	                            throw TypeError(".RPC.ControlMessage.iwant: object expected");
	                        m.iwant[i] = $root.RPC.ControlIWant.fromObject(d.iwant[i]);
	                    }
	                }
	                if (d.graft) {
	                    if (!Array.isArray(d.graft))
	                        throw TypeError(".RPC.ControlMessage.graft: array expected");
	                    m.graft = [];
	                    for (var i = 0; i < d.graft.length; ++i) {
	                        if (typeof d.graft[i] !== "object")
	                            throw TypeError(".RPC.ControlMessage.graft: object expected");
	                        m.graft[i] = $root.RPC.ControlGraft.fromObject(d.graft[i]);
	                    }
	                }
	                if (d.prune) {
	                    if (!Array.isArray(d.prune))
	                        throw TypeError(".RPC.ControlMessage.prune: array expected");
	                    m.prune = [];
	                    for (var i = 0; i < d.prune.length; ++i) {
	                        if (typeof d.prune[i] !== "object")
	                            throw TypeError(".RPC.ControlMessage.prune: object expected");
	                        m.prune[i] = $root.RPC.ControlPrune.fromObject(d.prune[i]);
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlMessage message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlMessage
	             * @static
	             * @param {RPC.ControlMessage} m ControlMessage
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlMessage.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.arrays || o.defaults) {
	                    d.ihave = [];
	                    d.iwant = [];
	                    d.graft = [];
	                    d.prune = [];
	                }
	                if (m.ihave && m.ihave.length) {
	                    d.ihave = [];
	                    for (var j = 0; j < m.ihave.length; ++j) {
	                        d.ihave[j] = $root.RPC.ControlIHave.toObject(m.ihave[j], o);
	                    }
	                }
	                if (m.iwant && m.iwant.length) {
	                    d.iwant = [];
	                    for (var j = 0; j < m.iwant.length; ++j) {
	                        d.iwant[j] = $root.RPC.ControlIWant.toObject(m.iwant[j], o);
	                    }
	                }
	                if (m.graft && m.graft.length) {
	                    d.graft = [];
	                    for (var j = 0; j < m.graft.length; ++j) {
	                        d.graft[j] = $root.RPC.ControlGraft.toObject(m.graft[j], o);
	                    }
	                }
	                if (m.prune && m.prune.length) {
	                    d.prune = [];
	                    for (var j = 0; j < m.prune.length; ++j) {
	                        d.prune[j] = $root.RPC.ControlPrune.toObject(m.prune[j], o);
	                    }
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlMessage to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlMessage
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlMessage.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlMessage;
	        })();

	        RPC.ControlIHave = (function() {

	            /**
	             * Properties of a ControlIHave.
	             * @memberof RPC
	             * @interface IControlIHave
	             * @property {string|null} [topicID] ControlIHave topicID
	             * @property {Array.<Uint8Array>|null} [messageIDs] ControlIHave messageIDs
	             */

	            /**
	             * Constructs a new ControlIHave.
	             * @memberof RPC
	             * @classdesc Represents a ControlIHave.
	             * @implements IControlIHave
	             * @constructor
	             * @param {RPC.IControlIHave=} [p] Properties to set
	             */
	            function ControlIHave(p) {
	                this.messageIDs = [];
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlIHave topicID.
	             * @member {string|null|undefined} topicID
	             * @memberof RPC.ControlIHave
	             * @instance
	             */
	            ControlIHave.prototype.topicID = null;

	            /**
	             * ControlIHave messageIDs.
	             * @member {Array.<Uint8Array>} messageIDs
	             * @memberof RPC.ControlIHave
	             * @instance
	             */
	            ControlIHave.prototype.messageIDs = $util.emptyArray;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * ControlIHave _topicID.
	             * @member {"topicID"|undefined} _topicID
	             * @memberof RPC.ControlIHave
	             * @instance
	             */
	            Object.defineProperty(ControlIHave.prototype, "_topicID", {
	                get: $util.oneOfGetter($oneOfFields = ["topicID"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified ControlIHave message. Does not implicitly {@link RPC.ControlIHave.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlIHave
	             * @static
	             * @param {RPC.IControlIHave} m ControlIHave message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlIHave.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.topicID != null && Object.hasOwnProperty.call(m, "topicID"))
	                    w.uint32(10).string(m.topicID);
	                if (m.messageIDs != null && m.messageIDs.length) {
	                    for (var i = 0; i < m.messageIDs.length; ++i)
	                        w.uint32(18).bytes(m.messageIDs[i]);
	                }
	                return w;
	            };

	            /**
	             * Decodes a ControlIHave message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlIHave
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlIHave} ControlIHave
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlIHave.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlIHave();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.topicID = r.string();
	                        break;
	                    case 2:
	                        if (!(m.messageIDs && m.messageIDs.length))
	                            m.messageIDs = [];
	                        m.messageIDs.push(r.bytes());
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlIHave message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlIHave
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlIHave} ControlIHave
	             */
	            ControlIHave.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlIHave)
	                    return d;
	                var m = new $root.RPC.ControlIHave();
	                if (d.topicID != null) {
	                    m.topicID = String(d.topicID);
	                }
	                if (d.messageIDs) {
	                    if (!Array.isArray(d.messageIDs))
	                        throw TypeError(".RPC.ControlIHave.messageIDs: array expected");
	                    m.messageIDs = [];
	                    for (var i = 0; i < d.messageIDs.length; ++i) {
	                        if (typeof d.messageIDs[i] === "string")
	                            $util.base64.decode(d.messageIDs[i], m.messageIDs[i] = $util.newBuffer($util.base64.length(d.messageIDs[i])), 0);
	                        else if (d.messageIDs[i].length)
	                            m.messageIDs[i] = d.messageIDs[i];
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlIHave message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlIHave
	             * @static
	             * @param {RPC.ControlIHave} m ControlIHave
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlIHave.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.arrays || o.defaults) {
	                    d.messageIDs = [];
	                }
	                if (m.topicID != null && m.hasOwnProperty("topicID")) {
	                    d.topicID = m.topicID;
	                    if (o.oneofs)
	                        d._topicID = "topicID";
	                }
	                if (m.messageIDs && m.messageIDs.length) {
	                    d.messageIDs = [];
	                    for (var j = 0; j < m.messageIDs.length; ++j) {
	                        d.messageIDs[j] = o.bytes === String ? $util.base64.encode(m.messageIDs[j], 0, m.messageIDs[j].length) : o.bytes === Array ? Array.prototype.slice.call(m.messageIDs[j]) : m.messageIDs[j];
	                    }
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlIHave to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlIHave
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlIHave.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlIHave;
	        })();

	        RPC.ControlIWant = (function() {

	            /**
	             * Properties of a ControlIWant.
	             * @memberof RPC
	             * @interface IControlIWant
	             * @property {Array.<Uint8Array>|null} [messageIDs] ControlIWant messageIDs
	             */

	            /**
	             * Constructs a new ControlIWant.
	             * @memberof RPC
	             * @classdesc Represents a ControlIWant.
	             * @implements IControlIWant
	             * @constructor
	             * @param {RPC.IControlIWant=} [p] Properties to set
	             */
	            function ControlIWant(p) {
	                this.messageIDs = [];
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlIWant messageIDs.
	             * @member {Array.<Uint8Array>} messageIDs
	             * @memberof RPC.ControlIWant
	             * @instance
	             */
	            ControlIWant.prototype.messageIDs = $util.emptyArray;

	            /**
	             * Encodes the specified ControlIWant message. Does not implicitly {@link RPC.ControlIWant.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlIWant
	             * @static
	             * @param {RPC.IControlIWant} m ControlIWant message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlIWant.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.messageIDs != null && m.messageIDs.length) {
	                    for (var i = 0; i < m.messageIDs.length; ++i)
	                        w.uint32(10).bytes(m.messageIDs[i]);
	                }
	                return w;
	            };

	            /**
	             * Decodes a ControlIWant message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlIWant
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlIWant} ControlIWant
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlIWant.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlIWant();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        if (!(m.messageIDs && m.messageIDs.length))
	                            m.messageIDs = [];
	                        m.messageIDs.push(r.bytes());
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlIWant message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlIWant
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlIWant} ControlIWant
	             */
	            ControlIWant.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlIWant)
	                    return d;
	                var m = new $root.RPC.ControlIWant();
	                if (d.messageIDs) {
	                    if (!Array.isArray(d.messageIDs))
	                        throw TypeError(".RPC.ControlIWant.messageIDs: array expected");
	                    m.messageIDs = [];
	                    for (var i = 0; i < d.messageIDs.length; ++i) {
	                        if (typeof d.messageIDs[i] === "string")
	                            $util.base64.decode(d.messageIDs[i], m.messageIDs[i] = $util.newBuffer($util.base64.length(d.messageIDs[i])), 0);
	                        else if (d.messageIDs[i].length)
	                            m.messageIDs[i] = d.messageIDs[i];
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlIWant message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlIWant
	             * @static
	             * @param {RPC.ControlIWant} m ControlIWant
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlIWant.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.arrays || o.defaults) {
	                    d.messageIDs = [];
	                }
	                if (m.messageIDs && m.messageIDs.length) {
	                    d.messageIDs = [];
	                    for (var j = 0; j < m.messageIDs.length; ++j) {
	                        d.messageIDs[j] = o.bytes === String ? $util.base64.encode(m.messageIDs[j], 0, m.messageIDs[j].length) : o.bytes === Array ? Array.prototype.slice.call(m.messageIDs[j]) : m.messageIDs[j];
	                    }
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlIWant to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlIWant
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlIWant.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlIWant;
	        })();

	        RPC.ControlGraft = (function() {

	            /**
	             * Properties of a ControlGraft.
	             * @memberof RPC
	             * @interface IControlGraft
	             * @property {string|null} [topicID] ControlGraft topicID
	             */

	            /**
	             * Constructs a new ControlGraft.
	             * @memberof RPC
	             * @classdesc Represents a ControlGraft.
	             * @implements IControlGraft
	             * @constructor
	             * @param {RPC.IControlGraft=} [p] Properties to set
	             */
	            function ControlGraft(p) {
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlGraft topicID.
	             * @member {string|null|undefined} topicID
	             * @memberof RPC.ControlGraft
	             * @instance
	             */
	            ControlGraft.prototype.topicID = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * ControlGraft _topicID.
	             * @member {"topicID"|undefined} _topicID
	             * @memberof RPC.ControlGraft
	             * @instance
	             */
	            Object.defineProperty(ControlGraft.prototype, "_topicID", {
	                get: $util.oneOfGetter($oneOfFields = ["topicID"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified ControlGraft message. Does not implicitly {@link RPC.ControlGraft.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlGraft
	             * @static
	             * @param {RPC.IControlGraft} m ControlGraft message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlGraft.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.topicID != null && Object.hasOwnProperty.call(m, "topicID"))
	                    w.uint32(10).string(m.topicID);
	                return w;
	            };

	            /**
	             * Decodes a ControlGraft message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlGraft
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlGraft} ControlGraft
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlGraft.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlGraft();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.topicID = r.string();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlGraft message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlGraft
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlGraft} ControlGraft
	             */
	            ControlGraft.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlGraft)
	                    return d;
	                var m = new $root.RPC.ControlGraft();
	                if (d.topicID != null) {
	                    m.topicID = String(d.topicID);
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlGraft message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlGraft
	             * @static
	             * @param {RPC.ControlGraft} m ControlGraft
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlGraft.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (m.topicID != null && m.hasOwnProperty("topicID")) {
	                    d.topicID = m.topicID;
	                    if (o.oneofs)
	                        d._topicID = "topicID";
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlGraft to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlGraft
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlGraft.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlGraft;
	        })();

	        RPC.ControlPrune = (function() {

	            /**
	             * Properties of a ControlPrune.
	             * @memberof RPC
	             * @interface IControlPrune
	             * @property {string|null} [topicID] ControlPrune topicID
	             * @property {Array.<RPC.IPeerInfo>|null} [peers] ControlPrune peers
	             * @property {number|null} [backoff] ControlPrune backoff
	             */

	            /**
	             * Constructs a new ControlPrune.
	             * @memberof RPC
	             * @classdesc Represents a ControlPrune.
	             * @implements IControlPrune
	             * @constructor
	             * @param {RPC.IControlPrune=} [p] Properties to set
	             */
	            function ControlPrune(p) {
	                this.peers = [];
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * ControlPrune topicID.
	             * @member {string|null|undefined} topicID
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            ControlPrune.prototype.topicID = null;

	            /**
	             * ControlPrune peers.
	             * @member {Array.<RPC.IPeerInfo>} peers
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            ControlPrune.prototype.peers = $util.emptyArray;

	            /**
	             * ControlPrune backoff.
	             * @member {number|null|undefined} backoff
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            ControlPrune.prototype.backoff = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * ControlPrune _topicID.
	             * @member {"topicID"|undefined} _topicID
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            Object.defineProperty(ControlPrune.prototype, "_topicID", {
	                get: $util.oneOfGetter($oneOfFields = ["topicID"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * ControlPrune _backoff.
	             * @member {"backoff"|undefined} _backoff
	             * @memberof RPC.ControlPrune
	             * @instance
	             */
	            Object.defineProperty(ControlPrune.prototype, "_backoff", {
	                get: $util.oneOfGetter($oneOfFields = ["backoff"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified ControlPrune message. Does not implicitly {@link RPC.ControlPrune.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.ControlPrune
	             * @static
	             * @param {RPC.IControlPrune} m ControlPrune message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            ControlPrune.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.topicID != null && Object.hasOwnProperty.call(m, "topicID"))
	                    w.uint32(10).string(m.topicID);
	                if (m.peers != null && m.peers.length) {
	                    for (var i = 0; i < m.peers.length; ++i)
	                        $root.RPC.PeerInfo.encode(m.peers[i], w.uint32(18).fork()).ldelim();
	                }
	                if (m.backoff != null && Object.hasOwnProperty.call(m, "backoff"))
	                    w.uint32(24).uint64(m.backoff);
	                return w;
	            };

	            /**
	             * Decodes a ControlPrune message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.ControlPrune
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.ControlPrune} ControlPrune
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            ControlPrune.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.ControlPrune();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.topicID = r.string();
	                        break;
	                    case 2:
	                        if (!(m.peers && m.peers.length))
	                            m.peers = [];
	                        m.peers.push($root.RPC.PeerInfo.decode(r, r.uint32()));
	                        break;
	                    case 3:
	                        m.backoff = r.uint64();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a ControlPrune message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.ControlPrune
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.ControlPrune} ControlPrune
	             */
	            ControlPrune.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.ControlPrune)
	                    return d;
	                var m = new $root.RPC.ControlPrune();
	                if (d.topicID != null) {
	                    m.topicID = String(d.topicID);
	                }
	                if (d.peers) {
	                    if (!Array.isArray(d.peers))
	                        throw TypeError(".RPC.ControlPrune.peers: array expected");
	                    m.peers = [];
	                    for (var i = 0; i < d.peers.length; ++i) {
	                        if (typeof d.peers[i] !== "object")
	                            throw TypeError(".RPC.ControlPrune.peers: object expected");
	                        m.peers[i] = $root.RPC.PeerInfo.fromObject(d.peers[i]);
	                    }
	                }
	                if (d.backoff != null) {
	                    if ($util.Long)
	                        (m.backoff = $util.Long.fromValue(d.backoff)).unsigned = true;
	                    else if (typeof d.backoff === "string")
	                        m.backoff = parseInt(d.backoff, 10);
	                    else if (typeof d.backoff === "number")
	                        m.backoff = d.backoff;
	                    else if (typeof d.backoff === "object")
	                        m.backoff = new $util.LongBits(d.backoff.low >>> 0, d.backoff.high >>> 0).toNumber(true);
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a ControlPrune message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.ControlPrune
	             * @static
	             * @param {RPC.ControlPrune} m ControlPrune
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            ControlPrune.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (o.arrays || o.defaults) {
	                    d.peers = [];
	                }
	                if (m.topicID != null && m.hasOwnProperty("topicID")) {
	                    d.topicID = m.topicID;
	                    if (o.oneofs)
	                        d._topicID = "topicID";
	                }
	                if (m.peers && m.peers.length) {
	                    d.peers = [];
	                    for (var j = 0; j < m.peers.length; ++j) {
	                        d.peers[j] = $root.RPC.PeerInfo.toObject(m.peers[j], o);
	                    }
	                }
	                if (m.backoff != null && m.hasOwnProperty("backoff")) {
	                    if (typeof m.backoff === "number")
	                        d.backoff = o.longs === String ? String(m.backoff) : m.backoff;
	                    else
	                        d.backoff = o.longs === String ? $util.Long.prototype.toString.call(m.backoff) : o.longs === Number ? new $util.LongBits(m.backoff.low >>> 0, m.backoff.high >>> 0).toNumber(true) : m.backoff;
	                    if (o.oneofs)
	                        d._backoff = "backoff";
	                }
	                return d;
	            };

	            /**
	             * Converts this ControlPrune to JSON.
	             * @function toJSON
	             * @memberof RPC.ControlPrune
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            ControlPrune.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return ControlPrune;
	        })();

	        RPC.PeerInfo = (function() {

	            /**
	             * Properties of a PeerInfo.
	             * @memberof RPC
	             * @interface IPeerInfo
	             * @property {Uint8Array|null} [peerID] PeerInfo peerID
	             * @property {Uint8Array|null} [signedPeerRecord] PeerInfo signedPeerRecord
	             */

	            /**
	             * Constructs a new PeerInfo.
	             * @memberof RPC
	             * @classdesc Represents a PeerInfo.
	             * @implements IPeerInfo
	             * @constructor
	             * @param {RPC.IPeerInfo=} [p] Properties to set
	             */
	            function PeerInfo(p) {
	                if (p)
	                    for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)
	                        if (p[ks[i]] != null)
	                            this[ks[i]] = p[ks[i]];
	            }

	            /**
	             * PeerInfo peerID.
	             * @member {Uint8Array|null|undefined} peerID
	             * @memberof RPC.PeerInfo
	             * @instance
	             */
	            PeerInfo.prototype.peerID = null;

	            /**
	             * PeerInfo signedPeerRecord.
	             * @member {Uint8Array|null|undefined} signedPeerRecord
	             * @memberof RPC.PeerInfo
	             * @instance
	             */
	            PeerInfo.prototype.signedPeerRecord = null;

	            // OneOf field names bound to virtual getters and setters
	            var $oneOfFields;

	            /**
	             * PeerInfo _peerID.
	             * @member {"peerID"|undefined} _peerID
	             * @memberof RPC.PeerInfo
	             * @instance
	             */
	            Object.defineProperty(PeerInfo.prototype, "_peerID", {
	                get: $util.oneOfGetter($oneOfFields = ["peerID"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * PeerInfo _signedPeerRecord.
	             * @member {"signedPeerRecord"|undefined} _signedPeerRecord
	             * @memberof RPC.PeerInfo
	             * @instance
	             */
	            Object.defineProperty(PeerInfo.prototype, "_signedPeerRecord", {
	                get: $util.oneOfGetter($oneOfFields = ["signedPeerRecord"]),
	                set: $util.oneOfSetter($oneOfFields)
	            });

	            /**
	             * Encodes the specified PeerInfo message. Does not implicitly {@link RPC.PeerInfo.verify|verify} messages.
	             * @function encode
	             * @memberof RPC.PeerInfo
	             * @static
	             * @param {RPC.IPeerInfo} m PeerInfo message or plain object to encode
	             * @param {$protobuf.Writer} [w] Writer to encode to
	             * @returns {$protobuf.Writer} Writer
	             */
	            PeerInfo.encode = function encode(m, w) {
	                if (!w)
	                    w = $Writer.create();
	                if (m.peerID != null && Object.hasOwnProperty.call(m, "peerID"))
	                    w.uint32(10).bytes(m.peerID);
	                if (m.signedPeerRecord != null && Object.hasOwnProperty.call(m, "signedPeerRecord"))
	                    w.uint32(18).bytes(m.signedPeerRecord);
	                return w;
	            };

	            /**
	             * Decodes a PeerInfo message from the specified reader or buffer.
	             * @function decode
	             * @memberof RPC.PeerInfo
	             * @static
	             * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from
	             * @param {number} [l] Message length if known beforehand
	             * @returns {RPC.PeerInfo} PeerInfo
	             * @throws {Error} If the payload is not a reader or valid buffer
	             * @throws {$protobuf.util.ProtocolError} If required fields are missing
	             */
	            PeerInfo.decode = function decode(r, l) {
	                if (!(r instanceof $Reader))
	                    r = $Reader.create(r);
	                var c = l === undefined ? r.len : r.pos + l, m = new $root.RPC.PeerInfo();
	                while (r.pos < c) {
	                    var t = r.uint32();
	                    switch (t >>> 3) {
	                    case 1:
	                        m.peerID = r.bytes();
	                        break;
	                    case 2:
	                        m.signedPeerRecord = r.bytes();
	                        break;
	                    default:
	                        r.skipType(t & 7);
	                        break;
	                    }
	                }
	                return m;
	            };

	            /**
	             * Creates a PeerInfo message from a plain object. Also converts values to their respective internal types.
	             * @function fromObject
	             * @memberof RPC.PeerInfo
	             * @static
	             * @param {Object.<string,*>} d Plain object
	             * @returns {RPC.PeerInfo} PeerInfo
	             */
	            PeerInfo.fromObject = function fromObject(d) {
	                if (d instanceof $root.RPC.PeerInfo)
	                    return d;
	                var m = new $root.RPC.PeerInfo();
	                if (d.peerID != null) {
	                    if (typeof d.peerID === "string")
	                        $util.base64.decode(d.peerID, m.peerID = $util.newBuffer($util.base64.length(d.peerID)), 0);
	                    else if (d.peerID.length)
	                        m.peerID = d.peerID;
	                }
	                if (d.signedPeerRecord != null) {
	                    if (typeof d.signedPeerRecord === "string")
	                        $util.base64.decode(d.signedPeerRecord, m.signedPeerRecord = $util.newBuffer($util.base64.length(d.signedPeerRecord)), 0);
	                    else if (d.signedPeerRecord.length)
	                        m.signedPeerRecord = d.signedPeerRecord;
	                }
	                return m;
	            };

	            /**
	             * Creates a plain object from a PeerInfo message. Also converts values to other types if specified.
	             * @function toObject
	             * @memberof RPC.PeerInfo
	             * @static
	             * @param {RPC.PeerInfo} m PeerInfo
	             * @param {$protobuf.IConversionOptions} [o] Conversion options
	             * @returns {Object.<string,*>} Plain object
	             */
	            PeerInfo.toObject = function toObject(m, o) {
	                if (!o)
	                    o = {};
	                var d = {};
	                if (m.peerID != null && m.hasOwnProperty("peerID")) {
	                    d.peerID = o.bytes === String ? $util.base64.encode(m.peerID, 0, m.peerID.length) : o.bytes === Array ? Array.prototype.slice.call(m.peerID) : m.peerID;
	                    if (o.oneofs)
	                        d._peerID = "peerID";
	                }
	                if (m.signedPeerRecord != null && m.hasOwnProperty("signedPeerRecord")) {
	                    d.signedPeerRecord = o.bytes === String ? $util.base64.encode(m.signedPeerRecord, 0, m.signedPeerRecord.length) : o.bytes === Array ? Array.prototype.slice.call(m.signedPeerRecord) : m.signedPeerRecord;
	                    if (o.oneofs)
	                        d._signedPeerRecord = "signedPeerRecord";
	                }
	                return d;
	            };

	            /**
	             * Converts this PeerInfo to JSON.
	             * @function toJSON
	             * @memberof RPC.PeerInfo
	             * @instance
	             * @returns {Object.<string,*>} JSON object
	             */
	            PeerInfo.prototype.toJSON = function toJSON() {
	                return this.constructor.toObject(this, $protobuf.util.toJSONOptions);
	            };

	            return PeerInfo;
	        })();

	        return RPC;
	    })();

	    return $root;
	}); 
} (rpc$1));

var rpcExports = rpc$1.exports;
var cjs = /*@__PURE__*/getDefaultExportFromCjs(rpcExports);

const {RPC} = cjs;

const second = 1000;
const minute = 60 * second;
// Protocol identifiers
const FloodsubID = '/floodsub/1.0.0';
/**
 * The protocol ID for version 1.0.0 of the Gossipsub protocol
 * It is advertised along with GossipsubIDv11 for backwards compatability
 */
const GossipsubIDv10 = '/meshsub/1.0.0';
/**
 * The protocol ID for version 1.1.0 of the Gossipsub protocol
 * See the spec for details about how v1.1.0 compares to v1.0.0:
 * https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md
 */
const GossipsubIDv11 = '/meshsub/1.1.0';
// Overlay parameters
/**
 * GossipsubD sets the optimal degree for a Gossipsub topic mesh. For example, if GossipsubD == 6,
 * each peer will want to have about six peers in their mesh for each topic they're subscribed to.
 * GossipsubD should be set somewhere between GossipsubDlo and GossipsubDhi.
 */
const GossipsubD = 6;
/**
 * GossipsubDlo sets the lower bound on the number of peers we keep in a Gossipsub topic mesh.
 * If we have fewer than GossipsubDlo peers, we will attempt to graft some more into the mesh at
 * the next heartbeat.
 */
const GossipsubDlo = 4;
/**
 * GossipsubDhi sets the upper bound on the number of peers we keep in a Gossipsub topic mesh.
 * If we have more than GossipsubDhi peers, we will select some to prune from the mesh at the next heartbeat.
 */
const GossipsubDhi = 12;
/**
 * GossipsubDscore affects how peers are selected when pruning a mesh due to over subscription.
 * At least GossipsubDscore of the retained peers will be high-scoring, while the remainder are
 * chosen randomly.
 */
const GossipsubDscore = 4;
/**
 * GossipsubDout sets the quota for the number of outbound connections to maintain in a topic mesh.
 * When the mesh is pruned due to over subscription, we make sure that we have outbound connections
 * to at least GossipsubDout of the survivor peers. This prevents sybil attackers from overwhelming
 * our mesh with incoming connections.
 *
 * GossipsubDout must be set below GossipsubDlo, and must not exceed GossipsubD / 2.
 */
const GossipsubDout = 2;
// Gossip parameters
/**
 * GossipsubHistoryLength controls the size of the message cache used for gossip.
 * The message cache will remember messages for GossipsubHistoryLength heartbeats.
 */
const GossipsubHistoryLength = 5;
/**
 * GossipsubHistoryGossip controls how many cached message ids we will advertise in
 * IHAVE gossip messages. When asked for our seen message IDs, we will return
 * only those from the most recent GossipsubHistoryGossip heartbeats. The slack between
 * GossipsubHistoryGossip and GossipsubHistoryLength allows us to avoid advertising messages
 * that will be expired by the time they're requested.
 *
 * GossipsubHistoryGossip must be less than or equal to GossipsubHistoryLength to
 * avoid a runtime panic.
 */
const GossipsubHistoryGossip = 3;
/**
 * GossipsubDlazy affects how many peers we will emit gossip to at each heartbeat.
 * We will send gossip to at least GossipsubDlazy peers outside our mesh. The actual
 * number may be more, depending on GossipsubGossipFactor and how many peers we're
 * connected to.
 */
const GossipsubDlazy = 6;
/**
 * GossipsubGossipFactor affects how many peers we will emit gossip to at each heartbeat.
 * We will send gossip to GossipsubGossipFactor * (total number of non-mesh peers), or
 * GossipsubDlazy, whichever is greater.
 */
const GossipsubGossipFactor = 0.25;
/**
 * GossipsubGossipRetransmission controls how many times we will allow a peer to request
 * the same message id through IWANT gossip before we start ignoring them. This is designed
 * to prevent peers from spamming us with requests and wasting our resources.
 */
const GossipsubGossipRetransmission = 3;
// Heartbeat interval
/**
 * GossipsubHeartbeatInitialDelay is the short delay before the heartbeat timer begins
 * after the router is initialized.
 */
const GossipsubHeartbeatInitialDelay = 100;
/**
 * GossipsubHeartbeatInterval controls the time between heartbeats.
 */
const GossipsubHeartbeatInterval = second;
/**
 * GossipsubFanoutTTL controls how long we keep track of the fanout state. If it's been
 * GossipsubFanoutTTL since we've published to a topic that we're not subscribed to,
 * we'll delete the fanout map for that topic.
 */
const GossipsubFanoutTTL = minute;
/**
 * GossipsubPrunePeers controls the number of peers to include in prune Peer eXchange.
 * When we prune a peer that's eligible for PX (has a good score, etc), we will try to
 * send them signed peer records for up to GossipsubPrunePeers other peers that we
 * know of.
 */
const GossipsubPrunePeers = 16;
/**
 * GossipsubPruneBackoff controls the backoff time for pruned peers. This is how long
 * a peer must wait before attempting to graft into our mesh again after being pruned.
 * When pruning a peer, we send them our value of GossipsubPruneBackoff so they know
 * the minimum time to wait. Peers running older versions may not send a backoff time,
 * so if we receive a prune message without one, we will wait at least GossipsubPruneBackoff
 * before attempting to re-graft.
 */
const GossipsubPruneBackoff = minute;
/**
 * Backoff to use when unsuscribing from a topic. Should not resubscribe to this topic before it expired.
 */
const GossipsubUnsubscribeBackoff = 10 * second;
/**
 * GossipsubPruneBackoffTicks is the number of heartbeat ticks for attempting to prune expired
 * backoff timers.
 */
const GossipsubPruneBackoffTicks = 15;
/**
 * GossipsubDirectConnectTicks is the number of heartbeat ticks for attempting to reconnect direct peers
 * that are not currently connected.
 */
const GossipsubDirectConnectTicks = 300;
/**
 * GossipsubDirectConnectInitialDelay is the initial delay before opening connections to direct peers
 */
const GossipsubDirectConnectInitialDelay = second;
/**
 * GossipsubOpportunisticGraftTicks is the number of heartbeat ticks for attempting to improve the mesh
 * with opportunistic grafting. Every GossipsubOpportunisticGraftTicks we will attempt to select some
 * high-scoring mesh peers to replace lower-scoring ones, if the median score of our mesh peers falls
 * below a threshold
 */
const GossipsubOpportunisticGraftTicks = 60;
/**
 * GossipsubOpportunisticGraftPeers is the number of peers to opportunistically graft.
 */
const GossipsubOpportunisticGraftPeers = 2;
/**
 * If a GRAFT comes before GossipsubGraftFloodThreshold has elapsed since the last PRUNE,
 * then there is an extra score penalty applied to the peer through P7.
 */
const GossipsubGraftFloodThreshold = 10 * second;
/**
 * GossipsubMaxIHaveLength is the maximum number of messages to include in an IHAVE message.
 * Also controls the maximum number of IHAVE ids we will accept and request with IWANT from a
 * peer within a heartbeat, to protect from IHAVE floods. You should adjust this value from the
 * default if your system is pushing more than 5000 messages in GossipsubHistoryGossip heartbeats;
 * with the defaults this is 1666 messages/s.
 */
const GossipsubMaxIHaveLength = 5000;
/**
 * GossipsubMaxIHaveMessages is the maximum number of IHAVE messages to accept from a peer within a heartbeat.
 */
const GossipsubMaxIHaveMessages = 10;
/**
 * Time to wait for a message requested through IWANT following an IHAVE advertisement.
 * If the message is not received within this window, a broken promise is declared and
 * the router may apply bahavioural penalties.
 */
const GossipsubIWantFollowupTime = 3 * second;
/**
 * Time in milliseconds to keep message ids in the seen cache
 */
const GossipsubSeenTTL = 2 * minute;
const TimeCacheDuration = 120 * 1000;
const ERR_TOPIC_VALIDATOR_REJECT = 'ERR_TOPIC_VALIDATOR_REJECT';
const ERR_TOPIC_VALIDATOR_IGNORE = 'ERR_TOPIC_VALIDATOR_IGNORE';
/**
 * If peer score is better than this, we accept messages from this peer
 * within ACCEPT_FROM_WHITELIST_DURATION_MS from the last time computing score.
 **/
const ACCEPT_FROM_WHITELIST_THRESHOLD_SCORE = 0;
/**
 * If peer score >= ACCEPT_FROM_WHITELIST_THRESHOLD_SCORE, accept up to this
 * number of messages from that peer.
 */
const ACCEPT_FROM_WHITELIST_MAX_MESSAGES = 128;
/**
 * If peer score >= ACCEPT_FROM_WHITELIST_THRESHOLD_SCORE, accept messages from
 * this peer up to this time duration.
 */
const ACCEPT_FROM_WHITELIST_DURATION_MS = 1000;
/**
 * The default MeshMessageDeliveriesWindow to be used in metrics.
 */
const DEFAULT_METRIC_MESH_MESSAGE_DELIVERIES_WINDOWS = 1000;
/** Wait for 1 more heartbeats before clearing a backoff */
const BACKOFF_SLACK = 1;

/**
 * Pseudo-randomly shuffles an array
 *
 * Mutates the input array
 */
function shuffle(arr) {
    if (arr.length <= 1) {
        return arr;
    }
    const randInt = () => {
        return Math.floor(Math.random() * Math.floor(arr.length));
    };
    for (let i = 0; i < arr.length; i++) {
        const j = randInt();
        const tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
    return arr;
}

/**
 * Browser friendly function to convert Uint8Array message id to base64 string.
 */
function messageIdToString(msgId) {
    return toString$9(msgId, 'base64');
}

var encode_1$4 = encode$h;

var MSB$5 = 0x80
  , REST$5 = 0x7F
  , MSBALL$4 = ~REST$5
  , INT$4 = Math.pow(2, 31);

function encode$h(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$4) {
    out[offset++] = (num & 0xFF) | MSB$5;
    num /= 128;
  }
  while(num & MSBALL$4) {
    out[offset++] = (num & 0xFF) | MSB$5;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$h.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$b = read$5;

var MSB$1$4 = 0x80
  , REST$1$4 = 0x7F;

function read$5(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$5.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$4) << shift
      : (b & REST$1$4) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$4)

  read$5.bytes = counter - offset;

  return res
}

var N1$4 = Math.pow(2,  7);
var N2$4 = Math.pow(2, 14);
var N3$4 = Math.pow(2, 21);
var N4$4 = Math.pow(2, 28);
var N5$4 = Math.pow(2, 35);
var N6$4 = Math.pow(2, 42);
var N7$4 = Math.pow(2, 49);
var N8$4 = Math.pow(2, 56);
var N9$4 = Math.pow(2, 63);

var length$4 = function (value) {
  return (
    value < N1$4 ? 1
  : value < N2$4 ? 2
  : value < N3$4 ? 3
  : value < N4$4 ? 4
  : value < N5$4 ? 5
  : value < N6$4 ? 6
  : value < N7$4 ? 7
  : value < N8$4 ? 8
  : value < N9$4 ? 9
  :              10
  )
};

var varint$4 = {
    encode: encode_1$4
  , decode: decode$b
  , encodingLength: length$4
};

var _brrp_varint$4 = varint$4;

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo$4 = (int, target, offset = 0) => {
  _brrp_varint$4.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$4 = (int) => {
  return _brrp_varint$4.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$9 = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$4(code);
  const digestOffset = sizeOffset + encodingLength$4(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo$4(code, bytes, 0);
  encodeTo$4(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest$4(code, size, digest, bytes)
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
let Digest$4 = class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
};

const code$4 = 0x0;
const name$4 = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$g = coerce$7;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest$4 = (input) => create$9(code$4, encode$g(input));

const identity$4 = { code: code$4, name: name$4, encode: encode$g, digest: digest$4 };

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$b = ({ name, code, encode }) => new Hasher$4(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
let Hasher$4 = class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$9(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$9(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
};

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */


/**
 * @param {AlgorithmIdentifier} name
 */
const sha$4 = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256$5 = from$b({
  name: 'sha2-256',
  code: 0x12,
  encode: sha$4('SHA-256')
});

const PUBLIC_KEY_BYTE_LENGTH$4 = 32;
const PRIVATE_KEY_BYTE_LENGTH$4 = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH$4 = 32;
async function generateKey$e() {
    // the actual private key (32 bytes)
    const privateKeyRaw = utils$1.randomPrivateKey();
    const publicKey = await getPublicKey$1(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys$4(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
async function generateKeyFromSeed$4(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH$4) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = await getPublicKey$1(privateKeyRaw);
    const privateKey = concatKeys$4(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSign$e(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH$4);
    return sign$2(msg, privateKeyRaw);
}
async function hashAndVerify$e(publicKey, sig, msg) {
    return verify$1(sig, msg, publicKey);
}
function concatKeys$4(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH$4);
    for (let i = 0; i < KEYS_BYTE_LENGTH$4; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH$4 + i] = publicKey[i];
    }
    return privateKey;
}

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto$4 = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto == null || nativeCrypto.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p-crypto/blob/master/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

// WebKit on Linux does not support deriving a key from an empty PBKDF2 key.
// So, as a workaround, we provide the generated key as a constant. We test that
// this generated key is accurate in test/workaround.spec.ts
// Generated via:
// await crypto.subtle.exportKey('jwk',
//   await crypto.subtle.deriveKey(
//     { name: 'PBKDF2', salt: new Uint8Array(16), iterations: 32767, hash: { name: 'SHA-256' } },
//     await crypto.subtle.importKey('raw', new Uint8Array(0), { name: 'PBKDF2' }, false, ['deriveKey']),
//     { name: 'AES-GCM', length: 128 }, true, ['encrypt', 'decrypt'])
// )
const derivedEmptyPasswordKey$4 = { alg: 'A128GCM', ext: true, k: 'scm9jmO_4BJAgdwWGVulLg', key_ops: ['encrypt', 'decrypt'], kty: 'oct' };
// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create$8(opts) {
    const algorithm = opts?.algorithm ?? 'AES-GCM';
    let keyLength = opts?.keyLength ?? 16;
    const nonceLength = opts?.nonceLength ?? 12;
    const digest = opts?.digest ?? 'SHA-256';
    const saltLength = opts?.saltLength ?? 16;
    const iterations = opts?.iterations ?? 32767;
    const crypto = webcrypto$4.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$4, { name: 'AES-GCM' }, true, ['encrypt']);
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['encrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$4, { name: 'AES-GCM' }, true, ['encrypt']);
            }
        }
        else {
            // Derive a key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        }
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat$1([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['decrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$4, { name: 'AES-GCM' }, true, ['decrypt']);
            }
        }
        else {
            // Derive the key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        }
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter$4(privateKey, password) {
    const cipher = create$8();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64$6.encode(encryptedKey);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType$5;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType$5 || (KeyType$5 = {}));
var __KeyTypeValues$5;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues$5 || (__KeyTypeValues$5 = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues$5);
    };
})(KeyType$5 || (KeyType$5 = {}));
var PublicKey$5;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$5.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$5.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$1(buf, PublicKey.codec());
    };
})(PublicKey$5 || (PublicKey$5 = {}));
var PrivateKey$5;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$5.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$5.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$1(buf, PrivateKey.codec());
    };
})(PrivateKey$5 || (PrivateKey$5 = {}));

let Ed25519PublicKey$4 = class Ed25519PublicKey {
    _key;
    constructor(key) {
        this._key = ensureKey$4(key, PUBLIC_KEY_BYTE_LENGTH$4);
    }
    async verify(data, sig) {
        return hashAndVerify$e(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey$5.encode({
            Type: KeyType$5.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$5.digest(this.bytes);
        return bytes;
    }
};
let Ed25519PrivateKey$4 = class Ed25519PrivateKey {
    _key;
    _publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey$4(key, PRIVATE_KEY_BYTE_LENGTH$4);
        this._publicKey = ensureKey$4(publicKey, PUBLIC_KEY_BYTE_LENGTH$4);
    }
    async sign(message) {
        return hashAndSign$e(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey$4(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$5.encode({
            Type: KeyType$5.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$5.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity$4.digest(this.public.bytes);
        return base58btc$6.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$4(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalEd25519PrivateKey$4(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH$4) {
        bytes = ensureKey$4(bytes, PRIVATE_KEY_BYTE_LENGTH$4 + PUBLIC_KEY_BYTE_LENGTH$4);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$4);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH$4, bytes.length);
        return new Ed25519PrivateKey$4(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey$4(bytes, PRIVATE_KEY_BYTE_LENGTH$4);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$4);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH$4);
    return new Ed25519PrivateKey$4(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey$4(bytes) {
    bytes = ensureKey$4(bytes, PUBLIC_KEY_BYTE_LENGTH$4);
    return new Ed25519PublicKey$4(bytes);
}
async function generateKeyPair$g() {
    const { privateKey, publicKey } = await generateKey$e();
    return new Ed25519PrivateKey$4(privateKey, publicKey);
}
async function generateKeyPairFromSeed$4(seed) {
    const { privateKey, publicKey } = await generateKeyFromSeed$4(seed);
    return new Ed25519PrivateKey$4(privateKey, publicKey);
}
function ensureKey$4(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError$3(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519$4 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey$4,
    Ed25519PublicKey: Ed25519PublicKey$4,
    generateKeyPair: generateKeyPair$g,
    generateKeyPairFromSeed: generateKeyPairFromSeed$4,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey$4,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey$4
});

function bigIntegerToUintBase64url$4(num, len) {
    // Call `.abs()` to convert to unsigned
    let buf = Uint8Array.from(num.abs().toByteArray()); // toByteArray converts to big endian
    // toByteArray() gives us back a signed array, which will include a leading 0
    // byte if the most significant bit of the number is 1:
    // https://docs.microsoft.com/en-us/windows/win32/seccertenroll/about-integer
    // Our number will always be positive so we should remove the leading padding.
    buf = buf[0] === 0 ? buf.subarray(1) : buf;
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return toString$9(buf, 'base64url');
}
// Convert a base64url encoded string to a BigInteger
function base64urlToBigInteger$4(str) {
    const buf = base64urlToBuffer$4(str);
    return new forge$n.jsbn.BigInteger(toString$9(buf, 'base16'), 16);
}
function base64urlToBuffer$4(str, len) {
    let buf = fromString$3(str, 'base64urlpad');
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return buf;
}

const bits$5 = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes$5 = Object.keys(bits$5);
curveTypes$5.join(' / ');

function randomBytes$4(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError$3('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return utils.randomBytes(length);
}

function convert$4(key, types) {
    return types.map(t => base64urlToBigInteger$4(key[t]));
}
function jwk2priv$4(key) {
    return forge$n.pki.setRsaPrivateKey(...convert$4(key, ['n', 'e', 'd', 'p', 'q', 'dp', 'dq', 'qi']));
}
function jwk2pub$4(key) {
    return forge$n.pki.setRsaPublicKey(...convert$4(key, ['n', 'e']));
}

// Convert a PKCS#1 in ASN1 DER format to a JWK key
function pkcs1ToJwk$4(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
    // https://tools.ietf.org/html/rfc7518#section-6.3.1
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$4(privateKey.n),
        e: bigIntegerToUintBase64url$4(privateKey.e),
        d: bigIntegerToUintBase64url$4(privateKey.d),
        p: bigIntegerToUintBase64url$4(privateKey.p),
        q: bigIntegerToUintBase64url$4(privateKey.q),
        dp: bigIntegerToUintBase64url$4(privateKey.dP),
        dq: bigIntegerToUintBase64url$4(privateKey.dQ),
        qi: bigIntegerToUintBase64url$4(privateKey.qInv),
        alg: 'RS256'
    };
}
// Convert a JWK key into PKCS#1 in ASN1 DER format
function jwkToPkcs1$4(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.privateKeyToAsn1({
        n: base64urlToBigInteger$4(jwk.n),
        e: base64urlToBigInteger$4(jwk.e),
        d: base64urlToBigInteger$4(jwk.d),
        p: base64urlToBigInteger$4(jwk.p),
        q: base64urlToBigInteger$4(jwk.q),
        dP: base64urlToBigInteger$4(jwk.dp),
        dQ: base64urlToBigInteger$4(jwk.dq),
        qInv: base64urlToBigInteger$4(jwk.qi)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}
// Convert a PKCIX in ASN1 DER format to a JWK key
function pkixToJwk$4(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const publicKey = forge$n.pki.publicKeyFromAsn1(asn1);
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$4(publicKey.n),
        e: bigIntegerToUintBase64url$4(publicKey.e)
    };
}
// Convert a JWK key to PKCIX in ASN1 DER format
function jwkToPkix$4(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.publicKeyToAsn1({
        n: base64urlToBigInteger$4(jwk.n),
        e: base64urlToBigInteger$4(jwk.e)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}

async function generateKey$d(bits) {
    const pair = await webcrypto$4.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey$4(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$7(key) {
    const privateKey = await webcrypto$4.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate$4(key)
    ];
    const keys = await exportKey$4({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$d(key, msg) {
    const privateKey = await webcrypto$4.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto$4.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, Uint8Array.from(msg));
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$d(key, sig, msg) {
    const publicKey = await webcrypto$4.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return webcrypto$4.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg);
}
async function exportKey$4(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError$3('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return Promise.all([
        webcrypto$4.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto$4.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate$4(jwKey) {
    return webcrypto$4.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
/*

RSA encryption/decryption for the browser with webcrypto workaround
"bloody dark magic. webcrypto's why."

Explanation:
  - Convert JWK to nodeForge
  - Convert msg Uint8Array to nodeForge buffer: ByteBuffer is a "binary-string backed buffer", so let's make our Uint8Array a binary string
  - Convert resulting nodeForge buffer to Uint8Array: it returns a binary string, turn that into a Uint8Array

*/
function convertKey$4(key, pub, msg, handle) {
    const fkey = pub ? jwk2pub$4(key) : jwk2priv$4(key);
    const fmsg = toString$9(Uint8Array.from(msg), 'ascii');
    const fomsg = handle(fmsg, fkey);
    return fromString$3(fomsg, 'ascii');
}
function encrypt$4(key, msg) {
    return convertKey$4(key, true, msg, (msg, key) => key.encrypt(msg));
}
function decrypt$4(key, msg) {
    return convertKey$4(key, false, msg, (msg, key) => key.decrypt(msg));
}
function keySize$4(jwk) {
    if (jwk.kty !== 'RSA') {
        throw new CodeError$3('invalid key type', 'ERR_INVALID_KEY_TYPE');
    }
    else if (jwk.n == null) {
        throw new CodeError$3('invalid key modulus', 'ERR_INVALID_KEY_MODULUS');
    }
    const bytes = fromString$3(jwk.n, 'base64url');
    return bytes.length * 8;
}

const MAX_KEY_SIZE$4 = 8192;
let RsaPublicKey$4 = class RsaPublicKey {
    _key;
    constructor(key) {
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$d(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix$4(this._key);
    }
    get bytes() {
        return PublicKey$5.encode({
            Type: KeyType$5.RSA,
            Data: this.marshal()
        }).subarray();
    }
    encrypt(bytes) {
        return encrypt$4(this._key, bytes);
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$5.digest(this.bytes);
        return bytes;
    }
};
let RsaPrivateKey$4 = class RsaPrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes$4(16);
    }
    async sign(message) {
        return hashAndSign$d(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError$3('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey$4(this._publicKey);
    }
    decrypt(bytes) {
        return decrypt$4(this._key, bytes);
    }
    marshal() {
        return jwkToPkcs1$4(this._key);
    }
    get bytes() {
        return PrivateKey$5.encode({
            Type: KeyType$5.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$5.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected PEM format
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            const buffer = new forge$n.util.ByteBuffer(this.marshal());
            const asn1 = forge$n.asn1.fromDer(buffer);
            const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
            const options = {
                algorithm: 'aes256',
                count: 10000,
                saltSize: 128 / 8,
                prfAlgorithm: 'sha512'
            };
            return forge$n.pki.encryptRsaPrivateKey(privateKey, password, options);
        }
        else if (format === 'libp2p-key') {
            return exporter$4(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
async function unmarshalRsaPrivateKey$4(bytes) {
    const jwk = pkcs1ToJwk$4(bytes);
    if (keySize$4(jwk) > MAX_KEY_SIZE$4) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$7(jwk);
    return new RsaPrivateKey$4(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey$4(bytes) {
    const jwk = pkixToJwk$4(bytes);
    if (keySize$4(jwk) > MAX_KEY_SIZE$4) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    return new RsaPublicKey$4(jwk);
}
async function fromJwk$4(jwk) {
    if (keySize$4(jwk) > MAX_KEY_SIZE$4) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$7(jwk);
    return new RsaPrivateKey$4(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$f(bits) {
    if (bits > MAX_KEY_SIZE$4) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await generateKey$d(bits);
    return new RsaPrivateKey$4(keys.privateKey, keys.publicKey);
}

var RSA$4 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MAX_KEY_SIZE: MAX_KEY_SIZE$4,
    RsaPrivateKey: RsaPrivateKey$4,
    RsaPublicKey: RsaPublicKey$4,
    fromJwk: fromJwk$4,
    generateKeyPair: generateKeyPair$f,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey$4,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey$4
});

function generateKey$c() {
    return utils.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
async function hashAndSign$c(key, msg) {
    const { digest } = await sha256$5.digest(msg);
    try {
        return await sign$1(digest, key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
async function hashAndVerify$c(key, sig, msg) {
    try {
        const { digest } = await sha256$5.digest(msg);
        return verify(sig, digest, key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey$4(key) {
    const point = Point.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey$4(key) {
    try {
        getPublicKey(key, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey$4(key) {
    try {
        Point.fromHex(key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey$4(privateKey) {
    try {
        return getPublicKey(privateKey, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

let Secp256k1PublicKey$4 = class Secp256k1PublicKey {
    _key;
    constructor(key) {
        validatePublicKey$4(key);
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$c(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey$4(this._key);
    }
    get bytes() {
        return PublicKey$5.encode({
            Type: KeyType$5.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$5.digest(this.bytes);
        return bytes;
    }
};
let Secp256k1PrivateKey$4 = class Secp256k1PrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey$4(key);
        validatePrivateKey$4(this._key);
        validatePublicKey$4(this._publicKey);
    }
    async sign(message) {
        return hashAndSign$c(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey$4(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$5.encode({
            Type: KeyType$5.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$5.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$4(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalSecp256k1PrivateKey$4(bytes) {
    return new Secp256k1PrivateKey$4(bytes);
}
function unmarshalSecp256k1PublicKey$4(bytes) {
    return new Secp256k1PublicKey$4(bytes);
}
async function generateKeyPair$e() {
    const privateKeyBytes = generateKey$c();
    return new Secp256k1PrivateKey$4(privateKeyBytes);
}

var Secp256k1$4 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey$4,
    Secp256k1PublicKey: Secp256k1PublicKey$4,
    generateKeyPair: generateKeyPair$e,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey$4,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey$4
});

const supportedKeys$4 = {
    rsa: RSA$4,
    ed25519: Ed25519$4,
    secp256k1: Secp256k1$4
};
function unsupportedKey$4(type) {
    const supported = Object.keys(supportedKeys$4).join(' / ');
    return new CodeError$3(`invalid or unsupported key type ${type}. Must be ${supported}`, 'ERR_UNSUPPORTED_KEY_TYPE');
}
function typeToKey$2(type) {
    type = type.toLowerCase();
    if (type === 'rsa' || type === 'ed25519' || type === 'secp256k1') {
        return supportedKeys$4[type];
    }
    throw unsupportedKey$4(type);
}
// Converts a protobuf serialized public key into its
// representative object
function unmarshalPublicKey$2(buf) {
    const decoded = PublicKey$5.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType$5.RSA:
            return supportedKeys$4.rsa.unmarshalRsaPublicKey(data);
        case KeyType$5.Ed25519:
            return supportedKeys$4.ed25519.unmarshalEd25519PublicKey(data);
        case KeyType$5.Secp256k1:
            return supportedKeys$4.secp256k1.unmarshalSecp256k1PublicKey(data);
        default:
            throw unsupportedKey$4(decoded.Type ?? 'RSA');
    }
}
// Converts a public key object into a protobuf serialized public key
function marshalPublicKey$1(key, type) {
    type = (type ?? 'rsa').toLowerCase();
    typeToKey$2(type); // check type
    return key.bytes;
}
// Converts a protobuf serialized private key into its
// representative object
async function unmarshalPrivateKey$6(buf) {
    const decoded = PrivateKey$5.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType$5.RSA:
            return supportedKeys$4.rsa.unmarshalRsaPrivateKey(data);
        case KeyType$5.Ed25519:
            return supportedKeys$4.ed25519.unmarshalEd25519PrivateKey(data);
        case KeyType$5.Secp256k1:
            return supportedKeys$4.secp256k1.unmarshalSecp256k1PrivateKey(data);
        default:
            throw unsupportedKey$4(decoded.Type ?? 'RSA');
    }
}

/**
 * On the producing side:
 * * Build messages with the signature, key (from may be enough for certain inlineable public key types), from and seqno fields.
 *
 * On the consuming side:
 * * Enforce the fields to be present, reject otherwise.
 * * Propagate only if the fields are valid and signature can be verified, reject otherwise.
 */
const StrictSign = 'StrictSign';
/**
 * On the producing side:
 * * Build messages without the signature, key, from and seqno fields.
 * * The corresponding protobuf key-value pairs are absent from the marshalled message, not just empty.
 *
 * On the consuming side:
 * * Enforce the fields to be absent, reject otherwise.
 * * Propagate only if the fields are absent, reject otherwise.
 * * A message_id function will not be able to use the above fields, and should instead rely on the data field. A commonplace strategy is to calculate a hash.
 */
const StrictNoSign = 'StrictNoSign';
var TopicValidatorResult;
(function (TopicValidatorResult) {
    /**
     * The message is considered valid, and it should be delivered and forwarded to the network
     */
    TopicValidatorResult["Accept"] = "accept";
    /**
     * The message is neither delivered nor forwarded to the network
     */
    TopicValidatorResult["Ignore"] = "ignore";
    /**
     * The message is considered invalid, and it should be rejected
     */
    TopicValidatorResult["Reject"] = "reject";
})(TopicValidatorResult || (TopicValidatorResult = {}));

var SignaturePolicy;
(function (SignaturePolicy) {
    /**
     * On the producing side:
     * - Build messages with the signature, key (from may be enough for certain inlineable public key types), from and seqno fields.
     *
     * On the consuming side:
     * - Enforce the fields to be present, reject otherwise.
     * - Propagate only if the fields are valid and signature can be verified, reject otherwise.
     */
    SignaturePolicy["StrictSign"] = "StrictSign";
    /**
     * On the producing side:
     * - Build messages without the signature, key, from and seqno fields.
     * - The corresponding protobuf key-value pairs are absent from the marshalled message, not just empty.
     *
     * On the consuming side:
     * - Enforce the fields to be absent, reject otherwise.
     * - Propagate only if the fields are absent, reject otherwise.
     * - A message_id function will not be able to use the above fields, and should instead rely on the data field. A commonplace strategy is to calculate a hash.
     */
    SignaturePolicy["StrictNoSign"] = "StrictNoSign";
})(SignaturePolicy || (SignaturePolicy = {}));
var PublishConfigType;
(function (PublishConfigType) {
    PublishConfigType[PublishConfigType["Signing"] = 0] = "Signing";
    PublishConfigType[PublishConfigType["Anonymous"] = 1] = "Anonymous";
})(PublishConfigType || (PublishConfigType = {}));
var RejectReason;
(function (RejectReason) {
    /**
     * The message failed the configured validation during decoding.
     * SelfOrigin is considered a ValidationError
     */
    RejectReason["Error"] = "error";
    /**
     * Custom validator fn reported status IGNORE.
     */
    RejectReason["Ignore"] = "ignore";
    /**
     * Custom validator fn reported status REJECT.
     */
    RejectReason["Reject"] = "reject";
    /**
     * The peer that sent the message OR the source from field is blacklisted.
     * Causes messages to be ignored, not penalized, neither do score record creation.
     */
    RejectReason["Blacklisted"] = "blacklisted";
})(RejectReason || (RejectReason = {}));
var ValidateError;
(function (ValidateError) {
    /// The message has an invalid signature,
    ValidateError["InvalidSignature"] = "invalid_signature";
    /// The sequence number was the incorrect size
    ValidateError["InvalidSeqno"] = "invalid_seqno";
    /// The PeerId was invalid
    ValidateError["InvalidPeerId"] = "invalid_peerid";
    /// Signature existed when validation has been sent to
    /// [`crate::behaviour::MessageAuthenticity::Anonymous`].
    ValidateError["SignaturePresent"] = "signature_present";
    /// Sequence number existed when validation has been sent to
    /// [`crate::behaviour::MessageAuthenticity::Anonymous`].
    ValidateError["SeqnoPresent"] = "seqno_present";
    /// Message source existed when validation has been sent to
    /// [`crate::behaviour::MessageAuthenticity::Anonymous`].
    ValidateError["FromPresent"] = "from_present";
    /// The data transformation failed.
    ValidateError["TransformFailed"] = "transform_failed";
})(ValidateError || (ValidateError = {}));
var MessageStatus;
(function (MessageStatus) {
    MessageStatus["duplicate"] = "duplicate";
    MessageStatus["invalid"] = "invalid";
    MessageStatus["valid"] = "valid";
})(MessageStatus || (MessageStatus = {}));
/**
 * Typesafe conversion of MessageAcceptance -> RejectReason. TS ensures all values covered
 */
function rejectReasonFromAcceptance(acceptance) {
    switch (acceptance) {
        case TopicValidatorResult.Ignore:
            return RejectReason.Ignore;
        case TopicValidatorResult.Reject:
            return RejectReason.Reject;
    }
}

/**
 * Prepare a PublishConfig object from a PeerId.
 */
async function getPublishConfigFromPeerId(signaturePolicy, peerId) {
    switch (signaturePolicy) {
        case StrictSign: {
            if (!peerId) {
                throw Error('Must provide PeerId');
            }
            if (peerId.privateKey == null) {
                throw Error('Cannot sign message, no private key present');
            }
            if (peerId.publicKey == null) {
                throw Error('Cannot sign message, no public key present');
            }
            // Transform privateKey once at initialization time instead of once per message
            const privateKey = await unmarshalPrivateKey$6(peerId.privateKey);
            return {
                type: PublishConfigType.Signing,
                author: peerId,
                key: peerId.publicKey,
                privateKey
            };
        }
        case StrictNoSign:
            return {
                type: PublishConfigType.Anonymous
            };
        default:
            throw new Error(`Unknown signature policy "${signaturePolicy}"`);
    }
}

const ERR_INVALID_PEER_SCORE_PARAMS = 'ERR_INVALID_PEER_SCORE_PARAMS';

const defaultPeerScoreParams = {
    topics: {},
    topicScoreCap: 10.0,
    appSpecificScore: () => 0.0,
    appSpecificWeight: 10.0,
    IPColocationFactorWeight: -5.0,
    IPColocationFactorThreshold: 10.0,
    IPColocationFactorWhitelist: new Set(),
    behaviourPenaltyWeight: -10.0,
    behaviourPenaltyThreshold: 0.0,
    behaviourPenaltyDecay: 0.2,
    decayInterval: 1000.0,
    decayToZero: 0.1,
    retainScore: 3600 * 1000
};
const defaultTopicScoreParams = {
    topicWeight: 0.5,
    timeInMeshWeight: 1,
    timeInMeshQuantum: 1,
    timeInMeshCap: 3600,
    firstMessageDeliveriesWeight: 1,
    firstMessageDeliveriesDecay: 0.5,
    firstMessageDeliveriesCap: 2000,
    meshMessageDeliveriesWeight: -1,
    meshMessageDeliveriesDecay: 0.5,
    meshMessageDeliveriesCap: 100,
    meshMessageDeliveriesThreshold: 20,
    meshMessageDeliveriesWindow: 10,
    meshMessageDeliveriesActivation: 5000,
    meshFailurePenaltyWeight: -1,
    meshFailurePenaltyDecay: 0.5,
    invalidMessageDeliveriesWeight: -1,
    invalidMessageDeliveriesDecay: 0.3
};
function createPeerScoreParams(p = {}) {
    return {
        ...defaultPeerScoreParams,
        ...p,
        topics: p.topics
            ? Object.entries(p.topics).reduce((topics, [topic, topicScoreParams]) => {
                topics[topic] = createTopicScoreParams(topicScoreParams);
                return topics;
            }, {})
            : {}
    };
}
function createTopicScoreParams(p = {}) {
    return {
        ...defaultTopicScoreParams,
        ...p
    };
}
// peer score parameter validation
function validatePeerScoreParams(p) {
    for (const [topic, params] of Object.entries(p.topics)) {
        try {
            validateTopicScoreParams(params);
        }
        catch (e) {
            throw new CodeError$3(`invalid score parameters for topic ${topic}: ${e.message}`, ERR_INVALID_PEER_SCORE_PARAMS);
        }
    }
    // check that the topic score is 0 or something positive
    if (p.topicScoreCap < 0) {
        throw new CodeError$3('invalid topic score cap; must be positive (or 0 for no cap)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check that we have an app specific score; the weight can be anything (but expected positive)
    if (p.appSpecificScore === null || p.appSpecificScore === undefined) {
        throw new CodeError$3('missing application specific score function', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check the IP colocation factor
    if (p.IPColocationFactorWeight > 0) {
        throw new CodeError$3('invalid IPColocationFactorWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.IPColocationFactorWeight !== 0 && p.IPColocationFactorThreshold < 1) {
        throw new CodeError$3('invalid IPColocationFactorThreshold; must be at least 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check the behaviour penalty
    if (p.behaviourPenaltyWeight > 0) {
        throw new CodeError$3('invalid BehaviourPenaltyWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.behaviourPenaltyWeight !== 0 && (p.behaviourPenaltyDecay <= 0 || p.behaviourPenaltyDecay >= 1)) {
        throw new CodeError$3('invalid BehaviourPenaltyDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check the decay parameters
    if (p.decayInterval < 1000) {
        throw new CodeError$3('invalid DecayInterval; must be at least 1s', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.decayToZero <= 0 || p.decayToZero >= 1) {
        throw new CodeError$3('invalid DecayToZero; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // no need to check the score retention; a value of 0 means that we don't retain scores
}
function validateTopicScoreParams(p) {
    // make sure we have a sane topic weight
    if (p.topicWeight < 0) {
        throw new CodeError$3('invalid topic weight; must be >= 0', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P1
    if (p.timeInMeshQuantum === 0) {
        throw new CodeError$3('invalid TimeInMeshQuantum; must be non zero', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.timeInMeshWeight < 0) {
        throw new CodeError$3('invalid TimeInMeshWeight; must be positive (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.timeInMeshWeight !== 0 && p.timeInMeshQuantum <= 0) {
        throw new CodeError$3('invalid TimeInMeshQuantum; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.timeInMeshWeight !== 0 && p.timeInMeshCap <= 0) {
        throw new CodeError$3('invalid TimeInMeshCap; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P2
    if (p.firstMessageDeliveriesWeight < 0) {
        throw new CodeError$3('invallid FirstMessageDeliveriesWeight; must be positive (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.firstMessageDeliveriesWeight !== 0 &&
        (p.firstMessageDeliveriesDecay <= 0 || p.firstMessageDeliveriesDecay >= 1)) {
        throw new CodeError$3('invalid FirstMessageDeliveriesDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.firstMessageDeliveriesWeight !== 0 && p.firstMessageDeliveriesCap <= 0) {
        throw new CodeError$3('invalid FirstMessageDeliveriesCap; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P3
    if (p.meshMessageDeliveriesWeight > 0) {
        throw new CodeError$3('invalid MeshMessageDeliveriesWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWeight !== 0 && (p.meshMessageDeliveriesDecay <= 0 || p.meshMessageDeliveriesDecay >= 1)) {
        throw new CodeError$3('invalid MeshMessageDeliveriesDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWeight !== 0 && p.meshMessageDeliveriesCap <= 0) {
        throw new CodeError$3('invalid MeshMessageDeliveriesCap; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWeight !== 0 && p.meshMessageDeliveriesThreshold <= 0) {
        throw new CodeError$3('invalid MeshMessageDeliveriesThreshold; must be positive', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWindow < 0) {
        throw new CodeError$3('invalid MeshMessageDeliveriesWindow; must be non-negative', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshMessageDeliveriesWeight !== 0 && p.meshMessageDeliveriesActivation < 1000) {
        throw new CodeError$3('invalid MeshMessageDeliveriesActivation; must be at least 1s', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P3b
    if (p.meshFailurePenaltyWeight > 0) {
        throw new CodeError$3('invalid MeshFailurePenaltyWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.meshFailurePenaltyWeight !== 0 && (p.meshFailurePenaltyDecay <= 0 || p.meshFailurePenaltyDecay >= 1)) {
        throw new CodeError$3('invalid MeshFailurePenaltyDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    // check P4
    if (p.invalidMessageDeliveriesWeight > 0) {
        throw new CodeError$3('invalid InvalidMessageDeliveriesWeight; must be negative (or 0 to disable)', ERR_INVALID_PEER_SCORE_PARAMS);
    }
    if (p.invalidMessageDeliveriesDecay <= 0 || p.invalidMessageDeliveriesDecay >= 1) {
        throw new CodeError$3('invalid InvalidMessageDeliveriesDecay; must be between 0 and 1', ERR_INVALID_PEER_SCORE_PARAMS);
    }
}

const defaultPeerScoreThresholds = {
    gossipThreshold: -10,
    publishThreshold: -50,
    graylistThreshold: -80,
    acceptPXThreshold: 10,
    opportunisticGraftThreshold: 20
};
function createPeerScoreThresholds(p = {}) {
    return {
        ...defaultPeerScoreThresholds,
        ...p
    };
}

function computeScore(peer, pstats, params, peerIPs) {
    let score = 0;
    // topic stores
    Object.entries(pstats.topics).forEach(([topic, tstats]) => {
        // the topic parameters
        const topicParams = params.topics[topic];
        if (topicParams === undefined) {
            // we are not scoring this topic
            return;
        }
        let topicScore = 0;
        // P1: time in Mesh
        if (tstats.inMesh) {
            let p1 = tstats.meshTime / topicParams.timeInMeshQuantum;
            if (p1 > topicParams.timeInMeshCap) {
                p1 = topicParams.timeInMeshCap;
            }
            topicScore += p1 * topicParams.timeInMeshWeight;
        }
        // P2: first message deliveries
        let p2 = tstats.firstMessageDeliveries;
        if (p2 > topicParams.firstMessageDeliveriesCap) {
            p2 = topicParams.firstMessageDeliveriesCap;
        }
        topicScore += p2 * topicParams.firstMessageDeliveriesWeight;
        // P3: mesh message deliveries
        if (tstats.meshMessageDeliveriesActive &&
            tstats.meshMessageDeliveries < topicParams.meshMessageDeliveriesThreshold) {
            const deficit = topicParams.meshMessageDeliveriesThreshold - tstats.meshMessageDeliveries;
            const p3 = deficit * deficit;
            topicScore += p3 * topicParams.meshMessageDeliveriesWeight;
        }
        // P3b:
        // NOTE: the weight of P3b is negative (validated in validateTopicScoreParams) so this detracts
        const p3b = tstats.meshFailurePenalty;
        topicScore += p3b * topicParams.meshFailurePenaltyWeight;
        // P4: invalid messages
        // NOTE: the weight of P4 is negative (validated in validateTopicScoreParams) so this detracts
        const p4 = tstats.invalidMessageDeliveries * tstats.invalidMessageDeliveries;
        topicScore += p4 * topicParams.invalidMessageDeliveriesWeight;
        // update score, mixing with topic weight
        score += topicScore * topicParams.topicWeight;
    });
    // apply the topic score cap, if any
    if (params.topicScoreCap > 0 && score > params.topicScoreCap) {
        score = params.topicScoreCap;
    }
    // P5: application-specific score
    const p5 = params.appSpecificScore(peer);
    score += p5 * params.appSpecificWeight;
    // P6: IP colocation factor
    pstats.knownIPs.forEach((ip) => {
        if (params.IPColocationFactorWhitelist.has(ip)) {
            return;
        }
        // P6 has a cliff (IPColocationFactorThreshold)
        // It's only applied if at least that many peers are connected to us from that source IP addr.
        // It is quadratic, and the weight is negative (validated in validatePeerScoreParams)
        const peersInIP = peerIPs.get(ip);
        const numPeersInIP = peersInIP ? peersInIP.size : 0;
        if (numPeersInIP > params.IPColocationFactorThreshold) {
            const surplus = numPeersInIP - params.IPColocationFactorThreshold;
            const p6 = surplus * surplus;
            score += p6 * params.IPColocationFactorWeight;
        }
    });
    // P7: behavioural pattern penalty
    if (pstats.behaviourPenalty > params.behaviourPenaltyThreshold) {
        const excess = pstats.behaviourPenalty - params.behaviourPenaltyThreshold;
        const p7 = excess * excess;
        score += p7 * params.behaviourPenaltyWeight;
    }
    return score;
}

/**
 * Custom implementation of a double ended queue.
 */
function Denque(array, options) {
  var options = options || {};
  this._capacity = options.capacity;

  this._head = 0;
  this._tail = 0;

  if (Array.isArray(array)) {
    this._fromArray(array);
  } else {
    this._capacityMask = 0x3;
    this._list = new Array(4);
  }
}

/**
 * --------------
 *  PUBLIC API
 * -------------
 */

/**
 * Returns the item at the specified index from the list.
 * 0 is the first element, 1 is the second, and so on...
 * Elements at negative values are that many from the end: -1 is one before the end
 * (the last element), -2 is two before the end (one before last), etc.
 * @param index
 * @returns {*}
 */
Denque.prototype.peekAt = function peekAt(index) {
  var i = index;
  // expect a number or return undefined
  if ((i !== (i | 0))) {
    return void 0;
  }
  var len = this.size();
  if (i >= len || i < -len) return undefined;
  if (i < 0) i += len;
  i = (this._head + i) & this._capacityMask;
  return this._list[i];
};

/**
 * Alias for peekAt()
 * @param i
 * @returns {*}
 */
Denque.prototype.get = function get(i) {
  return this.peekAt(i);
};

/**
 * Returns the first item in the list without removing it.
 * @returns {*}
 */
Denque.prototype.peek = function peek() {
  if (this._head === this._tail) return undefined;
  return this._list[this._head];
};

/**
 * Alias for peek()
 * @returns {*}
 */
Denque.prototype.peekFront = function peekFront() {
  return this.peek();
};

/**
 * Returns the item that is at the back of the queue without removing it.
 * Uses peekAt(-1)
 */
Denque.prototype.peekBack = function peekBack() {
  return this.peekAt(-1);
};

/**
 * Returns the current length of the queue
 * @return {Number}
 */
Object.defineProperty(Denque.prototype, 'length', {
  get: function length() {
    return this.size();
  }
});

/**
 * Return the number of items on the list, or 0 if empty.
 * @returns {number}
 */
Denque.prototype.size = function size() {
  if (this._head === this._tail) return 0;
  if (this._head < this._tail) return this._tail - this._head;
  else return this._capacityMask + 1 - (this._head - this._tail);
};

/**
 * Add an item at the beginning of the list.
 * @param item
 */
Denque.prototype.unshift = function unshift(item) {
  if (arguments.length === 0) return this.size();
  var len = this._list.length;
  this._head = (this._head - 1 + len) & this._capacityMask;
  this._list[this._head] = item;
  if (this._tail === this._head) this._growArray();
  if (this._capacity && this.size() > this._capacity) this.pop();
  if (this._head < this._tail) return this._tail - this._head;
  else return this._capacityMask + 1 - (this._head - this._tail);
};

/**
 * Remove and return the first item on the list,
 * Returns undefined if the list is empty.
 * @returns {*}
 */
Denque.prototype.shift = function shift() {
  var head = this._head;
  if (head === this._tail) return undefined;
  var item = this._list[head];
  this._list[head] = undefined;
  this._head = (head + 1) & this._capacityMask;
  if (head < 2 && this._tail > 10000 && this._tail <= this._list.length >>> 2) this._shrinkArray();
  return item;
};

/**
 * Add an item to the bottom of the list.
 * @param item
 */
Denque.prototype.push = function push(item) {
  if (arguments.length === 0) return this.size();
  var tail = this._tail;
  this._list[tail] = item;
  this._tail = (tail + 1) & this._capacityMask;
  if (this._tail === this._head) {
    this._growArray();
  }
  if (this._capacity && this.size() > this._capacity) {
    this.shift();
  }
  if (this._head < this._tail) return this._tail - this._head;
  else return this._capacityMask + 1 - (this._head - this._tail);
};

/**
 * Remove and return the last item on the list.
 * Returns undefined if the list is empty.
 * @returns {*}
 */
Denque.prototype.pop = function pop() {
  var tail = this._tail;
  if (tail === this._head) return undefined;
  var len = this._list.length;
  this._tail = (tail - 1 + len) & this._capacityMask;
  var item = this._list[this._tail];
  this._list[this._tail] = undefined;
  if (this._head < 2 && tail > 10000 && tail <= len >>> 2) this._shrinkArray();
  return item;
};

/**
 * Remove and return the item at the specified index from the list.
 * Returns undefined if the list is empty.
 * @param index
 * @returns {*}
 */
Denque.prototype.removeOne = function removeOne(index) {
  var i = index;
  // expect a number or return undefined
  if ((i !== (i | 0))) {
    return void 0;
  }
  if (this._head === this._tail) return void 0;
  var size = this.size();
  var len = this._list.length;
  if (i >= size || i < -size) return void 0;
  if (i < 0) i += size;
  i = (this._head + i) & this._capacityMask;
  var item = this._list[i];
  var k;
  if (index < size / 2) {
    for (k = index; k > 0; k--) {
      this._list[i] = this._list[i = (i - 1 + len) & this._capacityMask];
    }
    this._list[i] = void 0;
    this._head = (this._head + 1 + len) & this._capacityMask;
  } else {
    for (k = size - 1 - index; k > 0; k--) {
      this._list[i] = this._list[i = (i + 1 + len) & this._capacityMask];
    }
    this._list[i] = void 0;
    this._tail = (this._tail - 1 + len) & this._capacityMask;
  }
  return item;
};

/**
 * Remove number of items from the specified index from the list.
 * Returns array of removed items.
 * Returns undefined if the list is empty.
 * @param index
 * @param count
 * @returns {array}
 */
Denque.prototype.remove = function remove(index, count) {
  var i = index;
  var removed;
  var del_count = count;
  // expect a number or return undefined
  if ((i !== (i | 0))) {
    return void 0;
  }
  if (this._head === this._tail) return void 0;
  var size = this.size();
  var len = this._list.length;
  if (i >= size || i < -size || count < 1) return void 0;
  if (i < 0) i += size;
  if (count === 1 || !count) {
    removed = new Array(1);
    removed[0] = this.removeOne(i);
    return removed;
  }
  if (i === 0 && i + count >= size) {
    removed = this.toArray();
    this.clear();
    return removed;
  }
  if (i + count > size) count = size - i;
  var k;
  removed = new Array(count);
  for (k = 0; k < count; k++) {
    removed[k] = this._list[(this._head + i + k) & this._capacityMask];
  }
  i = (this._head + i) & this._capacityMask;
  if (index + count === size) {
    this._tail = (this._tail - count + len) & this._capacityMask;
    for (k = count; k > 0; k--) {
      this._list[i = (i + 1 + len) & this._capacityMask] = void 0;
    }
    return removed;
  }
  if (index === 0) {
    this._head = (this._head + count + len) & this._capacityMask;
    for (k = count - 1; k > 0; k--) {
      this._list[i = (i + 1 + len) & this._capacityMask] = void 0;
    }
    return removed;
  }
  if (i < size / 2) {
    this._head = (this._head + index + count + len) & this._capacityMask;
    for (k = index; k > 0; k--) {
      this.unshift(this._list[i = (i - 1 + len) & this._capacityMask]);
    }
    i = (this._head - 1 + len) & this._capacityMask;
    while (del_count > 0) {
      this._list[i = (i - 1 + len) & this._capacityMask] = void 0;
      del_count--;
    }
    if (index < 0) this._tail = i;
  } else {
    this._tail = i;
    i = (i + count + len) & this._capacityMask;
    for (k = size - (count + index); k > 0; k--) {
      this.push(this._list[i++]);
    }
    i = this._tail;
    while (del_count > 0) {
      this._list[i = (i + 1 + len) & this._capacityMask] = void 0;
      del_count--;
    }
  }
  if (this._head < 2 && this._tail > 10000 && this._tail <= len >>> 2) this._shrinkArray();
  return removed;
};

/**
 * Native splice implementation.
 * Remove number of items from the specified index from the list and/or add new elements.
 * Returns array of removed items or empty array if count == 0.
 * Returns undefined if the list is empty.
 *
 * @param index
 * @param count
 * @param {...*} [elements]
 * @returns {array}
 */
Denque.prototype.splice = function splice(index, count) {
  var i = index;
  // expect a number or return undefined
  if ((i !== (i | 0))) {
    return void 0;
  }
  var size = this.size();
  if (i < 0) i += size;
  if (i > size) return void 0;
  if (arguments.length > 2) {
    var k;
    var temp;
    var removed;
    var arg_len = arguments.length;
    var len = this._list.length;
    var arguments_index = 2;
    if (!size || i < size / 2) {
      temp = new Array(i);
      for (k = 0; k < i; k++) {
        temp[k] = this._list[(this._head + k) & this._capacityMask];
      }
      if (count === 0) {
        removed = [];
        if (i > 0) {
          this._head = (this._head + i + len) & this._capacityMask;
        }
      } else {
        removed = this.remove(i, count);
        this._head = (this._head + i + len) & this._capacityMask;
      }
      while (arg_len > arguments_index) {
        this.unshift(arguments[--arg_len]);
      }
      for (k = i; k > 0; k--) {
        this.unshift(temp[k - 1]);
      }
    } else {
      temp = new Array(size - (i + count));
      var leng = temp.length;
      for (k = 0; k < leng; k++) {
        temp[k] = this._list[(this._head + i + count + k) & this._capacityMask];
      }
      if (count === 0) {
        removed = [];
        if (i != size) {
          this._tail = (this._head + i + len) & this._capacityMask;
        }
      } else {
        removed = this.remove(i, count);
        this._tail = (this._tail - leng + len) & this._capacityMask;
      }
      while (arguments_index < arg_len) {
        this.push(arguments[arguments_index++]);
      }
      for (k = 0; k < leng; k++) {
        this.push(temp[k]);
      }
    }
    return removed;
  } else {
    return this.remove(i, count);
  }
};

/**
 * Soft clear - does not reset capacity.
 */
Denque.prototype.clear = function clear() {
  this._list = new Array(this._list.length);
  this._head = 0;
  this._tail = 0;
};

/**
 * Returns true or false whether the list is empty.
 * @returns {boolean}
 */
Denque.prototype.isEmpty = function isEmpty() {
  return this._head === this._tail;
};

/**
 * Returns an array of all queue items.
 * @returns {Array}
 */
Denque.prototype.toArray = function toArray() {
  return this._copyArray(false);
};

/**
 * -------------
 *   INTERNALS
 * -------------
 */

/**
 * Fills the queue with items from an array
 * For use in the constructor
 * @param array
 * @private
 */
Denque.prototype._fromArray = function _fromArray(array) {
  var length = array.length;
  var capacity = this._nextPowerOf2(length);

  this._list = new Array(capacity);
  this._capacityMask = capacity - 1;
  this._tail = length;

  for (var i = 0; i < length; i++) this._list[i] = array[i];
};

/**
 *
 * @param fullCopy
 * @param size Initialize the array with a specific size. Will default to the current list size
 * @returns {Array}
 * @private
 */
Denque.prototype._copyArray = function _copyArray(fullCopy, size) {
  var src = this._list;
  var capacity = src.length;
  var length = this.length;
  size = size | length;

  // No prealloc requested and the buffer is contiguous
  if (size == length && this._head < this._tail) {
    // Simply do a fast slice copy
    return this._list.slice(this._head, this._tail);
  }

  var dest = new Array(size);

  var k = 0;
  var i;
  if (fullCopy || this._head > this._tail) {
    for (i = this._head; i < capacity; i++) dest[k++] = src[i];
    for (i = 0; i < this._tail; i++) dest[k++] = src[i];
  } else {
    for (i = this._head; i < this._tail; i++) dest[k++] = src[i];
  }

  return dest;
};

/**
 * Grows the internal list array.
 * @private
 */
Denque.prototype._growArray = function _growArray() {
  if (this._head != 0) {
    // double array size and copy existing data, head to end, then beginning to tail.
    var newList = this._copyArray(true, this._list.length << 1);

    this._tail = this._list.length;
    this._head = 0;

    this._list = newList;
  } else {
    this._tail = this._list.length;
    this._list.length <<= 1;
  }

  this._capacityMask = (this._capacityMask << 1) | 1;
};

/**
 * Shrinks the internal list array.
 * @private
 */
Denque.prototype._shrinkArray = function _shrinkArray() {
  this._list.length >>>= 1;
  this._capacityMask >>>= 1;
};

/**
 * Find the next power of 2, at least 4
 * @private
 * @param {number} num 
 * @returns {number}
 */
Denque.prototype._nextPowerOf2 = function _nextPowerOf2(num) {
  var log2 = Math.log(num) / Math.log(2);
  var nextPow2 = 1 << (log2 + 1);

  return Math.max(nextPow2, 4);
};

var denque = Denque;

var Denque$1 = /*@__PURE__*/getDefaultExportFromCjs(denque);

var DeliveryRecordStatus;
(function (DeliveryRecordStatus) {
    /**
     * we don't know (yet) if the message is valid
     */
    DeliveryRecordStatus[DeliveryRecordStatus["unknown"] = 0] = "unknown";
    /**
     * we know the message is valid
     */
    DeliveryRecordStatus[DeliveryRecordStatus["valid"] = 1] = "valid";
    /**
     * we know the message is invalid
     */
    DeliveryRecordStatus[DeliveryRecordStatus["invalid"] = 2] = "invalid";
    /**
     * we were instructed by the validator to ignore the message
     */
    DeliveryRecordStatus[DeliveryRecordStatus["ignored"] = 3] = "ignored";
})(DeliveryRecordStatus || (DeliveryRecordStatus = {}));
/**
 * Map of canonical message ID to DeliveryRecord
 *
 * Maintains an internal queue for efficient gc of old messages
 */
class MessageDeliveries {
    records;
    queue;
    constructor() {
        this.records = new Map();
        this.queue = new Denque$1();
    }
    getRecord(msgIdStr) {
        return this.records.get(msgIdStr);
    }
    ensureRecord(msgIdStr) {
        let drec = this.records.get(msgIdStr);
        if (drec) {
            return drec;
        }
        // record doesn't exist yet
        // create record
        drec = {
            status: DeliveryRecordStatus.unknown,
            firstSeenTsMs: Date.now(),
            validated: 0,
            peers: new Set()
        };
        this.records.set(msgIdStr, drec);
        // and add msgId to the queue
        const entry = {
            msgId: msgIdStr,
            expire: Date.now() + TimeCacheDuration
        };
        this.queue.push(entry);
        return drec;
    }
    gc() {
        const now = Date.now();
        // queue is sorted by expiry time
        // remove expired messages, remove from queue until first un-expired message found
        let head = this.queue.peekFront();
        while (head && head.expire < now) {
            this.records.delete(head.msgId);
            this.queue.shift();
            head = this.queue.peekFront();
        }
    }
    clear() {
        this.records.clear();
        this.queue.clear();
    }
}

/**
 * Exclude up to `ineed` items from a set if item meets condition `cond`
 */
function removeItemsFromSet(superSet, ineed, cond = () => true) {
    const subset = new Set();
    if (ineed <= 0)
        return subset;
    for (const id of superSet) {
        if (subset.size >= ineed)
            break;
        if (cond(id)) {
            subset.add(id);
            superSet.delete(id);
        }
    }
    return subset;
}
/**
 * Exclude up to `ineed` items from a set
 */
function removeFirstNItemsFromSet(superSet, ineed) {
    return removeItemsFromSet(superSet, ineed, () => true);
}
class MapDef extends Map {
    getDefault;
    constructor(getDefault) {
        super();
        this.getDefault = getDefault;
    }
    getOrDefault(key) {
        let value = super.get(key);
        if (value === undefined) {
            value = this.getDefault();
            this.set(key, value);
        }
        return value;
    }
}

const log$o = logger$4('libp2p:gossipsub:score');
class PeerScore {
    params;
    metrics;
    /**
     * Per-peer stats for score calculation
     */
    peerStats = new Map();
    /**
     * IP colocation tracking; maps IP => set of peers.
     */
    peerIPs = new MapDef(() => new Set());
    /**
     * Cache score up to decayInterval if topic stats are unchanged.
     */
    scoreCache = new Map();
    /**
     * Recent message delivery timing/participants
     */
    deliveryRecords = new MessageDeliveries();
    _backgroundInterval;
    scoreCacheValidityMs;
    computeScore;
    constructor(params, metrics, opts) {
        this.params = params;
        this.metrics = metrics;
        validatePeerScoreParams(params);
        this.scoreCacheValidityMs = opts.scoreCacheValidityMs;
        this.computeScore = opts.computeScore ?? computeScore;
    }
    get size() {
        return this.peerStats.size;
    }
    /**
     * Start PeerScore instance
     */
    start() {
        if (this._backgroundInterval) {
            log$o('Peer score already running');
            return;
        }
        this._backgroundInterval = setInterval(() => this.background(), this.params.decayInterval);
        log$o('started');
    }
    /**
     * Stop PeerScore instance
     */
    stop() {
        if (!this._backgroundInterval) {
            log$o('Peer score already stopped');
            return;
        }
        clearInterval(this._backgroundInterval);
        delete this._backgroundInterval;
        this.peerIPs.clear();
        this.peerStats.clear();
        this.deliveryRecords.clear();
        log$o('stopped');
    }
    /**
     * Periodic maintenance
     */
    background() {
        this.refreshScores();
        this.deliveryRecords.gc();
    }
    dumpPeerScoreStats() {
        return Object.fromEntries(Array.from(this.peerStats.entries()).map(([peer, stats]) => [peer, stats]));
    }
    messageFirstSeenTimestampMs(msgIdStr) {
        const drec = this.deliveryRecords.getRecord(msgIdStr);
        return drec ? drec.firstSeenTsMs : null;
    }
    /**
     * Decays scores, and purges score records for disconnected peers once their expiry has elapsed.
     */
    refreshScores() {
        const now = Date.now();
        const decayToZero = this.params.decayToZero;
        this.peerStats.forEach((pstats, id) => {
            if (!pstats.connected) {
                // has the retention period expired?
                if (now > pstats.expire) {
                    // yes, throw it away (but clean up the IP tracking first)
                    this.removeIPsForPeer(id, pstats.knownIPs);
                    this.peerStats.delete(id);
                    this.scoreCache.delete(id);
                }
                // we don't decay retained scores, as the peer is not active.
                // this way the peer cannot reset a negative score by simply disconnecting and reconnecting,
                // unless the retention period has elapsed.
                // similarly, a well behaved peer does not lose its score by getting disconnected.
                return;
            }
            Object.entries(pstats.topics).forEach(([topic, tstats]) => {
                const tparams = this.params.topics[topic];
                if (tparams === undefined) {
                    // we are not scoring this topic
                    // should be unreachable, we only add scored topics to pstats
                    return;
                }
                // decay counters
                tstats.firstMessageDeliveries *= tparams.firstMessageDeliveriesDecay;
                if (tstats.firstMessageDeliveries < decayToZero) {
                    tstats.firstMessageDeliveries = 0;
                }
                tstats.meshMessageDeliveries *= tparams.meshMessageDeliveriesDecay;
                if (tstats.meshMessageDeliveries < decayToZero) {
                    tstats.meshMessageDeliveries = 0;
                }
                tstats.meshFailurePenalty *= tparams.meshFailurePenaltyDecay;
                if (tstats.meshFailurePenalty < decayToZero) {
                    tstats.meshFailurePenalty = 0;
                }
                tstats.invalidMessageDeliveries *= tparams.invalidMessageDeliveriesDecay;
                if (tstats.invalidMessageDeliveries < decayToZero) {
                    tstats.invalidMessageDeliveries = 0;
                }
                // update mesh time and activate mesh message delivery parameter if need be
                if (tstats.inMesh) {
                    tstats.meshTime = now - tstats.graftTime;
                    if (tstats.meshTime > tparams.meshMessageDeliveriesActivation) {
                        tstats.meshMessageDeliveriesActive = true;
                    }
                }
            });
            // decay P7 counter
            pstats.behaviourPenalty *= this.params.behaviourPenaltyDecay;
            if (pstats.behaviourPenalty < decayToZero) {
                pstats.behaviourPenalty = 0;
            }
        });
    }
    /**
     * Return the score for a peer
     */
    score(id) {
        this.metrics?.scoreFnCalls.inc();
        const pstats = this.peerStats.get(id);
        if (!pstats) {
            return 0;
        }
        const now = Date.now();
        const cacheEntry = this.scoreCache.get(id);
        // Found cached score within validity period
        if (cacheEntry && cacheEntry.cacheUntil > now) {
            return cacheEntry.score;
        }
        this.metrics?.scoreFnRuns.inc();
        const score = this.computeScore(id, pstats, this.params, this.peerIPs);
        const cacheUntil = now + this.scoreCacheValidityMs;
        if (cacheEntry) {
            this.metrics?.scoreCachedDelta.observe(Math.abs(score - cacheEntry.score));
            cacheEntry.score = score;
            cacheEntry.cacheUntil = cacheUntil;
        }
        else {
            this.scoreCache.set(id, { score, cacheUntil });
        }
        return score;
    }
    /**
     * Apply a behavioural penalty to a peer
     */
    addPenalty(id, penalty, penaltyLabel) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            pstats.behaviourPenalty += penalty;
            this.metrics?.onScorePenalty(penaltyLabel);
        }
    }
    addPeer(id) {
        // create peer stats (not including topic stats for each topic to be scored)
        // topic stats will be added as needed
        const pstats = {
            connected: true,
            expire: 0,
            topics: {},
            knownIPs: new Set(),
            behaviourPenalty: 0
        };
        this.peerStats.set(id, pstats);
    }
    /** Adds a new IP to a peer, if the peer is not known the update is ignored */
    addIP(id, ip) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            pstats.knownIPs.add(ip);
        }
        this.peerIPs.getOrDefault(ip).add(id);
    }
    /** Remove peer association with IP */
    removeIP(id, ip) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            pstats.knownIPs.delete(ip);
        }
        const peersWithIP = this.peerIPs.get(ip);
        if (peersWithIP) {
            peersWithIP.delete(id);
            if (peersWithIP.size === 0) {
                this.peerIPs.delete(ip);
            }
        }
    }
    removePeer(id) {
        const pstats = this.peerStats.get(id);
        if (!pstats) {
            return;
        }
        // decide whether to retain the score; this currently only retains non-positive scores
        // to dissuade attacks on the score function.
        if (this.score(id) > 0) {
            this.removeIPsForPeer(id, pstats.knownIPs);
            this.peerStats.delete(id);
            return;
        }
        // furthermore, when we decide to retain the score, the firstMessageDelivery counters are
        // reset to 0 and mesh delivery penalties applied.
        Object.entries(pstats.topics).forEach(([topic, tstats]) => {
            tstats.firstMessageDeliveries = 0;
            const threshold = this.params.topics[topic].meshMessageDeliveriesThreshold;
            if (tstats.inMesh && tstats.meshMessageDeliveriesActive && tstats.meshMessageDeliveries < threshold) {
                const deficit = threshold - tstats.meshMessageDeliveries;
                tstats.meshFailurePenalty += deficit * deficit;
            }
            tstats.inMesh = false;
            tstats.meshMessageDeliveriesActive = false;
        });
        pstats.connected = false;
        pstats.expire = Date.now() + this.params.retainScore;
    }
    /** Handles scoring functionality as a peer GRAFTs to a topic. */
    graft(id, topic) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats) {
                // if we are scoring the topic, update the mesh status.
                tstats.inMesh = true;
                tstats.graftTime = Date.now();
                tstats.meshTime = 0;
                tstats.meshMessageDeliveriesActive = false;
            }
        }
    }
    /** Handles scoring functionality as a peer PRUNEs from a topic. */
    prune(id, topic) {
        const pstats = this.peerStats.get(id);
        if (pstats) {
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats) {
                // sticky mesh delivery rate failure penalty
                const threshold = this.params.topics[topic].meshMessageDeliveriesThreshold;
                if (tstats.meshMessageDeliveriesActive && tstats.meshMessageDeliveries < threshold) {
                    const deficit = threshold - tstats.meshMessageDeliveries;
                    tstats.meshFailurePenalty += deficit * deficit;
                }
                tstats.meshMessageDeliveriesActive = false;
                tstats.inMesh = false;
                // TODO: Consider clearing score cache on important penalties
                // this.scoreCache.delete(id)
            }
        }
    }
    validateMessage(msgIdStr) {
        this.deliveryRecords.ensureRecord(msgIdStr);
    }
    deliverMessage(from, msgIdStr, topic) {
        this.markFirstMessageDelivery(from, topic);
        const drec = this.deliveryRecords.ensureRecord(msgIdStr);
        const now = Date.now();
        // defensive check that this is the first delivery trace -- delivery status should be unknown
        if (drec.status !== DeliveryRecordStatus.unknown) {
            log$o('unexpected delivery: message from %s was first seen %s ago and has delivery status %s', from, now - drec.firstSeenTsMs, DeliveryRecordStatus[drec.status]);
            return;
        }
        // mark the message as valid and reward mesh peers that have already forwarded it to us
        drec.status = DeliveryRecordStatus.valid;
        drec.validated = now;
        drec.peers.forEach((p) => {
            // this check is to make sure a peer can't send us a message twice and get a double count
            // if it is a first delivery.
            if (p !== from.toString()) {
                this.markDuplicateMessageDelivery(p, topic);
            }
        });
    }
    /**
     * Similar to `rejectMessage` except does not require the message id or reason for an invalid message.
     */
    rejectInvalidMessage(from, topic) {
        this.markInvalidMessageDelivery(from, topic);
    }
    rejectMessage(from, msgIdStr, topic, reason) {
        switch (reason) {
            // these messages are not tracked, but the peer is penalized as they are invalid
            case RejectReason.Error:
                this.markInvalidMessageDelivery(from, topic);
                return;
            // we ignore those messages, so do nothing.
            case RejectReason.Blacklisted:
                return;
            // the rest are handled after record creation
        }
        const drec = this.deliveryRecords.ensureRecord(msgIdStr);
        // defensive check that this is the first rejection -- delivery status should be unknown
        if (drec.status !== DeliveryRecordStatus.unknown) {
            log$o('unexpected rejection: message from %s was first seen %s ago and has delivery status %d', from, Date.now() - drec.firstSeenTsMs, DeliveryRecordStatus[drec.status]);
            return;
        }
        if (reason === RejectReason.Ignore) {
            // we were explicitly instructed by the validator to ignore the message but not penalize the peer
            drec.status = DeliveryRecordStatus.ignored;
            drec.peers.clear();
            return;
        }
        // mark the message as invalid and penalize peers that have already forwarded it.
        drec.status = DeliveryRecordStatus.invalid;
        this.markInvalidMessageDelivery(from, topic);
        drec.peers.forEach((p) => {
            this.markInvalidMessageDelivery(p, topic);
        });
        // release the delivery time tracking map to free some memory early
        drec.peers.clear();
    }
    duplicateMessage(from, msgIdStr, topic) {
        const drec = this.deliveryRecords.ensureRecord(msgIdStr);
        if (drec.peers.has(from)) {
            // we have already seen this duplicate
            return;
        }
        switch (drec.status) {
            case DeliveryRecordStatus.unknown:
                // the message is being validated; track the peer delivery and wait for
                // the Deliver/Reject/Ignore notification.
                drec.peers.add(from);
                break;
            case DeliveryRecordStatus.valid:
                // mark the peer delivery time to only count a duplicate delivery once.
                drec.peers.add(from);
                this.markDuplicateMessageDelivery(from, topic, drec.validated);
                break;
            case DeliveryRecordStatus.invalid:
                // we no longer track delivery time
                this.markInvalidMessageDelivery(from, topic);
                break;
            case DeliveryRecordStatus.ignored:
                // the message was ignored; do nothing (we don't know if it was valid)
                break;
        }
    }
    /**
     * Increments the "invalid message deliveries" counter for all scored topics the message is published in.
     */
    markInvalidMessageDelivery(from, topic) {
        const pstats = this.peerStats.get(from);
        if (pstats) {
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats) {
                tstats.invalidMessageDeliveries += 1;
            }
        }
    }
    /**
     * Increments the "first message deliveries" counter for all scored topics the message is published in,
     * as well as the "mesh message deliveries" counter, if the peer is in the mesh for the topic.
     * Messages already known (with the seenCache) are counted with markDuplicateMessageDelivery()
     */
    markFirstMessageDelivery(from, topic) {
        const pstats = this.peerStats.get(from);
        if (pstats) {
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats) {
                let cap = this.params.topics[topic].firstMessageDeliveriesCap;
                tstats.firstMessageDeliveries = Math.min(cap, tstats.firstMessageDeliveries + 1);
                if (tstats.inMesh) {
                    cap = this.params.topics[topic].meshMessageDeliveriesCap;
                    tstats.meshMessageDeliveries = Math.min(cap, tstats.meshMessageDeliveries + 1);
                }
            }
        }
    }
    /**
     * Increments the "mesh message deliveries" counter for messages we've seen before,
     * as long the message was received within the P3 window.
     */
    markDuplicateMessageDelivery(from, topic, validatedTime) {
        const pstats = this.peerStats.get(from);
        if (pstats) {
            const now = validatedTime !== undefined ? Date.now() : 0;
            const tstats = this.getPtopicStats(pstats, topic);
            if (tstats && tstats.inMesh) {
                const tparams = this.params.topics[topic];
                // check against the mesh delivery window -- if the validated time is passed as 0, then
                // the message was received before we finished validation and thus falls within the mesh
                // delivery window.
                if (validatedTime !== undefined) {
                    const deliveryDelayMs = now - validatedTime;
                    const isLateDelivery = deliveryDelayMs > tparams.meshMessageDeliveriesWindow;
                    this.metrics?.onDuplicateMsgDelivery(topic, deliveryDelayMs, isLateDelivery);
                    if (isLateDelivery) {
                        return;
                    }
                }
                const cap = tparams.meshMessageDeliveriesCap;
                tstats.meshMessageDeliveries = Math.min(cap, tstats.meshMessageDeliveries + 1);
            }
        }
    }
    /**
     * Removes an IP list from the tracking list for a peer.
     */
    removeIPsForPeer(id, ipsToRemove) {
        for (const ipToRemove of ipsToRemove) {
            const peerSet = this.peerIPs.get(ipToRemove);
            if (peerSet) {
                peerSet.delete(id);
                if (peerSet.size === 0) {
                    this.peerIPs.delete(ipToRemove);
                }
            }
        }
    }
    /**
     * Returns topic stats if they exist, otherwise if the supplied parameters score the
     * topic, inserts the default stats and returns a reference to those. If neither apply, returns None.
     */
    getPtopicStats(pstats, topic) {
        let topicStats = pstats.topics[topic];
        if (topicStats !== undefined) {
            return topicStats;
        }
        if (this.params.topics[topic] !== undefined) {
            topicStats = {
                inMesh: false,
                graftTime: 0,
                meshTime: 0,
                firstMessageDeliveries: 0,
                meshMessageDeliveries: 0,
                meshMessageDeliveriesActive: false,
                meshFailurePenalty: 0,
                invalidMessageDeliveries: 0
            };
            pstats.topics[topic] = topicStats;
            return topicStats;
        }
        return null;
    }
}

/**
 * IWantTracer is an internal tracer that tracks IWANT requests in order to penalize
 * peers who don't follow up on IWANT requests after an IHAVE advertisement.
 * The tracking of promises is probabilistic to avoid using too much memory.
 *
 * Note: Do not confuse these 'promises' with JS Promise objects.
 * These 'promises' are merely expectations of a peer's behavior.
 */
class IWantTracer {
    gossipsubIWantFollowupMs;
    msgIdToStrFn;
    metrics;
    /**
     * Promises to deliver a message
     * Map per message id, per peer, promise expiration time
     */
    promises = new Map();
    /**
     * First request time by msgId. Used for metrics to track expire times.
     * Necessary to know if peers are actually breaking promises or simply sending them a bit later
     */
    requestMsByMsg = new Map();
    requestMsByMsgExpire;
    constructor(gossipsubIWantFollowupMs, msgIdToStrFn, metrics) {
        this.gossipsubIWantFollowupMs = gossipsubIWantFollowupMs;
        this.msgIdToStrFn = msgIdToStrFn;
        this.metrics = metrics;
        this.requestMsByMsgExpire = 10 * gossipsubIWantFollowupMs;
    }
    get size() {
        return this.promises.size;
    }
    get requestMsByMsgSize() {
        return this.requestMsByMsg.size;
    }
    /**
     * Track a promise to deliver a message from a list of msgIds we are requesting
     */
    addPromise(from, msgIds) {
        // pick msgId randomly from the list
        const ix = Math.floor(Math.random() * msgIds.length);
        const msgId = msgIds[ix];
        const msgIdStr = this.msgIdToStrFn(msgId);
        let expireByPeer = this.promises.get(msgIdStr);
        if (!expireByPeer) {
            expireByPeer = new Map();
            this.promises.set(msgIdStr, expireByPeer);
        }
        const now = Date.now();
        // If a promise for this message id and peer already exists we don't update the expiry
        if (!expireByPeer.has(from)) {
            expireByPeer.set(from, now + this.gossipsubIWantFollowupMs);
            if (this.metrics) {
                this.metrics.iwantPromiseStarted.inc(1);
                if (!this.requestMsByMsg.has(msgIdStr)) {
                    this.requestMsByMsg.set(msgIdStr, now);
                }
            }
        }
    }
    /**
     * Returns the number of broken promises for each peer who didn't follow up on an IWANT request.
     *
     * This should be called not too often relative to the expire times, since it iterates over the whole data.
     */
    getBrokenPromises() {
        const now = Date.now();
        const result = new Map();
        let brokenPromises = 0;
        this.promises.forEach((expireByPeer, msgId) => {
            expireByPeer.forEach((expire, p) => {
                // the promise has been broken
                if (expire < now) {
                    // add 1 to result
                    result.set(p, (result.get(p) ?? 0) + 1);
                    // delete from tracked promises
                    expireByPeer.delete(p);
                    // for metrics
                    brokenPromises++;
                }
            });
            // clean up empty promises for a msgId
            if (!expireByPeer.size) {
                this.promises.delete(msgId);
            }
        });
        this.metrics?.iwantPromiseBroken.inc(brokenPromises);
        return result;
    }
    /**
     * Someone delivered a message, stop tracking promises for it
     */
    deliverMessage(msgIdStr, isDuplicate = false) {
        this.trackMessage(msgIdStr);
        const expireByPeer = this.promises.get(msgIdStr);
        // Expired promise, check requestMsByMsg
        if (expireByPeer) {
            this.promises.delete(msgIdStr);
            if (this.metrics) {
                this.metrics.iwantPromiseResolved.inc(1);
                if (isDuplicate)
                    this.metrics.iwantPromiseResolvedFromDuplicate.inc(1);
                this.metrics.iwantPromiseResolvedPeers.inc(expireByPeer.size);
            }
        }
    }
    /**
     * A message got rejected, so we can stop tracking promises and let the score penalty apply from invalid message delivery,
     * unless its an obviously invalid message.
     */
    rejectMessage(msgIdStr, reason) {
        this.trackMessage(msgIdStr);
        // A message got rejected, so we can stop tracking promises and let the score penalty apply.
        // With the expection of obvious invalid messages
        switch (reason) {
            case RejectReason.Error:
                return;
        }
        this.promises.delete(msgIdStr);
    }
    clear() {
        this.promises.clear();
    }
    prune() {
        const maxMs = Date.now() - this.requestMsByMsgExpire;
        let count = 0;
        for (const [k, v] of this.requestMsByMsg.entries()) {
            if (v < maxMs) {
                // messages that stay too long in the requestMsByMsg map, delete
                this.requestMsByMsg.delete(k);
                count++;
            }
            else {
                // recent messages, keep them
                // sort by insertion order
                break;
            }
        }
        this.metrics?.iwantMessagePruned.inc(count);
    }
    trackMessage(msgIdStr) {
        if (this.metrics) {
            const requestMs = this.requestMsByMsg.get(msgIdStr);
            if (requestMs !== undefined) {
                this.metrics.iwantPromiseDeliveryTime.observe((Date.now() - requestMs) / 1000);
                this.requestMsByMsg.delete(msgIdStr);
            }
        }
    }
}

/**
 * This is similar to https://github.com/daviddias/time-cache/blob/master/src/index.js
 * for our own need, we don't use lodash throttle to improve performance.
 * This gives 4x - 5x performance gain compared to npm TimeCache
 */
class SimpleTimeCache {
    entries = new Map();
    validityMs;
    constructor(opts) {
        this.validityMs = opts.validityMs;
        // allow negative validityMs so that this does not cache anything, spec test compliance.spec.js
        // sends duplicate messages and expect peer to receive all. Application likely uses positive validityMs
    }
    get size() {
        return this.entries.size;
    }
    /** Returns true if there was a key collision and the entry is dropped */
    put(key, value) {
        if (this.entries.has(key)) {
            // Key collisions break insertion order in the entries cache, which break prune logic.
            // prune relies on each iterated entry to have strictly ascending validUntilMs, else it
            // won't prune expired entries and SimpleTimeCache will grow unexpectedly.
            // As of Oct 2022 NodeJS v16, inserting the same key twice with different value does not
            // change the key position in the iterator stream. A unit test asserts this behaviour.
            return true;
        }
        this.entries.set(key, { value, validUntilMs: Date.now() + this.validityMs });
        return false;
    }
    prune() {
        const now = Date.now();
        for (const [k, v] of this.entries.entries()) {
            if (v.validUntilMs < now) {
                this.entries.delete(k);
            }
            else {
                // Entries are inserted with strictly ascending validUntilMs.
                // Stop early to save iterations
                break;
            }
        }
    }
    has(key) {
        return this.entries.has(key);
    }
    get(key) {
        const value = this.entries.get(key);
        return value && value.validUntilMs >= Date.now() ? value.value : undefined;
    }
    clear() {
        this.entries.clear();
    }
}

var MessageSource;
(function (MessageSource) {
    MessageSource["forward"] = "forward";
    MessageSource["publish"] = "publish";
})(MessageSource || (MessageSource = {}));
var InclusionReason;
(function (InclusionReason) {
    /** Peer was a fanaout peer. */
    InclusionReason["Fanout"] = "fanout";
    /** Included from random selection. */
    InclusionReason["Random"] = "random";
    /** Peer subscribed. */
    InclusionReason["Subscribed"] = "subscribed";
    /** On heartbeat, peer was included to fill the outbound quota. */
    InclusionReason["Outbound"] = "outbound";
    /** On heartbeat, not enough peers in mesh */
    InclusionReason["NotEnough"] = "not_enough";
    /** On heartbeat opportunistic grafting due to low mesh score */
    InclusionReason["Opportunistic"] = "opportunistic";
})(InclusionReason || (InclusionReason = {}));
/// Reasons why a peer was removed from the mesh.
var ChurnReason;
(function (ChurnReason) {
    /// Peer disconnected.
    ChurnReason["Dc"] = "disconnected";
    /// Peer had a bad score.
    ChurnReason["BadScore"] = "bad_score";
    /// Peer sent a PRUNE.
    ChurnReason["Prune"] = "prune";
    /// Too many peers.
    ChurnReason["Excess"] = "excess";
})(ChurnReason || (ChurnReason = {}));
/// Kinds of reasons a peer's score has been penalized
var ScorePenalty;
(function (ScorePenalty) {
    /// A peer grafted before waiting the back-off time.
    ScorePenalty["GraftBackoff"] = "graft_backoff";
    /// A Peer did not respond to an IWANT request in time.
    ScorePenalty["BrokenPromise"] = "broken_promise";
    /// A Peer did not send enough messages as expected.
    ScorePenalty["MessageDeficit"] = "message_deficit";
    /// Too many peers under one IP address.
    ScorePenalty["IPColocation"] = "IP_colocation";
})(ScorePenalty || (ScorePenalty = {}));
var IHaveIgnoreReason;
(function (IHaveIgnoreReason) {
    IHaveIgnoreReason["LowScore"] = "low_score";
    IHaveIgnoreReason["MaxIhave"] = "max_ihave";
    IHaveIgnoreReason["MaxIasked"] = "max_iasked";
})(IHaveIgnoreReason || (IHaveIgnoreReason = {}));
var ScoreThreshold;
(function (ScoreThreshold) {
    ScoreThreshold["graylist"] = "graylist";
    ScoreThreshold["publish"] = "publish";
    ScoreThreshold["gossip"] = "gossip";
    ScoreThreshold["mesh"] = "mesh";
})(ScoreThreshold || (ScoreThreshold = {}));
/**
 * A collection of metrics used throughout the Gossipsub behaviour.
 * NOTE: except for special reasons, do not add more than 1 label for frequent metrics,
 * there's a performance penalty as of June 2023.
 */
// eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types
function getMetrics(register, topicStrToLabel, opts) {
    // Using function style instead of class to prevent having to re-declare all MetricsPrometheus types.
    return {
        /* Metrics for static config */
        protocolsEnabled: register.gauge({
            name: 'gossipsub_protocol',
            help: 'Status of enabled protocols',
            labelNames: ['protocol']
        }),
        /* Metrics per known topic */
        /** Status of our subscription to this topic. This metric allows analyzing other topic metrics
         *  filtered by our current subscription status.
         *  = rust-libp2p `topic_subscription_status` */
        topicSubscriptionStatus: register.gauge({
            name: 'gossipsub_topic_subscription_status',
            help: 'Status of our subscription to this topic',
            labelNames: ['topicStr']
        }),
        /** Number of peers subscribed to each topic. This allows us to analyze a topic's behaviour
         * regardless of our subscription status. */
        topicPeersCount: register.gauge({
            name: 'gossipsub_topic_peer_count',
            help: 'Number of peers subscribed to each topic',
            labelNames: ['topicStr']
        }),
        /* Metrics regarding mesh state */
        /** Number of peers in our mesh. This metric should be updated with the count of peers for a
         *  topic in the mesh regardless of inclusion and churn events.
         *  = rust-libp2p `mesh_peer_counts` */
        meshPeerCounts: register.gauge({
            name: 'gossipsub_mesh_peer_count',
            help: 'Number of peers in our mesh',
            labelNames: ['topicStr']
        }),
        /** Number of times we include peers in a topic mesh for different reasons.
         *  = rust-libp2p `mesh_peer_inclusion_events` */
        meshPeerInclusionEventsFanout: register.gauge({
            name: 'gossipsub_mesh_peer_inclusion_events_fanout_total',
            help: 'Number of times we include peers in a topic mesh for fanout reasons',
            labelNames: ['topic']
        }),
        meshPeerInclusionEventsRandom: register.gauge({
            name: 'gossipsub_mesh_peer_inclusion_events_random_total',
            help: 'Number of times we include peers in a topic mesh for random reasons',
            labelNames: ['topic']
        }),
        meshPeerInclusionEventsSubscribed: register.gauge({
            name: 'gossipsub_mesh_peer_inclusion_events_subscribed_total',
            help: 'Number of times we include peers in a topic mesh for subscribed reasons',
            labelNames: ['topic']
        }),
        meshPeerInclusionEventsOutbound: register.gauge({
            name: 'gossipsub_mesh_peer_inclusion_events_outbound_total',
            help: 'Number of times we include peers in a topic mesh for outbound reasons',
            labelNames: ['topic']
        }),
        meshPeerInclusionEventsNotEnough: register.gauge({
            name: 'gossipsub_mesh_peer_inclusion_events_not_enough_total',
            help: 'Number of times we include peers in a topic mesh for not_enough reasons',
            labelNames: ['topic']
        }),
        meshPeerInclusionEventsOpportunistic: register.gauge({
            name: 'gossipsub_mesh_peer_inclusion_events_opportunistic_total',
            help: 'Number of times we include peers in a topic mesh for opportunistic reasons',
            labelNames: ['topic']
        }),
        meshPeerInclusionEventsUnknown: register.gauge({
            name: 'gossipsub_mesh_peer_inclusion_events_unknown_total',
            help: 'Number of times we include peers in a topic mesh for unknown reasons',
            labelNames: ['topic']
        }),
        /** Number of times we remove peers in a topic mesh for different reasons.
         *  = rust-libp2p `mesh_peer_churn_events` */
        meshPeerChurnEventsDisconnected: register.gauge({
            name: 'gossipsub_peer_churn_events_disconnected_total',
            help: 'Number of times we remove peers in a topic mesh for disconnected reasons',
            labelNames: ['topic']
        }),
        meshPeerChurnEventsBadScore: register.gauge({
            name: 'gossipsub_peer_churn_events_bad_score_total',
            help: 'Number of times we remove peers in a topic mesh for bad_score reasons',
            labelNames: ['topic']
        }),
        meshPeerChurnEventsPrune: register.gauge({
            name: 'gossipsub_peer_churn_events_prune_total',
            help: 'Number of times we remove peers in a topic mesh for prune reasons',
            labelNames: ['topic']
        }),
        meshPeerChurnEventsExcess: register.gauge({
            name: 'gossipsub_peer_churn_events_excess_total',
            help: 'Number of times we remove peers in a topic mesh for excess reasons',
            labelNames: ['topic']
        }),
        meshPeerChurnEventsUnknown: register.gauge({
            name: 'gossipsub_peer_churn_events_unknown_total',
            help: 'Number of times we remove peers in a topic mesh for unknown reasons',
            labelNames: ['topic']
        }),
        /* General Metrics */
        /** Gossipsub supports floodsub, gossipsub v1.0 and gossipsub v1.1. Peers are classified based
         *  on which protocol they support. This metric keeps track of the number of peers that are
         *  connected of each type. */
        peersPerProtocol: register.gauge({
            name: 'gossipsub_peers_per_protocol_count',
            help: 'Peers connected for each topic',
            labelNames: ['protocol']
        }),
        /** The time it takes to complete one iteration of the heartbeat. */
        heartbeatDuration: register.histogram({
            name: 'gossipsub_heartbeat_duration_seconds',
            help: 'The time it takes to complete one iteration of the heartbeat',
            // Should take <10ms, over 1s it's a huge issue that needs debugging, since a heartbeat will be cancelled
            buckets: [0.01, 0.1, 1]
        }),
        /** Heartbeat run took longer than heartbeat interval so next is skipped */
        heartbeatSkipped: register.gauge({
            name: 'gossipsub_heartbeat_skipped',
            help: 'Heartbeat run took longer than heartbeat interval so next is skipped'
        }),
        /** Message validation results for each topic.
         *  Invalid == Reject?
         *  = rust-libp2p `invalid_messages`, `accepted_messages`, `ignored_messages`, `rejected_messages` */
        acceptedMessagesTotal: register.gauge({
            name: 'gossipsub_accepted_messages_total',
            help: 'Total accepted messages for each topic',
            labelNames: ['topic']
        }),
        ignoredMessagesTotal: register.gauge({
            name: 'gossipsub_ignored_messages_total',
            help: 'Total ignored messages for each topic',
            labelNames: ['topic']
        }),
        rejectedMessagesTotal: register.gauge({
            name: 'gossipsub_rejected_messages_total',
            help: 'Total rejected messages for each topic',
            labelNames: ['topic']
        }),
        unknownValidationResultsTotal: register.gauge({
            name: 'gossipsub_unknown_validation_results_total',
            help: 'Total unknown validation results for each topic',
            labelNames: ['topic']
        }),
        /** When the user validates a message, it tries to re propagate it to its mesh peers. If the
         *  message expires from the memcache before it can be validated, we count this a cache miss
         *  and it is an indicator that the memcache size should be increased.
         *  = rust-libp2p `mcache_misses` */
        asyncValidationMcacheHit: register.gauge({
            name: 'gossipsub_async_validation_mcache_hit_total',
            help: 'Async validation result reported by the user layer',
            labelNames: ['hit']
        }),
        asyncValidationDelayFromFirstSeenSec: register.histogram({
            name: 'gossipsub_async_validation_delay_from_first_seen',
            help: 'Async validation report delay from first seen in second',
            labelNames: ['topic'],
            buckets: [0.01, 0.03, 0.1, 0.3, 1, 3, 10]
        }),
        asyncValidationUnknownFirstSeen: register.gauge({
            name: 'gossipsub_async_validation_unknown_first_seen_count_total',
            help: 'Async validation report unknown first seen value for message'
        }),
        // peer stream
        peerReadStreamError: register.gauge({
            name: 'gossipsub_peer_read_stream_err_count_total',
            help: 'Peer read stream error'
        }),
        // RPC outgoing. Track byte length + data structure sizes
        rpcRecvBytes: register.gauge({ name: 'gossipsub_rpc_recv_bytes_total', help: 'RPC recv' }),
        rpcRecvCount: register.gauge({ name: 'gossipsub_rpc_recv_count_total', help: 'RPC recv' }),
        rpcRecvSubscription: register.gauge({ name: 'gossipsub_rpc_recv_subscription_total', help: 'RPC recv' }),
        rpcRecvMessage: register.gauge({ name: 'gossipsub_rpc_recv_message_total', help: 'RPC recv' }),
        rpcRecvControl: register.gauge({ name: 'gossipsub_rpc_recv_control_total', help: 'RPC recv' }),
        rpcRecvIHave: register.gauge({ name: 'gossipsub_rpc_recv_ihave_total', help: 'RPC recv' }),
        rpcRecvIWant: register.gauge({ name: 'gossipsub_rpc_recv_iwant_total', help: 'RPC recv' }),
        rpcRecvGraft: register.gauge({ name: 'gossipsub_rpc_recv_graft_total', help: 'RPC recv' }),
        rpcRecvPrune: register.gauge({ name: 'gossipsub_rpc_recv_prune_total', help: 'RPC recv' }),
        rpcDataError: register.gauge({ name: 'gossipsub_rpc_data_err_count_total', help: 'RPC data error' }),
        rpcRecvError: register.gauge({ name: 'gossipsub_rpc_recv_err_count_total', help: 'RPC recv error' }),
        /** Total count of RPC dropped because acceptFrom() == false */
        rpcRecvNotAccepted: register.gauge({
            name: 'gossipsub_rpc_rcv_not_accepted_total',
            help: 'Total count of RPC dropped because acceptFrom() == false'
        }),
        // RPC incoming. Track byte length + data structure sizes
        rpcSentBytes: register.gauge({ name: 'gossipsub_rpc_sent_bytes_total', help: 'RPC sent' }),
        rpcSentCount: register.gauge({ name: 'gossipsub_rpc_sent_count_total', help: 'RPC sent' }),
        rpcSentSubscription: register.gauge({ name: 'gossipsub_rpc_sent_subscription_total', help: 'RPC sent' }),
        rpcSentMessage: register.gauge({ name: 'gossipsub_rpc_sent_message_total', help: 'RPC sent' }),
        rpcSentControl: register.gauge({ name: 'gossipsub_rpc_sent_control_total', help: 'RPC sent' }),
        rpcSentIHave: register.gauge({ name: 'gossipsub_rpc_sent_ihave_total', help: 'RPC sent' }),
        rpcSentIWant: register.gauge({ name: 'gossipsub_rpc_sent_iwant_total', help: 'RPC sent' }),
        rpcSentGraft: register.gauge({ name: 'gossipsub_rpc_sent_graft_total', help: 'RPC sent' }),
        rpcSentPrune: register.gauge({ name: 'gossipsub_rpc_sent_prune_total', help: 'RPC sent' }),
        // publish message. Track peers sent to and bytes
        /** Total count of msg published by topic */
        msgPublishCount: register.gauge({
            name: 'gossipsub_msg_publish_count_total',
            help: 'Total count of msg published by topic',
            labelNames: ['topic']
        }),
        /** Total count of peers that we publish a msg to */
        msgPublishPeersByTopic: register.gauge({
            name: 'gossipsub_msg_publish_peers_total',
            help: 'Total count of peers that we publish a msg to',
            labelNames: ['topic']
        }),
        /** Total count of peers (by group) that we publish a msg to */
        directPeersPublishedTotal: register.gauge({
            name: 'gossipsub_direct_peers_published_total',
            help: 'Total direct peers that we publish a msg to',
            labelNames: ['topic']
        }),
        floodsubPeersPublishedTotal: register.gauge({
            name: 'gossipsub_floodsub_peers_published_total',
            help: 'Total floodsub peers that we publish a msg to',
            labelNames: ['topic']
        }),
        meshPeersPublishedTotal: register.gauge({
            name: 'gossipsub_mesh_peers_published_total',
            help: 'Total mesh peers that we publish a msg to',
            labelNames: ['topic']
        }),
        fanoutPeersPublishedTotal: register.gauge({
            name: 'gossipsub_fanout_peers_published_total',
            help: 'Total fanout peers that we publish a msg to',
            labelNames: ['topic']
        }),
        /** Total count of msg publish data.length bytes */
        msgPublishBytes: register.gauge({
            name: 'gossipsub_msg_publish_bytes_total',
            help: 'Total count of msg publish data.length bytes',
            labelNames: ['topic']
        }),
        /** Total time in seconds to publish a message */
        msgPublishTime: register.histogram({
            name: 'gossipsub_msg_publish_seconds',
            help: 'Total time in seconds to publish a message',
            buckets: [0.001, 0.002, 0.005, 0.01, 0.1, 0.5, 1],
            labelNames: ['topic']
        }),
        /** Total count of msg forwarded by topic */
        msgForwardCount: register.gauge({
            name: 'gossipsub_msg_forward_count_total',
            help: 'Total count of msg forwarded by topic',
            labelNames: ['topic']
        }),
        /** Total count of peers that we forward a msg to */
        msgForwardPeers: register.gauge({
            name: 'gossipsub_msg_forward_peers_total',
            help: 'Total count of peers that we forward a msg to',
            labelNames: ['topic']
        }),
        /** Total count of recv msgs before any validation */
        msgReceivedPreValidation: register.gauge({
            name: 'gossipsub_msg_received_prevalidation_total',
            help: 'Total count of recv msgs before any validation',
            labelNames: ['topic']
        }),
        /** Total count of recv msgs error */
        msgReceivedError: register.gauge({
            name: 'gossipsub_msg_received_error_total',
            help: 'Total count of recv msgs error',
            labelNames: ['topic']
        }),
        /** Tracks distribution of recv msgs by duplicate, invalid, valid */
        prevalidationInvalidTotal: register.gauge({
            name: 'gossipsub_pre_validation_invalid_total',
            help: 'Total count of invalid messages received',
            labelNames: ['topic']
        }),
        prevalidationValidTotal: register.gauge({
            name: 'gossipsub_pre_validation_valid_total',
            help: 'Total count of valid messages received',
            labelNames: ['topic']
        }),
        prevalidationDuplicateTotal: register.gauge({
            name: 'gossipsub_pre_validation_duplicate_total',
            help: 'Total count of duplicate messages received',
            labelNames: ['topic']
        }),
        prevalidationUnknownTotal: register.gauge({
            name: 'gossipsub_pre_validation_unknown_status_total',
            help: 'Total count of unknown_status messages received',
            labelNames: ['topic']
        }),
        /** Tracks specific reason of invalid */
        msgReceivedInvalid: register.gauge({
            name: 'gossipsub_msg_received_invalid_total',
            help: 'Tracks specific reason of invalid',
            labelNames: ['error']
        }),
        msgReceivedInvalidByTopic: register.gauge({
            name: 'gossipsub_msg_received_invalid_by_topic_total',
            help: 'Tracks specific invalid message by topic',
            labelNames: ['topic']
        }),
        /** Track duplicate message delivery time */
        duplicateMsgDeliveryDelay: register.histogram({
            name: 'gossisub_duplicate_msg_delivery_delay_seconds',
            help: 'Time since the 1st duplicated message validated',
            labelNames: ['topic'],
            buckets: [
                0.25 * opts.maxMeshMessageDeliveriesWindowSec,
                0.5 * opts.maxMeshMessageDeliveriesWindowSec,
                1 * opts.maxMeshMessageDeliveriesWindowSec,
                2 * opts.maxMeshMessageDeliveriesWindowSec,
                4 * opts.maxMeshMessageDeliveriesWindowSec
            ]
        }),
        /** Total count of late msg delivery total by topic */
        duplicateMsgLateDelivery: register.gauge({
            name: 'gossisub_duplicate_msg_late_delivery_total',
            help: 'Total count of late duplicate message delivery by topic, which triggers P3 penalty',
            labelNames: ['topic']
        }),
        duplicateMsgIgnored: register.gauge({
            name: 'gossisub_ignored_published_duplicate_msgs_total',
            help: 'Total count of published duplicate message ignored by topic',
            labelNames: ['topic']
        }),
        /* Metrics related to scoring */
        /** Total times score() is called */
        scoreFnCalls: register.gauge({
            name: 'gossipsub_score_fn_calls_total',
            help: 'Total times score() is called'
        }),
        /** Total times score() call actually computed computeScore(), no cache */
        scoreFnRuns: register.gauge({
            name: 'gossipsub_score_fn_runs_total',
            help: 'Total times score() call actually computed computeScore(), no cache'
        }),
        scoreCachedDelta: register.histogram({
            name: 'gossipsub_score_cache_delta',
            help: 'Delta of score between cached values that expired',
            buckets: [10, 100, 1000]
        }),
        /** Current count of peers by score threshold */
        peersByScoreThreshold: register.gauge({
            name: 'gossipsub_peers_by_score_threshold_count',
            help: 'Current count of peers by score threshold',
            labelNames: ['threshold']
        }),
        score: register.avgMinMax({
            name: 'gossipsub_score',
            help: 'Avg min max of gossip scores'
        }),
        /**
         * Separate score weights
         * Need to use 2-label metrics in this case to debug the score weights
         **/
        scoreWeights: register.avgMinMax({
            name: 'gossipsub_score_weights',
            help: 'Separate score weights',
            labelNames: ['topic', 'p']
        }),
        /** Histogram of the scores for each mesh topic. */
        // TODO: Not implemented
        scorePerMesh: register.avgMinMax({
            name: 'gossipsub_score_per_mesh',
            help: 'Histogram of the scores for each mesh topic',
            labelNames: ['topic']
        }),
        /** A counter of the kind of penalties being applied to peers. */
        // TODO: Not fully implemented
        scoringPenalties: register.gauge({
            name: 'gossipsub_scoring_penalties_total',
            help: 'A counter of the kind of penalties being applied to peers',
            labelNames: ['penalty']
        }),
        behaviourPenalty: register.histogram({
            name: 'gossipsub_peer_stat_behaviour_penalty',
            help: 'Current peer stat behaviour_penalty at each scrape',
            buckets: [
                0.25 * opts.behaviourPenaltyThreshold,
                0.5 * opts.behaviourPenaltyThreshold,
                1 * opts.behaviourPenaltyThreshold,
                2 * opts.behaviourPenaltyThreshold,
                4 * opts.behaviourPenaltyThreshold
            ]
        }),
        // TODO:
        // - iasked per peer (on heartbeat)
        // - when promise is resolved, track messages from promises
        /** Total received IHAVE messages that we ignore for some reason */
        ihaveRcvIgnored: register.gauge({
            name: 'gossipsub_ihave_rcv_ignored_total',
            help: 'Total received IHAVE messages that we ignore for some reason',
            labelNames: ['reason']
        }),
        /** Total received IHAVE messages by topic */
        ihaveRcvMsgids: register.gauge({
            name: 'gossipsub_ihave_rcv_msgids_total',
            help: 'Total received IHAVE messages by topic',
            labelNames: ['topic']
        }),
        /** Total messages per topic we don't have. Not actual requests.
         *  The number of times we have decided that an IWANT control message is required for this
         *  topic. A very high metric might indicate an underperforming network.
         *  = rust-libp2p `topic_iwant_msgs` */
        ihaveRcvNotSeenMsgids: register.gauge({
            name: 'gossipsub_ihave_rcv_not_seen_msgids_total',
            help: 'Total messages per topic we do not have, not actual requests',
            labelNames: ['topic']
        }),
        /** Total received IWANT messages by topic */
        iwantRcvMsgids: register.gauge({
            name: 'gossipsub_iwant_rcv_msgids_total',
            help: 'Total received IWANT messages by topic',
            labelNames: ['topic']
        }),
        /** Total requested messageIDs that we don't have */
        iwantRcvDonthaveMsgids: register.gauge({
            name: 'gossipsub_iwant_rcv_dont_have_msgids_total',
            help: 'Total requested messageIDs that we do not have'
        }),
        iwantPromiseStarted: register.gauge({
            name: 'gossipsub_iwant_promise_sent_total',
            help: 'Total count of started IWANT promises'
        }),
        /** Total count of resolved IWANT promises */
        iwantPromiseResolved: register.gauge({
            name: 'gossipsub_iwant_promise_resolved_total',
            help: 'Total count of resolved IWANT promises'
        }),
        /** Total count of resolved IWANT promises from duplicate messages */
        iwantPromiseResolvedFromDuplicate: register.gauge({
            name: 'gossipsub_iwant_promise_resolved_from_duplicate_total',
            help: 'Total count of resolved IWANT promises from duplicate messages'
        }),
        /** Total count of peers we have asked IWANT promises that are resolved */
        iwantPromiseResolvedPeers: register.gauge({
            name: 'gossipsub_iwant_promise_resolved_peers',
            help: 'Total count of peers we have asked IWANT promises that are resolved'
        }),
        iwantPromiseBroken: register.gauge({
            name: 'gossipsub_iwant_promise_broken',
            help: 'Total count of broken IWANT promises'
        }),
        iwantMessagePruned: register.gauge({
            name: 'gossipsub_iwant_message_pruned',
            help: 'Total count of pruned IWANT messages'
        }),
        /** Histogram of delivery time of resolved IWANT promises */
        iwantPromiseDeliveryTime: register.histogram({
            name: 'gossipsub_iwant_promise_delivery_seconds',
            help: 'Histogram of delivery time of resolved IWANT promises',
            buckets: [
                0.5 * opts.gossipPromiseExpireSec,
                1 * opts.gossipPromiseExpireSec,
                2 * opts.gossipPromiseExpireSec,
                4 * opts.gossipPromiseExpireSec
            ]
        }),
        iwantPromiseUntracked: register.gauge({
            name: 'gossip_iwant_promise_untracked',
            help: 'Total count of untracked IWANT promise'
        }),
        /** Backoff time */
        connectedPeersBackoffSec: register.histogram({
            name: 'gossipsub_connected_peers_backoff_seconds',
            help: 'Backoff time in seconds',
            // Using 1 seconds as minimum as that's close to the heartbeat duration, no need for more resolution.
            // As per spec, backoff times are 10 seconds for UnsubscribeBackoff and 60 seconds for PruneBackoff.
            // Higher values of 60 seconds should not occur, but we add 120 seconds just in case
            // https://github.com/libp2p/specs/blob/master/pubsub/gossipsub/gossipsub-v1.1.md#overview-of-new-parameters
            buckets: [1, 2, 4, 10, 20, 60, 120]
        }),
        /* Data structure sizes */
        /** Unbounded cache sizes */
        cacheSize: register.gauge({
            name: 'gossipsub_cache_size',
            help: 'Unbounded cache sizes',
            labelNames: ['cache']
        }),
        /** Current mcache msg count */
        mcacheSize: register.gauge({
            name: 'gossipsub_mcache_size',
            help: 'Current mcache msg count'
        }),
        mcacheNotValidatedCount: register.gauge({
            name: 'gossipsub_mcache_not_validated_count',
            help: 'Current mcache msg count not validated'
        }),
        fastMsgIdCacheCollision: register.gauge({
            name: 'gossipsub_fastmsgid_cache_collision_total',
            help: 'Total count of key collisions on fastmsgid cache put'
        }),
        newConnectionCount: register.gauge({
            name: 'gossipsub_new_connection_total',
            help: 'Total new connection by status',
            labelNames: ['status']
        }),
        topicStrToLabel: topicStrToLabel,
        toTopic(topicStr) {
            return this.topicStrToLabel.get(topicStr) ?? topicStr;
        },
        /** We joined a topic */
        onJoin(topicStr) {
            this.topicSubscriptionStatus.set({ topicStr }, 1);
            this.meshPeerCounts.set({ topicStr }, 0); // Reset count
        },
        /** We left a topic */
        onLeave(topicStr) {
            this.topicSubscriptionStatus.set({ topicStr }, 0);
            this.meshPeerCounts.set({ topicStr }, 0); // Reset count
        },
        /** Register the inclusion of peers in our mesh due to some reason. */
        onAddToMesh(topicStr, reason, count) {
            const topic = this.toTopic(topicStr);
            switch (reason) {
                case InclusionReason.Fanout:
                    this.meshPeerInclusionEventsFanout.inc({ topic }, count);
                    break;
                case InclusionReason.Random:
                    this.meshPeerInclusionEventsRandom.inc({ topic }, count);
                    break;
                case InclusionReason.Subscribed:
                    this.meshPeerInclusionEventsSubscribed.inc({ topic }, count);
                    break;
                case InclusionReason.Outbound:
                    this.meshPeerInclusionEventsOutbound.inc({ topic }, count);
                    break;
                case InclusionReason.NotEnough:
                    this.meshPeerInclusionEventsNotEnough.inc({ topic }, count);
                    break;
                case InclusionReason.Opportunistic:
                    this.meshPeerInclusionEventsOpportunistic.inc({ topic }, count);
                    break;
                default:
                    this.meshPeerInclusionEventsUnknown.inc({ topic }, count);
                    break;
            }
        },
        /** Register the removal of peers in our mesh due to some reason */
        // - remove_peer_from_mesh()
        // - heartbeat() Churn::BadScore
        // - heartbeat() Churn::Excess
        // - on_disconnect() Churn::Ds
        onRemoveFromMesh(topicStr, reason, count) {
            const topic = this.toTopic(topicStr);
            switch (reason) {
                case ChurnReason.Dc:
                    this.meshPeerChurnEventsDisconnected.inc({ topic }, count);
                    break;
                case ChurnReason.BadScore:
                    this.meshPeerChurnEventsBadScore.inc({ topic }, count);
                    break;
                case ChurnReason.Prune:
                    this.meshPeerChurnEventsPrune.inc({ topic }, count);
                    break;
                case ChurnReason.Excess:
                    this.meshPeerChurnEventsExcess.inc({ topic }, count);
                    break;
                default:
                    this.meshPeerChurnEventsUnknown.inc({ topic }, count);
                    break;
            }
        },
        /**
         * Update validation result to metrics
         * @param messageRecord null means the message's mcache record was not known at the time of acceptance report
         */
        onReportValidation(messageRecord, acceptance, firstSeenTimestampMs) {
            this.asyncValidationMcacheHit.inc({ hit: messageRecord != null ? 'hit' : 'miss' });
            if (messageRecord != null) {
                const topic = this.toTopic(messageRecord.message.topic);
                switch (acceptance) {
                    case TopicValidatorResult.Accept:
                        this.acceptedMessagesTotal.inc({ topic });
                        break;
                    case TopicValidatorResult.Ignore:
                        this.ignoredMessagesTotal.inc({ topic });
                        break;
                    case TopicValidatorResult.Reject:
                        this.rejectedMessagesTotal.inc({ topic });
                        break;
                    default:
                        this.unknownValidationResultsTotal.inc({ topic });
                        break;
                }
            }
            if (firstSeenTimestampMs != null) {
                this.asyncValidationDelayFromFirstSeenSec.observe((Date.now() - firstSeenTimestampMs) / 1000);
            }
            else {
                this.asyncValidationUnknownFirstSeen.inc();
            }
        },
        /**
         * - in handle_graft() Penalty::GraftBackoff
         * - in apply_iwant_penalties() Penalty::BrokenPromise
         * - in metric_score() P3 Penalty::MessageDeficit
         * - in metric_score() P6 Penalty::IPColocation
         */
        onScorePenalty(penalty) {
            // Can this be labeled by topic too?
            this.scoringPenalties.inc({ penalty }, 1);
        },
        onIhaveRcv(topicStr, ihave, idonthave) {
            const topic = this.toTopic(topicStr);
            this.ihaveRcvMsgids.inc({ topic }, ihave);
            this.ihaveRcvNotSeenMsgids.inc({ topic }, idonthave);
        },
        onIwantRcv(iwantByTopic, iwantDonthave) {
            for (const [topicStr, iwant] of iwantByTopic) {
                const topic = this.toTopic(topicStr);
                this.iwantRcvMsgids.inc({ topic }, iwant);
            }
            this.iwantRcvDonthaveMsgids.inc(iwantDonthave);
        },
        onForwardMsg(topicStr, tosendCount) {
            const topic = this.toTopic(topicStr);
            this.msgForwardCount.inc({ topic }, 1);
            this.msgForwardPeers.inc({ topic }, tosendCount);
        },
        onPublishMsg(topicStr, tosendGroupCount, tosendCount, dataLen, ms) {
            const topic = this.toTopic(topicStr);
            this.msgPublishCount.inc({ topic }, 1);
            this.msgPublishBytes.inc({ topic }, tosendCount * dataLen);
            this.msgPublishPeersByTopic.inc({ topic }, tosendCount);
            this.directPeersPublishedTotal.inc({ topic }, tosendGroupCount.direct);
            this.floodsubPeersPublishedTotal.inc({ topic }, tosendGroupCount.floodsub);
            this.meshPeersPublishedTotal.inc({ topic }, tosendGroupCount.mesh);
            this.fanoutPeersPublishedTotal.inc({ topic }, tosendGroupCount.fanout);
            this.msgPublishTime.observe({ topic }, ms / 1000);
        },
        onMsgRecvPreValidation(topicStr) {
            const topic = this.toTopic(topicStr);
            this.msgReceivedPreValidation.inc({ topic }, 1);
        },
        onMsgRecvError(topicStr) {
            const topic = this.toTopic(topicStr);
            this.msgReceivedError.inc({ topic }, 1);
        },
        onPrevalidationResult(topicStr, status) {
            const topic = this.toTopic(topicStr);
            switch (status) {
                case MessageStatus.duplicate:
                    this.prevalidationDuplicateTotal.inc({ topic });
                    break;
                case MessageStatus.invalid:
                    this.prevalidationInvalidTotal.inc({ topic });
                    break;
                case MessageStatus.valid:
                    this.prevalidationValidTotal.inc({ topic });
                    break;
                default:
                    this.prevalidationUnknownTotal.inc({ topic });
                    break;
            }
        },
        onMsgRecvInvalid(topicStr, reason) {
            const topic = this.toTopic(topicStr);
            const error = reason.reason === RejectReason.Error ? reason.error : reason.reason;
            this.msgReceivedInvalid.inc({ error }, 1);
            this.msgReceivedInvalidByTopic.inc({ topic }, 1);
        },
        onDuplicateMsgDelivery(topicStr, deliveryDelayMs, isLateDelivery) {
            this.duplicateMsgDeliveryDelay.observe(deliveryDelayMs / 1000);
            if (isLateDelivery) {
                const topic = this.toTopic(topicStr);
                this.duplicateMsgLateDelivery.inc({ topic }, 1);
            }
        },
        onPublishDuplicateMsg(topicStr) {
            const topic = this.toTopic(topicStr);
            this.duplicateMsgIgnored.inc({ topic }, 1);
        },
        onPeerReadStreamError() {
            this.peerReadStreamError.inc(1);
        },
        onRpcRecvError() {
            this.rpcRecvError.inc(1);
        },
        onRpcDataError() {
            this.rpcDataError.inc(1);
        },
        onRpcRecv(rpc, rpcBytes) {
            this.rpcRecvBytes.inc(rpcBytes);
            this.rpcRecvCount.inc(1);
            if (rpc.subscriptions)
                this.rpcRecvSubscription.inc(rpc.subscriptions.length);
            if (rpc.messages)
                this.rpcRecvMessage.inc(rpc.messages.length);
            if (rpc.control) {
                this.rpcRecvControl.inc(1);
                if (rpc.control.ihave)
                    this.rpcRecvIHave.inc(rpc.control.ihave.length);
                if (rpc.control.iwant)
                    this.rpcRecvIWant.inc(rpc.control.iwant.length);
                if (rpc.control.graft)
                    this.rpcRecvGraft.inc(rpc.control.graft.length);
                if (rpc.control.prune)
                    this.rpcRecvPrune.inc(rpc.control.prune.length);
            }
        },
        onRpcSent(rpc, rpcBytes) {
            this.rpcSentBytes.inc(rpcBytes);
            this.rpcSentCount.inc(1);
            if (rpc.subscriptions)
                this.rpcSentSubscription.inc(rpc.subscriptions.length);
            if (rpc.messages)
                this.rpcSentMessage.inc(rpc.messages.length);
            if (rpc.control) {
                const ihave = rpc.control.ihave?.length ?? 0;
                const iwant = rpc.control.iwant?.length ?? 0;
                const graft = rpc.control.graft?.length ?? 0;
                const prune = rpc.control.prune?.length ?? 0;
                if (ihave > 0)
                    this.rpcSentIHave.inc(ihave);
                if (iwant > 0)
                    this.rpcSentIWant.inc(iwant);
                if (graft > 0)
                    this.rpcSentGraft.inc(graft);
                if (prune > 0)
                    this.rpcSentPrune.inc(prune);
                if (ihave > 0 || iwant > 0 || graft > 0 || prune > 0)
                    this.rpcSentControl.inc(1);
            }
        },
        registerScores(scores, scoreThresholds) {
            let graylist = 0;
            let publish = 0;
            let gossip = 0;
            let mesh = 0;
            for (const score of scores) {
                if (score >= scoreThresholds.graylistThreshold)
                    graylist++;
                if (score >= scoreThresholds.publishThreshold)
                    publish++;
                if (score >= scoreThresholds.gossipThreshold)
                    gossip++;
                if (score >= 0)
                    mesh++;
            }
            this.peersByScoreThreshold.set({ threshold: ScoreThreshold.graylist }, graylist);
            this.peersByScoreThreshold.set({ threshold: ScoreThreshold.publish }, publish);
            this.peersByScoreThreshold.set({ threshold: ScoreThreshold.gossip }, gossip);
            this.peersByScoreThreshold.set({ threshold: ScoreThreshold.mesh }, mesh);
            // Register full score too
            this.score.set(scores);
        },
        registerScoreWeights(sw) {
            for (const [topic, wsTopic] of sw.byTopic) {
                this.scoreWeights.set({ topic, p: 'p1' }, wsTopic.p1w);
                this.scoreWeights.set({ topic, p: 'p2' }, wsTopic.p2w);
                this.scoreWeights.set({ topic, p: 'p3' }, wsTopic.p3w);
                this.scoreWeights.set({ topic, p: 'p3b' }, wsTopic.p3bw);
                this.scoreWeights.set({ topic, p: 'p4' }, wsTopic.p4w);
            }
            this.scoreWeights.set({ p: 'p5' }, sw.p5w);
            this.scoreWeights.set({ p: 'p6' }, sw.p6w);
            this.scoreWeights.set({ p: 'p7' }, sw.p7w);
        },
        registerScorePerMesh(mesh, scoreByPeer) {
            const peersPerTopicLabel = new Map();
            mesh.forEach((peers, topicStr) => {
                // Aggregate by known topicLabel or throw to 'unknown'. This prevent too high cardinality
                const topicLabel = this.topicStrToLabel.get(topicStr) ?? 'unknown';
                let peersInMesh = peersPerTopicLabel.get(topicLabel);
                if (!peersInMesh) {
                    peersInMesh = new Set();
                    peersPerTopicLabel.set(topicLabel, peersInMesh);
                }
                peers.forEach((p) => peersInMesh?.add(p));
            });
            for (const [topic, peers] of peersPerTopicLabel) {
                const meshScores = [];
                peers.forEach((peer) => {
                    meshScores.push(scoreByPeer.get(peer) ?? 0);
                });
                this.scorePerMesh.set({ topic }, meshScores);
            }
        }
    };
}

const SignPrefix = fromString$3('libp2p-pubsub:');
async function buildRawMessage(publishConfig, topic, originalData, transformedData) {
    switch (publishConfig.type) {
        case PublishConfigType.Signing: {
            const rpcMsg = {
                from: publishConfig.author.toBytes(),
                data: transformedData,
                seqno: randomBytes$4(8),
                topic,
                signature: undefined,
                key: undefined // Exclude key field for signing
            };
            // Get the message in bytes, and prepend with the pubsub prefix
            // the signature is over the bytes "libp2p-pubsub:<protobuf-message>"
            const bytes = concat$1([SignPrefix, RPC.Message.encode(rpcMsg).finish()]);
            rpcMsg.signature = await publishConfig.privateKey.sign(bytes);
            rpcMsg.key = publishConfig.key;
            const msg = {
                type: 'signed',
                from: publishConfig.author,
                data: originalData,
                sequenceNumber: BigInt(`0x${toString$9(rpcMsg.seqno, 'base16')}`),
                topic,
                signature: rpcMsg.signature,
                key: rpcMsg.key
            };
            return {
                raw: rpcMsg,
                msg: msg
            };
        }
        case PublishConfigType.Anonymous: {
            return {
                raw: {
                    from: undefined,
                    data: transformedData,
                    seqno: undefined,
                    topic,
                    signature: undefined,
                    key: undefined
                },
                msg: {
                    type: 'unsigned',
                    data: originalData,
                    topic
                }
            };
        }
    }
}
async function validateToRawMessage(signaturePolicy, msg) {
    // If strict-sign, verify all
    // If anonymous (no-sign), ensure no preven
    switch (signaturePolicy) {
        case StrictNoSign:
            if (msg.signature != null)
                return { valid: false, error: ValidateError.SignaturePresent };
            if (msg.seqno != null)
                return { valid: false, error: ValidateError.SeqnoPresent };
            if (msg.key != null)
                return { valid: false, error: ValidateError.FromPresent };
            return { valid: true, message: { type: 'unsigned', topic: msg.topic, data: msg.data ?? new Uint8Array(0) } };
        case StrictSign: {
            // Verify seqno
            if (msg.seqno == null)
                return { valid: false, error: ValidateError.InvalidSeqno };
            if (msg.seqno.length !== 8) {
                return { valid: false, error: ValidateError.InvalidSeqno };
            }
            if (msg.signature == null)
                return { valid: false, error: ValidateError.InvalidSignature };
            if (msg.from == null)
                return { valid: false, error: ValidateError.InvalidPeerId };
            let fromPeerId;
            try {
                // TODO: Fix PeerId types
                fromPeerId = peerIdFromBytes(msg.from);
            }
            catch (e) {
                return { valid: false, error: ValidateError.InvalidPeerId };
            }
            // - check from defined
            // - transform source to PeerId
            // - parse signature
            // - get .key, else from source
            // - check key == source if present
            // - verify sig
            let publicKey;
            if (msg.key) {
                publicKey = unmarshalPublicKey$2(msg.key);
                // TODO: Should `fromPeerId.pubKey` be optional?
                if (fromPeerId.publicKey !== undefined && !equals$4(publicKey.bytes, fromPeerId.publicKey)) {
                    return { valid: false, error: ValidateError.InvalidPeerId };
                }
            }
            else {
                if (fromPeerId.publicKey == null) {
                    return { valid: false, error: ValidateError.InvalidPeerId };
                }
                publicKey = unmarshalPublicKey$2(fromPeerId.publicKey);
            }
            const rpcMsgPreSign = {
                from: msg.from,
                data: msg.data,
                seqno: msg.seqno,
                topic: msg.topic,
                signature: undefined,
                key: undefined // Exclude key field for signing
            };
            // Get the message in bytes, and prepend with the pubsub prefix
            // the signature is over the bytes "libp2p-pubsub:<protobuf-message>"
            const bytes = concat$1([SignPrefix, RPC.Message.encode(rpcMsgPreSign).finish()]);
            if (!(await publicKey.verify(bytes, msg.signature))) {
                return { valid: false, error: ValidateError.InvalidSignature };
            }
            return {
                valid: true,
                message: {
                    type: 'signed',
                    from: fromPeerId,
                    data: msg.data ?? new Uint8Array(0),
                    sequenceNumber: BigInt(`0x${toString$9(msg.seqno, 'base16')}`),
                    topic: msg.topic,
                    signature: msg.signature,
                    key: msg.key ?? marshalPublicKey$1(publicKey)
                }
            };
        }
    }
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$6 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$6 = base$6;

var _brrp__multiformats_scope_baseX$6 = src$6;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$6 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$6 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$6 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$6(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$6 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$6(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$6 = (left, right) => new ComposedDecoder$6(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$6 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$6(name, prefix, baseEncode);
    this.decoder = new Decoder$6(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$a = ({ name, prefix, encode, decode }) =>
  new Codec$6(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$6 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$6(alphabet, name);
  return from$a({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$6(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$a = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$f = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$6 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$a({
    prefix,
    name,
    encode (input) {
      return encode$f(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$a(input, alphabet, bitsPerChar, name)
    }
  })
};

baseX$6({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$6({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

// @ts-check


rfc4648$6({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$6({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$6({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$6({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType$4;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType$4 || (KeyType$4 = {}));
var __KeyTypeValues$4;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues$4 || (__KeyTypeValues$4 = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues$4);
    };
})(KeyType$4 || (KeyType$4 = {}));
var PublicKey$4;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$4.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$4.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$1(buf, PublicKey.codec());
    };
})(PublicKey$4 || (PublicKey$4 = {}));
var PrivateKey$4;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$4.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$4.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$1(buf, PrivateKey.codec());
    };
})(PrivateKey$4 || (PrivateKey$4 = {}));

const bits$4 = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes$4 = Object.keys(bits$4);
curveTypes$4.join(' / ');

/**
 * Generate a message id, based on the `key` and `seqno`
 */
const msgId = (key, seqno) => {
    const seqnoBytes = fromString$3(seqno.toString(16).padStart(16, '0'), 'base16');
    const msgId = new Uint8Array(key.length + seqnoBytes.length);
    msgId.set(key, 0);
    msgId.set(seqnoBytes, key.length);
    return msgId;
};

/**
 * Generate a message id, based on the `key` and `seqno`
 */
function msgIdFnStrictSign(msg) {
    if (msg.type !== 'signed') {
        throw new Error('expected signed message type');
    }
    // Should never happen
    if (msg.sequenceNumber == null)
        throw Error('missing seqno field');
    // TODO: Should use .from here or key?
    return msgId(msg.from.toBytes(), msg.sequenceNumber);
}
/**
 * Generate a message id, based on message `data`
 */
async function msgIdFnStrictNoSign(msg) {
    return await sha256$5.encode(msg.data);
}

function computeScoreWeights(peer, pstats, params, peerIPs, topicStrToLabel) {
    let score = 0;
    const byTopic = new Map();
    // topic stores
    Object.entries(pstats.topics).forEach(([topic, tstats]) => {
        // the topic parameters
        // Aggregate by known topicLabel or throw to 'unknown'. This prevent too high cardinality
        const topicLabel = topicStrToLabel.get(topic) ?? 'unknown';
        const topicParams = params.topics[topic];
        if (topicParams === undefined) {
            // we are not scoring this topic
            return;
        }
        let topicScores = byTopic.get(topicLabel);
        if (!topicScores) {
            topicScores = {
                p1w: 0,
                p2w: 0,
                p3w: 0,
                p3bw: 0,
                p4w: 0
            };
            byTopic.set(topicLabel, topicScores);
        }
        let p1w = 0;
        let p2w = 0;
        let p3w = 0;
        let p3bw = 0;
        let p4w = 0;
        // P1: time in Mesh
        if (tstats.inMesh) {
            const p1 = Math.max(tstats.meshTime / topicParams.timeInMeshQuantum, topicParams.timeInMeshCap);
            p1w += p1 * topicParams.timeInMeshWeight;
        }
        // P2: first message deliveries
        let p2 = tstats.firstMessageDeliveries;
        if (p2 > topicParams.firstMessageDeliveriesCap) {
            p2 = topicParams.firstMessageDeliveriesCap;
        }
        p2w += p2 * topicParams.firstMessageDeliveriesWeight;
        // P3: mesh message deliveries
        if (tstats.meshMessageDeliveriesActive &&
            tstats.meshMessageDeliveries < topicParams.meshMessageDeliveriesThreshold) {
            const deficit = topicParams.meshMessageDeliveriesThreshold - tstats.meshMessageDeliveries;
            const p3 = deficit * deficit;
            p3w += p3 * topicParams.meshMessageDeliveriesWeight;
        }
        // P3b:
        // NOTE: the weight of P3b is negative (validated in validateTopicScoreParams) so this detracts
        const p3b = tstats.meshFailurePenalty;
        p3bw += p3b * topicParams.meshFailurePenaltyWeight;
        // P4: invalid messages
        // NOTE: the weight of P4 is negative (validated in validateTopicScoreParams) so this detracts
        const p4 = tstats.invalidMessageDeliveries * tstats.invalidMessageDeliveries;
        p4w += p4 * topicParams.invalidMessageDeliveriesWeight;
        // update score, mixing with topic weight
        score += (p1w + p2w + p3w + p3bw + p4w) * topicParams.topicWeight;
        topicScores.p1w += p1w;
        topicScores.p2w += p2w;
        topicScores.p3w += p3w;
        topicScores.p3bw += p3bw;
        topicScores.p4w += p4w;
    });
    // apply the topic score cap, if any
    if (params.topicScoreCap > 0 && score > params.topicScoreCap) {
        score = params.topicScoreCap;
        // Proportionally apply cap to all individual contributions
        const capF = params.topicScoreCap / score;
        for (const ws of byTopic.values()) {
            ws.p1w *= capF;
            ws.p2w *= capF;
            ws.p3w *= capF;
            ws.p3bw *= capF;
            ws.p4w *= capF;
        }
    }
    let p5w = 0;
    let p6w = 0;
    let p7w = 0;
    // P5: application-specific score
    const p5 = params.appSpecificScore(peer);
    p5w += p5 * params.appSpecificWeight;
    // P6: IP colocation factor
    pstats.knownIPs.forEach((ip) => {
        if (params.IPColocationFactorWhitelist.has(ip)) {
            return;
        }
        // P6 has a cliff (IPColocationFactorThreshold)
        // It's only applied if at least that many peers are connected to us from that source IP addr.
        // It is quadratic, and the weight is negative (validated in validatePeerScoreParams)
        const peersInIP = peerIPs.get(ip);
        const numPeersInIP = peersInIP ? peersInIP.size : 0;
        if (numPeersInIP > params.IPColocationFactorThreshold) {
            const surplus = numPeersInIP - params.IPColocationFactorThreshold;
            const p6 = surplus * surplus;
            p6w += p6 * params.IPColocationFactorWeight;
        }
    });
    // P7: behavioural pattern penalty
    const p7 = pstats.behaviourPenalty * pstats.behaviourPenalty;
    p7w += p7 * params.behaviourPenaltyWeight;
    score += p5w + p6w + p7w;
    return {
        byTopic,
        p5w,
        p6w,
        p7w,
        score
    };
}
function computeAllPeersScoreWeights(peerIdStrs, peerStats, params, peerIPs, topicStrToLabel) {
    const sw = {
        byTopic: new Map(),
        p5w: [],
        p6w: [],
        p7w: [],
        score: []
    };
    for (const peerIdStr of peerIdStrs) {
        const pstats = peerStats.get(peerIdStr);
        if (pstats) {
            const swPeer = computeScoreWeights(peerIdStr, pstats, params, peerIPs, topicStrToLabel);
            for (const [topic, swPeerTopic] of swPeer.byTopic) {
                let swTopic = sw.byTopic.get(topic);
                if (!swTopic) {
                    swTopic = {
                        p1w: [],
                        p2w: [],
                        p3w: [],
                        p3bw: [],
                        p4w: []
                    };
                    sw.byTopic.set(topic, swTopic);
                }
                swTopic.p1w.push(swPeerTopic.p1w);
                swTopic.p2w.push(swPeerTopic.p2w);
                swTopic.p3w.push(swPeerTopic.p3w);
                swTopic.p3bw.push(swPeerTopic.p3bw);
                swTopic.p4w.push(swPeerTopic.p4w);
            }
            sw.p5w.push(swPeer.p5w);
            sw.p6w.push(swPeer.p6w);
            sw.p7w.push(swPeer.p7w);
            sw.score.push(swPeer.score);
        }
        else {
            sw.p5w.push(0);
            sw.p6w.push(0);
            sw.p7w.push(0);
            sw.score.push(0);
        }
    }
    return sw;
}

class OutboundStream {
    rawStream;
    pushable;
    closeController;
    maxBufferSize;
    constructor(rawStream, errCallback, opts) {
        this.rawStream = rawStream;
        this.pushable = pushable({ objectMode: false });
        this.closeController = new AbortController();
        this.maxBufferSize = opts.maxBufferSize ?? Infinity;
        pipe(abortableSource(this.pushable, this.closeController.signal, { returnOnAbort: true }), (source) => encode$B(source), this.rawStream).catch(errCallback);
    }
    get protocol() {
        // TODO remove this non-nullish assertion after https://github.com/libp2p/js-libp2p-interfaces/pull/265 is incorporated
        return this.rawStream.protocol;
    }
    push(data) {
        if (this.pushable.readableLength > this.maxBufferSize) {
            throw Error(`OutboundStream buffer full, size > ${this.maxBufferSize}`);
        }
        this.pushable.push(data);
    }
    close() {
        this.closeController.abort();
        // similar to pushable.end() but clear the internal buffer
        this.pushable.return();
        this.rawStream.close();
    }
}
class InboundStream {
    source;
    rawStream;
    closeController;
    constructor(rawStream, opts = {}) {
        this.rawStream = rawStream;
        this.closeController = new AbortController();
        this.source = abortableSource(pipe(this.rawStream, (source) => decode$v(source, opts)), this.closeController.signal, {
            returnOnAbort: true
        });
    }
    close() {
        this.closeController.abort();
        this.rawStream.close();
    }
}

const defaultDecodeRpcLimits = {
    maxSubscriptions: Infinity,
    maxMessages: Infinity,
    maxIhaveMessageIDs: Infinity,
    maxIwantMessageIDs: Infinity,
    maxControlMessages: Infinity,
    maxPeerInfos: Infinity
};
/**
 * Copied code from src/message/rpc.cjs but with decode limits to prevent OOM attacks
 */
function decodeRpc(bytes, opts) {
    // Mutate to use the option as stateful counter. Must limit the total count of messageIDs across all IWANT, IHAVE
    // else one count put 100 messageIDs into each 100 IWANT and "get around" the limit
    opts = { ...opts };
    const r = protobuf.Reader.create(bytes);
    const l = bytes.length;
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                if (!(m.subscriptions && m.subscriptions.length))
                    m.subscriptions = [];
                if (m.subscriptions.length < opts.maxSubscriptions)
                    m.subscriptions.push(decodeSubOpts(r, r.uint32()));
                else
                    r.skipType(t & 7);
                break;
            case 2:
                if (!(m.messages && m.messages.length))
                    m.messages = [];
                if (m.messages.length < opts.maxMessages)
                    m.messages.push(decodeMessage(r, r.uint32()));
                else
                    r.skipType(t & 7);
                break;
            case 3:
                m.control = decodeControlMessage(r, r.uint32(), opts);
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeSubOpts(r, l) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.subscribe = r.bool();
                break;
            case 2:
                m.topic = r.string();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeMessage(r, l) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.from = r.bytes();
                break;
            case 2:
                m.data = r.bytes();
                break;
            case 3:
                m.seqno = r.bytes();
                break;
            case 4:
                m.topic = r.string();
                break;
            case 5:
                m.signature = r.bytes();
                break;
            case 6:
                m.key = r.bytes();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    if (!m.topic)
        throw Error("missing required 'topic'");
    return m;
}
function decodeControlMessage(r, l, opts) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                if (!(m.ihave && m.ihave.length))
                    m.ihave = [];
                if (m.ihave.length < opts.maxControlMessages)
                    m.ihave.push(decodeControlIHave(r, r.uint32(), opts));
                else
                    r.skipType(t & 7);
                break;
            case 2:
                if (!(m.iwant && m.iwant.length))
                    m.iwant = [];
                if (m.iwant.length < opts.maxControlMessages)
                    m.iwant.push(decodeControlIWant(r, r.uint32(), opts));
                else
                    r.skipType(t & 7);
                break;
            case 3:
                if (!(m.graft && m.graft.length))
                    m.graft = [];
                if (m.graft.length < opts.maxControlMessages)
                    m.graft.push(decodeControlGraft(r, r.uint32()));
                else
                    r.skipType(t & 7);
                break;
            case 4:
                if (!(m.prune && m.prune.length))
                    m.prune = [];
                if (m.prune.length < opts.maxControlMessages)
                    m.prune.push(decodeControlPrune(r, r.uint32(), opts));
                else
                    r.skipType(t & 7);
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeControlIHave(r, l, opts) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.topicID = r.string();
                break;
            case 2:
                if (!(m.messageIDs && m.messageIDs.length))
                    m.messageIDs = [];
                if (opts.maxIhaveMessageIDs-- > 0)
                    m.messageIDs.push(r.bytes());
                else
                    r.skipType(t & 7);
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeControlIWant(r, l, opts) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                if (!(m.messageIDs && m.messageIDs.length))
                    m.messageIDs = [];
                if (opts.maxIwantMessageIDs-- > 0)
                    m.messageIDs.push(r.bytes());
                else
                    r.skipType(t & 7);
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeControlGraft(r, l) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.topicID = r.string();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodeControlPrune(r, l, opts) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.topicID = r.string();
                break;
            case 2:
                if (!(m.peers && m.peers.length))
                    m.peers = [];
                if (opts.maxPeerInfos-- > 0)
                    m.peers.push(decodePeerInfo(r, r.uint32()));
                else
                    r.skipType(t & 7);
                break;
            case 3:
                m.backoff = r.uint64();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}
function decodePeerInfo(r, l) {
    const c = l === undefined ? r.len : r.pos + l;
    const m = {};
    while (r.pos < c) {
        const t = r.uint32();
        switch (t >>> 3) {
            case 1:
                m.peerID = r.bytes();
                break;
            case 2:
                m.signedPeerRecord = r.bytes();
                break;
            default:
                r.skipType(t & 7);
                break;
        }
    }
    return m;
}

// Protocols https://github.com/multiformats/multiaddr/blob/master/protocols.csv
// code  size  name
// 4     32    ip4
// 41    128   ip6
var Protocol;
(function (Protocol) {
    Protocol[Protocol["ip4"] = 4] = "ip4";
    Protocol[Protocol["ip6"] = 41] = "ip6";
})(Protocol || (Protocol = {}));
function multiaddrToIPStr(multiaddr) {
    for (const tuple of multiaddr.tuples()) {
        switch (tuple[0]) {
            case Protocol.ip4:
            case Protocol.ip6:
                return convertToString$1(tuple[0], tuple[1]);
        }
    }
    return null;
}

var GossipStatusCode;
(function (GossipStatusCode) {
    GossipStatusCode[GossipStatusCode["started"] = 0] = "started";
    GossipStatusCode[GossipStatusCode["stopped"] = 1] = "stopped";
})(GossipStatusCode || (GossipStatusCode = {}));
class GossipSub extends EventEmitter$2 {
    /**
     * The signature policy to follow by default
     */
    globalSignaturePolicy;
    multicodecs = [GossipsubIDv11, GossipsubIDv10];
    publishConfig;
    dataTransform;
    // State
    peers = new Set();
    streamsInbound = new Map();
    streamsOutbound = new Map();
    /** Ensures outbound streams are created sequentially */
    outboundInflightQueue = pushable({ objectMode: true });
    /** Direct peers */
    direct = new Set();
    /** Floodsub peers */
    floodsubPeers = new Set();
    /** Cache of seen messages */
    seenCache;
    /**
     * Map of peer id and AcceptRequestWhileListEntry
     */
    acceptFromWhitelist = new Map();
    /**
     * Map of topics to which peers are subscribed to
     */
    topics = new Map();
    /**
     * List of our subscriptions
     */
    subscriptions = new Set();
    /**
     * Map of topic meshes
     * topic => peer id set
     */
    mesh = new Map();
    /**
     * Map of topics to set of peers. These mesh peers are the ones to which we are publishing without a topic membership
     * topic => peer id set
     */
    fanout = new Map();
    /**
     * Map of last publish time for fanout topics
     * topic => last publish time
     */
    fanoutLastpub = new Map();
    /**
     * Map of pending messages to gossip
     * peer id => control messages
     */
    gossip = new Map();
    /**
     * Map of control messages
     * peer id => control message
     */
    control = new Map();
    /**
     * Number of IHAVEs received from peer in the last heartbeat
     */
    peerhave = new Map();
    /** Number of messages we have asked from peer in the last heartbeat */
    iasked = new Map();
    /** Prune backoff map */
    backoff = new Map();
    /**
     * Connection direction cache, marks peers with outbound connections
     * peer id => direction
     */
    outbound = new Map();
    msgIdFn;
    /**
     * A fast message id function used for internal message de-duplication
     */
    fastMsgIdFn;
    msgIdToStrFn;
    /** Maps fast message-id to canonical message-id */
    fastMsgIdCache;
    /**
     * Short term cache for published message ids. This is used for penalizing peers sending
     * our own messages back if the messages are anonymous or use a random author.
     */
    publishedMessageIds;
    /**
     * A message cache that contains the messages for last few heartbeat ticks
     */
    mcache;
    /** Peer score tracking */
    score;
    /**
     * Custom validator function per topic.
     * Must return or resolve quickly (< 100ms) to prevent causing penalties for late messages.
     * If you need to apply validation that may require longer times use `asyncValidation` option and callback the
     * validation result through `Gossipsub.reportValidationResult`
     */
    topicValidators = new Map();
    /**
     * Make this protected so child class may want to redirect to its own log.
     */
    log;
    /**
     * Number of heartbeats since the beginning of time
     * This allows us to amortize some resource cleanup -- eg: backoff cleanup
     */
    heartbeatTicks = 0;
    /**
     * Tracks IHAVE/IWANT promises broken by peers
     */
    gossipTracer;
    components;
    directPeerInitial = null;
    static multicodec = GossipsubIDv11;
    // Options
    opts;
    decodeRpcLimits;
    metrics;
    status = { code: GossipStatusCode.stopped };
    maxInboundStreams;
    maxOutboundStreams;
    allowedTopics;
    heartbeatTimer = null;
    constructor(components, options = {}) {
        super();
        const opts = {
            fallbackToFloodsub: true,
            floodPublish: true,
            doPX: false,
            directPeers: [],
            D: GossipsubD,
            Dlo: GossipsubDlo,
            Dhi: GossipsubDhi,
            Dscore: GossipsubDscore,
            Dout: GossipsubDout,
            Dlazy: GossipsubDlazy,
            heartbeatInterval: GossipsubHeartbeatInterval,
            fanoutTTL: GossipsubFanoutTTL,
            mcacheLength: GossipsubHistoryLength,
            mcacheGossip: GossipsubHistoryGossip,
            seenTTL: GossipsubSeenTTL,
            gossipsubIWantFollowupMs: GossipsubIWantFollowupTime,
            prunePeers: GossipsubPrunePeers,
            pruneBackoff: GossipsubPruneBackoff,
            unsubcribeBackoff: GossipsubUnsubscribeBackoff,
            graftFloodThreshold: GossipsubGraftFloodThreshold,
            opportunisticGraftPeers: GossipsubOpportunisticGraftPeers,
            opportunisticGraftTicks: GossipsubOpportunisticGraftTicks,
            directConnectTicks: GossipsubDirectConnectTicks,
            ...options,
            scoreParams: createPeerScoreParams(options.scoreParams),
            scoreThresholds: createPeerScoreThresholds(options.scoreThresholds)
        };
        this.components = components;
        this.decodeRpcLimits = opts.decodeRpcLimits ?? defaultDecodeRpcLimits;
        this.globalSignaturePolicy = opts.globalSignaturePolicy ?? StrictSign;
        // Also wants to get notified of peers connected using floodsub
        if (opts.fallbackToFloodsub) {
            this.multicodecs.push(FloodsubID);
        }
        // From pubsub
        this.log = logger$4(opts.debugName ?? 'libp2p:gossipsub');
        // Gossipsub
        this.opts = opts;
        this.direct = new Set(opts.directPeers.map((p) => p.id.toString()));
        this.seenCache = new SimpleTimeCache({ validityMs: opts.seenTTL });
        this.publishedMessageIds = new SimpleTimeCache({ validityMs: opts.seenTTL });
        if (options.msgIdFn) {
            // Use custom function
            this.msgIdFn = options.msgIdFn;
        }
        else {
            switch (this.globalSignaturePolicy) {
                case StrictSign:
                    this.msgIdFn = msgIdFnStrictSign;
                    break;
                case StrictNoSign:
                    this.msgIdFn = msgIdFnStrictNoSign;
                    break;
            }
        }
        if (options.fastMsgIdFn) {
            this.fastMsgIdFn = options.fastMsgIdFn;
            this.fastMsgIdCache = new SimpleTimeCache({ validityMs: opts.seenTTL });
        }
        // By default, gossipsub only provide a browser friendly function to convert Uint8Array message id to string.
        this.msgIdToStrFn = options.msgIdToStrFn ?? messageIdToString;
        this.mcache = options.messageCache || new MessageCache(opts.mcacheGossip, opts.mcacheLength, this.msgIdToStrFn);
        if (options.dataTransform) {
            this.dataTransform = options.dataTransform;
        }
        if (options.metricsRegister) {
            if (!options.metricsTopicStrToLabel) {
                throw Error('Must set metricsTopicStrToLabel with metrics');
            }
            // in theory, each topic has its own meshMessageDeliveriesWindow param
            // however in lodestar, we configure it mostly the same so just pick the max of positive ones
            // (some topics have meshMessageDeliveriesWindow as 0)
            const maxMeshMessageDeliveriesWindowMs = Math.max(...Object.values(opts.scoreParams.topics).map((topicParam) => topicParam.meshMessageDeliveriesWindow), DEFAULT_METRIC_MESH_MESSAGE_DELIVERIES_WINDOWS);
            const metrics = getMetrics(options.metricsRegister, options.metricsTopicStrToLabel, {
                gossipPromiseExpireSec: this.opts.gossipsubIWantFollowupMs / 1000,
                behaviourPenaltyThreshold: opts.scoreParams.behaviourPenaltyThreshold,
                maxMeshMessageDeliveriesWindowSec: maxMeshMessageDeliveriesWindowMs / 1000
            });
            metrics.mcacheSize.addCollect(() => this.onScrapeMetrics(metrics));
            for (const protocol of this.multicodecs) {
                metrics.protocolsEnabled.set({ protocol }, 1);
            }
            this.metrics = metrics;
        }
        else {
            this.metrics = null;
        }
        this.gossipTracer = new IWantTracer(this.opts.gossipsubIWantFollowupMs, this.msgIdToStrFn, this.metrics);
        /**
         * libp2p
         */
        this.score = new PeerScore(this.opts.scoreParams, this.metrics, {
            scoreCacheValidityMs: opts.heartbeatInterval
        });
        this.maxInboundStreams = options.maxInboundStreams;
        this.maxOutboundStreams = options.maxOutboundStreams;
        this.allowedTopics = opts.allowedTopics ? new Set(opts.allowedTopics) : null;
    }
    getPeers() {
        return [...this.peers.keys()].map((str) => peerIdFromString(str));
    }
    isStarted() {
        return this.status.code === GossipStatusCode.started;
    }
    // LIFECYCLE METHODS
    /**
     * Mounts the gossipsub protocol onto the libp2p node and sends our
     * our subscriptions to every peer connected
     */
    async start() {
        // From pubsub
        if (this.isStarted()) {
            return;
        }
        this.log('starting');
        this.publishConfig = await getPublishConfigFromPeerId(this.globalSignaturePolicy, this.components.peerId);
        // Create the outbound inflight queue
        // This ensures that outbound stream creation happens sequentially
        this.outboundInflightQueue = pushable({ objectMode: true });
        pipe(this.outboundInflightQueue, async (source) => {
            for await (const { peerId, connection } of source) {
                await this.createOutboundStream(peerId, connection);
            }
        }).catch((e) => this.log.error('outbound inflight queue error', e));
        // set direct peer addresses in the address book
        await Promise.all(this.opts.directPeers.map(async (p) => {
            await this.components.peerStore.merge(p.id, {
                multiaddrs: p.addrs
            });
        }));
        const registrar = this.components.registrar;
        // Incoming streams
        // Called after a peer dials us
        await Promise.all(this.multicodecs.map((multicodec) => registrar.handle(multicodec, this.onIncomingStream.bind(this), {
            maxInboundStreams: this.maxInboundStreams,
            maxOutboundStreams: this.maxOutboundStreams
        })));
        // # How does Gossipsub interact with libp2p? Rough guide from Mar 2022
        //
        // ## Setup:
        // Gossipsub requests libp2p to callback, TBD
        //
        // `this.libp2p.handle()` registers a handler for `/meshsub/1.1.0` and other Gossipsub protocols
        // The handler callback is registered in libp2p Upgrader.protocols map.
        //
        // Upgrader receives an inbound connection from some transport and (`Upgrader.upgradeInbound`):
        // - Adds encryption (NOISE in our case)
        // - Multiplex stream
        // - Create a muxer and register that for each new stream call Upgrader.protocols handler
        //
        // ## Topology
        // - new instance of Topology (unlinked to libp2p) with handlers
        // - registar.register(topology)
        // register protocol with topology
        // Topology callbacks called on connection manager changes
        const topology = {
            onConnect: this.onPeerConnected.bind(this),
            onDisconnect: this.onPeerDisconnected.bind(this)
        };
        const registrarTopologyIds = await Promise.all(this.multicodecs.map((multicodec) => registrar.register(multicodec, topology)));
        // Schedule to start heartbeat after `GossipsubHeartbeatInitialDelay`
        const heartbeatTimeout = setTimeout(this.runHeartbeat, GossipsubHeartbeatInitialDelay);
        // Then, run heartbeat every `heartbeatInterval` offset by `GossipsubHeartbeatInitialDelay`
        this.status = {
            code: GossipStatusCode.started,
            registrarTopologyIds,
            heartbeatTimeout: heartbeatTimeout,
            hearbeatStartMs: Date.now() + GossipsubHeartbeatInitialDelay
        };
        this.score.start();
        // connect to direct peers
        this.directPeerInitial = setTimeout(() => {
            Promise.resolve()
                .then(async () => {
                await Promise.all(Array.from(this.direct).map(async (id) => await this.connect(id)));
            })
                .catch((err) => {
                this.log(err);
            });
        }, GossipsubDirectConnectInitialDelay);
        this.log('started');
    }
    /**
     * Unmounts the gossipsub protocol and shuts down every connection
     */
    async stop() {
        this.log('stopping');
        // From pubsub
        if (this.status.code !== GossipStatusCode.started) {
            return;
        }
        const { registrarTopologyIds } = this.status;
        this.status = { code: GossipStatusCode.stopped };
        // unregister protocol and handlers
        const registrar = this.components.registrar;
        await Promise.all(this.multicodecs.map((multicodec) => registrar.unhandle(multicodec)));
        registrarTopologyIds.forEach((id) => registrar.unregister(id));
        this.outboundInflightQueue.end();
        for (const outboundStream of this.streamsOutbound.values()) {
            outboundStream.close();
        }
        this.streamsOutbound.clear();
        for (const inboundStream of this.streamsInbound.values()) {
            inboundStream.close();
        }
        this.streamsInbound.clear();
        this.peers.clear();
        this.subscriptions.clear();
        // Gossipsub
        if (this.heartbeatTimer) {
            this.heartbeatTimer.cancel();
            this.heartbeatTimer = null;
        }
        this.score.stop();
        this.mesh.clear();
        this.fanout.clear();
        this.fanoutLastpub.clear();
        this.gossip.clear();
        this.control.clear();
        this.peerhave.clear();
        this.iasked.clear();
        this.backoff.clear();
        this.outbound.clear();
        this.gossipTracer.clear();
        this.seenCache.clear();
        if (this.fastMsgIdCache)
            this.fastMsgIdCache.clear();
        if (this.directPeerInitial)
            clearTimeout(this.directPeerInitial);
        this.log('stopped');
    }
    /** FOR DEBUG ONLY - Dump peer stats for all peers. Data is cloned, safe to mutate */
    dumpPeerScoreStats() {
        return this.score.dumpPeerScoreStats();
    }
    /**
     * On an inbound stream opened
     */
    onIncomingStream({ stream, connection }) {
        if (!this.isStarted()) {
            return;
        }
        const peerId = connection.remotePeer;
        // add peer to router
        this.addPeer(peerId, connection.direction, connection.remoteAddr);
        // create inbound stream
        this.createInboundStream(peerId, stream);
        // attempt to create outbound stream
        this.outboundInflightQueue.push({ peerId, connection });
    }
    /**
     * Registrar notifies an established connection with pubsub protocol
     */
    onPeerConnected(peerId, connection) {
        this.metrics?.newConnectionCount.inc({ status: connection.status });
        // libp2p may emit a closed connection and never issue peer:disconnect event
        // see https://github.com/ChainSafe/js-libp2p-gossipsub/issues/398
        if (!this.isStarted() || connection.status !== 'open') {
            return;
        }
        this.addPeer(peerId, connection.direction, connection.remoteAddr);
        this.outboundInflightQueue.push({ peerId, connection });
    }
    /**
     * Registrar notifies a closing connection with pubsub protocol
     */
    onPeerDisconnected(peerId) {
        this.log('connection ended %p', peerId);
        this.removePeer(peerId);
    }
    async createOutboundStream(peerId, connection) {
        if (!this.isStarted()) {
            return;
        }
        const id = peerId.toString();
        if (!this.peers.has(id)) {
            return;
        }
        // TODO make this behavior more robust
        // This behavior is different than for inbound streams
        // If an outbound stream already exists, don't create a new stream
        if (this.streamsOutbound.has(id)) {
            return;
        }
        try {
            const stream = new OutboundStream(await connection.newStream(this.multicodecs), (e) => this.log.error('outbound pipe error', e), { maxBufferSize: this.opts.maxOutboundBufferSize });
            this.log('create outbound stream %p', peerId);
            this.streamsOutbound.set(id, stream);
            const protocol = stream.protocol;
            if (protocol === FloodsubID) {
                this.floodsubPeers.add(id);
            }
            this.metrics?.peersPerProtocol.inc({ protocol }, 1);
            // Immediately send own subscriptions via the newly attached stream
            if (this.subscriptions.size > 0) {
                this.log('send subscriptions to', id);
                this.sendSubscriptions(id, Array.from(this.subscriptions), true);
            }
        }
        catch (e) {
            this.log.error('createOutboundStream error', e);
        }
    }
    async createInboundStream(peerId, stream) {
        if (!this.isStarted()) {
            return;
        }
        const id = peerId.toString();
        if (!this.peers.has(id)) {
            return;
        }
        // TODO make this behavior more robust
        // This behavior is different than for outbound streams
        // If a peer initiates a new inbound connection
        // we assume that one is the new canonical inbound stream
        const priorInboundStream = this.streamsInbound.get(id);
        if (priorInboundStream !== undefined) {
            this.log('replacing existing inbound steam %s', id);
            priorInboundStream.close();
        }
        this.log('create inbound stream %s', id);
        const inboundStream = new InboundStream(stream, { maxDataLength: this.opts.maxInboundDataLength });
        this.streamsInbound.set(id, inboundStream);
        this.pipePeerReadStream(peerId, inboundStream.source).catch((err) => this.log(err));
    }
    /**
     * Add a peer to the router
     */
    addPeer(peerId, direction, addr) {
        const id = peerId.toString();
        if (!this.peers.has(id)) {
            this.log('new peer %p', peerId);
            this.peers.add(id);
            // Add to peer scoring
            this.score.addPeer(id);
            const currentIP = multiaddrToIPStr(addr);
            if (currentIP !== null) {
                this.score.addIP(id, currentIP);
            }
            else {
                this.log('Added peer has no IP in current address %s %s', id, addr.toString());
            }
            // track the connection direction. Don't allow to unset outbound
            if (!this.outbound.has(id)) {
                this.outbound.set(id, direction === 'outbound');
            }
        }
    }
    /**
     * Removes a peer from the router
     */
    removePeer(peerId) {
        const id = peerId.toString();
        if (!this.peers.has(id)) {
            return;
        }
        // delete peer
        this.log('delete peer %p', peerId);
        this.peers.delete(id);
        const outboundStream = this.streamsOutbound.get(id);
        const inboundStream = this.streamsInbound.get(id);
        if (outboundStream) {
            this.metrics?.peersPerProtocol.inc({ protocol: outboundStream.protocol }, -1);
        }
        // close streams
        outboundStream?.close();
        inboundStream?.close();
        // remove streams
        this.streamsOutbound.delete(id);
        this.streamsInbound.delete(id);
        // remove peer from topics map
        for (const peers of this.topics.values()) {
            peers.delete(id);
        }
        // Remove this peer from the mesh
        for (const [topicStr, peers] of this.mesh) {
            if (peers.delete(id) === true) {
                this.metrics?.onRemoveFromMesh(topicStr, ChurnReason.Dc, 1);
            }
        }
        // Remove this peer from the fanout
        for (const peers of this.fanout.values()) {
            peers.delete(id);
        }
        // Remove from floodsubPeers
        this.floodsubPeers.delete(id);
        // Remove from gossip mapping
        this.gossip.delete(id);
        // Remove from control mapping
        this.control.delete(id);
        // Remove from backoff mapping
        this.outbound.delete(id);
        // Remove from peer scoring
        this.score.removePeer(id);
        this.acceptFromWhitelist.delete(id);
    }
    // API METHODS
    get started() {
        return this.status.code === GossipStatusCode.started;
    }
    /**
     * Get a the peer-ids in a topic mesh
     */
    getMeshPeers(topic) {
        const peersInTopic = this.mesh.get(topic);
        return peersInTopic ? Array.from(peersInTopic) : [];
    }
    /**
     * Get a list of the peer-ids that are subscribed to one topic.
     */
    getSubscribers(topic) {
        const peersInTopic = this.topics.get(topic);
        return (peersInTopic ? Array.from(peersInTopic) : []).map((str) => peerIdFromString(str));
    }
    /**
     * Get the list of topics which the peer is subscribed to.
     */
    getTopics() {
        return Array.from(this.subscriptions);
    }
    // TODO: Reviewing Pubsub API
    // MESSAGE METHODS
    /**
     * Responsible for processing each RPC message received by other peers.
     */
    async pipePeerReadStream(peerId, stream) {
        try {
            await pipe(stream, async (source) => {
                for await (const data of source) {
                    try {
                        // TODO: Check max gossip message size, before decodeRpc()
                        const rpcBytes = data.subarray();
                        // Note: This function may throw, it must be wrapped in a try {} catch {} to prevent closing the stream.
                        // TODO: What should we do if the entire RPC is invalid?
                        const rpc = decodeRpc(rpcBytes, this.decodeRpcLimits);
                        this.metrics?.onRpcRecv(rpc, rpcBytes.length);
                        // Since processRpc may be overridden entirely in unsafe ways,
                        // the simplest/safest option here is to wrap in a function and capture all errors
                        // to prevent a top-level unhandled exception
                        // This processing of rpc messages should happen without awaiting full validation/execution of prior messages
                        if (this.opts.awaitRpcHandler) {
                            try {
                                await this.handleReceivedRpc(peerId, rpc);
                            }
                            catch (err) {
                                this.metrics?.onRpcRecvError();
                                this.log(err);
                            }
                        }
                        else {
                            this.handleReceivedRpc(peerId, rpc).catch((err) => {
                                this.metrics?.onRpcRecvError();
                                this.log(err);
                            });
                        }
                    }
                    catch (e) {
                        this.metrics?.onRpcDataError();
                        this.log(e);
                    }
                }
            });
        }
        catch (err) {
            this.metrics?.onPeerReadStreamError();
            this.handlePeerReadStreamError(err, peerId);
        }
    }
    /**
     * Handle error when read stream pipe throws, less of the functional use but more
     * to for testing purposes to spy on the error handling
     * */
    handlePeerReadStreamError(err, peerId) {
        this.log.error(err);
        this.onPeerDisconnected(peerId);
    }
    /**
     * Handles an rpc request from a peer
     */
    async handleReceivedRpc(from, rpc) {
        // Check if peer is graylisted in which case we ignore the event
        if (!this.acceptFrom(from.toString())) {
            this.log('received message from unacceptable peer %p', from);
            this.metrics?.rpcRecvNotAccepted.inc();
            return;
        }
        const subscriptions = rpc.subscriptions ? rpc.subscriptions.length : 0;
        const messages = rpc.messages ? rpc.messages.length : 0;
        let ihave = 0;
        let iwant = 0;
        let graft = 0;
        let prune = 0;
        if (rpc.control) {
            if (rpc.control.ihave)
                ihave = rpc.control.ihave.length;
            if (rpc.control.iwant)
                iwant = rpc.control.iwant.length;
            if (rpc.control.graft)
                graft = rpc.control.graft.length;
            if (rpc.control.prune)
                prune = rpc.control.prune.length;
        }
        this.log(`rpc.from ${from.toString()} subscriptions ${subscriptions} messages ${messages} ihave ${ihave} iwant ${iwant} graft ${graft} prune ${prune}`);
        // Handle received subscriptions
        if (rpc.subscriptions && rpc.subscriptions.length > 0) {
            // update peer subscriptions
            const subscriptions = [];
            rpc.subscriptions.forEach((subOpt) => {
                const topic = subOpt.topic;
                const subscribe = subOpt.subscribe === true;
                if (topic != null) {
                    if (this.allowedTopics && !this.allowedTopics.has(topic)) {
                        // Not allowed: subscription data-structures are not bounded by topic count
                        // TODO: Should apply behaviour penalties?
                        return;
                    }
                    this.handleReceivedSubscription(from, topic, subscribe);
                    subscriptions.push({ topic, subscribe });
                }
            });
            this.dispatchEvent(new CustomEvent('subscription-change', {
                detail: { peerId: from, subscriptions }
            }));
        }
        // Handle messages
        // TODO: (up to limit)
        if (rpc.messages) {
            for (const message of rpc.messages) {
                if (this.allowedTopics && !this.allowedTopics.has(message.topic)) {
                    // Not allowed: message cache data-structures are not bounded by topic count
                    // TODO: Should apply behaviour penalties?
                    continue;
                }
                const handleReceivedMessagePromise = this.handleReceivedMessage(from, message)
                    // Should never throw, but handle just in case
                    .catch((err) => {
                    this.metrics?.onMsgRecvError(message.topic);
                    this.log(err);
                });
                if (this.opts.awaitRpcMessageHandler) {
                    await handleReceivedMessagePromise;
                }
            }
        }
        // Handle control messages
        if (rpc.control) {
            await this.handleControlMessage(from.toString(), rpc.control);
        }
    }
    /**
     * Handles a subscription change from a peer
     */
    handleReceivedSubscription(from, topic, subscribe) {
        this.log('subscription update from %p topic %s', from, topic);
        let topicSet = this.topics.get(topic);
        if (topicSet == null) {
            topicSet = new Set();
            this.topics.set(topic, topicSet);
        }
        if (subscribe) {
            // subscribe peer to new topic
            topicSet.add(from.toString());
        }
        else {
            // unsubscribe from existing topic
            topicSet.delete(from.toString());
        }
        // TODO: rust-libp2p has A LOT more logic here
    }
    /**
     * Handles a newly received message from an RPC.
     * May forward to all peers in the mesh.
     */
    async handleReceivedMessage(from, rpcMsg) {
        this.metrics?.onMsgRecvPreValidation(rpcMsg.topic);
        const validationResult = await this.validateReceivedMessage(from, rpcMsg);
        this.metrics?.onPrevalidationResult(rpcMsg.topic, validationResult.code);
        switch (validationResult.code) {
            case MessageStatus.duplicate:
                // Report the duplicate
                this.score.duplicateMessage(from.toString(), validationResult.msgIdStr, rpcMsg.topic);
                // due to the collision of fastMsgIdFn, 2 different messages may end up the same fastMsgId
                // so we need to also mark the duplicate message as delivered or the promise is not resolved
                // and peer gets penalized. See https://github.com/ChainSafe/js-libp2p-gossipsub/pull/385
                this.gossipTracer.deliverMessage(validationResult.msgIdStr, true);
                this.mcache.observeDuplicate(validationResult.msgIdStr, from.toString());
                return;
            case MessageStatus.invalid:
                // invalid messages received
                // metrics.register_invalid_message(&raw_message.topic)
                // Tell peer_score about reject
                // Reject the original source, and any duplicates we've seen from other peers.
                if (validationResult.msgIdStr) {
                    const msgIdStr = validationResult.msgIdStr;
                    this.score.rejectMessage(from.toString(), msgIdStr, rpcMsg.topic, validationResult.reason);
                    this.gossipTracer.rejectMessage(msgIdStr, validationResult.reason);
                }
                else {
                    this.score.rejectInvalidMessage(from.toString(), rpcMsg.topic);
                }
                this.metrics?.onMsgRecvInvalid(rpcMsg.topic, validationResult);
                return;
            case MessageStatus.valid:
                // Tells score that message arrived (but is maybe not fully validated yet).
                // Consider the message as delivered for gossip promises.
                this.score.validateMessage(validationResult.messageId.msgIdStr);
                this.gossipTracer.deliverMessage(validationResult.messageId.msgIdStr);
                // Add the message to our memcache
                // if no validation is required, mark the message as validated
                this.mcache.put(validationResult.messageId, rpcMsg, !this.opts.asyncValidation);
                // Dispatch the message to the user if we are subscribed to the topic
                if (this.subscriptions.has(rpcMsg.topic)) {
                    const isFromSelf = this.components.peerId.equals(from);
                    if (!isFromSelf || this.opts.emitSelf) {
                        super.dispatchEvent(new CustomEvent('gossipsub:message', {
                            detail: {
                                propagationSource: from,
                                msgId: validationResult.messageId.msgIdStr,
                                msg: validationResult.msg
                            }
                        }));
                        // TODO: Add option to switch between emit per topic or all messages in one
                        super.dispatchEvent(new CustomEvent('message', { detail: validationResult.msg }));
                    }
                }
                // Forward the message to mesh peers, if no validation is required
                // If asyncValidation is ON, expect the app layer to call reportMessageValidationResult(), then forward
                if (!this.opts.asyncValidation) {
                    // TODO: in rust-libp2p
                    // .forward_msg(&msg_id, raw_message, Some(propagation_source))
                    this.forwardMessage(validationResult.messageId.msgIdStr, rpcMsg, from.toString());
                }
        }
    }
    /**
     * Handles a newly received message from an RPC.
     * May forward to all peers in the mesh.
     */
    async validateReceivedMessage(propagationSource, rpcMsg) {
        // Fast message ID stuff
        const fastMsgIdStr = this.fastMsgIdFn?.(rpcMsg);
        const msgIdCached = fastMsgIdStr !== undefined ? this.fastMsgIdCache?.get(fastMsgIdStr) : undefined;
        if (msgIdCached) {
            // This message has been seen previously. Ignore it
            return { code: MessageStatus.duplicate, msgIdStr: msgIdCached };
        }
        // Perform basic validation on message and convert to RawGossipsubMessage for fastMsgIdFn()
        const validationResult = await validateToRawMessage(this.globalSignaturePolicy, rpcMsg);
        if (!validationResult.valid) {
            return { code: MessageStatus.invalid, reason: RejectReason.Error, error: validationResult.error };
        }
        const msg = validationResult.message;
        // Try and perform the data transform to the message. If it fails, consider it invalid.
        try {
            if (this.dataTransform) {
                msg.data = this.dataTransform.inboundTransform(rpcMsg.topic, msg.data);
            }
        }
        catch (e) {
            this.log('Invalid message, transform failed', e);
            return { code: MessageStatus.invalid, reason: RejectReason.Error, error: ValidateError.TransformFailed };
        }
        // TODO: Check if message is from a blacklisted source or propagation origin
        // - Reject any message from a blacklisted peer
        // - Also reject any message that originated from a blacklisted peer
        // - reject messages claiming to be from ourselves but not locally published
        // Calculate the message id on the transformed data.
        const msgId = await this.msgIdFn(msg);
        const msgIdStr = this.msgIdToStrFn(msgId);
        const messageId = { msgId, msgIdStr };
        // Add the message to the duplicate caches
        if (fastMsgIdStr !== undefined && this.fastMsgIdCache) {
            const collision = this.fastMsgIdCache.put(fastMsgIdStr, msgIdStr);
            if (collision) {
                this.metrics?.fastMsgIdCacheCollision.inc();
            }
        }
        if (this.seenCache.has(msgIdStr)) {
            return { code: MessageStatus.duplicate, msgIdStr };
        }
        else {
            this.seenCache.put(msgIdStr);
        }
        // (Optional) Provide custom validation here with dynamic validators per topic
        // NOTE: This custom topicValidator() must resolve fast (< 100ms) to allow scores
        // to not penalize peers for long validation times.
        const topicValidator = this.topicValidators.get(rpcMsg.topic);
        if (topicValidator != null) {
            let acceptance;
            // Use try {} catch {} in case topicValidator() is synchronous
            try {
                acceptance = await topicValidator(propagationSource, msg);
            }
            catch (e) {
                const errCode = e.code;
                if (errCode === ERR_TOPIC_VALIDATOR_IGNORE)
                    acceptance = TopicValidatorResult.Ignore;
                if (errCode === ERR_TOPIC_VALIDATOR_REJECT)
                    acceptance = TopicValidatorResult.Reject;
                else
                    acceptance = TopicValidatorResult.Ignore;
            }
            if (acceptance !== TopicValidatorResult.Accept) {
                return { code: MessageStatus.invalid, reason: rejectReasonFromAcceptance(acceptance), msgIdStr };
            }
        }
        return { code: MessageStatus.valid, messageId, msg };
    }
    /**
     * Return score of a peer.
     */
    getScore(peerId) {
        return this.score.score(peerId);
    }
    /**
     * Send an rpc object to a peer with subscriptions
     */
    sendSubscriptions(toPeer, topics, subscribe) {
        this.sendRpc(toPeer, {
            subscriptions: topics.map((topic) => ({ topic, subscribe }))
        });
    }
    /**
     * Handles an rpc control message from a peer
     */
    async handleControlMessage(id, controlMsg) {
        if (controlMsg === undefined) {
            return;
        }
        const iwant = controlMsg.ihave ? this.handleIHave(id, controlMsg.ihave) : [];
        const ihave = controlMsg.iwant ? this.handleIWant(id, controlMsg.iwant) : [];
        const prune = controlMsg.graft ? await this.handleGraft(id, controlMsg.graft) : [];
        controlMsg.prune && (await this.handlePrune(id, controlMsg.prune));
        if (!iwant.length && !ihave.length && !prune.length) {
            return;
        }
        const sent = this.sendRpc(id, { messages: ihave, control: { iwant, prune } });
        const iwantMessageIds = iwant[0]?.messageIDs;
        if (iwantMessageIds) {
            if (sent) {
                this.gossipTracer.addPromise(id, iwantMessageIds);
            }
            else {
                this.metrics?.iwantPromiseUntracked.inc(1);
            }
        }
    }
    /**
     * Whether to accept a message from a peer
     */
    acceptFrom(id) {
        if (this.direct.has(id)) {
            return true;
        }
        const now = Date.now();
        const entry = this.acceptFromWhitelist.get(id);
        if (entry && entry.messagesAccepted < ACCEPT_FROM_WHITELIST_MAX_MESSAGES && entry.acceptUntil >= now) {
            entry.messagesAccepted += 1;
            return true;
        }
        const score = this.score.score(id);
        if (score >= ACCEPT_FROM_WHITELIST_THRESHOLD_SCORE) {
            // peer is unlikely to be able to drop its score to `graylistThreshold`
            // after 128 messages or 1s
            this.acceptFromWhitelist.set(id, {
                messagesAccepted: 0,
                acceptUntil: now + ACCEPT_FROM_WHITELIST_DURATION_MS
            });
        }
        else {
            this.acceptFromWhitelist.delete(id);
        }
        return score >= this.opts.scoreThresholds.graylistThreshold;
    }
    /**
     * Handles IHAVE messages
     */
    handleIHave(id, ihave) {
        if (!ihave.length) {
            return [];
        }
        // we ignore IHAVE gossip from any peer whose score is below the gossips threshold
        const score = this.score.score(id);
        if (score < this.opts.scoreThresholds.gossipThreshold) {
            this.log('IHAVE: ignoring peer %s with score below threshold [ score = %d ]', id, score);
            this.metrics?.ihaveRcvIgnored.inc({ reason: IHaveIgnoreReason.LowScore });
            return [];
        }
        // IHAVE flood protection
        const peerhave = (this.peerhave.get(id) ?? 0) + 1;
        this.peerhave.set(id, peerhave);
        if (peerhave > GossipsubMaxIHaveMessages) {
            this.log('IHAVE: peer %s has advertised too many times (%d) within this heartbeat interval; ignoring', id, peerhave);
            this.metrics?.ihaveRcvIgnored.inc({ reason: IHaveIgnoreReason.MaxIhave });
            return [];
        }
        const iasked = this.iasked.get(id) ?? 0;
        if (iasked >= GossipsubMaxIHaveLength) {
            this.log('IHAVE: peer %s has already advertised too many messages (%d); ignoring', id, iasked);
            this.metrics?.ihaveRcvIgnored.inc({ reason: IHaveIgnoreReason.MaxIasked });
            return [];
        }
        // string msgId => msgId
        const iwant = new Map();
        ihave.forEach(({ topicID, messageIDs }) => {
            if (!topicID || !messageIDs || !this.mesh.has(topicID)) {
                return;
            }
            let idonthave = 0;
            messageIDs.forEach((msgId) => {
                const msgIdStr = this.msgIdToStrFn(msgId);
                if (!this.seenCache.has(msgIdStr)) {
                    iwant.set(msgIdStr, msgId);
                    idonthave++;
                }
            });
            this.metrics?.onIhaveRcv(topicID, messageIDs.length, idonthave);
        });
        if (!iwant.size) {
            return [];
        }
        let iask = iwant.size;
        if (iask + iasked > GossipsubMaxIHaveLength) {
            iask = GossipsubMaxIHaveLength - iasked;
        }
        this.log('IHAVE: Asking for %d out of %d messages from %s', iask, iwant.size, id);
        let iwantList = Array.from(iwant.values());
        // ask in random order
        shuffle(iwantList);
        // truncate to the messages we are actually asking for and update the iasked counter
        iwantList = iwantList.slice(0, iask);
        this.iasked.set(id, iasked + iask);
        // do not add gossipTracer promise here until a successful sendRpc()
        return [
            {
                messageIDs: iwantList
            }
        ];
    }
    /**
     * Handles IWANT messages
     * Returns messages to send back to peer
     */
    handleIWant(id, iwant) {
        if (!iwant.length) {
            return [];
        }
        // we don't respond to IWANT requests from any per whose score is below the gossip threshold
        const score = this.score.score(id);
        if (score < this.opts.scoreThresholds.gossipThreshold) {
            this.log('IWANT: ignoring peer %s with score below threshold [score = %d]', id, score);
            return [];
        }
        const ihave = new Map();
        const iwantByTopic = new Map();
        let iwantDonthave = 0;
        iwant.forEach(({ messageIDs }) => {
            messageIDs &&
                messageIDs.forEach((msgId) => {
                    const msgIdStr = this.msgIdToStrFn(msgId);
                    const entry = this.mcache.getWithIWantCount(msgIdStr, id);
                    if (entry == null) {
                        iwantDonthave++;
                        return;
                    }
                    iwantByTopic.set(entry.msg.topic, 1 + (iwantByTopic.get(entry.msg.topic) ?? 0));
                    if (entry.count > GossipsubGossipRetransmission) {
                        this.log('IWANT: Peer %s has asked for message %s too many times: ignoring request', id, msgId);
                        return;
                    }
                    ihave.set(msgIdStr, entry.msg);
                });
        });
        this.metrics?.onIwantRcv(iwantByTopic, iwantDonthave);
        if (!ihave.size) {
            this.log('IWANT: Could not provide any wanted messages to %s', id);
            return [];
        }
        this.log('IWANT: Sending %d messages to %s', ihave.size, id);
        return Array.from(ihave.values());
    }
    /**
     * Handles Graft messages
     */
    async handleGraft(id, graft) {
        const prune = [];
        const score = this.score.score(id);
        const now = Date.now();
        let doPX = this.opts.doPX;
        graft.forEach(({ topicID }) => {
            if (!topicID) {
                return;
            }
            const peersInMesh = this.mesh.get(topicID);
            if (!peersInMesh) {
                // don't do PX when there is an unknown topic to avoid leaking our peers
                doPX = false;
                // spam hardening: ignore GRAFTs for unknown topics
                return;
            }
            // check if peer is already in the mesh; if so do nothing
            if (peersInMesh.has(id)) {
                return;
            }
            // we don't GRAFT to/from direct peers; complain loudly if this happens
            if (this.direct.has(id)) {
                this.log('GRAFT: ignoring request from direct peer %s', id);
                // this is possibly a bug from a non-reciprical configuration; send a PRUNE
                prune.push(topicID);
                // but don't px
                doPX = false;
                return;
            }
            // make sure we are not backing off that peer
            const expire = this.backoff.get(topicID)?.get(id);
            if (typeof expire === 'number' && now < expire) {
                this.log('GRAFT: ignoring backed off peer %s', id);
                // add behavioral penalty
                this.score.addPenalty(id, 1, ScorePenalty.GraftBackoff);
                // no PX
                doPX = false;
                // check the flood cutoff -- is the GRAFT coming too fast?
                const floodCutoff = expire + this.opts.graftFloodThreshold - this.opts.pruneBackoff;
                if (now < floodCutoff) {
                    // extra penalty
                    this.score.addPenalty(id, 1, ScorePenalty.GraftBackoff);
                }
                // refresh the backoff
                this.addBackoff(id, topicID);
                prune.push(topicID);
                return;
            }
            // check the score
            if (score < 0) {
                // we don't GRAFT peers with negative score
                this.log('GRAFT: ignoring peer %s with negative score: score=%d, topic=%s', id, score, topicID);
                // we do send them PRUNE however, because it's a matter of protocol correctness
                prune.push(topicID);
                // but we won't PX to them
                doPX = false;
                // add/refresh backoff so that we don't reGRAFT too early even if the score decays
                this.addBackoff(id, topicID);
                return;
            }
            // check the number of mesh peers; if it is at (or over) Dhi, we only accept grafts
            // from peers with outbound connections; this is a defensive check to restrict potential
            // mesh takeover attacks combined with love bombing
            if (peersInMesh.size >= this.opts.Dhi && !this.outbound.get(id)) {
                prune.push(topicID);
                this.addBackoff(id, topicID);
                return;
            }
            this.log('GRAFT: Add mesh link from %s in %s', id, topicID);
            this.score.graft(id, topicID);
            peersInMesh.add(id);
            this.metrics?.onAddToMesh(topicID, InclusionReason.Subscribed, 1);
        });
        if (!prune.length) {
            return [];
        }
        const onUnsubscribe = false;
        return await Promise.all(prune.map((topic) => this.makePrune(id, topic, doPX, onUnsubscribe)));
    }
    /**
     * Handles Prune messages
     */
    async handlePrune(id, prune) {
        const score = this.score.score(id);
        for (const { topicID, backoff, peers } of prune) {
            if (topicID == null) {
                continue;
            }
            const peersInMesh = this.mesh.get(topicID);
            if (!peersInMesh) {
                return;
            }
            this.log('PRUNE: Remove mesh link to %s in %s', id, topicID);
            this.score.prune(id, topicID);
            if (peersInMesh.has(id)) {
                peersInMesh.delete(id);
                this.metrics?.onRemoveFromMesh(topicID, ChurnReason.Prune, 1);
            }
            // is there a backoff specified by the peer? if so obey it
            if (typeof backoff === 'number' && backoff > 0) {
                this.doAddBackoff(id, topicID, backoff * 1000);
            }
            else {
                this.addBackoff(id, topicID);
            }
            // PX
            if (peers && peers.length) {
                // we ignore PX from peers with insufficient scores
                if (score < this.opts.scoreThresholds.acceptPXThreshold) {
                    this.log('PRUNE: ignoring PX from peer %s with insufficient score [score = %d, topic = %s]', id, score, topicID);
                    continue;
                }
                await this.pxConnect(peers);
            }
        }
    }
    /**
     * Add standard backoff log for a peer in a topic
     */
    addBackoff(id, topic) {
        this.doAddBackoff(id, topic, this.opts.pruneBackoff);
    }
    /**
     * Add backoff expiry interval for a peer in a topic
     *
     * @param id
     * @param topic
     * @param intervalMs - backoff duration in milliseconds
     */
    doAddBackoff(id, topic, intervalMs) {
        let backoff = this.backoff.get(topic);
        if (!backoff) {
            backoff = new Map();
            this.backoff.set(topic, backoff);
        }
        const expire = Date.now() + intervalMs;
        const existingExpire = backoff.get(id) ?? 0;
        if (existingExpire < expire) {
            backoff.set(id, expire);
        }
    }
    /**
     * Apply penalties from broken IHAVE/IWANT promises
     */
    applyIwantPenalties() {
        this.gossipTracer.getBrokenPromises().forEach((count, p) => {
            this.log("peer %s didn't follow up in %d IWANT requests; adding penalty", p, count);
            this.score.addPenalty(p, count, ScorePenalty.BrokenPromise);
        });
    }
    /**
     * Clear expired backoff expiries
     */
    clearBackoff() {
        // we only clear once every GossipsubPruneBackoffTicks ticks to avoid iterating over the maps too much
        if (this.heartbeatTicks % GossipsubPruneBackoffTicks !== 0) {
            return;
        }
        const now = Date.now();
        this.backoff.forEach((backoff, topic) => {
            backoff.forEach((expire, id) => {
                // add some slack time to the expiration, see https://github.com/libp2p/specs/pull/289
                if (expire + BACKOFF_SLACK * this.opts.heartbeatInterval < now) {
                    backoff.delete(id);
                }
            });
            if (backoff.size === 0) {
                this.backoff.delete(topic);
            }
        });
    }
    /**
     * Maybe reconnect to direct peers
     */
    async directConnect() {
        const toconnect = [];
        this.direct.forEach((id) => {
            if (!this.streamsOutbound.has(id)) {
                toconnect.push(id);
            }
        });
        await Promise.all(toconnect.map(async (id) => await this.connect(id)));
    }
    /**
     * Maybe attempt connection given signed peer records
     */
    async pxConnect(peers) {
        if (peers.length > this.opts.prunePeers) {
            shuffle(peers);
            peers = peers.slice(0, this.opts.prunePeers);
        }
        const toconnect = [];
        await Promise.all(peers.map(async (pi) => {
            if (!pi.peerID) {
                return;
            }
            const peer = peerIdFromBytes(pi.peerID);
            const p = peer.toString();
            if (this.peers.has(p)) {
                return;
            }
            if (!pi.signedPeerRecord) {
                toconnect.push(p);
                return;
            }
            // The peer sent us a signed record
            // This is not a record from the peer who sent the record, but another peer who is connected with it
            // Ensure that it is valid
            try {
                if (!(await this.components.peerStore.consumePeerRecord(pi.signedPeerRecord, peer))) {
                    this.log('bogus peer record obtained through px: could not add peer record to address book');
                    return;
                }
                toconnect.push(p);
            }
            catch (e) {
                this.log('bogus peer record obtained through px: invalid signature or not a peer record');
            }
        }));
        if (!toconnect.length) {
            return;
        }
        await Promise.all(toconnect.map(async (id) => await this.connect(id)));
    }
    /**
     * Connect to a peer using the gossipsub protocol
     */
    async connect(id) {
        this.log('Initiating connection with %s', id);
        const peerId = peerIdFromString(id);
        const connection = await this.components.connectionManager.openConnection(peerId);
        for (const multicodec of this.multicodecs) {
            for (const topology of this.components.registrar.getTopologies(multicodec)) {
                topology.onConnect?.(peerId, connection);
            }
        }
    }
    /**
     * Subscribes to a topic
     */
    subscribe(topic) {
        if (this.status.code !== GossipStatusCode.started) {
            throw new Error('Pubsub has not started');
        }
        if (!this.subscriptions.has(topic)) {
            this.subscriptions.add(topic);
            for (const peerId of this.peers.keys()) {
                this.sendSubscriptions(peerId, [topic], true);
            }
        }
        this.join(topic);
    }
    /**
     * Unsubscribe to a topic
     */
    unsubscribe(topic) {
        if (this.status.code !== GossipStatusCode.started) {
            throw new Error('Pubsub is not started');
        }
        const wasSubscribed = this.subscriptions.delete(topic);
        this.log('unsubscribe from %s - am subscribed %s', topic, wasSubscribed);
        if (wasSubscribed) {
            for (const peerId of this.peers.keys()) {
                this.sendSubscriptions(peerId, [topic], false);
            }
        }
        this.leave(topic);
    }
    /**
     * Join topic
     */
    join(topic) {
        if (this.status.code !== GossipStatusCode.started) {
            throw new Error('Gossipsub has not started');
        }
        // if we are already in the mesh, return
        if (this.mesh.has(topic)) {
            return;
        }
        this.log('JOIN %s', topic);
        this.metrics?.onJoin(topic);
        const toAdd = new Set();
        const backoff = this.backoff.get(topic);
        // check if we have mesh_n peers in fanout[topic] and add them to the mesh if we do,
        // removing the fanout entry.
        const fanoutPeers = this.fanout.get(topic);
        if (fanoutPeers) {
            // Remove fanout entry and the last published time
            this.fanout.delete(topic);
            this.fanoutLastpub.delete(topic);
            // remove explicit peers, peers with negative scores, and backoffed peers
            fanoutPeers.forEach((id) => {
                if (!this.direct.has(id) && this.score.score(id) >= 0 && (!backoff || !backoff.has(id))) {
                    toAdd.add(id);
                }
            });
            this.metrics?.onAddToMesh(topic, InclusionReason.Fanout, toAdd.size);
        }
        // check if we need to get more peers, which we randomly select
        if (toAdd.size < this.opts.D) {
            const fanoutCount = toAdd.size;
            const newPeers = this.getRandomGossipPeers(topic, this.opts.D, (id) => 
            // filter direct peers and peers with negative score
            !toAdd.has(id) && !this.direct.has(id) && this.score.score(id) >= 0 && (!backoff || !backoff.has(id)));
            newPeers.forEach((peer) => {
                toAdd.add(peer);
            });
            this.metrics?.onAddToMesh(topic, InclusionReason.Random, toAdd.size - fanoutCount);
        }
        this.mesh.set(topic, toAdd);
        toAdd.forEach((id) => {
            this.log('JOIN: Add mesh link to %s in %s', id, topic);
            this.sendGraft(id, topic);
            // rust-libp2p
            // - peer_score.graft()
            // - Self::control_pool_add()
            // - peer_added_to_mesh()
        });
    }
    /**
     * Leave topic
     */
    leave(topic) {
        if (this.status.code !== GossipStatusCode.started) {
            throw new Error('Gossipsub has not started');
        }
        this.log('LEAVE %s', topic);
        this.metrics?.onLeave(topic);
        // Send PRUNE to mesh peers
        const meshPeers = this.mesh.get(topic);
        if (meshPeers) {
            Promise.all(Array.from(meshPeers).map(async (id) => {
                this.log('LEAVE: Remove mesh link to %s in %s', id, topic);
                return await this.sendPrune(id, topic);
            })).catch((err) => {
                this.log('Error sending prunes to mesh peers', err);
            });
            this.mesh.delete(topic);
        }
    }
    selectPeersToForward(topic, propagationSource, excludePeers) {
        const tosend = new Set();
        // Add explicit peers
        const peersInTopic = this.topics.get(topic);
        if (peersInTopic) {
            this.direct.forEach((peer) => {
                if (peersInTopic.has(peer) && propagationSource !== peer && !excludePeers?.has(peer)) {
                    tosend.add(peer);
                }
            });
            // As of Mar 2022, spec + golang-libp2p include this while rust-libp2p does not
            // rust-libp2p: https://github.com/libp2p/rust-libp2p/blob/6cc3b4ec52c922bfcf562a29b5805c3150e37c75/protocols/gossipsub/src/behaviour.rs#L2693
            // spec: https://github.com/libp2p/specs/blob/10712c55ab309086a52eec7d25f294df4fa96528/pubsub/gossipsub/gossipsub-v1.0.md?plain=1#L361
            this.floodsubPeers.forEach((peer) => {
                if (peersInTopic.has(peer) &&
                    propagationSource !== peer &&
                    !excludePeers?.has(peer) &&
                    this.score.score(peer) >= this.opts.scoreThresholds.publishThreshold) {
                    tosend.add(peer);
                }
            });
        }
        // add mesh peers
        const meshPeers = this.mesh.get(topic);
        if (meshPeers && meshPeers.size > 0) {
            meshPeers.forEach((peer) => {
                if (propagationSource !== peer && !excludePeers?.has(peer)) {
                    tosend.add(peer);
                }
            });
        }
        return tosend;
    }
    selectPeersToPublish(topic) {
        const tosend = new Set();
        const tosendCount = {
            direct: 0,
            floodsub: 0,
            mesh: 0,
            fanout: 0
        };
        const peersInTopic = this.topics.get(topic);
        if (peersInTopic) {
            // flood-publish behavior
            // send to direct peers and _all_ peers meeting the publishThreshold
            if (this.opts.floodPublish) {
                peersInTopic.forEach((id) => {
                    if (this.direct.has(id)) {
                        tosend.add(id);
                        tosendCount.direct++;
                    }
                    else if (this.score.score(id) >= this.opts.scoreThresholds.publishThreshold) {
                        tosend.add(id);
                        tosendCount.floodsub++;
                    }
                });
            }
            else {
                // non-flood-publish behavior
                // send to direct peers, subscribed floodsub peers
                // and some mesh peers above publishThreshold
                // direct peers (if subscribed)
                this.direct.forEach((id) => {
                    if (peersInTopic.has(id)) {
                        tosend.add(id);
                        tosendCount.direct++;
                    }
                });
                // floodsub peers
                // Note: if there are no floodsub peers, we save a loop through peersInTopic Map
                this.floodsubPeers.forEach((id) => {
                    if (peersInTopic.has(id) && this.score.score(id) >= this.opts.scoreThresholds.publishThreshold) {
                        tosend.add(id);
                        tosendCount.floodsub++;
                    }
                });
                // Gossipsub peers handling
                const meshPeers = this.mesh.get(topic);
                if (meshPeers && meshPeers.size > 0) {
                    meshPeers.forEach((peer) => {
                        tosend.add(peer);
                        tosendCount.mesh++;
                    });
                }
                // We are not in the mesh for topic, use fanout peers
                else {
                    const fanoutPeers = this.fanout.get(topic);
                    if (fanoutPeers && fanoutPeers.size > 0) {
                        fanoutPeers.forEach((peer) => {
                            tosend.add(peer);
                            tosendCount.fanout++;
                        });
                    }
                    // We have no fanout peers, select mesh_n of them and add them to the fanout
                    else {
                        // If we are not in the fanout, then pick peers in topic above the publishThreshold
                        const newFanoutPeers = this.getRandomGossipPeers(topic, this.opts.D, (id) => {
                            return this.score.score(id) >= this.opts.scoreThresholds.publishThreshold;
                        });
                        if (newFanoutPeers.size > 0) {
                            // eslint-disable-line max-depth
                            this.fanout.set(topic, newFanoutPeers);
                            newFanoutPeers.forEach((peer) => {
                                // eslint-disable-line max-depth
                                tosend.add(peer);
                                tosendCount.fanout++;
                            });
                        }
                    }
                    // We are publishing to fanout peers - update the time we published
                    this.fanoutLastpub.set(topic, Date.now());
                }
            }
        }
        return { tosend, tosendCount };
    }
    /**
     * Forwards a message from our peers.
     *
     * For messages published by us (the app layer), this class uses `publish`
     */
    forwardMessage(msgIdStr, rawMsg, propagationSource, excludePeers) {
        // message is fully validated inform peer_score
        if (propagationSource) {
            this.score.deliverMessage(propagationSource, msgIdStr, rawMsg.topic);
        }
        const tosend = this.selectPeersToForward(rawMsg.topic, propagationSource, excludePeers);
        // Note: Don't throw if tosend is empty, we can have a mesh with a single peer
        // forward the message to peers
        tosend.forEach((id) => {
            // sendRpc may mutate RPC message on piggyback, create a new message for each peer
            this.sendRpc(id, { messages: [rawMsg] });
        });
        this.metrics?.onForwardMsg(rawMsg.topic, tosend.size);
    }
    /**
     * App layer publishes a message to peers, return number of peers this message is published to
     * Note: `async` due to crypto only if `StrictSign`, otherwise it's a sync fn.
     *
     * For messages not from us, this class uses `forwardMessage`.
     */
    async publish(topic, data, opts) {
        const startMs = Date.now();
        const transformedData = this.dataTransform ? this.dataTransform.outboundTransform(topic, data) : data;
        if (this.publishConfig == null) {
            throw Error('PublishError.Uninitialized');
        }
        // Prepare raw message with user's publishConfig
        const { raw: rawMsg, msg } = await buildRawMessage(this.publishConfig, topic, data, transformedData);
        // calculate the message id from the un-transformed data
        const msgId = await this.msgIdFn(msg);
        const msgIdStr = this.msgIdToStrFn(msgId);
        // Current publish opt takes precedence global opts, while preserving false value
        const ignoreDuplicatePublishError = opts?.ignoreDuplicatePublishError ?? this.opts.ignoreDuplicatePublishError;
        if (this.seenCache.has(msgIdStr)) {
            // This message has already been seen. We don't re-publish messages that have already
            // been published on the network.
            if (ignoreDuplicatePublishError) {
                this.metrics?.onPublishDuplicateMsg(topic);
                return { recipients: [] };
            }
            throw Error('PublishError.Duplicate');
        }
        const { tosend, tosendCount } = this.selectPeersToPublish(topic);
        const willSendToSelf = this.opts.emitSelf === true && this.subscriptions.has(topic);
        // Current publish opt takes precedence global opts, while preserving false value
        const allowPublishToZeroPeers = opts?.allowPublishToZeroPeers ?? this.opts.allowPublishToZeroPeers;
        if (tosend.size === 0 && !allowPublishToZeroPeers && !willSendToSelf) {
            throw Error('PublishError.InsufficientPeers');
        }
        // If the message isn't a duplicate and we have sent it to some peers add it to the
        // duplicate cache and memcache.
        this.seenCache.put(msgIdStr);
        // all published messages are valid
        this.mcache.put({ msgId, msgIdStr }, rawMsg, true);
        // If the message is anonymous or has a random author add it to the published message ids cache.
        this.publishedMessageIds.put(msgIdStr);
        // Send to set of peers aggregated from direct, mesh, fanout
        for (const id of tosend) {
            // sendRpc may mutate RPC message on piggyback, create a new message for each peer
            const sent = this.sendRpc(id, { messages: [rawMsg] });
            // did not actually send the message
            if (!sent) {
                tosend.delete(id);
            }
        }
        const durationMs = Date.now() - startMs;
        this.metrics?.onPublishMsg(topic, tosendCount, tosend.size, rawMsg.data != null ? rawMsg.data.length : 0, durationMs);
        // Dispatch the message to the user if we are subscribed to the topic
        if (willSendToSelf) {
            tosend.add(this.components.peerId.toString());
            super.dispatchEvent(new CustomEvent('gossipsub:message', {
                detail: {
                    propagationSource: this.components.peerId,
                    msgId: msgIdStr,
                    msg
                }
            }));
            // TODO: Add option to switch between emit per topic or all messages in one
            super.dispatchEvent(new CustomEvent('message', { detail: msg }));
        }
        return {
            recipients: Array.from(tosend.values()).map((str) => peerIdFromString(str))
        };
    }
    /**
     * This function should be called when `asyncValidation` is `true` after
     * the message got validated by the caller. Messages are stored in the `mcache` and
     * validation is expected to be fast enough that the messages should still exist in the cache.
     * There are three possible validation outcomes and the outcome is given in acceptance.
     *
     * If acceptance = `MessageAcceptance.Accept` the message will get propagated to the
     * network. The `propagation_source` parameter indicates who the message was received by and
     * will not be forwarded back to that peer.
     *
     * If acceptance = `MessageAcceptance.Reject` the message will be deleted from the memcache
     * and the P₄ penalty will be applied to the `propagationSource`.
     *
     * If acceptance = `MessageAcceptance.Ignore` the message will be deleted from the memcache
     * but no P₄ penalty will be applied.
     *
     * This function will return true if the message was found in the cache and false if was not
     * in the cache anymore.
     *
     * This should only be called once per message.
     */
    reportMessageValidationResult(msgId, propagationSource, acceptance) {
        let cacheEntry;
        if (acceptance === TopicValidatorResult.Accept) {
            cacheEntry = this.mcache.validate(msgId);
            if (cacheEntry != null) {
                const { message: rawMsg, originatingPeers } = cacheEntry;
                // message is fully validated inform peer_score
                this.score.deliverMessage(propagationSource, msgId, rawMsg.topic);
                this.forwardMessage(msgId, cacheEntry.message, propagationSource, originatingPeers);
            }
            // else, Message not in cache. Ignoring forwarding
        }
        // Not valid
        else {
            cacheEntry = this.mcache.remove(msgId);
            if (cacheEntry) {
                const rejectReason = rejectReasonFromAcceptance(acceptance);
                const { message: rawMsg, originatingPeers } = cacheEntry;
                // Tell peer_score about reject
                // Reject the original source, and any duplicates we've seen from other peers.
                this.score.rejectMessage(propagationSource, msgId, rawMsg.topic, rejectReason);
                for (const peer of originatingPeers) {
                    this.score.rejectMessage(peer, msgId, rawMsg.topic, rejectReason);
                }
            }
            // else, Message not in cache. Ignoring forwarding
        }
        const firstSeenTimestampMs = this.score.messageFirstSeenTimestampMs(msgId);
        this.metrics?.onReportValidation(cacheEntry, acceptance, firstSeenTimestampMs);
    }
    /**
     * Sends a GRAFT message to a peer
     */
    sendGraft(id, topic) {
        const graft = [
            {
                topicID: topic
            }
        ];
        this.sendRpc(id, { control: { graft } });
    }
    /**
     * Sends a PRUNE message to a peer
     */
    async sendPrune(id, topic) {
        // this is only called from leave() function
        const onUnsubscribe = true;
        const prune = [await this.makePrune(id, topic, this.opts.doPX, onUnsubscribe)];
        this.sendRpc(id, { control: { prune } });
    }
    /**
     * Send an rpc object to a peer
     */
    sendRpc(id, rpc) {
        const outboundStream = this.streamsOutbound.get(id);
        if (!outboundStream) {
            this.log(`Cannot send RPC to ${id} as there is no open stream to it available`);
            return false;
        }
        // piggyback control message retries
        const ctrl = this.control.get(id);
        if (ctrl) {
            this.piggybackControl(id, rpc, ctrl);
            this.control.delete(id);
        }
        // piggyback gossip
        const ihave = this.gossip.get(id);
        if (ihave) {
            this.piggybackGossip(id, rpc, ihave);
            this.gossip.delete(id);
        }
        const rpcBytes = RPC.encode(rpc).finish();
        try {
            outboundStream.push(rpcBytes);
        }
        catch (e) {
            this.log.error(`Cannot send rpc to ${id}`, e);
            // if the peer had control messages or gossip, re-attach
            if (ctrl) {
                this.control.set(id, ctrl);
            }
            if (ihave) {
                this.gossip.set(id, ihave);
            }
            return false;
        }
        this.metrics?.onRpcSent(rpc, rpcBytes.length);
        return true;
    }
    /** Mutates `outRpc` adding graft and prune control messages */
    piggybackControl(id, outRpc, ctrl) {
        if (ctrl.graft) {
            if (!outRpc.control)
                outRpc.control = {};
            if (!outRpc.control.graft)
                outRpc.control.graft = [];
            for (const graft of ctrl.graft) {
                if (graft.topicID && this.mesh.get(graft.topicID)?.has(id)) {
                    outRpc.control.graft.push(graft);
                }
            }
        }
        if (ctrl.prune) {
            if (!outRpc.control)
                outRpc.control = {};
            if (!outRpc.control.prune)
                outRpc.control.prune = [];
            for (const prune of ctrl.prune) {
                if (prune.topicID && !this.mesh.get(prune.topicID)?.has(id)) {
                    outRpc.control.prune.push(prune);
                }
            }
        }
    }
    /** Mutates `outRpc` adding ihave control messages */
    piggybackGossip(id, outRpc, ihave) {
        if (!outRpc.control)
            outRpc.control = {};
        outRpc.control.ihave = ihave;
    }
    /**
     * Send graft and prune messages
     *
     * @param tograft - peer id => topic[]
     * @param toprune - peer id => topic[]
     */
    async sendGraftPrune(tograft, toprune, noPX) {
        const doPX = this.opts.doPX;
        const onUnsubscribe = false;
        for (const [id, topics] of tograft) {
            const graft = topics.map((topicID) => ({ topicID }));
            let prune = [];
            // If a peer also has prunes, process them now
            const pruning = toprune.get(id);
            if (pruning) {
                prune = await Promise.all(pruning.map(async (topicID) => await this.makePrune(id, topicID, doPX && !(noPX.get(id) ?? false), onUnsubscribe)));
                toprune.delete(id);
            }
            this.sendRpc(id, { control: { graft, prune } });
        }
        for (const [id, topics] of toprune) {
            const prune = await Promise.all(topics.map(async (topicID) => await this.makePrune(id, topicID, doPX && !(noPX.get(id) ?? false), onUnsubscribe)));
            this.sendRpc(id, { control: { prune } });
        }
    }
    /**
     * Emits gossip - Send IHAVE messages to a random set of gossip peers
     */
    emitGossip(peersToGossipByTopic) {
        const gossipIDsByTopic = this.mcache.getGossipIDs(new Set(peersToGossipByTopic.keys()));
        for (const [topic, peersToGossip] of peersToGossipByTopic) {
            this.doEmitGossip(topic, peersToGossip, gossipIDsByTopic.get(topic) ?? []);
        }
    }
    /**
     * Send gossip messages to GossipFactor peers above threshold with a minimum of D_lazy
     * Peers are randomly selected from the heartbeat which exclude mesh + fanout peers
     * We also exclude direct peers, as there is no reason to emit gossip to them
     * @param topic
     * @param candidateToGossip - peers to gossip
     * @param messageIDs - message ids to gossip
     */
    doEmitGossip(topic, candidateToGossip, messageIDs) {
        if (!messageIDs.length) {
            return;
        }
        // shuffle to emit in random order
        shuffle(messageIDs);
        // if we are emitting more than GossipsubMaxIHaveLength ids, truncate the list
        if (messageIDs.length > GossipsubMaxIHaveLength) {
            // we do the truncation (with shuffling) per peer below
            this.log('too many messages for gossip; will truncate IHAVE list (%d messages)', messageIDs.length);
        }
        if (!candidateToGossip.size)
            return;
        let target = this.opts.Dlazy;
        const factor = GossipsubGossipFactor * candidateToGossip.size;
        let peersToGossip = candidateToGossip;
        if (factor > target) {
            target = factor;
        }
        if (target > peersToGossip.size) {
            target = peersToGossip.size;
        }
        else {
            // only shuffle if needed
            peersToGossip = shuffle(Array.from(peersToGossip)).slice(0, target);
        }
        // Emit the IHAVE gossip to the selected peers up to the target
        peersToGossip.forEach((id) => {
            let peerMessageIDs = messageIDs;
            if (messageIDs.length > GossipsubMaxIHaveLength) {
                // shuffle and slice message IDs per peer so that we emit a different set for each peer
                // we have enough reduncancy in the system that this will significantly increase the message
                // coverage when we do truncate
                peerMessageIDs = shuffle(peerMessageIDs.slice()).slice(0, GossipsubMaxIHaveLength);
            }
            this.pushGossip(id, {
                topicID: topic,
                messageIDs: peerMessageIDs
            });
        });
    }
    /**
     * Flush gossip and control messages
     */
    flush() {
        // send gossip first, which will also piggyback control
        for (const [peer, ihave] of this.gossip.entries()) {
            this.gossip.delete(peer);
            this.sendRpc(peer, { control: { ihave } });
        }
        // send the remaining control messages
        for (const [peer, control] of this.control.entries()) {
            this.control.delete(peer);
            this.sendRpc(peer, { control: { graft: control.graft, prune: control.prune } });
        }
    }
    /**
     * Adds new IHAVE messages to pending gossip
     */
    pushGossip(id, controlIHaveMsgs) {
        this.log('Add gossip to %s', id);
        const gossip = this.gossip.get(id) || [];
        this.gossip.set(id, gossip.concat(controlIHaveMsgs));
    }
    /**
     * Make a PRUNE control message for a peer in a topic
     */
    async makePrune(id, topic, doPX, onUnsubscribe) {
        this.score.prune(id, topic);
        if (this.streamsOutbound.get(id).protocol === GossipsubIDv10) {
            // Gossipsub v1.0 -- no backoff, the peer won't be able to parse it anyway
            return {
                topicID: topic,
                peers: []
            };
        }
        // backoff is measured in seconds
        // GossipsubPruneBackoff and GossipsubUnsubscribeBackoff are measured in milliseconds
        // The protobuf has it as a uint64
        const backoffMs = onUnsubscribe ? this.opts.unsubcribeBackoff : this.opts.pruneBackoff;
        const backoff = backoffMs / 1000;
        this.doAddBackoff(id, topic, backoffMs);
        if (!doPX) {
            return {
                topicID: topic,
                peers: [],
                backoff: backoff
            };
        }
        // select peers for Peer eXchange
        const peers = this.getRandomGossipPeers(topic, this.opts.prunePeers, (xid) => {
            return xid !== id && this.score.score(xid) >= 0;
        });
        const px = await Promise.all(Array.from(peers).map(async (peerId) => {
            // see if we have a signed record to send back; if we don't, just send
            // the peer ID and let the pruned peer find them in the DHT -- we can't trust
            // unsigned address records through PX anyways
            // Finding signed records in the DHT is not supported at the time of writing in js-libp2p
            const id = peerIdFromString(peerId);
            let peerInfo;
            try {
                peerInfo = await this.components.peerStore.get(id);
            }
            catch (err) {
                if (err.code !== 'ERR_NOT_FOUND') {
                    throw err;
                }
            }
            return {
                peerID: id.toBytes(),
                signedPeerRecord: peerInfo?.peerRecordEnvelope
            };
        }));
        return {
            topicID: topic,
            peers: px,
            backoff: backoff
        };
    }
    runHeartbeat = () => {
        const timer = this.metrics?.heartbeatDuration.startTimer();
        this.heartbeat()
            .catch((err) => {
            this.log('Error running heartbeat', err);
        })
            .finally(() => {
            if (timer != null) {
                timer();
            }
            // Schedule the next run if still in started status
            if (this.status.code === GossipStatusCode.started) {
                // Clear previous timeout before overwriting `status.heartbeatTimeout`, it should be completed tho.
                clearTimeout(this.status.heartbeatTimeout);
                // NodeJS setInterval function is innexact, calls drift by a few miliseconds on each call.
                // To run the heartbeat precisely setTimeout() must be used recomputing the delay on every loop.
                let msToNextHeartbeat = this.opts.heartbeatInterval - ((Date.now() - this.status.hearbeatStartMs) % this.opts.heartbeatInterval);
                // If too close to next heartbeat, skip one
                if (msToNextHeartbeat < this.opts.heartbeatInterval * 0.25) {
                    msToNextHeartbeat += this.opts.heartbeatInterval;
                    this.metrics?.heartbeatSkipped.inc();
                }
                this.status.heartbeatTimeout = setTimeout(this.runHeartbeat, msToNextHeartbeat);
            }
        });
    };
    /**
     * Maintains the mesh and fanout maps in gossipsub.
     */
    async heartbeat() {
        const { D, Dlo, Dhi, Dscore, Dout, fanoutTTL } = this.opts;
        this.heartbeatTicks++;
        // cache scores throught the heartbeat
        const scores = new Map();
        const getScore = (id) => {
            let s = scores.get(id);
            if (s === undefined) {
                s = this.score.score(id);
                scores.set(id, s);
            }
            return s;
        };
        // peer id => topic[]
        const tograft = new Map();
        // peer id => topic[]
        const toprune = new Map();
        // peer id => don't px
        const noPX = new Map();
        // clean up expired backoffs
        this.clearBackoff();
        // clean up peerhave/iasked counters
        this.peerhave.clear();
        this.metrics?.cacheSize.set({ cache: 'iasked' }, this.iasked.size);
        this.iasked.clear();
        // apply IWANT request penalties
        this.applyIwantPenalties();
        // ensure direct peers are connected
        if (this.heartbeatTicks % this.opts.directConnectTicks === 0) {
            // we only do this every few ticks to allow pending connections to complete and account for restarts/downtime
            await this.directConnect();
        }
        // EXTRA: Prune caches
        this.fastMsgIdCache?.prune();
        this.seenCache.prune();
        this.gossipTracer.prune();
        this.publishedMessageIds.prune();
        /**
         * Instead of calling getRandomGossipPeers multiple times to:
         *   + get more mesh peers
         *   + more outbound peers
         *   + oppportunistic grafting
         *   + emitGossip
         *
         * We want to loop through the topic peers only a single time and prepare gossip peers for all topics to improve the performance
         */
        const peersToGossipByTopic = new Map();
        // maintain the mesh for topics we have joined
        this.mesh.forEach((peers, topic) => {
            const peersInTopic = this.topics.get(topic);
            const candidateMeshPeers = new Set();
            const peersToGossip = new Set();
            peersToGossipByTopic.set(topic, peersToGossip);
            if (peersInTopic) {
                const shuffledPeers = shuffle(Array.from(peersInTopic));
                const backoff = this.backoff.get(topic);
                for (const id of shuffledPeers) {
                    const peerStreams = this.streamsOutbound.get(id);
                    if (peerStreams &&
                        this.multicodecs.includes(peerStreams.protocol) &&
                        !peers.has(id) &&
                        !this.direct.has(id)) {
                        const score = getScore(id);
                        if ((!backoff || !backoff.has(id)) && score >= 0)
                            candidateMeshPeers.add(id);
                        // instead of having to find gossip peers after heartbeat which require another loop
                        // we prepare peers to gossip in a topic within heartbeat to improve performance
                        if (score >= this.opts.scoreThresholds.gossipThreshold)
                            peersToGossip.add(id);
                    }
                }
            }
            // prune/graft helper functions (defined per topic)
            const prunePeer = (id, reason) => {
                this.log('HEARTBEAT: Remove mesh link to %s in %s', id, topic);
                // no need to update peer score here as we do it in makePrune
                // add prune backoff record
                this.addBackoff(id, topic);
                // remove peer from mesh
                peers.delete(id);
                // after pruning a peer from mesh, we want to gossip topic to it if its score meet the gossip threshold
                if (getScore(id) >= this.opts.scoreThresholds.gossipThreshold)
                    peersToGossip.add(id);
                this.metrics?.onRemoveFromMesh(topic, reason, 1);
                // add to toprune
                const topics = toprune.get(id);
                if (!topics) {
                    toprune.set(id, [topic]);
                }
                else {
                    topics.push(topic);
                }
            };
            const graftPeer = (id, reason) => {
                this.log('HEARTBEAT: Add mesh link to %s in %s', id, topic);
                // update peer score
                this.score.graft(id, topic);
                // add peer to mesh
                peers.add(id);
                // when we add a new mesh peer, we don't want to gossip messages to it
                peersToGossip.delete(id);
                this.metrics?.onAddToMesh(topic, reason, 1);
                // add to tograft
                const topics = tograft.get(id);
                if (!topics) {
                    tograft.set(id, [topic]);
                }
                else {
                    topics.push(topic);
                }
            };
            // drop all peers with negative score, without PX
            peers.forEach((id) => {
                const score = getScore(id);
                // Record the score
                if (score < 0) {
                    this.log('HEARTBEAT: Prune peer %s with negative score: score=%d, topic=%s', id, score, topic);
                    prunePeer(id, ChurnReason.BadScore);
                    noPX.set(id, true);
                }
            });
            // do we have enough peers?
            if (peers.size < Dlo) {
                const ineed = D - peers.size;
                // slice up to first `ineed` items and remove them from candidateMeshPeers
                // same to `const newMeshPeers = candidateMeshPeers.slice(0, ineed)`
                const newMeshPeers = removeFirstNItemsFromSet(candidateMeshPeers, ineed);
                newMeshPeers.forEach((p) => {
                    graftPeer(p, InclusionReason.NotEnough);
                });
            }
            // do we have to many peers?
            if (peers.size > Dhi) {
                let peersArray = Array.from(peers);
                // sort by score
                peersArray.sort((a, b) => getScore(b) - getScore(a));
                // We keep the first D_score peers by score and the remaining up to D randomly
                // under the constraint that we keep D_out peers in the mesh (if we have that many)
                peersArray = peersArray.slice(0, Dscore).concat(shuffle(peersArray.slice(Dscore)));
                // count the outbound peers we are keeping
                let outbound = 0;
                peersArray.slice(0, D).forEach((p) => {
                    if (this.outbound.get(p)) {
                        outbound++;
                    }
                });
                // if it's less than D_out, bubble up some outbound peers from the random selection
                if (outbound < Dout) {
                    const rotate = (i) => {
                        // rotate the peersArray to the right and put the ith peer in the front
                        const p = peersArray[i];
                        for (let j = i; j > 0; j--) {
                            peersArray[j] = peersArray[j - 1];
                        }
                        peersArray[0] = p;
                    };
                    // first bubble up all outbound peers already in the selection to the front
                    if (outbound > 0) {
                        let ihave = outbound;
                        for (let i = 1; i < D && ihave > 0; i++) {
                            if (this.outbound.get(peersArray[i])) {
                                rotate(i);
                                ihave--;
                            }
                        }
                    }
                    // now bubble up enough outbound peers outside the selection to the front
                    let ineed = D - outbound;
                    for (let i = D; i < peersArray.length && ineed > 0; i++) {
                        if (this.outbound.get(peersArray[i])) {
                            rotate(i);
                            ineed--;
                        }
                    }
                }
                // prune the excess peers
                peersArray.slice(D).forEach((p) => {
                    prunePeer(p, ChurnReason.Excess);
                });
            }
            // do we have enough outbound peers?
            if (peers.size >= Dlo) {
                // count the outbound peers we have
                let outbound = 0;
                peers.forEach((p) => {
                    if (this.outbound.get(p)) {
                        outbound++;
                    }
                });
                // if it's less than D_out, select some peers with outbound connections and graft them
                if (outbound < Dout) {
                    const ineed = Dout - outbound;
                    const newMeshPeers = removeItemsFromSet(candidateMeshPeers, ineed, (id) => this.outbound.get(id) === true);
                    newMeshPeers.forEach((p) => {
                        graftPeer(p, InclusionReason.Outbound);
                    });
                }
            }
            // should we try to improve the mesh with opportunistic grafting?
            if (this.heartbeatTicks % this.opts.opportunisticGraftTicks === 0 && peers.size > 1) {
                // Opportunistic grafting works as follows: we check the median score of peers in the
                // mesh; if this score is below the opportunisticGraftThreshold, we select a few peers at
                // random with score over the median.
                // The intention is to (slowly) improve an underperforming mesh by introducing good
                // scoring peers that may have been gossiping at us. This allows us to get out of sticky
                // situations where we are stuck with poor peers and also recover from churn of good peers.
                // now compute the median peer score in the mesh
                const peersList = Array.from(peers).sort((a, b) => getScore(a) - getScore(b));
                const medianIndex = Math.floor(peers.size / 2);
                const medianScore = getScore(peersList[medianIndex]);
                // if the median score is below the threshold, select a better peer (if any) and GRAFT
                if (medianScore < this.opts.scoreThresholds.opportunisticGraftThreshold) {
                    const ineed = this.opts.opportunisticGraftPeers;
                    const newMeshPeers = removeItemsFromSet(candidateMeshPeers, ineed, (id) => getScore(id) > medianScore);
                    for (const id of newMeshPeers) {
                        this.log('HEARTBEAT: Opportunistically graft peer %s on topic %s', id, topic);
                        graftPeer(id, InclusionReason.Opportunistic);
                    }
                }
            }
        });
        // expire fanout for topics we haven't published to in a while
        const now = Date.now();
        this.fanoutLastpub.forEach((lastpb, topic) => {
            if (lastpb + fanoutTTL < now) {
                this.fanout.delete(topic);
                this.fanoutLastpub.delete(topic);
            }
        });
        // maintain our fanout for topics we are publishing but we have not joined
        this.fanout.forEach((fanoutPeers, topic) => {
            // checks whether our peers are still in the topic and have a score above the publish threshold
            const topicPeers = this.topics.get(topic);
            fanoutPeers.forEach((id) => {
                if (!topicPeers.has(id) || getScore(id) < this.opts.scoreThresholds.publishThreshold) {
                    fanoutPeers.delete(id);
                }
            });
            const peersInTopic = this.topics.get(topic);
            const candidateFanoutPeers = [];
            // the fanout map contains topics to which we are not subscribed.
            const peersToGossip = new Set();
            peersToGossipByTopic.set(topic, peersToGossip);
            if (peersInTopic) {
                const shuffledPeers = shuffle(Array.from(peersInTopic));
                for (const id of shuffledPeers) {
                    const peerStreams = this.streamsOutbound.get(id);
                    if (peerStreams &&
                        this.multicodecs.includes(peerStreams.protocol) &&
                        !fanoutPeers.has(id) &&
                        !this.direct.has(id)) {
                        const score = getScore(id);
                        if (score >= this.opts.scoreThresholds.publishThreshold)
                            candidateFanoutPeers.push(id);
                        // instead of having to find gossip peers after heartbeat which require another loop
                        // we prepare peers to gossip in a topic within heartbeat to improve performance
                        if (score >= this.opts.scoreThresholds.gossipThreshold)
                            peersToGossip.add(id);
                    }
                }
            }
            // do we need more peers?
            if (fanoutPeers.size < D) {
                const ineed = D - fanoutPeers.size;
                candidateFanoutPeers.slice(0, ineed).forEach((id) => {
                    fanoutPeers.add(id);
                    peersToGossip?.delete(id);
                });
            }
        });
        this.emitGossip(peersToGossipByTopic);
        // send coalesced GRAFT/PRUNE messages (will piggyback gossip)
        await this.sendGraftPrune(tograft, toprune, noPX);
        // flush pending gossip that wasn't piggybacked above
        this.flush();
        // advance the message history window
        this.mcache.shift();
        this.dispatchEvent(new CustomEvent('gossipsub:heartbeat'));
    }
    /**
     * Given a topic, returns up to count peers subscribed to that topic
     * that pass an optional filter function
     *
     * @param topic
     * @param count
     * @param filter - a function to filter acceptable peers
     */
    getRandomGossipPeers(topic, count, filter = () => true) {
        const peersInTopic = this.topics.get(topic);
        if (!peersInTopic) {
            return new Set();
        }
        // Adds all peers using our protocol
        // that also pass the filter function
        let peers = [];
        peersInTopic.forEach((id) => {
            const peerStreams = this.streamsOutbound.get(id);
            if (!peerStreams) {
                return;
            }
            if (this.multicodecs.includes(peerStreams.protocol) && filter(id)) {
                peers.push(id);
            }
        });
        // Pseudo-randomly shuffles peers
        peers = shuffle(peers);
        if (count > 0 && peers.length > count) {
            peers = peers.slice(0, count);
        }
        return new Set(peers);
    }
    onScrapeMetrics(metrics) {
        /* Data structure sizes */
        metrics.mcacheSize.set(this.mcache.size);
        metrics.mcacheNotValidatedCount.set(this.mcache.notValidatedCount);
        // Arbitrary size
        metrics.cacheSize.set({ cache: 'direct' }, this.direct.size);
        metrics.cacheSize.set({ cache: 'seenCache' }, this.seenCache.size);
        metrics.cacheSize.set({ cache: 'fastMsgIdCache' }, this.fastMsgIdCache?.size ?? 0);
        metrics.cacheSize.set({ cache: 'publishedMessageIds' }, this.publishedMessageIds.size);
        metrics.cacheSize.set({ cache: 'mcache' }, this.mcache.size);
        metrics.cacheSize.set({ cache: 'score' }, this.score.size);
        metrics.cacheSize.set({ cache: 'gossipTracer.promises' }, this.gossipTracer.size);
        metrics.cacheSize.set({ cache: 'gossipTracer.requests' }, this.gossipTracer.requestMsByMsgSize);
        // Bounded by topic
        metrics.cacheSize.set({ cache: 'topics' }, this.topics.size);
        metrics.cacheSize.set({ cache: 'subscriptions' }, this.subscriptions.size);
        metrics.cacheSize.set({ cache: 'mesh' }, this.mesh.size);
        metrics.cacheSize.set({ cache: 'fanout' }, this.fanout.size);
        // Bounded by peer
        metrics.cacheSize.set({ cache: 'peers' }, this.peers.size);
        metrics.cacheSize.set({ cache: 'streamsOutbound' }, this.streamsOutbound.size);
        metrics.cacheSize.set({ cache: 'streamsInbound' }, this.streamsInbound.size);
        metrics.cacheSize.set({ cache: 'acceptFromWhitelist' }, this.acceptFromWhitelist.size);
        metrics.cacheSize.set({ cache: 'gossip' }, this.gossip.size);
        metrics.cacheSize.set({ cache: 'control' }, this.control.size);
        metrics.cacheSize.set({ cache: 'peerhave' }, this.peerhave.size);
        metrics.cacheSize.set({ cache: 'outbound' }, this.outbound.size);
        // 2D nested data structure
        let backoffSize = 0;
        const now = Date.now();
        metrics.connectedPeersBackoffSec.reset();
        for (const backoff of this.backoff.values()) {
            backoffSize += backoff.size;
            for (const [peer, expiredMs] of backoff.entries()) {
                if (this.peers.has(peer)) {
                    metrics.connectedPeersBackoffSec.observe(Math.max(0, expiredMs - now) / 1000);
                }
            }
        }
        metrics.cacheSize.set({ cache: 'backoff' }, backoffSize);
        // Peer counts
        for (const [topicStr, peers] of this.topics) {
            metrics.topicPeersCount.set({ topicStr }, peers.size);
        }
        for (const [topicStr, peers] of this.mesh) {
            metrics.meshPeerCounts.set({ topicStr }, peers.size);
        }
        // Peer scores
        const scores = [];
        const scoreByPeer = new Map();
        metrics.behaviourPenalty.reset();
        for (const peerIdStr of this.peers.keys()) {
            const score = this.score.score(peerIdStr);
            scores.push(score);
            scoreByPeer.set(peerIdStr, score);
            metrics.behaviourPenalty.observe(this.score.peerStats.get(peerIdStr)?.behaviourPenalty ?? 0);
        }
        metrics.registerScores(scores, this.opts.scoreThresholds);
        // Breakdown score per mesh topicLabel
        metrics.registerScorePerMesh(this.mesh, scoreByPeer);
        // Breakdown on each score weight
        const sw = computeAllPeersScoreWeights(this.peers.keys(), this.score.peerStats, this.score.params, this.score.peerIPs, metrics.topicStrToLabel);
        metrics.registerScoreWeights(sw);
    }
}

/**
 * RelayCodec is the libp2p identifier for the waku relay protocol
 */
const RelayCodecs = ["/vac/waku/relay/2.0.0"];

const log$n = debug("waku:relay");
function messageValidator(peer, message$1) {
    const startTime = performance.now();
    log$n(`validating message from ${peer} received on ${message$1.topic}`);
    let result = TopicValidatorResult.Accept;
    try {
        const protoMessage = WakuMessage$4.decode(message$1.data);
        if (!protoMessage.contentTopic ||
            !protoMessage.contentTopic.length ||
            !protoMessage.payload ||
            !protoMessage.payload.length) {
            result = TopicValidatorResult.Reject;
        }
    }
    catch (e) {
        result = TopicValidatorResult.Reject;
    }
    const endTime = performance.now();
    log$n(`Validation time (must be <100ms): ${endTime - startTime}ms`);
    return result;
}

const log$m = debug("waku:message:topic-only");
class TopicOnlyMessage {
    pubSubTopic;
    proto;
    payload = new Uint8Array();
    rateLimitProof;
    timestamp;
    meta;
    ephemeral;
    constructor(pubSubTopic, proto) {
        this.pubSubTopic = pubSubTopic;
        this.proto = proto;
    }
    get contentTopic() {
        return this.proto.contentTopic;
    }
}
class TopicOnlyDecoder {
    contentTopic = "";
    fromWireToProtoObj(bytes) {
        const protoMessage = TopicOnlyMessage$1.decode(bytes);
        log$m("Message decoded", protoMessage);
        return Promise.resolve({
            contentTopic: protoMessage.contentTopic,
            payload: new Uint8Array(),
            rateLimitProof: undefined,
            timestamp: undefined,
            meta: undefined,
            version: undefined,
            ephemeral: undefined
        });
    }
    async fromProtoObj(pubSubTopic, proto) {
        return new TopicOnlyMessage(pubSubTopic, proto);
    }
}

const log$l = debug("waku:relay");
/**
 * Implements the [Waku v2 Relay protocol](https://rfc.vac.dev/spec/11/).
 * Throws if libp2p.pubsub does not support Waku Relay
 */
class Relay {
    pubSubTopic;
    defaultDecoder;
    static multicodec = RelayCodecs[0];
    gossipSub;
    /**
     * observers called when receiving new message.
     * Observers under key `""` are always called.
     */
    observers;
    constructor(libp2p, options) {
        if (!this.isRelayPubSub(libp2p.services.pubsub)) {
            throw Error(`Failed to initialize Relay. libp2p.pubsub does not support ${Relay.multicodec}`);
        }
        this.gossipSub = libp2p.services.pubsub;
        this.pubSubTopic = options?.pubSubTopic ?? DefaultPubSubTopic;
        if (this.gossipSub.isStarted()) {
            this.gossipSubSubscribe(this.pubSubTopic);
        }
        this.observers = new Map();
        // TODO: User might want to decide what decoder should be used (e.g. for RLN)
        this.defaultDecoder = new TopicOnlyDecoder();
    }
    /**
     * Mounts the gossipsub protocol onto the libp2p node
     * and subscribes to the default topic.
     *
     * @override
     * @returns {void}
     */
    async start() {
        if (this.gossipSub.isStarted()) {
            throw Error("GossipSub already started.");
        }
        await this.gossipSub.start();
        this.gossipSubSubscribe(this.pubSubTopic);
    }
    /**
     * Send Waku message.
     */
    async send(encoder, message) {
        const recipients = [];
        if (!isSizeValid(message.payload)) {
            log$l("Failed to send waku relay: message is bigger that 1MB");
            return {
                recipients,
                errors: [SendError.SIZE_TOO_BIG]
            };
        }
        const msg = await encoder.toWire(message);
        if (!msg) {
            log$l("Failed to encode message, aborting publish");
            return {
                recipients,
                errors: [SendError.ENCODE_FAILED]
            };
        }
        return this.gossipSub.publish(this.pubSubTopic, msg);
    }
    /**
     * Add an observer and associated Decoder to process incoming messages on a given content topic.
     *
     * @returns Function to delete the observer
     */
    subscribe(decoders, callback) {
        const contentTopicToObservers = Array.isArray(decoders)
            ? toObservers(decoders, callback)
            : toObservers([decoders], callback);
        for (const contentTopic of contentTopicToObservers.keys()) {
            const currObservers = this.observers.get(contentTopic) || new Set();
            const newObservers = contentTopicToObservers.get(contentTopic) || new Set();
            this.observers.set(contentTopic, union(currObservers, newObservers));
        }
        return () => {
            for (const contentTopic of contentTopicToObservers.keys()) {
                const currentObservers = this.observers.get(contentTopic) || new Set();
                const observersToRemove = contentTopicToObservers.get(contentTopic) || new Set();
                const nextObservers = leftMinusJoin(currentObservers, observersToRemove);
                if (nextObservers.size) {
                    this.observers.set(contentTopic, nextObservers);
                }
                else {
                    this.observers.delete(contentTopic);
                }
            }
        };
    }
    toSubscriptionIterator(decoders) {
        return toAsyncIterator(this, decoders);
    }
    getActiveSubscriptions() {
        const map = new Map();
        map.set(this.pubSubTopic, this.observers.keys());
        return map;
    }
    getMeshPeers(topic) {
        return this.gossipSub.getMeshPeers(topic ?? this.pubSubTopic);
    }
    async processIncomingMessage(pubSubTopic, bytes) {
        const topicOnlyMsg = await this.defaultDecoder.fromWireToProtoObj(bytes);
        if (!topicOnlyMsg || !topicOnlyMsg.contentTopic) {
            log$l("Message does not have a content topic, skipping");
            return;
        }
        const observers = this.observers.get(topicOnlyMsg.contentTopic);
        if (!observers) {
            return;
        }
        await Promise.all(Array.from(observers).map(({ decoder, callback }) => {
            return (async () => {
                try {
                    const protoMsg = await decoder.fromWireToProtoObj(bytes);
                    if (!protoMsg) {
                        log$l("Internal error: message previously decoded failed on 2nd pass.");
                        return;
                    }
                    const msg = await decoder.fromProtoObj(pubSubTopic, protoMsg);
                    if (msg) {
                        await callback(msg);
                    }
                    else {
                        log$l("Failed to decode messages on", topicOnlyMsg.contentTopic);
                    }
                }
                catch (error) {
                    log$l("Error while decoding message:", error);
                }
            })();
        }));
    }
    /**
     * Subscribe to a pubsub topic and start emitting Waku messages to observers.
     *
     * @override
     */
    gossipSubSubscribe(pubSubTopic) {
        this.gossipSub.addEventListener("gossipsub:message", (event) => {
            if (event.detail.msg.topic !== pubSubTopic)
                return;
            log$l(`Message received on ${pubSubTopic}`);
            this.processIncomingMessage(event.detail.msg.topic, event.detail.msg.data).catch((e) => log$l("Failed to process incoming message", e));
        });
        this.gossipSub.topicValidators.set(pubSubTopic, messageValidator);
        this.gossipSub.subscribe(pubSubTopic);
    }
    isRelayPubSub(pubsub) {
        return pubsub?.multicodecs?.includes(Relay.multicodec) || false;
    }
}
function wakuRelay(init = {}) {
    return (libp2p) => new Relay(libp2p, init);
}
function wakuGossipSub(init = {}) {
    return (components) => {
        init = {
            ...init,
            msgIdFn: ({ data }) => sha256$a(data),
            // Ensure that no signature is included nor expected in the messages.
            globalSignaturePolicy: SignaturePolicy.StrictNoSign,
            fallbackToFloodsub: false
        };
        const pubsub = new GossipSub(components, init);
        pubsub.multicodecs = RelayCodecs;
        return pubsub;
    };
}
function toObservers(decoders, callback) {
    const contentTopicToDecoders = Array.from(groupByContentTopic(decoders).entries());
    const contentTopicToObserversEntries = contentTopicToDecoders.map(([contentTopic, decoders]) => [
        contentTopic,
        new Set(decoders.map((decoder) => ({
            decoder,
            callback
        })))
    ]);
    return new Map(contentTopicToObserversEntries);
}
function union(left, right) {
    for (const val of right.values()) {
        left.add(val);
    }
    return left;
}
function leftMinusJoin(left, right) {
    for (const val of right.values()) {
        if (left.has(val)) {
            left.delete(val);
        }
    }
    return left;
}

var index = /*#__PURE__*/Object.freeze({
    __proto__: null,
    wakuGossipSub: wakuGossipSub,
    wakuRelay: wakuRelay
});

var events$1 = {exports: {}};

var R = typeof Reflect === 'object' ? Reflect : null;
var ReflectApply = R && typeof R.apply === 'function'
  ? R.apply
  : function ReflectApply(target, receiver, args) {
    return Function.prototype.apply.call(target, receiver, args);
  };

var ReflectOwnKeys;
if (R && typeof R.ownKeys === 'function') {
  ReflectOwnKeys = R.ownKeys;
} else if (Object.getOwnPropertySymbols) {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target)
      .concat(Object.getOwnPropertySymbols(target));
  };
} else {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target);
  };
}

function ProcessEmitWarning(warning) {
  if (console && console.warn) console.warn(warning);
}

var NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {
  return value !== value;
};

function EventEmitter$1() {
  EventEmitter$1.init.call(this);
}
events$1.exports = EventEmitter$1;
events$1.exports.once = once;

// Backwards-compat with node 0.10.x
EventEmitter$1.EventEmitter = EventEmitter$1;

EventEmitter$1.prototype._events = undefined;
EventEmitter$1.prototype._eventsCount = 0;
EventEmitter$1.prototype._maxListeners = undefined;

// By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.
var defaultMaxListeners = 10;

function checkListener(listener) {
  if (typeof listener !== 'function') {
    throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
  }
}

Object.defineProperty(EventEmitter$1, 'defaultMaxListeners', {
  enumerable: true,
  get: function() {
    return defaultMaxListeners;
  },
  set: function(arg) {
    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {
      throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + '.');
    }
    defaultMaxListeners = arg;
  }
});

EventEmitter$1.init = function() {

  if (this._events === undefined ||
      this._events === Object.getPrototypeOf(this)._events) {
    this._events = Object.create(null);
    this._eventsCount = 0;
  }

  this._maxListeners = this._maxListeners || undefined;
};

// Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.
EventEmitter$1.prototype.setMaxListeners = function setMaxListeners(n) {
  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {
    throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + '.');
  }
  this._maxListeners = n;
  return this;
};

function _getMaxListeners(that) {
  if (that._maxListeners === undefined)
    return EventEmitter$1.defaultMaxListeners;
  return that._maxListeners;
}

EventEmitter$1.prototype.getMaxListeners = function getMaxListeners() {
  return _getMaxListeners(this);
};

EventEmitter$1.prototype.emit = function emit(type) {
  var args = [];
  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);
  var doError = (type === 'error');

  var events = this._events;
  if (events !== undefined)
    doError = (doError && events.error === undefined);
  else if (!doError)
    return false;

  // If there is no 'error' event listener then throw.
  if (doError) {
    var er;
    if (args.length > 0)
      er = args[0];
    if (er instanceof Error) {
      // Note: The comments on the `throw` lines are intentional, they show
      // up in Node's output if this results in an unhandled exception.
      throw er; // Unhandled 'error' event
    }
    // At least give some kind of context to the user
    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));
    err.context = er;
    throw err; // Unhandled 'error' event
  }

  var handler = events[type];

  if (handler === undefined)
    return false;

  if (typeof handler === 'function') {
    ReflectApply(handler, this, args);
  } else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      ReflectApply(listeners[i], this, args);
  }

  return true;
};

function _addListener(target, type, listener, prepend) {
  var m;
  var events;
  var existing;

  checkListener(listener);

  events = target._events;
  if (events === undefined) {
    events = target._events = Object.create(null);
    target._eventsCount = 0;
  } else {
    // To avoid recursion in the case that type === "newListener"! Before
    // adding it to the listeners, first emit "newListener".
    if (events.newListener !== undefined) {
      target.emit('newListener', type,
                  listener.listener ? listener.listener : listener);

      // Re-assign `events` because a newListener handler could have caused the
      // this._events to be assigned to a new object
      events = target._events;
    }
    existing = events[type];
  }

  if (existing === undefined) {
    // Optimize the case of one listener. Don't need the extra array object.
    existing = events[type] = listener;
    ++target._eventsCount;
  } else {
    if (typeof existing === 'function') {
      // Adding the second element, need to change to array.
      existing = events[type] =
        prepend ? [listener, existing] : [existing, listener];
      // If we've already got an array, just append.
    } else if (prepend) {
      existing.unshift(listener);
    } else {
      existing.push(listener);
    }

    // Check for listener leak
    m = _getMaxListeners(target);
    if (m > 0 && existing.length > m && !existing.warned) {
      existing.warned = true;
      // No error code for this since it is a Warning
      // eslint-disable-next-line no-restricted-syntax
      var w = new Error('Possible EventEmitter memory leak detected. ' +
                          existing.length + ' ' + String(type) + ' listeners ' +
                          'added. Use emitter.setMaxListeners() to ' +
                          'increase limit');
      w.name = 'MaxListenersExceededWarning';
      w.emitter = target;
      w.type = type;
      w.count = existing.length;
      ProcessEmitWarning(w);
    }
  }

  return target;
}

EventEmitter$1.prototype.addListener = function addListener(type, listener) {
  return _addListener(this, type, listener, false);
};

EventEmitter$1.prototype.on = EventEmitter$1.prototype.addListener;

EventEmitter$1.prototype.prependListener =
    function prependListener(type, listener) {
      return _addListener(this, type, listener, true);
    };

function onceWrapper() {
  if (!this.fired) {
    this.target.removeListener(this.type, this.wrapFn);
    this.fired = true;
    if (arguments.length === 0)
      return this.listener.call(this.target);
    return this.listener.apply(this.target, arguments);
  }
}

function _onceWrap(target, type, listener) {
  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
  var wrapped = onceWrapper.bind(state);
  wrapped.listener = listener;
  state.wrapFn = wrapped;
  return wrapped;
}

EventEmitter$1.prototype.once = function once(type, listener) {
  checkListener(listener);
  this.on(type, _onceWrap(this, type, listener));
  return this;
};

EventEmitter$1.prototype.prependOnceListener =
    function prependOnceListener(type, listener) {
      checkListener(listener);
      this.prependListener(type, _onceWrap(this, type, listener));
      return this;
    };

// Emits a 'removeListener' event if and only if the listener was removed.
EventEmitter$1.prototype.removeListener =
    function removeListener(type, listener) {
      var list, events, position, i, originalListener;

      checkListener(listener);

      events = this._events;
      if (events === undefined)
        return this;

      list = events[type];
      if (list === undefined)
        return this;

      if (list === listener || list.listener === listener) {
        if (--this._eventsCount === 0)
          this._events = Object.create(null);
        else {
          delete events[type];
          if (events.removeListener)
            this.emit('removeListener', type, list.listener || listener);
        }
      } else if (typeof list !== 'function') {
        position = -1;

        for (i = list.length - 1; i >= 0; i--) {
          if (list[i] === listener || list[i].listener === listener) {
            originalListener = list[i].listener;
            position = i;
            break;
          }
        }

        if (position < 0)
          return this;

        if (position === 0)
          list.shift();
        else {
          spliceOne(list, position);
        }

        if (list.length === 1)
          events[type] = list[0];

        if (events.removeListener !== undefined)
          this.emit('removeListener', type, originalListener || listener);
      }

      return this;
    };

EventEmitter$1.prototype.off = EventEmitter$1.prototype.removeListener;

EventEmitter$1.prototype.removeAllListeners =
    function removeAllListeners(type) {
      var listeners, events, i;

      events = this._events;
      if (events === undefined)
        return this;

      // not listening for removeListener, no need to emit
      if (events.removeListener === undefined) {
        if (arguments.length === 0) {
          this._events = Object.create(null);
          this._eventsCount = 0;
        } else if (events[type] !== undefined) {
          if (--this._eventsCount === 0)
            this._events = Object.create(null);
          else
            delete events[type];
        }
        return this;
      }

      // emit removeListener for all listeners on all events
      if (arguments.length === 0) {
        var keys = Object.keys(events);
        var key;
        for (i = 0; i < keys.length; ++i) {
          key = keys[i];
          if (key === 'removeListener') continue;
          this.removeAllListeners(key);
        }
        this.removeAllListeners('removeListener');
        this._events = Object.create(null);
        this._eventsCount = 0;
        return this;
      }

      listeners = events[type];

      if (typeof listeners === 'function') {
        this.removeListener(type, listeners);
      } else if (listeners !== undefined) {
        // LIFO order
        for (i = listeners.length - 1; i >= 0; i--) {
          this.removeListener(type, listeners[i]);
        }
      }

      return this;
    };

function _listeners(target, type, unwrap) {
  var events = target._events;

  if (events === undefined)
    return [];

  var evlistener = events[type];
  if (evlistener === undefined)
    return [];

  if (typeof evlistener === 'function')
    return unwrap ? [evlistener.listener || evlistener] : [evlistener];

  return unwrap ?
    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
}

EventEmitter$1.prototype.listeners = function listeners(type) {
  return _listeners(this, type, true);
};

EventEmitter$1.prototype.rawListeners = function rawListeners(type) {
  return _listeners(this, type, false);
};

EventEmitter$1.listenerCount = function(emitter, type) {
  if (typeof emitter.listenerCount === 'function') {
    return emitter.listenerCount(type);
  } else {
    return listenerCount.call(emitter, type);
  }
};

EventEmitter$1.prototype.listenerCount = listenerCount;
function listenerCount(type) {
  var events = this._events;

  if (events !== undefined) {
    var evlistener = events[type];

    if (typeof evlistener === 'function') {
      return 1;
    } else if (evlistener !== undefined) {
      return evlistener.length;
    }
  }

  return 0;
}

EventEmitter$1.prototype.eventNames = function eventNames() {
  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
};

function arrayClone(arr, n) {
  var copy = new Array(n);
  for (var i = 0; i < n; ++i)
    copy[i] = arr[i];
  return copy;
}

function spliceOne(list, index) {
  for (; index + 1 < list.length; index++)
    list[index] = list[index + 1];
  list.pop();
}

function unwrapListeners(arr) {
  var ret = new Array(arr.length);
  for (var i = 0; i < ret.length; ++i) {
    ret[i] = arr[i].listener || arr[i];
  }
  return ret;
}

function once(emitter, name) {
  return new Promise(function (resolve, reject) {
    function errorListener(err) {
      emitter.removeListener(name, resolver);
      reject(err);
    }

    function resolver() {
      if (typeof emitter.removeListener === 'function') {
        emitter.removeListener('error', errorListener);
      }
      resolve([].slice.call(arguments));
    }
    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });
    if (name !== 'error') {
      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });
    }
  });
}

function addErrorHandlerIfEventEmitter(emitter, handler, flags) {
  if (typeof emitter.on === 'function') {
    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);
  }
}

function eventTargetAgnosticAddListener(emitter, name, listener, flags) {
  if (typeof emitter.on === 'function') {
    if (flags.once) {
      emitter.once(name, listener);
    } else {
      emitter.on(name, listener);
    }
  } else if (typeof emitter.addEventListener === 'function') {
    // EventTarget does not have `error` event semantics like Node
    // EventEmitters, we do not listen for `error` events here.
    emitter.addEventListener(name, function wrapListener(arg) {
      // IE does not have builtin `{ once: true }` support so we
      // have to do it manually.
      if (flags.once) {
        emitter.removeEventListener(name, wrapListener);
      }
      listener(arg);
    });
  } else {
    throw new TypeError('The "emitter" argument must be of type EventEmitter. Received type ' + typeof emitter);
  }
}

var eventsExports = events$1.exports;

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$5 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$5 = base$5;

var _brrp__multiformats_scope_baseX$5 = src$5;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$5 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$5 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$5 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$5(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$5 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$5(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$5 = (left, right) => new ComposedDecoder$5(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$5 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$5(name, prefix, baseEncode);
    this.decoder = new Decoder$5(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$9 = ({ name, prefix, encode, decode }) =>
  new Codec$5(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$5 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$5(alphabet, name);
  return from$9({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$5(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$9 = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$e = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$5 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$9({
    prefix,
    name,
    encode (input) {
      return encode$e(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$9(input, alphabet, bitsPerChar, name)
    }
  })
};

const base58btc$5 = baseX$5({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$5({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var encode_1$3 = encode$d;

var MSB$4 = 0x80
  , REST$4 = 0x7F
  , MSBALL$3 = ~REST$4
  , INT$3 = Math.pow(2, 31);

function encode$d(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$3) {
    out[offset++] = (num & 0xFF) | MSB$4;
    num /= 128;
  }
  while(num & MSBALL$3) {
    out[offset++] = (num & 0xFF) | MSB$4;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$d.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$8 = read$4;

var MSB$1$3 = 0x80
  , REST$1$3 = 0x7F;

function read$4(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$4.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$3) << shift
      : (b & REST$1$3) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$3)

  read$4.bytes = counter - offset;

  return res
}

var N1$3 = Math.pow(2,  7);
var N2$3 = Math.pow(2, 14);
var N3$3 = Math.pow(2, 21);
var N4$3 = Math.pow(2, 28);
var N5$3 = Math.pow(2, 35);
var N6$3 = Math.pow(2, 42);
var N7$3 = Math.pow(2, 49);
var N8$3 = Math.pow(2, 56);
var N9$3 = Math.pow(2, 63);

var length$3 = function (value) {
  return (
    value < N1$3 ? 1
  : value < N2$3 ? 2
  : value < N3$3 ? 3
  : value < N4$3 ? 4
  : value < N5$3 ? 5
  : value < N6$3 ? 6
  : value < N7$3 ? 7
  : value < N8$3 ? 8
  : value < N9$3 ? 9
  :              10
  )
};

var varint$3 = {
    encode: encode_1$3
  , decode: decode$8
  , encodingLength: length$3
};

var _brrp_varint$3 = varint$3;

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo$3 = (int, target, offset = 0) => {
  _brrp_varint$3.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$3 = (int) => {
  return _brrp_varint$3.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$7 = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$3(code);
  const digestOffset = sizeOffset + encodingLength$3(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo$3(code, bytes, 0);
  encodeTo$3(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest$3(code, size, digest, bytes)
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
let Digest$3 = class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
};

const code$3 = 0x0;
const name$3 = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$c = coerce$5;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest$3 = (input) => create$7(code$3, encode$c(input));

const identity$3 = { code: code$3, name: name$3, encode: encode$c, digest: digest$3 };

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$8 = ({ name, code, encode }) => new Hasher$3(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
let Hasher$3 = class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$7(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$7(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
};

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */


/**
 * @param {AlgorithmIdentifier} name
 */
const sha$3 = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256$4 = from$8({
  name: 'sha2-256',
  code: 0x12,
  encode: sha$3('SHA-256')
});

const PUBLIC_KEY_BYTE_LENGTH$3 = 32;
const PRIVATE_KEY_BYTE_LENGTH$3 = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH$3 = 32;
async function generateKey$b() {
    // the actual private key (32 bytes)
    const privateKeyRaw = ed25519.utils.randomPrivateKey();
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys$3(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
async function generateKeyFromSeed$3(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH$3) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    const privateKey = concatKeys$3(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSign$b(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH$3);
    return ed25519.sign(msg, privateKeyRaw);
}
async function hashAndVerify$b(publicKey, sig, msg) {
    return ed25519.verify(sig, msg, publicKey);
}
function concatKeys$3(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH$3);
    for (let i = 0; i < KEYS_BYTE_LENGTH$3; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH$3 + i] = publicKey[i];
    }
    return privateKey;
}

// @ts-check


const base64$5 = rfc4648$5({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$5({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$5({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$5({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto$3 = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto == null || nativeCrypto.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p-crypto/blob/master/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

// WebKit on Linux does not support deriving a key from an empty PBKDF2 key.
// So, as a workaround, we provide the generated key as a constant. We test that
// this generated key is accurate in test/workaround.spec.ts
// Generated via:
// await crypto.subtle.exportKey('jwk',
//   await crypto.subtle.deriveKey(
//     { name: 'PBKDF2', salt: new Uint8Array(16), iterations: 32767, hash: { name: 'SHA-256' } },
//     await crypto.subtle.importKey('raw', new Uint8Array(0), { name: 'PBKDF2' }, false, ['deriveKey']),
//     { name: 'AES-GCM', length: 128 }, true, ['encrypt', 'decrypt'])
// )
const derivedEmptyPasswordKey$3 = { alg: 'A128GCM', ext: true, k: 'scm9jmO_4BJAgdwWGVulLg', key_ops: ['encrypt', 'decrypt'], kty: 'oct' };
// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create$6(opts) {
    const algorithm = opts?.algorithm ?? 'AES-GCM';
    let keyLength = opts?.keyLength ?? 16;
    const nonceLength = opts?.nonceLength ?? 12;
    const digest = opts?.digest ?? 'SHA-256';
    const saltLength = opts?.saltLength ?? 16;
    const iterations = opts?.iterations ?? 32767;
    const crypto = webcrypto$3.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$3, { name: 'AES-GCM' }, true, ['encrypt']);
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['encrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$3, { name: 'AES-GCM' }, true, ['encrypt']);
            }
        }
        else {
            // Derive a key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        }
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat$1([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['decrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$3, { name: 'AES-GCM' }, true, ['decrypt']);
            }
        }
        else {
            // Derive the key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        }
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter$3(privateKey, password) {
    const cipher = create$6();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64$5.encode(encryptedKey);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType$3;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType$3 || (KeyType$3 = {}));
var __KeyTypeValues$3;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues$3 || (__KeyTypeValues$3 = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues$3);
    };
})(KeyType$3 || (KeyType$3 = {}));
var PublicKey$3;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$3.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$3.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$1(buf, PublicKey.codec());
    };
})(PublicKey$3 || (PublicKey$3 = {}));
var PrivateKey$3;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$3.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$3.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$1(buf, PrivateKey.codec());
    };
})(PrivateKey$3 || (PrivateKey$3 = {}));

let Ed25519PublicKey$3 = class Ed25519PublicKey {
    _key;
    constructor(key) {
        this._key = ensureKey$3(key, PUBLIC_KEY_BYTE_LENGTH$3);
    }
    async verify(data, sig) {
        return hashAndVerify$b(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey$3.encode({
            Type: KeyType$3.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$4.digest(this.bytes);
        return bytes;
    }
};
let Ed25519PrivateKey$3 = class Ed25519PrivateKey {
    _key;
    _publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey$3(key, PRIVATE_KEY_BYTE_LENGTH$3);
        this._publicKey = ensureKey$3(publicKey, PUBLIC_KEY_BYTE_LENGTH$3);
    }
    async sign(message) {
        return hashAndSign$b(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey$3(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$3.encode({
            Type: KeyType$3.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$4.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity$3.digest(this.public.bytes);
        return base58btc$5.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$3(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalEd25519PrivateKey$3(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH$3) {
        bytes = ensureKey$3(bytes, PRIVATE_KEY_BYTE_LENGTH$3 + PUBLIC_KEY_BYTE_LENGTH$3);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$3);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH$3, bytes.length);
        return new Ed25519PrivateKey$3(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey$3(bytes, PRIVATE_KEY_BYTE_LENGTH$3);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$3);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH$3);
    return new Ed25519PrivateKey$3(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey$3(bytes) {
    bytes = ensureKey$3(bytes, PUBLIC_KEY_BYTE_LENGTH$3);
    return new Ed25519PublicKey$3(bytes);
}
async function generateKeyPair$d() {
    const { privateKey, publicKey } = await generateKey$b();
    return new Ed25519PrivateKey$3(privateKey, publicKey);
}
async function generateKeyPairFromSeed$3(seed) {
    const { privateKey, publicKey } = await generateKeyFromSeed$3(seed);
    return new Ed25519PrivateKey$3(privateKey, publicKey);
}
function ensureKey$3(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError$3(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey$3,
    Ed25519PublicKey: Ed25519PublicKey$3,
    generateKeyPair: generateKeyPair$d,
    generateKeyPairFromSeed: generateKeyPairFromSeed$3,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey$3,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey$3
});

function bigIntegerToUintBase64url$3(num, len) {
    // Call `.abs()` to convert to unsigned
    let buf = Uint8Array.from(num.abs().toByteArray()); // toByteArray converts to big endian
    // toByteArray() gives us back a signed array, which will include a leading 0
    // byte if the most significant bit of the number is 1:
    // https://docs.microsoft.com/en-us/windows/win32/seccertenroll/about-integer
    // Our number will always be positive so we should remove the leading padding.
    buf = buf[0] === 0 ? buf.subarray(1) : buf;
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return toString$9(buf, 'base64url');
}
// Convert a base64url encoded string to a BigInteger
function base64urlToBigInteger$3(str) {
    const buf = base64urlToBuffer$3(str);
    return new forge$n.jsbn.BigInteger(toString$9(buf, 'base16'), 16);
}
function base64urlToBuffer$3(str, len) {
    let buf = fromString$3(str, 'base64urlpad');
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return buf;
}

const bits$3 = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes$3 = Object.keys(bits$3);
curveTypes$3.join(' / ');

function randomBytes$3(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError$3('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return randomBytes$8(length);
}

function convert$3(key, types) {
    return types.map(t => base64urlToBigInteger$3(key[t]));
}
function jwk2priv$3(key) {
    return forge$n.pki.setRsaPrivateKey(...convert$3(key, ['n', 'e', 'd', 'p', 'q', 'dp', 'dq', 'qi']));
}
function jwk2pub$3(key) {
    return forge$n.pki.setRsaPublicKey(...convert$3(key, ['n', 'e']));
}

// Convert a PKCS#1 in ASN1 DER format to a JWK key
function pkcs1ToJwk$3(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
    // https://tools.ietf.org/html/rfc7518#section-6.3.1
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$3(privateKey.n),
        e: bigIntegerToUintBase64url$3(privateKey.e),
        d: bigIntegerToUintBase64url$3(privateKey.d),
        p: bigIntegerToUintBase64url$3(privateKey.p),
        q: bigIntegerToUintBase64url$3(privateKey.q),
        dp: bigIntegerToUintBase64url$3(privateKey.dP),
        dq: bigIntegerToUintBase64url$3(privateKey.dQ),
        qi: bigIntegerToUintBase64url$3(privateKey.qInv),
        alg: 'RS256'
    };
}
// Convert a JWK key into PKCS#1 in ASN1 DER format
function jwkToPkcs1$3(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.privateKeyToAsn1({
        n: base64urlToBigInteger$3(jwk.n),
        e: base64urlToBigInteger$3(jwk.e),
        d: base64urlToBigInteger$3(jwk.d),
        p: base64urlToBigInteger$3(jwk.p),
        q: base64urlToBigInteger$3(jwk.q),
        dP: base64urlToBigInteger$3(jwk.dp),
        dQ: base64urlToBigInteger$3(jwk.dq),
        qInv: base64urlToBigInteger$3(jwk.qi)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}
// Convert a PKCIX in ASN1 DER format to a JWK key
function pkixToJwk$3(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const publicKey = forge$n.pki.publicKeyFromAsn1(asn1);
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$3(publicKey.n),
        e: bigIntegerToUintBase64url$3(publicKey.e)
    };
}
// Convert a JWK key to PKCIX in ASN1 DER format
function jwkToPkix$3(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.publicKeyToAsn1({
        n: base64urlToBigInteger$3(jwk.n),
        e: base64urlToBigInteger$3(jwk.e)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}

async function generateKey$a(bits) {
    const pair = await webcrypto$3.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey$3(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$5(key) {
    const privateKey = await webcrypto$3.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate$3(key)
    ];
    const keys = await exportKey$3({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$a(key, msg) {
    const privateKey = await webcrypto$3.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto$3.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, Uint8Array.from(msg));
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$a(key, sig, msg) {
    const publicKey = await webcrypto$3.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return webcrypto$3.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg);
}
async function exportKey$3(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError$3('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return Promise.all([
        webcrypto$3.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto$3.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate$3(jwKey) {
    return webcrypto$3.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
/*

RSA encryption/decryption for the browser with webcrypto workaround
"bloody dark magic. webcrypto's why."

Explanation:
  - Convert JWK to nodeForge
  - Convert msg Uint8Array to nodeForge buffer: ByteBuffer is a "binary-string backed buffer", so let's make our Uint8Array a binary string
  - Convert resulting nodeForge buffer to Uint8Array: it returns a binary string, turn that into a Uint8Array

*/
function convertKey$3(key, pub, msg, handle) {
    const fkey = pub ? jwk2pub$3(key) : jwk2priv$3(key);
    const fmsg = toString$9(Uint8Array.from(msg), 'ascii');
    const fomsg = handle(fmsg, fkey);
    return fromString$3(fomsg, 'ascii');
}
function encrypt$3(key, msg) {
    return convertKey$3(key, true, msg, (msg, key) => key.encrypt(msg));
}
function decrypt$3(key, msg) {
    return convertKey$3(key, false, msg, (msg, key) => key.decrypt(msg));
}
function keySize$3(jwk) {
    if (jwk.kty !== 'RSA') {
        throw new CodeError$3('invalid key type', 'ERR_INVALID_KEY_TYPE');
    }
    else if (jwk.n == null) {
        throw new CodeError$3('invalid key modulus', 'ERR_INVALID_KEY_MODULUS');
    }
    const bytes = fromString$3(jwk.n, 'base64url');
    return bytes.length * 8;
}

const MAX_KEY_SIZE$3 = 8192;
let RsaPublicKey$3 = class RsaPublicKey {
    _key;
    constructor(key) {
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$a(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix$3(this._key);
    }
    get bytes() {
        return PublicKey$3.encode({
            Type: KeyType$3.RSA,
            Data: this.marshal()
        }).subarray();
    }
    encrypt(bytes) {
        return encrypt$3(this._key, bytes);
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$4.digest(this.bytes);
        return bytes;
    }
};
let RsaPrivateKey$3 = class RsaPrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes$3(16);
    }
    async sign(message) {
        return hashAndSign$a(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError$3('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey$3(this._publicKey);
    }
    decrypt(bytes) {
        return decrypt$3(this._key, bytes);
    }
    marshal() {
        return jwkToPkcs1$3(this._key);
    }
    get bytes() {
        return PrivateKey$3.encode({
            Type: KeyType$3.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$4.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected PEM format
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            const buffer = new forge$n.util.ByteBuffer(this.marshal());
            const asn1 = forge$n.asn1.fromDer(buffer);
            const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
            const options = {
                algorithm: 'aes256',
                count: 10000,
                saltSize: 128 / 8,
                prfAlgorithm: 'sha512'
            };
            return forge$n.pki.encryptRsaPrivateKey(privateKey, password, options);
        }
        else if (format === 'libp2p-key') {
            return exporter$3(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
async function unmarshalRsaPrivateKey$3(bytes) {
    const jwk = pkcs1ToJwk$3(bytes);
    if (keySize$3(jwk) > MAX_KEY_SIZE$3) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$5(jwk);
    return new RsaPrivateKey$3(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey$3(bytes) {
    const jwk = pkixToJwk$3(bytes);
    if (keySize$3(jwk) > MAX_KEY_SIZE$3) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    return new RsaPublicKey$3(jwk);
}
async function fromJwk$3(jwk) {
    if (keySize$3(jwk) > MAX_KEY_SIZE$3) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$5(jwk);
    return new RsaPrivateKey$3(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$c(bits) {
    if (bits > MAX_KEY_SIZE$3) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await generateKey$a(bits);
    return new RsaPrivateKey$3(keys.privateKey, keys.publicKey);
}

var RSA$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MAX_KEY_SIZE: MAX_KEY_SIZE$3,
    RsaPrivateKey: RsaPrivateKey$3,
    RsaPublicKey: RsaPublicKey$3,
    fromJwk: fromJwk$3,
    generateKeyPair: generateKeyPair$c,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey$3,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey$3
});

// Choice: a ? b : c
const Chi = (a, b, c) => (a & b) ^ (~a & c);
// Majority function, true if any two inpust is true
const Maj = (a, b, c) => (a & b) ^ (a & c) ^ (b & c);
// Round constants:
// first 32 bits of the fractional parts of the cube roots of the first 64 primes 2..311)
// prettier-ignore
const SHA256_K = new Uint32Array([
    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
]);
// Initial state (first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19):
// prettier-ignore
const IV = new Uint32Array([
    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a, 0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
]);
// Temporary buffer, not used to store anything between runs
// Named this way because it matches specification.
const SHA256_W = new Uint32Array(64);
class SHA256 extends SHA2 {
    constructor() {
        super(64, 32, 8, false);
        // We cannot use array here since array allows indexing by variable
        // which means optimizer/compiler cannot use registers.
        this.A = IV[0] | 0;
        this.B = IV[1] | 0;
        this.C = IV[2] | 0;
        this.D = IV[3] | 0;
        this.E = IV[4] | 0;
        this.F = IV[5] | 0;
        this.G = IV[6] | 0;
        this.H = IV[7] | 0;
    }
    get() {
        const { A, B, C, D, E, F, G, H } = this;
        return [A, B, C, D, E, F, G, H];
    }
    // prettier-ignore
    set(A, B, C, D, E, F, G, H) {
        this.A = A | 0;
        this.B = B | 0;
        this.C = C | 0;
        this.D = D | 0;
        this.E = E | 0;
        this.F = F | 0;
        this.G = G | 0;
        this.H = H | 0;
    }
    process(view, offset) {
        // Extend the first 16 words into the remaining 48 words w[16..63] of the message schedule array
        for (let i = 0; i < 16; i++, offset += 4)
            SHA256_W[i] = view.getUint32(offset, false);
        for (let i = 16; i < 64; i++) {
            const W15 = SHA256_W[i - 15];
            const W2 = SHA256_W[i - 2];
            const s0 = rotr(W15, 7) ^ rotr(W15, 18) ^ (W15 >>> 3);
            const s1 = rotr(W2, 17) ^ rotr(W2, 19) ^ (W2 >>> 10);
            SHA256_W[i] = (s1 + SHA256_W[i - 7] + s0 + SHA256_W[i - 16]) | 0;
        }
        // Compression function main loop, 64 rounds
        let { A, B, C, D, E, F, G, H } = this;
        for (let i = 0; i < 64; i++) {
            const sigma1 = rotr(E, 6) ^ rotr(E, 11) ^ rotr(E, 25);
            const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;
            const sigma0 = rotr(A, 2) ^ rotr(A, 13) ^ rotr(A, 22);
            const T2 = (sigma0 + Maj(A, B, C)) | 0;
            H = G;
            G = F;
            F = E;
            E = (D + T1) | 0;
            D = C;
            C = B;
            B = A;
            A = (T1 + T2) | 0;
        }
        // Add the compressed chunk to the current hash value
        A = (A + this.A) | 0;
        B = (B + this.B) | 0;
        C = (C + this.C) | 0;
        D = (D + this.D) | 0;
        E = (E + this.E) | 0;
        F = (F + this.F) | 0;
        G = (G + this.G) | 0;
        H = (H + this.H) | 0;
        this.set(A, B, C, D, E, F, G, H);
    }
    roundClean() {
        SHA256_W.fill(0);
    }
    destroy() {
        this.set(0, 0, 0, 0, 0, 0, 0, 0);
        this.buffer.fill(0);
    }
}
// Constants from https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf
class SHA224 extends SHA256 {
    constructor() {
        super();
        this.A = 0xc1059ed8 | 0;
        this.B = 0x367cd507 | 0;
        this.C = 0x3070dd17 | 0;
        this.D = 0xf70e5939 | 0;
        this.E = 0xffc00b31 | 0;
        this.F = 0x68581511 | 0;
        this.G = 0x64f98fa7 | 0;
        this.H = 0xbefa4fa4 | 0;
        this.outputLen = 28;
    }
}
/**
 * SHA2-256 hash function
 * @param message - data that would be hashed
 */
const sha256$3 = wrapConstructor(() => new SHA256());
wrapConstructor(() => new SHA224());

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// Short Weierstrass curve. The formula is: y² = x³ + ax + b
function validatePointOpts(curve) {
    const opts = validateBasic(curve);
    validateObject(opts, {
        a: 'field',
        b: 'field',
    }, {
        allowedPrivateKeyLengths: 'array',
        wrapPrivateKey: 'boolean',
        isTorsionFree: 'function',
        clearCofactor: 'function',
        allowInfinityPoint: 'boolean',
        fromBytes: 'function',
        toBytes: 'function',
    });
    const { endo, Fp, a } = opts;
    if (endo) {
        if (!Fp.eql(a, Fp.ZERO)) {
            throw new Error('Endomorphism can only be defined for Koblitz curves that have a=0');
        }
        if (typeof endo !== 'object' ||
            typeof endo.beta !== 'bigint' ||
            typeof endo.splitScalar !== 'function') {
            throw new Error('Expected endomorphism with beta: bigint and splitScalar: function');
        }
    }
    return Object.freeze({ ...opts });
}
// ASN.1 DER encoding utilities
const { bytesToNumberBE: b2n, hexToBytes: h2b } = ut;
const DER = {
    // asn.1 DER encoding utils
    Err: class DERErr extends Error {
        constructor(m = '') {
            super(m);
        }
    },
    _parseInt(data) {
        const { Err: E } = DER;
        if (data.length < 2 || data[0] !== 0x02)
            throw new E('Invalid signature integer tag');
        const len = data[1];
        const res = data.subarray(2, len + 2);
        if (!len || res.length !== len)
            throw new E('Invalid signature integer: wrong length');
        // https://crypto.stackexchange.com/a/57734 Leftmost bit of first byte is 'negative' flag,
        // since we always use positive integers here. It must always be empty:
        // - add zero byte if exists
        // - if next byte doesn't have a flag, leading zero is not allowed (minimal encoding)
        if (res[0] & 0b10000000)
            throw new E('Invalid signature integer: negative');
        if (res[0] === 0x00 && !(res[1] & 0b10000000))
            throw new E('Invalid signature integer: unnecessary leading zero');
        return { d: b2n(res), l: data.subarray(len + 2) }; // d is data, l is left
    },
    toSig(hex) {
        // parse DER signature
        const { Err: E } = DER;
        const data = typeof hex === 'string' ? h2b(hex) : hex;
        if (!(data instanceof Uint8Array))
            throw new Error('ui8a expected');
        let l = data.length;
        if (l < 2 || data[0] != 0x30)
            throw new E('Invalid signature tag');
        if (data[1] !== l - 2)
            throw new E('Invalid signature: incorrect length');
        const { d: r, l: sBytes } = DER._parseInt(data.subarray(2));
        const { d: s, l: rBytesLeft } = DER._parseInt(sBytes);
        if (rBytesLeft.length)
            throw new E('Invalid signature: left bytes after parsing');
        return { r, s };
    },
    hexFromSig(sig) {
        // Add leading zero if first byte has negative bit enabled. More details in '_parseInt'
        const slice = (s) => (Number.parseInt(s[0], 16) & 0b1000 ? '00' + s : s);
        const h = (num) => {
            const hex = num.toString(16);
            return hex.length & 1 ? `0${hex}` : hex;
        };
        const s = slice(h(sig.s));
        const r = slice(h(sig.r));
        const shl = s.length / 2;
        const rhl = r.length / 2;
        const sl = h(shl);
        const rl = h(rhl);
        return `30${h(rhl + shl + 4)}02${rl}${r}02${sl}${s}`;
    },
};
// Be friendly to bad ECMAScript parsers by not using bigint literals
// prettier-ignore
const _0n = BigInt(0), _1n$1 = BigInt(1); BigInt(2); const _3n = BigInt(3); BigInt(4);
function weierstrassPoints(opts) {
    const CURVE = validatePointOpts(opts);
    const { Fp } = CURVE; // All curves has same field / group length as for now, but they can differ
    const toBytes = CURVE.toBytes ||
        ((c, point, isCompressed) => {
            const a = point.toAffine();
            return concatBytes$2(Uint8Array.from([0x04]), Fp.toBytes(a.x), Fp.toBytes(a.y));
        });
    const fromBytes = CURVE.fromBytes ||
        ((bytes) => {
            // const head = bytes[0];
            const tail = bytes.subarray(1);
            // if (head !== 0x04) throw new Error('Only non-compressed encoding is supported');
            const x = Fp.fromBytes(tail.subarray(0, Fp.BYTES));
            const y = Fp.fromBytes(tail.subarray(Fp.BYTES, 2 * Fp.BYTES));
            return { x, y };
        });
    /**
     * y² = x³ + ax + b: Short weierstrass curve formula
     * @returns y²
     */
    function weierstrassEquation(x) {
        const { a, b } = CURVE;
        const x2 = Fp.sqr(x); // x * x
        const x3 = Fp.mul(x2, x); // x2 * x
        return Fp.add(Fp.add(x3, Fp.mul(x, a)), b); // x3 + a * x + b
    }
    // Validate whether the passed curve params are valid.
    // We check if curve equation works for generator point.
    // `assertValidity()` won't work: `isTorsionFree()` is not available at this point in bls12-381.
    // ProjectivePoint class has not been initialized yet.
    if (!Fp.eql(Fp.sqr(CURVE.Gy), weierstrassEquation(CURVE.Gx)))
        throw new Error('bad generator point: equation left != right');
    // Valid group elements reside in range 1..n-1
    function isWithinCurveOrder(num) {
        return typeof num === 'bigint' && _0n < num && num < CURVE.n;
    }
    function assertGE(num) {
        if (!isWithinCurveOrder(num))
            throw new Error('Expected valid bigint: 0 < bigint < curve.n');
    }
    // Validates if priv key is valid and converts it to bigint.
    // Supports options allowedPrivateKeyLengths and wrapPrivateKey.
    function normPrivateKeyToScalar(key) {
        const { allowedPrivateKeyLengths: lengths, nByteLength, wrapPrivateKey, n } = CURVE;
        if (lengths && typeof key !== 'bigint') {
            if (key instanceof Uint8Array)
                key = bytesToHex$2(key);
            // Normalize to hex string, pad. E.g. P521 would norm 130-132 char hex to 132-char bytes
            if (typeof key !== 'string' || !lengths.includes(key.length))
                throw new Error('Invalid key');
            key = key.padStart(nByteLength * 2, '0');
        }
        let num;
        try {
            num =
                typeof key === 'bigint'
                    ? key
                    : bytesToNumberBE(ensureBytes$2('private key', key, nByteLength));
        }
        catch (error) {
            throw new Error(`private key must be ${nByteLength} bytes, hex or bigint, not ${typeof key}`);
        }
        if (wrapPrivateKey)
            num = mod$2(num, n); // disabled by default, enabled for BLS
        assertGE(num); // num in range [1..N-1]
        return num;
    }
    const pointPrecomputes = new Map();
    function assertPrjPoint(other) {
        if (!(other instanceof Point))
            throw new Error('ProjectivePoint expected');
    }
    /**
     * Projective Point works in 3d / projective (homogeneous) coordinates: (x, y, z) ∋ (x=x/z, y=y/z)
     * Default Point works in 2d / affine coordinates: (x, y)
     * We're doing calculations in projective, because its operations don't require costly inversion.
     */
    class Point {
        constructor(px, py, pz) {
            this.px = px;
            this.py = py;
            this.pz = pz;
            if (px == null || !Fp.isValid(px))
                throw new Error('x required');
            if (py == null || !Fp.isValid(py))
                throw new Error('y required');
            if (pz == null || !Fp.isValid(pz))
                throw new Error('z required');
        }
        // Does not validate if the point is on-curve.
        // Use fromHex instead, or call assertValidity() later.
        static fromAffine(p) {
            const { x, y } = p || {};
            if (!p || !Fp.isValid(x) || !Fp.isValid(y))
                throw new Error('invalid affine point');
            if (p instanceof Point)
                throw new Error('projective point not allowed');
            const is0 = (i) => Fp.eql(i, Fp.ZERO);
            // fromAffine(x:0, y:0) would produce (x:0, y:0, z:1), but we need (x:0, y:1, z:0)
            if (is0(x) && is0(y))
                return Point.ZERO;
            return new Point(x, y, Fp.ONE);
        }
        get x() {
            return this.toAffine().x;
        }
        get y() {
            return this.toAffine().y;
        }
        /**
         * Takes a bunch of Projective Points but executes only one
         * inversion on all of them. Inversion is very slow operation,
         * so this improves performance massively.
         * Optimization: converts a list of projective points to a list of identical points with Z=1.
         */
        static normalizeZ(points) {
            const toInv = Fp.invertBatch(points.map((p) => p.pz));
            return points.map((p, i) => p.toAffine(toInv[i])).map(Point.fromAffine);
        }
        /**
         * Converts hash string or Uint8Array to Point.
         * @param hex short/long ECDSA hex
         */
        static fromHex(hex) {
            const P = Point.fromAffine(fromBytes(ensureBytes$2('pointHex', hex)));
            P.assertValidity();
            return P;
        }
        // Multiplies generator point by privateKey.
        static fromPrivateKey(privateKey) {
            return Point.BASE.multiply(normPrivateKeyToScalar(privateKey));
        }
        // "Private method", don't use it directly
        _setWindowSize(windowSize) {
            this._WINDOW_SIZE = windowSize;
            pointPrecomputes.delete(this);
        }
        // A point on curve is valid if it conforms to equation.
        assertValidity() {
            // Zero is valid point too!
            if (this.is0()) {
                if (CURVE.allowInfinityPoint)
                    return;
                throw new Error('bad point: ZERO');
            }
            // Some 3rd-party test vectors require different wording between here & `fromCompressedHex`
            const { x, y } = this.toAffine();
            // Check if x, y are valid field elements
            if (!Fp.isValid(x) || !Fp.isValid(y))
                throw new Error('bad point: x or y not FE');
            const left = Fp.sqr(y); // y²
            const right = weierstrassEquation(x); // x³ + ax + b
            if (!Fp.eql(left, right))
                throw new Error('bad point: equation left != right');
            if (!this.isTorsionFree())
                throw new Error('bad point: not in prime-order subgroup');
        }
        hasEvenY() {
            const { y } = this.toAffine();
            if (Fp.isOdd)
                return !Fp.isOdd(y);
            throw new Error("Field doesn't support isOdd");
        }
        /**
         * Compare one point to another.
         */
        equals(other) {
            assertPrjPoint(other);
            const { px: X1, py: Y1, pz: Z1 } = this;
            const { px: X2, py: Y2, pz: Z2 } = other;
            const U1 = Fp.eql(Fp.mul(X1, Z2), Fp.mul(X2, Z1));
            const U2 = Fp.eql(Fp.mul(Y1, Z2), Fp.mul(Y2, Z1));
            return U1 && U2;
        }
        /**
         * Flips point to one corresponding to (x, -y) in Affine coordinates.
         */
        negate() {
            return new Point(this.px, Fp.neg(this.py), this.pz);
        }
        // Renes-Costello-Batina exception-free doubling formula.
        // There is 30% faster Jacobian formula, but it is not complete.
        // https://eprint.iacr.org/2015/1060, algorithm 3
        // Cost: 8M + 3S + 3*a + 2*b3 + 15add.
        double() {
            const { a, b } = CURVE;
            const b3 = Fp.mul(b, _3n);
            const { px: X1, py: Y1, pz: Z1 } = this;
            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore
            let t0 = Fp.mul(X1, X1); // step 1
            let t1 = Fp.mul(Y1, Y1);
            let t2 = Fp.mul(Z1, Z1);
            let t3 = Fp.mul(X1, Y1);
            t3 = Fp.add(t3, t3); // step 5
            Z3 = Fp.mul(X1, Z1);
            Z3 = Fp.add(Z3, Z3);
            X3 = Fp.mul(a, Z3);
            Y3 = Fp.mul(b3, t2);
            Y3 = Fp.add(X3, Y3); // step 10
            X3 = Fp.sub(t1, Y3);
            Y3 = Fp.add(t1, Y3);
            Y3 = Fp.mul(X3, Y3);
            X3 = Fp.mul(t3, X3);
            Z3 = Fp.mul(b3, Z3); // step 15
            t2 = Fp.mul(a, t2);
            t3 = Fp.sub(t0, t2);
            t3 = Fp.mul(a, t3);
            t3 = Fp.add(t3, Z3);
            Z3 = Fp.add(t0, t0); // step 20
            t0 = Fp.add(Z3, t0);
            t0 = Fp.add(t0, t2);
            t0 = Fp.mul(t0, t3);
            Y3 = Fp.add(Y3, t0);
            t2 = Fp.mul(Y1, Z1); // step 25
            t2 = Fp.add(t2, t2);
            t0 = Fp.mul(t2, t3);
            X3 = Fp.sub(X3, t0);
            Z3 = Fp.mul(t2, t1);
            Z3 = Fp.add(Z3, Z3); // step 30
            Z3 = Fp.add(Z3, Z3);
            return new Point(X3, Y3, Z3);
        }
        // Renes-Costello-Batina exception-free addition formula.
        // There is 30% faster Jacobian formula, but it is not complete.
        // https://eprint.iacr.org/2015/1060, algorithm 1
        // Cost: 12M + 0S + 3*a + 3*b3 + 23add.
        add(other) {
            assertPrjPoint(other);
            const { px: X1, py: Y1, pz: Z1 } = this;
            const { px: X2, py: Y2, pz: Z2 } = other;
            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore
            const a = CURVE.a;
            const b3 = Fp.mul(CURVE.b, _3n);
            let t0 = Fp.mul(X1, X2); // step 1
            let t1 = Fp.mul(Y1, Y2);
            let t2 = Fp.mul(Z1, Z2);
            let t3 = Fp.add(X1, Y1);
            let t4 = Fp.add(X2, Y2); // step 5
            t3 = Fp.mul(t3, t4);
            t4 = Fp.add(t0, t1);
            t3 = Fp.sub(t3, t4);
            t4 = Fp.add(X1, Z1);
            let t5 = Fp.add(X2, Z2); // step 10
            t4 = Fp.mul(t4, t5);
            t5 = Fp.add(t0, t2);
            t4 = Fp.sub(t4, t5);
            t5 = Fp.add(Y1, Z1);
            X3 = Fp.add(Y2, Z2); // step 15
            t5 = Fp.mul(t5, X3);
            X3 = Fp.add(t1, t2);
            t5 = Fp.sub(t5, X3);
            Z3 = Fp.mul(a, t4);
            X3 = Fp.mul(b3, t2); // step 20
            Z3 = Fp.add(X3, Z3);
            X3 = Fp.sub(t1, Z3);
            Z3 = Fp.add(t1, Z3);
            Y3 = Fp.mul(X3, Z3);
            t1 = Fp.add(t0, t0); // step 25
            t1 = Fp.add(t1, t0);
            t2 = Fp.mul(a, t2);
            t4 = Fp.mul(b3, t4);
            t1 = Fp.add(t1, t2);
            t2 = Fp.sub(t0, t2); // step 30
            t2 = Fp.mul(a, t2);
            t4 = Fp.add(t4, t2);
            t0 = Fp.mul(t1, t4);
            Y3 = Fp.add(Y3, t0);
            t0 = Fp.mul(t5, t4); // step 35
            X3 = Fp.mul(t3, X3);
            X3 = Fp.sub(X3, t0);
            t0 = Fp.mul(t3, t1);
            Z3 = Fp.mul(t5, Z3);
            Z3 = Fp.add(Z3, t0); // step 40
            return new Point(X3, Y3, Z3);
        }
        subtract(other) {
            return this.add(other.negate());
        }
        is0() {
            return this.equals(Point.ZERO);
        }
        wNAF(n) {
            return wnaf.wNAFCached(this, pointPrecomputes, n, (comp) => {
                const toInv = Fp.invertBatch(comp.map((p) => p.pz));
                return comp.map((p, i) => p.toAffine(toInv[i])).map(Point.fromAffine);
            });
        }
        /**
         * Non-constant-time multiplication. Uses double-and-add algorithm.
         * It's faster, but should only be used when you don't care about
         * an exposed private key e.g. sig verification, which works over *public* keys.
         */
        multiplyUnsafe(n) {
            const I = Point.ZERO;
            if (n === _0n)
                return I;
            assertGE(n); // Will throw on 0
            if (n === _1n$1)
                return this;
            const { endo } = CURVE;
            if (!endo)
                return wnaf.unsafeLadder(this, n);
            // Apply endomorphism
            let { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
            let k1p = I;
            let k2p = I;
            let d = this;
            while (k1 > _0n || k2 > _0n) {
                if (k1 & _1n$1)
                    k1p = k1p.add(d);
                if (k2 & _1n$1)
                    k2p = k2p.add(d);
                d = d.double();
                k1 >>= _1n$1;
                k2 >>= _1n$1;
            }
            if (k1neg)
                k1p = k1p.negate();
            if (k2neg)
                k2p = k2p.negate();
            k2p = new Point(Fp.mul(k2p.px, endo.beta), k2p.py, k2p.pz);
            return k1p.add(k2p);
        }
        /**
         * Constant time multiplication.
         * Uses wNAF method. Windowed method may be 10% faster,
         * but takes 2x longer to generate and consumes 2x memory.
         * Uses precomputes when available.
         * Uses endomorphism for Koblitz curves.
         * @param scalar by which the point would be multiplied
         * @returns New point
         */
        multiply(scalar) {
            assertGE(scalar);
            let n = scalar;
            let point, fake; // Fake point is used to const-time mult
            const { endo } = CURVE;
            if (endo) {
                const { k1neg, k1, k2neg, k2 } = endo.splitScalar(n);
                let { p: k1p, f: f1p } = this.wNAF(k1);
                let { p: k2p, f: f2p } = this.wNAF(k2);
                k1p = wnaf.constTimeNegate(k1neg, k1p);
                k2p = wnaf.constTimeNegate(k2neg, k2p);
                k2p = new Point(Fp.mul(k2p.px, endo.beta), k2p.py, k2p.pz);
                point = k1p.add(k2p);
                fake = f1p.add(f2p);
            }
            else {
                const { p, f } = this.wNAF(n);
                point = p;
                fake = f;
            }
            // Normalize `z` for both points, but return only real one
            return Point.normalizeZ([point, fake])[0];
        }
        /**
         * Efficiently calculate `aP + bQ`. Unsafe, can expose private key, if used incorrectly.
         * Not using Strauss-Shamir trick: precomputation tables are faster.
         * The trick could be useful if both P and Q are not G (not in our case).
         * @returns non-zero affine point
         */
        multiplyAndAddUnsafe(Q, a, b) {
            const G = Point.BASE; // No Strauss-Shamir trick: we have 10% faster G precomputes
            const mul = (P, a // Select faster multiply() method
            ) => (a === _0n || a === _1n$1 || !P.equals(G) ? P.multiplyUnsafe(a) : P.multiply(a));
            const sum = mul(this, a).add(mul(Q, b));
            return sum.is0() ? undefined : sum;
        }
        // Converts Projective point to affine (x, y) coordinates.
        // Can accept precomputed Z^-1 - for example, from invertBatch.
        // (x, y, z) ∋ (x=x/z, y=y/z)
        toAffine(iz) {
            const { px: x, py: y, pz: z } = this;
            const is0 = this.is0();
            // If invZ was 0, we return zero point. However we still want to execute
            // all operations, so we replace invZ with a random number, 1.
            if (iz == null)
                iz = is0 ? Fp.ONE : Fp.inv(z);
            const ax = Fp.mul(x, iz);
            const ay = Fp.mul(y, iz);
            const zz = Fp.mul(z, iz);
            if (is0)
                return { x: Fp.ZERO, y: Fp.ZERO };
            if (!Fp.eql(zz, Fp.ONE))
                throw new Error('invZ was invalid');
            return { x: ax, y: ay };
        }
        isTorsionFree() {
            const { h: cofactor, isTorsionFree } = CURVE;
            if (cofactor === _1n$1)
                return true; // No subgroups, always torsion-free
            if (isTorsionFree)
                return isTorsionFree(Point, this);
            throw new Error('isTorsionFree() has not been declared for the elliptic curve');
        }
        clearCofactor() {
            const { h: cofactor, clearCofactor } = CURVE;
            if (cofactor === _1n$1)
                return this; // Fast-path
            if (clearCofactor)
                return clearCofactor(Point, this);
            return this.multiplyUnsafe(CURVE.h);
        }
        toRawBytes(isCompressed = true) {
            this.assertValidity();
            return toBytes(Point, this, isCompressed);
        }
        toHex(isCompressed = true) {
            return bytesToHex$2(this.toRawBytes(isCompressed));
        }
    }
    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, Fp.ONE);
    Point.ZERO = new Point(Fp.ZERO, Fp.ONE, Fp.ZERO);
    const _bits = CURVE.nBitLength;
    const wnaf = wNAF(Point, CURVE.endo ? Math.ceil(_bits / 2) : _bits);
    // Validate if generator point is on curve
    return {
        CURVE,
        ProjectivePoint: Point,
        normPrivateKeyToScalar,
        weierstrassEquation,
        isWithinCurveOrder,
    };
}
function validateOpts(curve) {
    const opts = validateBasic(curve);
    validateObject(opts, {
        hash: 'hash',
        hmac: 'function',
        randomBytes: 'function',
    }, {
        bits2int: 'function',
        bits2int_modN: 'function',
        lowS: 'boolean',
    });
    return Object.freeze({ lowS: true, ...opts });
}
function weierstrass(curveDef) {
    const CURVE = validateOpts(curveDef);
    const { Fp, n: CURVE_ORDER } = CURVE;
    const compressedLen = Fp.BYTES + 1; // e.g. 33 for 32
    const uncompressedLen = 2 * Fp.BYTES + 1; // e.g. 65 for 32
    function isValidFieldElement(num) {
        return _0n < num && num < Fp.ORDER; // 0 is banned since it's not invertible FE
    }
    function modN(a) {
        return mod$2(a, CURVE_ORDER);
    }
    function invN(a) {
        return invert$2(a, CURVE_ORDER);
    }
    const { ProjectivePoint: Point, normPrivateKeyToScalar, weierstrassEquation, isWithinCurveOrder, } = weierstrassPoints({
        ...CURVE,
        toBytes(c, point, isCompressed) {
            const a = point.toAffine();
            const x = Fp.toBytes(a.x);
            const cat = concatBytes$2;
            if (isCompressed) {
                return cat(Uint8Array.from([point.hasEvenY() ? 0x02 : 0x03]), x);
            }
            else {
                return cat(Uint8Array.from([0x04]), x, Fp.toBytes(a.y));
            }
        },
        fromBytes(bytes) {
            const len = bytes.length;
            const head = bytes[0];
            const tail = bytes.subarray(1);
            // this.assertValidity() is done inside of fromHex
            if (len === compressedLen && (head === 0x02 || head === 0x03)) {
                const x = bytesToNumberBE(tail);
                if (!isValidFieldElement(x))
                    throw new Error('Point is not on curve');
                const y2 = weierstrassEquation(x); // y² = x³ + ax + b
                let y = Fp.sqrt(y2); // y = y² ^ (p+1)/4
                const isYOdd = (y & _1n$1) === _1n$1;
                // ECDSA
                const isHeadOdd = (head & 1) === 1;
                if (isHeadOdd !== isYOdd)
                    y = Fp.neg(y);
                return { x, y };
            }
            else if (len === uncompressedLen && head === 0x04) {
                const x = Fp.fromBytes(tail.subarray(0, Fp.BYTES));
                const y = Fp.fromBytes(tail.subarray(Fp.BYTES, 2 * Fp.BYTES));
                return { x, y };
            }
            else {
                throw new Error(`Point of length ${len} was invalid. Expected ${compressedLen} compressed bytes or ${uncompressedLen} uncompressed bytes`);
            }
        },
    });
    const numToNByteStr = (num) => bytesToHex$2(numberToBytesBE(num, CURVE.nByteLength));
    function isBiggerThanHalfOrder(number) {
        const HALF = CURVE_ORDER >> _1n$1;
        return number > HALF;
    }
    function normalizeS(s) {
        return isBiggerThanHalfOrder(s) ? modN(-s) : s;
    }
    // slice bytes num
    const slcNum = (b, from, to) => bytesToNumberBE(b.slice(from, to));
    /**
     * ECDSA signature with its (r, s) properties. Supports DER & compact representations.
     */
    class Signature {
        constructor(r, s, recovery) {
            this.r = r;
            this.s = s;
            this.recovery = recovery;
            this.assertValidity();
        }
        // pair (bytes of r, bytes of s)
        static fromCompact(hex) {
            const l = CURVE.nByteLength;
            hex = ensureBytes$2('compactSignature', hex, l * 2);
            return new Signature(slcNum(hex, 0, l), slcNum(hex, l, 2 * l));
        }
        // DER encoded ECDSA signature
        // https://bitcoin.stackexchange.com/questions/57644/what-are-the-parts-of-a-bitcoin-transaction-input-script
        static fromDER(hex) {
            const { r, s } = DER.toSig(ensureBytes$2('DER', hex));
            return new Signature(r, s);
        }
        assertValidity() {
            // can use assertGE here
            if (!isWithinCurveOrder(this.r))
                throw new Error('r must be 0 < r < CURVE.n');
            if (!isWithinCurveOrder(this.s))
                throw new Error('s must be 0 < s < CURVE.n');
        }
        addRecoveryBit(recovery) {
            return new Signature(this.r, this.s, recovery);
        }
        recoverPublicKey(msgHash) {
            const { r, s, recovery: rec } = this;
            const h = bits2int_modN(ensureBytes$2('msgHash', msgHash)); // Truncate hash
            if (rec == null || ![0, 1, 2, 3].includes(rec))
                throw new Error('recovery id invalid');
            const radj = rec === 2 || rec === 3 ? r + CURVE.n : r;
            if (radj >= Fp.ORDER)
                throw new Error('recovery id 2 or 3 invalid');
            const prefix = (rec & 1) === 0 ? '02' : '03';
            const R = Point.fromHex(prefix + numToNByteStr(radj));
            const ir = invN(radj); // r^-1
            const u1 = modN(-h * ir); // -hr^-1
            const u2 = modN(s * ir); // sr^-1
            const Q = Point.BASE.multiplyAndAddUnsafe(R, u1, u2); // (sr^-1)R-(hr^-1)G = -(hr^-1)G + (sr^-1)
            if (!Q)
                throw new Error('point at infinify'); // unsafe is fine: no priv data leaked
            Q.assertValidity();
            return Q;
        }
        // Signatures should be low-s, to prevent malleability.
        hasHighS() {
            return isBiggerThanHalfOrder(this.s);
        }
        normalizeS() {
            return this.hasHighS() ? new Signature(this.r, modN(-this.s), this.recovery) : this;
        }
        // DER-encoded
        toDERRawBytes() {
            return hexToBytes$2(this.toDERHex());
        }
        toDERHex() {
            return DER.hexFromSig({ r: this.r, s: this.s });
        }
        // padded bytes of r, then padded bytes of s
        toCompactRawBytes() {
            return hexToBytes$2(this.toCompactHex());
        }
        toCompactHex() {
            return numToNByteStr(this.r) + numToNByteStr(this.s);
        }
    }
    const utils = {
        isValidPrivateKey(privateKey) {
            try {
                normPrivateKeyToScalar(privateKey);
                return true;
            }
            catch (error) {
                return false;
            }
        },
        normPrivateKeyToScalar: normPrivateKeyToScalar,
        /**
         * Produces cryptographically secure private key from random of size (nBitLength+64)
         * as per FIPS 186 B.4.1 with modulo bias being neglible.
         */
        randomPrivateKey: () => {
            const rand = CURVE.randomBytes(Fp.BYTES + 8);
            const num = hashToPrivateScalar(rand, CURVE_ORDER);
            return numberToBytesBE(num, CURVE.nByteLength);
        },
        /**
         * Creates precompute table for an arbitrary EC point. Makes point "cached".
         * Allows to massively speed-up `point.multiply(scalar)`.
         * @returns cached point
         * @example
         * const fast = utils.precompute(8, ProjectivePoint.fromHex(someonesPubKey));
         * fast.multiply(privKey); // much faster ECDH now
         */
        precompute(windowSize = 8, point = Point.BASE) {
            point._setWindowSize(windowSize);
            point.multiply(BigInt(3)); // 3 is arbitrary, just need any number here
            return point;
        },
    };
    /**
     * Computes public key for a private key. Checks for validity of the private key.
     * @param privateKey private key
     * @param isCompressed whether to return compact (default), or full key
     * @returns Public key, full when isCompressed=false; short when isCompressed=true
     */
    function getPublicKey(privateKey, isCompressed = true) {
        return Point.fromPrivateKey(privateKey).toRawBytes(isCompressed);
    }
    /**
     * Quick and dirty check for item being public key. Does not validate hex, or being on-curve.
     */
    function isProbPub(item) {
        const arr = item instanceof Uint8Array;
        const str = typeof item === 'string';
        const len = (arr || str) && item.length;
        if (arr)
            return len === compressedLen || len === uncompressedLen;
        if (str)
            return len === 2 * compressedLen || len === 2 * uncompressedLen;
        if (item instanceof Point)
            return true;
        return false;
    }
    /**
     * ECDH (Elliptic Curve Diffie Hellman).
     * Computes shared public key from private key and public key.
     * Checks: 1) private key validity 2) shared key is on-curve.
     * Does NOT hash the result.
     * @param privateA private key
     * @param publicB different public key
     * @param isCompressed whether to return compact (default), or full key
     * @returns shared public key
     */
    function getSharedSecret(privateA, publicB, isCompressed = true) {
        if (isProbPub(privateA))
            throw new Error('first arg must be private key');
        if (!isProbPub(publicB))
            throw new Error('second arg must be public key');
        const b = Point.fromHex(publicB); // check for being on-curve
        return b.multiply(normPrivateKeyToScalar(privateA)).toRawBytes(isCompressed);
    }
    // RFC6979: ensure ECDSA msg is X bytes and < N. RFC suggests optional truncating via bits2octets.
    // FIPS 186-4 4.6 suggests the leftmost min(nBitLen, outLen) bits, which matches bits2int.
    // bits2int can produce res>N, we can do mod(res, N) since the bitLen is the same.
    // int2octets can't be used; pads small msgs with 0: unacceptatble for trunc as per RFC vectors
    const bits2int = CURVE.bits2int ||
        function (bytes) {
            // For curves with nBitLength % 8 !== 0: bits2octets(bits2octets(m)) !== bits2octets(m)
            // for some cases, since bytes.length * 8 is not actual bitLength.
            const num = bytesToNumberBE(bytes); // check for == u8 done here
            const delta = bytes.length * 8 - CURVE.nBitLength; // truncate to nBitLength leftmost bits
            return delta > 0 ? num >> BigInt(delta) : num;
        };
    const bits2int_modN = CURVE.bits2int_modN ||
        function (bytes) {
            return modN(bits2int(bytes)); // can't use bytesToNumberBE here
        };
    // NOTE: pads output with zero as per spec
    const ORDER_MASK = bitMask(CURVE.nBitLength);
    /**
     * Converts to bytes. Checks if num in `[0..ORDER_MASK-1]` e.g.: `[0..2^256-1]`.
     */
    function int2octets(num) {
        if (typeof num !== 'bigint')
            throw new Error('bigint expected');
        if (!(_0n <= num && num < ORDER_MASK))
            throw new Error(`bigint expected < 2^${CURVE.nBitLength}`);
        // works with order, can have different size than numToField!
        return numberToBytesBE(num, CURVE.nByteLength);
    }
    // Steps A, D of RFC6979 3.2
    // Creates RFC6979 seed; converts msg/privKey to numbers.
    // Used only in sign, not in verify.
    // NOTE: we cannot assume here that msgHash has same amount of bytes as curve order, this will be wrong at least for P521.
    // Also it can be bigger for P224 + SHA256
    function prepSig(msgHash, privateKey, opts = defaultSigOpts) {
        if (['recovered', 'canonical'].some((k) => k in opts))
            throw new Error('sign() legacy options not supported');
        const { hash, randomBytes } = CURVE;
        let { lowS, prehash, extraEntropy: ent } = opts; // generates low-s sigs by default
        if (lowS == null)
            lowS = true; // RFC6979 3.2: we skip step A, because we already provide hash
        msgHash = ensureBytes$2('msgHash', msgHash);
        if (prehash)
            msgHash = ensureBytes$2('prehashed msgHash', hash(msgHash));
        // We can't later call bits2octets, since nested bits2int is broken for curves
        // with nBitLength % 8 !== 0. Because of that, we unwrap it here as int2octets call.
        // const bits2octets = (bits) => int2octets(bits2int_modN(bits))
        const h1int = bits2int_modN(msgHash);
        const d = normPrivateKeyToScalar(privateKey); // validate private key, convert to bigint
        const seedArgs = [int2octets(d), int2octets(h1int)];
        // extraEntropy. RFC6979 3.6: additional k' (optional).
        if (ent != null) {
            // K = HMAC_K(V || 0x00 || int2octets(x) || bits2octets(h1) || k')
            const e = ent === true ? randomBytes(Fp.BYTES) : ent; // generate random bytes OR pass as-is
            seedArgs.push(ensureBytes$2('extraEntropy', e, Fp.BYTES)); // check for being of size BYTES
        }
        const seed = concatBytes$2(...seedArgs); // Step D of RFC6979 3.2
        const m = h1int; // NOTE: no need to call bits2int second time here, it is inside truncateHash!
        // Converts signature params into point w r/s, checks result for validity.
        function k2sig(kBytes) {
            // RFC 6979 Section 3.2, step 3: k = bits2int(T)
            const k = bits2int(kBytes); // Cannot use fields methods, since it is group element
            if (!isWithinCurveOrder(k))
                return; // Important: all mod() calls here must be done over N
            const ik = invN(k); // k^-1 mod n
            const q = Point.BASE.multiply(k).toAffine(); // q = Gk
            const r = modN(q.x); // r = q.x mod n
            if (r === _0n)
                return;
            // Can use scalar blinding b^-1(bm + bdr) where b ∈ [1,q−1] according to
            // https://tches.iacr.org/index.php/TCHES/article/view/7337/6509. We've decided against it:
            // a) dependency on CSPRNG b) 15% slowdown c) doesn't really help since bigints are not CT
            const s = modN(ik * modN(m + r * d)); // Not using blinding here
            if (s === _0n)
                return;
            let recovery = (q.x === r ? 0 : 2) | Number(q.y & _1n$1); // recovery bit (2 or 3, when q.x > n)
            let normS = s;
            if (lowS && isBiggerThanHalfOrder(s)) {
                normS = normalizeS(s); // if lowS was passed, ensure s is always
                recovery ^= 1; // // in the bottom half of N
            }
            return new Signature(r, normS, recovery); // use normS, not s
        }
        return { seed, k2sig };
    }
    const defaultSigOpts = { lowS: CURVE.lowS, prehash: false };
    const defaultVerOpts = { lowS: CURVE.lowS, prehash: false };
    /**
     * Signs message hash with a private key.
     * ```
     * sign(m, d, k) where
     *   (x, y) = G × k
     *   r = x mod n
     *   s = (m + dr)/k mod n
     * ```
     * @param msgHash NOT message. msg needs to be hashed to `msgHash`, or use `prehash`.
     * @param privKey private key
     * @param opts lowS for non-malleable sigs. extraEntropy for mixing randomness into k. prehash will hash first arg.
     * @returns signature with recovery param
     */
    function sign(msgHash, privKey, opts = defaultSigOpts) {
        const { seed, k2sig } = prepSig(msgHash, privKey, opts); // Steps A, D of RFC6979 3.2.
        const C = CURVE;
        const drbg = createHmacDrbg(C.hash.outputLen, C.nByteLength, C.hmac);
        return drbg(seed, k2sig); // Steps B, C, D, E, F, G
    }
    // Enable precomputes. Slows down first publicKey computation by 20ms.
    Point.BASE._setWindowSize(8);
    // utils.precompute(8, ProjectivePoint.BASE)
    /**
     * Verifies a signature against message hash and public key.
     * Rejects lowS signatures by default: to override,
     * specify option `{lowS: false}`. Implements section 4.1.4 from https://www.secg.org/sec1-v2.pdf:
     *
     * ```
     * verify(r, s, h, P) where
     *   U1 = hs^-1 mod n
     *   U2 = rs^-1 mod n
     *   R = U1⋅G - U2⋅P
     *   mod(R.x, n) == r
     * ```
     */
    function verify(signature, msgHash, publicKey, opts = defaultVerOpts) {
        const sg = signature;
        msgHash = ensureBytes$2('msgHash', msgHash);
        publicKey = ensureBytes$2('publicKey', publicKey);
        if ('strict' in opts)
            throw new Error('options.strict was renamed to lowS');
        const { lowS, prehash } = opts;
        let _sig = undefined;
        let P;
        try {
            if (typeof sg === 'string' || sg instanceof Uint8Array) {
                // Signature can be represented in 2 ways: compact (2*nByteLength) & DER (variable-length).
                // Since DER can also be 2*nByteLength bytes, we check for it first.
                try {
                    _sig = Signature.fromDER(sg);
                }
                catch (derError) {
                    if (!(derError instanceof DER.Err))
                        throw derError;
                    _sig = Signature.fromCompact(sg);
                }
            }
            else if (typeof sg === 'object' && typeof sg.r === 'bigint' && typeof sg.s === 'bigint') {
                const { r, s } = sg;
                _sig = new Signature(r, s);
            }
            else {
                throw new Error('PARSE');
            }
            P = Point.fromHex(publicKey);
        }
        catch (error) {
            if (error.message === 'PARSE')
                throw new Error(`signature must be Signature instance, Uint8Array or hex string`);
            return false;
        }
        if (lowS && _sig.hasHighS())
            return false;
        if (prehash)
            msgHash = CURVE.hash(msgHash);
        const { r, s } = _sig;
        const h = bits2int_modN(msgHash); // Cannot use fields methods, since it is group element
        const is = invN(s); // s^-1
        const u1 = modN(h * is); // u1 = hs^-1 mod n
        const u2 = modN(r * is); // u2 = rs^-1 mod n
        const R = Point.BASE.multiplyAndAddUnsafe(P, u1, u2)?.toAffine(); // R = u1⋅G + u2⋅P
        if (!R)
            return false;
        const v = modN(R.x);
        return v === r;
    }
    return {
        CURVE,
        getPublicKey,
        getSharedSecret,
        sign,
        verify,
        ProjectivePoint: Point,
        Signature,
        utils,
    };
}

// HMAC (RFC 2104)
class HMAC extends Hash {
    constructor(hash, _key) {
        super();
        this.finished = false;
        this.destroyed = false;
        assert.hash(hash);
        const key = toBytes$1(_key);
        this.iHash = hash.create();
        if (typeof this.iHash.update !== 'function')
            throw new Error('Expected instance of class which extends utils.Hash');
        this.blockLen = this.iHash.blockLen;
        this.outputLen = this.iHash.outputLen;
        const blockLen = this.blockLen;
        const pad = new Uint8Array(blockLen);
        // blockLen can be bigger than outputLen
        pad.set(key.length > blockLen ? hash.create().update(key).digest() : key);
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36;
        this.iHash.update(pad);
        // By doing update (processing of first block) of outer hash here we can re-use it between multiple calls via clone
        this.oHash = hash.create();
        // Undo internal XOR && apply outer XOR
        for (let i = 0; i < pad.length; i++)
            pad[i] ^= 0x36 ^ 0x5c;
        this.oHash.update(pad);
        pad.fill(0);
    }
    update(buf) {
        assert.exists(this);
        this.iHash.update(buf);
        return this;
    }
    digestInto(out) {
        assert.exists(this);
        assert.bytes(out, this.outputLen);
        this.finished = true;
        this.iHash.digestInto(out);
        this.oHash.update(out);
        this.oHash.digestInto(out);
        this.destroy();
    }
    digest() {
        const out = new Uint8Array(this.oHash.outputLen);
        this.digestInto(out);
        return out;
    }
    _cloneInto(to) {
        // Create new instance without calling constructor since key already in state and we don't know it.
        to || (to = Object.create(Object.getPrototypeOf(this), {}));
        const { oHash, iHash, finished, destroyed, blockLen, outputLen } = this;
        to = to;
        to.finished = finished;
        to.destroyed = destroyed;
        to.blockLen = blockLen;
        to.outputLen = outputLen;
        to.oHash = oHash._cloneInto(to.oHash);
        to.iHash = iHash._cloneInto(to.iHash);
        return to;
    }
    destroy() {
        this.destroyed = true;
        this.oHash.destroy();
        this.iHash.destroy();
    }
}
/**
 * HMAC: RFC2104 message authentication code.
 * @param hash - function that would be used e.g. sha256
 * @param key - message key
 * @param message - message data
 */
const hmac = (hash, key, message) => new HMAC(hash, key).update(message).digest();
hmac.create = (hash, key) => new HMAC(hash, key);

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
// connects noble-curves to noble-hashes
function getHash(hash) {
    return {
        hash,
        hmac: (key, ...msgs) => hmac(hash, key, concatBytes$3(...msgs)),
        randomBytes: randomBytes$7,
    };
}
function createCurve(curveDef, defHash) {
    const create = (hash) => weierstrass({ ...curveDef, ...getHash(hash) });
    return Object.freeze({ ...create(defHash), create });
}

/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */
const secp256k1P = BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f');
const secp256k1N = BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141');
const _1n = BigInt(1);
const _2n = BigInt(2);
const divNearest = (a, b) => (a + b / _2n) / b;
/**
 * √n = n^((p+1)/4) for fields p = 3 mod 4. We unwrap the loop and multiply bit-by-bit.
 * (P+1n/4n).toString(2) would produce bits [223x 1, 0, 22x 1, 4x 0, 11, 00]
 */
function sqrtMod(y) {
    const P = secp256k1P;
    // prettier-ignore
    const _3n = BigInt(3), _6n = BigInt(6), _11n = BigInt(11), _22n = BigInt(22);
    // prettier-ignore
    const _23n = BigInt(23), _44n = BigInt(44), _88n = BigInt(88);
    const b2 = (y * y * y) % P; // x^3, 11
    const b3 = (b2 * b2 * y) % P; // x^7
    const b6 = (pow2$2(b3, _3n, P) * b3) % P;
    const b9 = (pow2$2(b6, _3n, P) * b3) % P;
    const b11 = (pow2$2(b9, _2n, P) * b2) % P;
    const b22 = (pow2$2(b11, _11n, P) * b11) % P;
    const b44 = (pow2$2(b22, _22n, P) * b22) % P;
    const b88 = (pow2$2(b44, _44n, P) * b44) % P;
    const b176 = (pow2$2(b88, _88n, P) * b88) % P;
    const b220 = (pow2$2(b176, _44n, P) * b44) % P;
    const b223 = (pow2$2(b220, _3n, P) * b3) % P;
    const t1 = (pow2$2(b223, _23n, P) * b22) % P;
    const t2 = (pow2$2(t1, _6n, P) * b2) % P;
    const root = pow2$2(t2, _2n, P);
    if (!Fp.eql(Fp.sqr(root), y))
        throw new Error('Cannot find square root');
    return root;
}
const Fp = Field(secp256k1P, undefined, undefined, { sqrt: sqrtMod });
const secp256k1 = createCurve({
    a: BigInt(0),
    b: BigInt(7),
    Fp,
    n: secp256k1N,
    // Base point (x, y) aka generator point
    Gx: BigInt('55066263022277343669578718895168534326250603453777594175500187360389116729240'),
    Gy: BigInt('32670510020758816978083085130507043184471273380659243275938904335757337482424'),
    h: BigInt(1),
    lowS: true,
    /**
     * secp256k1 belongs to Koblitz curves: it has efficiently computable endomorphism.
     * Endomorphism uses 2x less RAM, speeds up precomputation by 2x and ECDH / key recovery by 20%.
     * For precomputed wNAF it trades off 1/2 init time & 1/3 ram for 20% perf hit.
     * Explanation: https://gist.github.com/paulmillr/eb670806793e84df628a7c434a873066
     */
    endo: {
        beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),
        splitScalar: (k) => {
            const n = secp256k1N;
            const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');
            const b1 = -_1n * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');
            const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');
            const b2 = a1;
            const POW_2_128 = BigInt('0x100000000000000000000000000000000'); // (2n**128n).toString(16)
            const c1 = divNearest(b2 * k, n);
            const c2 = divNearest(-b1 * k, n);
            let k1 = mod$2(k - c1 * a1 - c2 * a2, n);
            let k2 = mod$2(-c1 * b1 - c2 * b2, n);
            const k1neg = k1 > POW_2_128;
            const k2neg = k2 > POW_2_128;
            if (k1neg)
                k1 = n - k1;
            if (k2neg)
                k2 = n - k2;
            if (k1 > POW_2_128 || k2 > POW_2_128) {
                throw new Error('splitScalar: Endomorphism failed, k=' + k);
            }
            return { k1neg, k1, k2neg, k2 };
        },
    },
}, sha256$3);
// Schnorr signatures are superior to ECDSA from above. Below is Schnorr-specific BIP0340 code.
// https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki
BigInt(0);
secp256k1.ProjectivePoint;

function generateKey$9() {
    return secp256k1.utils.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
async function hashAndSign$9(key, msg) {
    const { digest } = await sha256$4.digest(msg);
    try {
        const signature = secp256k1.sign(digest, key);
        return signature.toDERRawBytes();
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
async function hashAndVerify$9(key, sig, msg) {
    try {
        const { digest } = await sha256$4.digest(msg);
        return secp256k1.verify(sig, digest, key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey$3(key) {
    const point = secp256k1.ProjectivePoint.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey$3(key) {
    try {
        secp256k1.getPublicKey(key, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey$3(key) {
    try {
        secp256k1.ProjectivePoint.fromHex(key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey$3(privateKey) {
    try {
        return secp256k1.getPublicKey(privateKey, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

let Secp256k1PublicKey$3 = class Secp256k1PublicKey {
    _key;
    constructor(key) {
        validatePublicKey$3(key);
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$9(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey$3(this._key);
    }
    get bytes() {
        return PublicKey$3.encode({
            Type: KeyType$3.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$4.digest(this.bytes);
        return bytes;
    }
};
let Secp256k1PrivateKey$3 = class Secp256k1PrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey$3(key);
        validatePrivateKey$3(this._key);
        validatePublicKey$3(this._publicKey);
    }
    async sign(message) {
        return hashAndSign$9(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey$3(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$3.encode({
            Type: KeyType$3.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$4.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$3(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalSecp256k1PrivateKey$3(bytes) {
    return new Secp256k1PrivateKey$3(bytes);
}
function unmarshalSecp256k1PublicKey$3(bytes) {
    return new Secp256k1PublicKey$3(bytes);
}
async function generateKeyPair$b() {
    const privateKeyBytes = generateKey$9();
    return new Secp256k1PrivateKey$3(privateKeyBytes);
}

var Secp256k1$3 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey$3,
    Secp256k1PublicKey: Secp256k1PublicKey$3,
    generateKeyPair: generateKeyPair$b,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey$3,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey$3
});

const supportedKeys$3 = {
    rsa: RSA$3,
    ed25519: Ed25519$3,
    secp256k1: Secp256k1$3
};
function unsupportedKey$3(type) {
    const supported = Object.keys(supportedKeys$3).join(' / ');
    return new CodeError$3(`invalid or unsupported key type ${type}. Must be ${supported}`, 'ERR_UNSUPPORTED_KEY_TYPE');
}
// Converts a protobuf serialized public key into its
// representative object
function unmarshalPublicKey$1(buf) {
    const decoded = PublicKey$3.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType$3.RSA:
            return supportedKeys$3.rsa.unmarshalRsaPublicKey(data);
        case KeyType$3.Ed25519:
            return supportedKeys$3.ed25519.unmarshalEd25519PublicKey(data);
        case KeyType$3.Secp256k1:
            return supportedKeys$3.secp256k1.unmarshalSecp256k1PublicKey(data);
        default:
            throw unsupportedKey$3(decoded.Type ?? 'RSA');
    }
}

/**
 * Any object that implements this Symbol as a property should return a
 * ContentRouting instance as the property value, similar to how
 * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```js
 * import { contentRouting, ContentRouting } from '@libp2p/content-routing'
 *
 * class MyContentRouter implements ContentRouting {
 *   get [contentRouting] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const contentRouting = Symbol.for('@libp2p/content-routing');

/**
 * Any object that implements this Symbol as a property should return a
 * PeerRouting instance as the property value, similar to how
 * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.
 *
 * @example
 *
 * ```js
 * import { peerRouting, PeerRouting } from '@libp2p/peer-routing'
 *
 * class MyPeerRouter implements PeerRouting {
 *   get [peerRouting] () {
 *     return this
 *   }
 *
 *   // ...other methods
 * }
 * ```
 */
const peerRouting = Symbol.for('@libp2p/peer-routing');

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto$2 = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto == null || nativeCrypto.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p-crypto/blob/master/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$4 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$4 = base$4;

var _brrp__multiformats_scope_baseX$4 = src$4;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$4 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$4 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$4 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$4(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$4 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$4(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$4 = (left, right) => new ComposedDecoder$4(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$4 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$4(name, prefix, baseEncode);
    this.decoder = new Decoder$4(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$7 = ({ name, prefix, encode, decode }) =>
  new Codec$4(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$4 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$4(alphabet, name);
  return from$7({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$4(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$7 = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$b = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$4 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$7({
    prefix,
    name,
    encode (input) {
      return encode$b(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$7(input, alphabet, bitsPerChar, name)
    }
  })
};

const base58btc$4 = baseX$4({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$4({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var encode_1$2 = encode$a;

var MSB$3 = 0x80
  , REST$3 = 0x7F
  , MSBALL$2 = ~REST$3
  , INT$2 = Math.pow(2, 31);

function encode$a(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$2) {
    out[offset++] = (num & 0xFF) | MSB$3;
    num /= 128;
  }
  while(num & MSBALL$2) {
    out[offset++] = (num & 0xFF) | MSB$3;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$a.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$6 = read$3;

var MSB$1$2 = 0x80
  , REST$1$2 = 0x7F;

function read$3(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$3.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$2) << shift
      : (b & REST$1$2) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$2)

  read$3.bytes = counter - offset;

  return res
}

var N1$2 = Math.pow(2,  7);
var N2$2 = Math.pow(2, 14);
var N3$2 = Math.pow(2, 21);
var N4$2 = Math.pow(2, 28);
var N5$2 = Math.pow(2, 35);
var N6$2 = Math.pow(2, 42);
var N7$2 = Math.pow(2, 49);
var N8$2 = Math.pow(2, 56);
var N9$2 = Math.pow(2, 63);

var length$2 = function (value) {
  return (
    value < N1$2 ? 1
  : value < N2$2 ? 2
  : value < N3$2 ? 3
  : value < N4$2 ? 4
  : value < N5$2 ? 5
  : value < N6$2 ? 6
  : value < N7$2 ? 7
  : value < N8$2 ? 8
  : value < N9$2 ? 9
  :              10
  )
};

var varint$2 = {
    encode: encode_1$2
  , decode: decode$6
  , encodingLength: length$2
};

var _brrp_varint$2 = varint$2;

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo$2 = (int, target, offset = 0) => {
  _brrp_varint$2.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$2 = (int) => {
  return _brrp_varint$2.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$5 = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$2(code);
  const digestOffset = sizeOffset + encodingLength$2(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo$2(code, bytes, 0);
  encodeTo$2(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest$2(code, size, digest, bytes)
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
let Digest$2 = class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
};

const code$2 = 0x0;
const name$2 = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$9 = coerce$4;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest$2 = (input) => create$5(code$2, encode$9(input));

const identity$2 = { code: code$2, name: name$2, encode: encode$9, digest: digest$2 };

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$6 = ({ name, code, encode }) => new Hasher$2(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
let Hasher$2 = class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$5(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$5(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
};

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */


/**
 * @param {AlgorithmIdentifier} name
 */
const sha$2 = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256$2 = from$6({
  name: 'sha2-256',
  code: 0x12,
  encode: sha$2('SHA-256')
});

const PUBLIC_KEY_BYTE_LENGTH$2 = 32;
const PRIVATE_KEY_BYTE_LENGTH$2 = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH$2 = 32;
async function generateKey$8() {
    // the actual private key (32 bytes)
    const privateKeyRaw = ed25519.utils.randomPrivateKey();
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys$2(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
async function generateKeyFromSeed$2(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH$2) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    const privateKey = concatKeys$2(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSign$8(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH$2);
    return ed25519.sign(msg, privateKeyRaw);
}
async function hashAndVerify$8(publicKey, sig, msg) {
    return ed25519.verify(sig, msg, publicKey);
}
function concatKeys$2(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH$2);
    for (let i = 0; i < KEYS_BYTE_LENGTH$2; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH$2 + i] = publicKey[i];
    }
    return privateKey;
}

// @ts-check


const base64$4 = rfc4648$4({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$4({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$4({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$4({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

// WebKit on Linux does not support deriving a key from an empty PBKDF2 key.
// So, as a workaround, we provide the generated key as a constant. We test that
// this generated key is accurate in test/workaround.spec.ts
// Generated via:
// await crypto.subtle.exportKey('jwk',
//   await crypto.subtle.deriveKey(
//     { name: 'PBKDF2', salt: new Uint8Array(16), iterations: 32767, hash: { name: 'SHA-256' } },
//     await crypto.subtle.importKey('raw', new Uint8Array(0), { name: 'PBKDF2' }, false, ['deriveKey']),
//     { name: 'AES-GCM', length: 128 }, true, ['encrypt', 'decrypt'])
// )
const derivedEmptyPasswordKey$2 = { alg: 'A128GCM', ext: true, k: 'scm9jmO_4BJAgdwWGVulLg', key_ops: ['encrypt', 'decrypt'], kty: 'oct' };
// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create$4(opts) {
    const algorithm = opts?.algorithm ?? 'AES-GCM';
    let keyLength = opts?.keyLength ?? 16;
    const nonceLength = opts?.nonceLength ?? 12;
    const digest = opts?.digest ?? 'SHA-256';
    const saltLength = opts?.saltLength ?? 16;
    const iterations = opts?.iterations ?? 32767;
    const crypto = webcrypto$2.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$2, { name: 'AES-GCM' }, true, ['encrypt']);
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['encrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$2, { name: 'AES-GCM' }, true, ['encrypt']);
            }
        }
        else {
            // Derive a key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        }
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat$1([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['decrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$2, { name: 'AES-GCM' }, true, ['decrypt']);
            }
        }
        else {
            // Derive the key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        }
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter$2(privateKey, password) {
    const cipher = create$4();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64$4.encode(encryptedKey);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType$2;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType$2 || (KeyType$2 = {}));
var __KeyTypeValues$2;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues$2 || (__KeyTypeValues$2 = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues$2);
    };
})(KeyType$2 || (KeyType$2 = {}));
var PublicKey$2;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$2.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$2.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$1(buf, PublicKey.codec());
    };
})(PublicKey$2 || (PublicKey$2 = {}));
var PrivateKey$2;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$2.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$2.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$1(buf, PrivateKey.codec());
    };
})(PrivateKey$2 || (PrivateKey$2 = {}));

let Ed25519PublicKey$2 = class Ed25519PublicKey {
    _key;
    constructor(key) {
        this._key = ensureKey$2(key, PUBLIC_KEY_BYTE_LENGTH$2);
    }
    async verify(data, sig) {
        return hashAndVerify$8(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey$2.encode({
            Type: KeyType$2.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$2.digest(this.bytes);
        return bytes;
    }
};
let Ed25519PrivateKey$2 = class Ed25519PrivateKey {
    _key;
    _publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey$2(key, PRIVATE_KEY_BYTE_LENGTH$2);
        this._publicKey = ensureKey$2(publicKey, PUBLIC_KEY_BYTE_LENGTH$2);
    }
    async sign(message) {
        return hashAndSign$8(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey$2(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$2.encode({
            Type: KeyType$2.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$2.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity$2.digest(this.public.bytes);
        return base58btc$4.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$2(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalEd25519PrivateKey$2(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH$2) {
        bytes = ensureKey$2(bytes, PRIVATE_KEY_BYTE_LENGTH$2 + PUBLIC_KEY_BYTE_LENGTH$2);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$2);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH$2, bytes.length);
        return new Ed25519PrivateKey$2(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey$2(bytes, PRIVATE_KEY_BYTE_LENGTH$2);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$2);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH$2);
    return new Ed25519PrivateKey$2(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey$2(bytes) {
    bytes = ensureKey$2(bytes, PUBLIC_KEY_BYTE_LENGTH$2);
    return new Ed25519PublicKey$2(bytes);
}
async function generateKeyPair$a() {
    const { privateKey, publicKey } = await generateKey$8();
    return new Ed25519PrivateKey$2(privateKey, publicKey);
}
async function generateKeyPairFromSeed$2(seed) {
    const { privateKey, publicKey } = await generateKeyFromSeed$2(seed);
    return new Ed25519PrivateKey$2(privateKey, publicKey);
}
function ensureKey$2(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError$3(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey$2,
    Ed25519PublicKey: Ed25519PublicKey$2,
    generateKeyPair: generateKeyPair$a,
    generateKeyPairFromSeed: generateKeyPairFromSeed$2,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey$2,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey$2
});

function bigIntegerToUintBase64url$2(num, len) {
    // Call `.abs()` to convert to unsigned
    let buf = Uint8Array.from(num.abs().toByteArray()); // toByteArray converts to big endian
    // toByteArray() gives us back a signed array, which will include a leading 0
    // byte if the most significant bit of the number is 1:
    // https://docs.microsoft.com/en-us/windows/win32/seccertenroll/about-integer
    // Our number will always be positive so we should remove the leading padding.
    buf = buf[0] === 0 ? buf.subarray(1) : buf;
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return toString$9(buf, 'base64url');
}
// Convert a base64url encoded string to a BigInteger
function base64urlToBigInteger$2(str) {
    const buf = base64urlToBuffer$2(str);
    return new forge$n.jsbn.BigInteger(toString$9(buf, 'base16'), 16);
}
function base64urlToBuffer$2(str, len) {
    let buf = fromString$3(str, 'base64urlpad');
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return buf;
}

const bits$2 = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes$2 = Object.keys(bits$2);
curveTypes$2.join(' / ');

/**
 * Attempts to decrypt a base64 encoded PrivateKey string
 * with the given password. The privateKey must have been exported
 * using the same password and underlying cipher (aes-gcm)
 */
async function importer(privateKey, password) {
    const encryptedKey = base64$4.decode(privateKey);
    const cipher = create$4();
    return cipher.decrypt(encryptedKey, password);
}

function randomBytes$2(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError$3('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return randomBytes$8(length);
}

function convert$2(key, types) {
    return types.map(t => base64urlToBigInteger$2(key[t]));
}
function jwk2priv$2(key) {
    return forge$n.pki.setRsaPrivateKey(...convert$2(key, ['n', 'e', 'd', 'p', 'q', 'dp', 'dq', 'qi']));
}
function jwk2pub$2(key) {
    return forge$n.pki.setRsaPublicKey(...convert$2(key, ['n', 'e']));
}

// Convert a PKCS#1 in ASN1 DER format to a JWK key
function pkcs1ToJwk$2(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
    // https://tools.ietf.org/html/rfc7518#section-6.3.1
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$2(privateKey.n),
        e: bigIntegerToUintBase64url$2(privateKey.e),
        d: bigIntegerToUintBase64url$2(privateKey.d),
        p: bigIntegerToUintBase64url$2(privateKey.p),
        q: bigIntegerToUintBase64url$2(privateKey.q),
        dp: bigIntegerToUintBase64url$2(privateKey.dP),
        dq: bigIntegerToUintBase64url$2(privateKey.dQ),
        qi: bigIntegerToUintBase64url$2(privateKey.qInv),
        alg: 'RS256'
    };
}
// Convert a JWK key into PKCS#1 in ASN1 DER format
function jwkToPkcs1$2(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.privateKeyToAsn1({
        n: base64urlToBigInteger$2(jwk.n),
        e: base64urlToBigInteger$2(jwk.e),
        d: base64urlToBigInteger$2(jwk.d),
        p: base64urlToBigInteger$2(jwk.p),
        q: base64urlToBigInteger$2(jwk.q),
        dP: base64urlToBigInteger$2(jwk.dp),
        dQ: base64urlToBigInteger$2(jwk.dq),
        qInv: base64urlToBigInteger$2(jwk.qi)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}
// Convert a PKCIX in ASN1 DER format to a JWK key
function pkixToJwk$2(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const publicKey = forge$n.pki.publicKeyFromAsn1(asn1);
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$2(publicKey.n),
        e: bigIntegerToUintBase64url$2(publicKey.e)
    };
}
// Convert a JWK key to PKCIX in ASN1 DER format
function jwkToPkix$2(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.publicKeyToAsn1({
        n: base64urlToBigInteger$2(jwk.n),
        e: base64urlToBigInteger$2(jwk.e)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}

async function generateKey$7(bits) {
    const pair = await webcrypto$2.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey$2(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$4(key) {
    const privateKey = await webcrypto$2.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate$2(key)
    ];
    const keys = await exportKey$2({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$7(key, msg) {
    const privateKey = await webcrypto$2.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto$2.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, Uint8Array.from(msg));
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$7(key, sig, msg) {
    const publicKey = await webcrypto$2.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return webcrypto$2.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg);
}
async function exportKey$2(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError$3('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return Promise.all([
        webcrypto$2.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto$2.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate$2(jwKey) {
    return webcrypto$2.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
/*

RSA encryption/decryption for the browser with webcrypto workaround
"bloody dark magic. webcrypto's why."

Explanation:
  - Convert JWK to nodeForge
  - Convert msg Uint8Array to nodeForge buffer: ByteBuffer is a "binary-string backed buffer", so let's make our Uint8Array a binary string
  - Convert resulting nodeForge buffer to Uint8Array: it returns a binary string, turn that into a Uint8Array

*/
function convertKey$2(key, pub, msg, handle) {
    const fkey = pub ? jwk2pub$2(key) : jwk2priv$2(key);
    const fmsg = toString$9(Uint8Array.from(msg), 'ascii');
    const fomsg = handle(fmsg, fkey);
    return fromString$3(fomsg, 'ascii');
}
function encrypt$2(key, msg) {
    return convertKey$2(key, true, msg, (msg, key) => key.encrypt(msg));
}
function decrypt$2(key, msg) {
    return convertKey$2(key, false, msg, (msg, key) => key.decrypt(msg));
}
function keySize$2(jwk) {
    if (jwk.kty !== 'RSA') {
        throw new CodeError$3('invalid key type', 'ERR_INVALID_KEY_TYPE');
    }
    else if (jwk.n == null) {
        throw new CodeError$3('invalid key modulus', 'ERR_INVALID_KEY_MODULUS');
    }
    const bytes = fromString$3(jwk.n, 'base64url');
    return bytes.length * 8;
}

const MAX_KEY_SIZE$2 = 8192;
let RsaPublicKey$2 = class RsaPublicKey {
    _key;
    constructor(key) {
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$7(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix$2(this._key);
    }
    get bytes() {
        return PublicKey$2.encode({
            Type: KeyType$2.RSA,
            Data: this.marshal()
        }).subarray();
    }
    encrypt(bytes) {
        return encrypt$2(this._key, bytes);
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$2.digest(this.bytes);
        return bytes;
    }
};
let RsaPrivateKey$2 = class RsaPrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes$2(16);
    }
    async sign(message) {
        return hashAndSign$7(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError$3('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey$2(this._publicKey);
    }
    decrypt(bytes) {
        return decrypt$2(this._key, bytes);
    }
    marshal() {
        return jwkToPkcs1$2(this._key);
    }
    get bytes() {
        return PrivateKey$2.encode({
            Type: KeyType$2.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$2.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected PEM format
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            const buffer = new forge$n.util.ByteBuffer(this.marshal());
            const asn1 = forge$n.asn1.fromDer(buffer);
            const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
            const options = {
                algorithm: 'aes256',
                count: 10000,
                saltSize: 128 / 8,
                prfAlgorithm: 'sha512'
            };
            return forge$n.pki.encryptRsaPrivateKey(privateKey, password, options);
        }
        else if (format === 'libp2p-key') {
            return exporter$2(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
async function unmarshalRsaPrivateKey$2(bytes) {
    const jwk = pkcs1ToJwk$2(bytes);
    if (keySize$2(jwk) > MAX_KEY_SIZE$2) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$4(jwk);
    return new RsaPrivateKey$2(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey$2(bytes) {
    const jwk = pkixToJwk$2(bytes);
    if (keySize$2(jwk) > MAX_KEY_SIZE$2) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    return new RsaPublicKey$2(jwk);
}
async function fromJwk$2(jwk) {
    if (keySize$2(jwk) > MAX_KEY_SIZE$2) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$4(jwk);
    return new RsaPrivateKey$2(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$9(bits) {
    if (bits > MAX_KEY_SIZE$2) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await generateKey$7(bits);
    return new RsaPrivateKey$2(keys.privateKey, keys.publicKey);
}

var RSA$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MAX_KEY_SIZE: MAX_KEY_SIZE$2,
    RsaPrivateKey: RsaPrivateKey$2,
    RsaPublicKey: RsaPublicKey$2,
    fromJwk: fromJwk$2,
    generateKeyPair: generateKeyPair$9,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey$2,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey$2
});

function generateKey$6() {
    return secp256k1.utils.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
async function hashAndSign$6(key, msg) {
    const { digest } = await sha256$2.digest(msg);
    try {
        const signature = secp256k1.sign(digest, key);
        return signature.toDERRawBytes();
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
async function hashAndVerify$6(key, sig, msg) {
    try {
        const { digest } = await sha256$2.digest(msg);
        return secp256k1.verify(sig, digest, key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey$2(key) {
    const point = secp256k1.ProjectivePoint.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey$2(key) {
    try {
        secp256k1.getPublicKey(key, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey$2(key) {
    try {
        secp256k1.ProjectivePoint.fromHex(key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey$2(privateKey) {
    try {
        return secp256k1.getPublicKey(privateKey, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

let Secp256k1PublicKey$2 = class Secp256k1PublicKey {
    _key;
    constructor(key) {
        validatePublicKey$2(key);
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$6(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey$2(this._key);
    }
    get bytes() {
        return PublicKey$2.encode({
            Type: KeyType$2.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$2.digest(this.bytes);
        return bytes;
    }
};
let Secp256k1PrivateKey$2 = class Secp256k1PrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey$2(key);
        validatePrivateKey$2(this._key);
        validatePublicKey$2(this._publicKey);
    }
    async sign(message) {
        return hashAndSign$6(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey$2(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$2.encode({
            Type: KeyType$2.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$2.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$2(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalSecp256k1PrivateKey$2(bytes) {
    return new Secp256k1PrivateKey$2(bytes);
}
function unmarshalSecp256k1PublicKey$2(bytes) {
    return new Secp256k1PublicKey$2(bytes);
}
async function generateKeyPair$8() {
    const privateKeyBytes = generateKey$6();
    return new Secp256k1PrivateKey$2(privateKeyBytes);
}

var Secp256k1$2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey$2,
    Secp256k1PublicKey: Secp256k1PublicKey$2,
    generateKeyPair: generateKeyPair$8,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey$2,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey$2
});

const supportedKeys$2 = {
    rsa: RSA$2,
    ed25519: Ed25519$2,
    secp256k1: Secp256k1$2
};
function unsupportedKey$2(type) {
    const supported = Object.keys(supportedKeys$2).join(' / ');
    return new CodeError$3(`invalid or unsupported key type ${type}. Must be ${supported}`, 'ERR_UNSUPPORTED_KEY_TYPE');
}
function typeToKey$1(type) {
    type = type.toLowerCase();
    if (type === 'rsa' || type === 'ed25519' || type === 'secp256k1') {
        return supportedKeys$2[type];
    }
    throw unsupportedKey$2(type);
}
// Generates a keypair of the given type and bitsize
async function generateKeyPair$7(type, bits) {
    return typeToKey$1(type).generateKeyPair(bits ?? 2048);
}
// Converts a protobuf serialized private key into its
// representative object
async function unmarshalPrivateKey$3(buf) {
    const decoded = PrivateKey$2.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType$2.RSA:
            return supportedKeys$2.rsa.unmarshalRsaPrivateKey(data);
        case KeyType$2.Ed25519:
            return supportedKeys$2.ed25519.unmarshalEd25519PrivateKey(data);
        case KeyType$2.Secp256k1:
            return supportedKeys$2.secp256k1.unmarshalSecp256k1PrivateKey(data);
        default:
            throw unsupportedKey$2(decoded.Type ?? 'RSA');
    }
}
/**
 *
 * @param {string} encryptedKey
 * @param {string} password
 */
async function importKey(encryptedKey, password) {
    try {
        const key = await importer(encryptedKey, password);
        return await unmarshalPrivateKey$3(key);
    }
    catch (_) {
        // Ignore and try the old pem decrypt
    }
    // Only rsa supports pem right now
    const key = forge$n.pki.decryptRsaPrivateKey(encryptedKey, password);
    if (key === null) {
        throw new CodeError$3('Cannot read the key, most likely the password is wrong or not a RSA key', 'ERR_CANNOT_DECRYPT_PEM');
    }
    let der = forge$n.asn1.toDer(forge$n.pki.privateKeyToAsn1(key));
    der = fromString$3(der.getBytes(), 'ascii');
    return supportedKeys$2.rsa.unmarshalRsaPrivateKey(der);
}

/**
 * Maps an IPFS hash name to its node-forge equivalent.
 *
 * See https://github.com/multiformats/multihash/blob/master/hashtable.csv
 *
 * @private
 */
const hashName = {
    sha1: 'sha1',
    'sha2-256': 'sha256',
    'sha2-512': 'sha512'
};
/**
 * Computes the Password-Based Key Derivation Function 2.
 */
function pbkdf2(password, salt, iterations, keySize, hash) {
    if (hash !== 'sha1' && hash !== 'sha2-256' && hash !== 'sha2-512') {
        const types = Object.keys(hashName).join(' / ');
        throw new CodeError$3(`Hash '${hash}' is unknown or not supported. Must be ${types}`, 'ERR_UNSUPPORTED_HASH_TYPE');
    }
    const hasher = hashName[hash];
    const dek = forgePbkdf2(password, salt, iterations, keySize, hasher);
    return forgeUtil.encode64(dek, null);
}

const base32$3 = rfc4648$4({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

rfc4648$4({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

rfc4648$4({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

rfc4648$4({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

rfc4648$4({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

rfc4648$4({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

rfc4648$4({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

rfc4648$4({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

rfc4648$4({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc$4.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$3.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64$4.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
debug.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger$3(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
function logger$3(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger$3(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (debug.enabled(`${name}:trace`) && debug.names.map(r => r.toString()).find(n => n.includes(':trace')) != null) {
        trace = debug(`${name}:trace`);
    }
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace
    });
}

let nanoid$1 = (size = 21) =>
  crypto.getRandomValues(new Uint8Array(size)).reduce((id, byte) => {
    byte &= 63;
    if (byte < 36) {
      id += byte.toString(36);
    } else if (byte < 62) {
      id += (byte - 26).toString(36).toUpperCase();
    } else if (byte > 62) {
      id += '-';
    } else {
      id += '_';
    }
    return id
  }, '');

const pathSepS = '/';
const pathSepB = new TextEncoder().encode(pathSepS);
const pathSep = pathSepB[0];
/**
 * A Key represents the unique identifier of an object.
 * Our Key scheme is inspired by file systems and Google App Engine key model.
 * Keys are meant to be unique across a system. Keys are hierarchical,
 * incorporating more and more specific namespaces. Thus keys can be deemed
 * 'children' or 'ancestors' of other keys:
 * - `new Key('/Comedy')`
 * - `new Key('/Comedy/MontyPython')`
 * Also, every namespace can be parametrized to embed relevant object
 * information. For example, the Key `name` (most specific namespace) could
 * include the object type:
 * - `new Key('/Comedy/MontyPython/Actor:JohnCleese')`
 * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop')`
 * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop/Character:Mousebender')`
 *
 */
class Key {
    _buf;
    /**
     * @param {string | Uint8Array} s
     * @param {boolean} [clean]
     */
    constructor(s, clean) {
        if (typeof s === 'string') {
            this._buf = fromString$3(s);
        }
        else if (s instanceof Uint8Array) {
            this._buf = s;
        }
        else {
            throw new Error('Invalid key, should be String of Uint8Array');
        }
        if (clean == null) {
            clean = true;
        }
        if (clean) {
            this.clean();
        }
        if (this._buf.byteLength === 0 || this._buf[0] !== pathSep) {
            throw new Error('Invalid key');
        }
    }
    /**
     * Convert to the string representation
     *
     * @param {import('uint8arrays/to-string').SupportedEncodings} [encoding='utf8'] - The encoding to use.
     * @returns {string}
     */
    toString(encoding = 'utf8') {
        return toString$9(this._buf, encoding);
    }
    /**
     * Return the Uint8Array representation of the key
     *
     * @returns {Uint8Array}
     */
    uint8Array() {
        return this._buf;
    }
    /**
     * Return string representation of the key
     *
     * @returns {string}
     */
    get [Symbol.toStringTag]() {
        return `Key(${this.toString()})`;
    }
    /**
     * Constructs a key out of a namespace array.
     *
     * @param {Array<string>} list - The array of namespaces
     * @returns {Key}
     *
     * @example
     * ```js
     * Key.withNamespaces(['one', 'two'])
     * // => Key('/one/two')
     * ```
     */
    static withNamespaces(list) {
        return new Key(list.join(pathSepS));
    }
    /**
     * Returns a randomly (uuid) generated key.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * Key.random()
     * // => Key('/f98719ea086343f7b71f32ea9d9d521d')
     * ```
     */
    static random() {
        return new Key(nanoid$1().replace(/-/g, ''));
    }
    /**
     * @param {*} other
     */
    static asKey(other) {
        if (other instanceof Uint8Array || typeof other === 'string') {
            // we can create a key from this
            return new Key(other);
        }
        if (typeof other.uint8Array === 'function') {
            // this is an older version or may have crossed the esm/cjs boundary
            return new Key(other.uint8Array());
        }
        return null;
    }
    /**
     * Cleanup the current key
     *
     * @returns {void}
     */
    clean() {
        if (this._buf == null || this._buf.byteLength === 0) {
            this._buf = pathSepB;
        }
        if (this._buf[0] !== pathSep) {
            const bytes = new Uint8Array(this._buf.byteLength + 1);
            bytes.fill(pathSep, 0, 1);
            bytes.set(this._buf, 1);
            this._buf = bytes;
        }
        // normalize does not remove trailing slashes
        while (this._buf.byteLength > 1 && this._buf[this._buf.byteLength - 1] === pathSep) {
            this._buf = this._buf.subarray(0, -1);
        }
    }
    /**
     * Check if the given key is sorted lower than ourself.
     *
     * @param {Key} key - The other Key to check against
     * @returns {boolean}
     */
    less(key) {
        const list1 = this.list();
        const list2 = key.list();
        for (let i = 0; i < list1.length; i++) {
            if (list2.length < i + 1) {
                return false;
            }
            const c1 = list1[i];
            const c2 = list2[i];
            if (c1 < c2) {
                return true;
            }
            else if (c1 > c2) {
                return false;
            }
        }
        return list1.length < list2.length;
    }
    /**
     * Returns the key with all parts in reversed order.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').reverse()
     * // => Key('/Actor:JohnCleese/MontyPython/Comedy')
     * ```
     */
    reverse() {
        return Key.withNamespaces(this.list().slice().reverse());
    }
    /**
     * Returns the `namespaces` making up this Key.
     *
     * @returns {Array<string>}
     */
    namespaces() {
        return this.list();
    }
    /** Returns the "base" namespace of this key.
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').baseNamespace()
     * // => 'Actor:JohnCleese'
     * ```
     */
    baseNamespace() {
        const ns = this.namespaces();
        return ns[ns.length - 1];
    }
    /**
     * Returns the `list` representation of this key.
     *
     * @returns {Array<string>}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').list()
     * // => ['Comedy', 'MontyPythong', 'Actor:JohnCleese']
     * ```
     */
    list() {
        return this.toString().split(pathSepS).slice(1);
    }
    /**
     * Returns the "type" of this key (value of last namespace).
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').type()
     * // => 'Actor'
     * ```
     */
    type() {
        return namespaceType(this.baseNamespace());
    }
    /**
     * Returns the "name" of this key (field of last namespace).
     *
     * @returns {string}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').name()
     * // => 'JohnCleese'
     * ```
     */
    name() {
        return namespaceValue(this.baseNamespace());
    }
    /**
     * Returns an "instance" of this type key (appends value to namespace).
     *
     * @param {string} s - The string to append.
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor').instance('JohnClesse')
     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')
     * ```
     */
    instance(s) {
        return new Key(this.toString() + ':' + s);
    }
    /**
     * Returns the "path" of this key (parent + type).
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython/Actor:JohnCleese').path()
     * // => Key('/Comedy/MontyPython/Actor')
     * ```
     */
    path() {
        let p = this.parent().toString();
        if (!p.endsWith(pathSepS)) {
            p += pathSepS;
        }
        p += this.type();
        return new Key(p);
    }
    /**
     * Returns the `parent` Key of this Key.
     *
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key("/Comedy/MontyPython/Actor:JohnCleese").parent()
     * // => Key("/Comedy/MontyPython")
     * ```
     */
    parent() {
        const list = this.list();
        if (list.length === 1) {
            return new Key(pathSepS);
        }
        return new Key(list.slice(0, -1).join(pathSepS));
    }
    /**
     * Returns the `child` Key of this Key.
     *
     * @param {Key} key - The child Key to add
     * @returns {Key}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython').child(new Key('Actor:JohnCleese'))
     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')
     * ```
     */
    child(key) {
        if (this.toString() === pathSepS) {
            return key;
        }
        else if (key.toString() === pathSepS) {
            return this;
        }
        return new Key(this.toString() + key.toString(), false);
    }
    /**
     * Returns whether this key is a prefix of `other`
     *
     * @param {Key} other - The other key to test against
     * @returns {boolean}
     *
     * @example
     * ```js
     * new Key('/Comedy').isAncestorOf('/Comedy/MontyPython')
     * // => true
     * ```
     */
    isAncestorOf(other) {
        if (other.toString() === this.toString()) {
            return false;
        }
        return other.toString().startsWith(this.toString());
    }
    /**
     * Returns whether this key is a contains another as prefix.
     *
     * @param {Key} other - The other Key to test against
     * @returns {boolean}
     *
     * @example
     * ```js
     * new Key('/Comedy/MontyPython').isDecendantOf('/Comedy')
     * // => true
     * ```
     */
    isDecendantOf(other) {
        if (other.toString() === this.toString()) {
            return false;
        }
        return this.toString().startsWith(other.toString());
    }
    /**
     * Checks if this key has only one namespace.
     *
     * @returns {boolean}
     */
    isTopLevel() {
        return this.list().length === 1;
    }
    /**
     * Concats one or more Keys into one new Key.
     *
     * @param {Array<Key>} keys - The array of keys to concatenate
     * @returns {Key}
     */
    concat(...keys) {
        return Key.withNamespaces([...this.namespaces(), ...flatten(keys.map(key => key.namespaces()))]);
    }
}
/**
 * The first component of a namespace. `foo` in `foo:bar`
 *
 * @param {string} ns
 * @returns {string}
 */
function namespaceType(ns) {
    const parts = ns.split(':');
    if (parts.length < 2) {
        return '';
    }
    return parts.slice(0, -1).join(':');
}
/**
 * The last component of a namespace, `baz` in `foo:bar:baz`.
 *
 * @param {string} ns
 * @returns {string}
 */
function namespaceValue(ns) {
    const parts = ns.split(':');
    return parts[parts.length - 1];
}
/**
 * Flatten array of arrays (only one level)
 *
 * @template T
 * @param {Array<any>} arr
 * @returns {T[]}
 */
function flatten(arr) {
    return ([]).concat(...arr);
}

var isPlainObj = value => {
	if (Object.prototype.toString.call(value) !== '[object Object]') {
		return false;
	}

	const prototype = Object.getPrototypeOf(value);
	return prototype === null || prototype === Object.prototype;
};

const isOptionObject = isPlainObj;

const {hasOwnProperty} = Object.prototype;
const {propertyIsEnumerable} = Object;
const defineProperty = (object, name, value) => Object.defineProperty(object, name, {
	value,
	writable: true,
	enumerable: true,
	configurable: true
});

const globalThis$1 = commonjsGlobal;
const defaultMergeOptions = {
	concatArrays: false,
	ignoreUndefined: false
};

const getEnumerableOwnPropertyKeys = value => {
	const keys = [];

	for (const key in value) {
		if (hasOwnProperty.call(value, key)) {
			keys.push(key);
		}
	}

	/* istanbul ignore else  */
	if (Object.getOwnPropertySymbols) {
		const symbols = Object.getOwnPropertySymbols(value);

		for (const symbol of symbols) {
			if (propertyIsEnumerable.call(value, symbol)) {
				keys.push(symbol);
			}
		}
	}

	return keys;
};

function clone(value) {
	if (Array.isArray(value)) {
		return cloneArray(value);
	}

	if (isOptionObject(value)) {
		return cloneOptionObject(value);
	}

	return value;
}

function cloneArray(array) {
	const result = array.slice(0, 0);

	getEnumerableOwnPropertyKeys(array).forEach(key => {
		defineProperty(result, key, clone(array[key]));
	});

	return result;
}

function cloneOptionObject(object) {
	const result = Object.getPrototypeOf(object) === null ? Object.create(null) : {};

	getEnumerableOwnPropertyKeys(object).forEach(key => {
		defineProperty(result, key, clone(object[key]));
	});

	return result;
}

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {string[]} keys keys to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 */
const mergeKeys = (merged, source, keys, config) => {
	keys.forEach(key => {
		if (typeof source[key] === 'undefined' && config.ignoreUndefined) {
			return;
		}

		// Do not recurse into prototype chain of merged
		if (key in merged && merged[key] !== Object.getPrototypeOf(merged)) {
			defineProperty(merged, key, merge(merged[key], source[key], config));
		} else {
			defineProperty(merged, key, clone(source[key]));
		}
	});

	return merged;
};

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 *
 * see [Array.prototype.concat ( ...arguments )](http://www.ecma-international.org/ecma-262/6.0/#sec-array.prototype.concat)
 */
const concatArrays = (merged, source, config) => {
	let result = merged.slice(0, 0);
	let resultIndex = 0;

	[merged, source].forEach(array => {
		const indices = [];

		// `result.concat(array)` with cloning
		for (let k = 0; k < array.length; k++) {
			if (!hasOwnProperty.call(array, k)) {
				continue;
			}

			indices.push(String(k));

			if (array === merged) {
				// Already cloned
				defineProperty(result, resultIndex++, array[k]);
			} else {
				defineProperty(result, resultIndex++, clone(array[k]));
			}
		}

		// Merge non-index keys
		result = mergeKeys(result, array, getEnumerableOwnPropertyKeys(array).filter(key => !indices.includes(key)), config);
	});

	return result;
};

/**
 * @param {*} merged already cloned
 * @param {*} source something to merge
 * @param {Object} config Config Object
 * @returns {*} cloned Object
 */
function merge(merged, source, config) {
	if (config.concatArrays && Array.isArray(merged) && Array.isArray(source)) {
		return concatArrays(merged, source, config);
	}

	if (!isOptionObject(source) || !isOptionObject(merged)) {
		return clone(source);
	}

	return mergeKeys(merged, source, getEnumerableOwnPropertyKeys(source), config);
}

var mergeOptions = function (...options) {
	const config = merge(clone(defaultMergeOptions), (this !== globalThis$1 && this) || {}, defaultMergeOptions);
	let merged = {_: {}};

	for (const option of options) {
		if (option === undefined) {
			continue;
		}

		if (!isOptionObject(option)) {
			throw new TypeError('`' + option + '` is not an Option Object');
		}

		merged = merge(merged, {_: option}, config);
	}

	return merged._;
};

var mergeOptions$1 = /*@__PURE__*/getDefaultExportFromCjs(mergeOptions);

function isHighSurrogate$1(codePoint) {
  return codePoint >= 0xd800 && codePoint <= 0xdbff;
}

function isLowSurrogate$1(codePoint) {
  return codePoint >= 0xdc00 && codePoint <= 0xdfff;
}

// Truncate string by size in bytes
var truncate$2 = function truncate(getLength, string, byteLength) {
  if (typeof string !== "string") {
    throw new Error("Input must be string");
  }

  var charLength = string.length;
  var curByteLength = 0;
  var codePoint;
  var segment;

  for (var i = 0; i < charLength; i += 1) {
    codePoint = string.charCodeAt(i);
    segment = string[i];

    if (isHighSurrogate$1(codePoint) && isLowSurrogate$1(string.charCodeAt(i + 1))) {
      i += 1;
      segment += string[i];
    }

    curByteLength += getLength(segment);

    if (curByteLength === byteLength) {
      return string.slice(0, i + 1);
    }
    else if (curByteLength > byteLength) {
      return string.slice(0, i - segment.length + 1);
    }
  }

  return string;
};

function isHighSurrogate(codePoint) {
  return codePoint >= 0xd800 && codePoint <= 0xdbff;
}

function isLowSurrogate(codePoint) {
  return codePoint >= 0xdc00 && codePoint <= 0xdfff;
}

// Truncate string by size in bytes
var browser$1 = function getByteLength(string) {
  if (typeof string !== "string") {
    throw new Error("Input must be string");
  }

  var charLength = string.length;
  var byteLength = 0;
  var codePoint = null;
  var prevCodePoint = null;
  for (var i = 0; i < charLength; i++) {
    codePoint = string.charCodeAt(i);
    // handle 4-byte non-BMP chars
    // low surrogate
    if (isLowSurrogate(codePoint)) {
      // when parsing previous hi-surrogate, 3 is added to byteLength
      if (prevCodePoint != null && isHighSurrogate(prevCodePoint)) {
        byteLength += 1;
      }
      else {
        byteLength += 3;
      }
    }
    else if (codePoint <= 0x7f ) {
      byteLength += 1;
    }
    else if (codePoint >= 0x80 && codePoint <= 0x7ff) {
      byteLength += 2;
    }
    else if (codePoint >= 0x800 && codePoint <= 0xffff) {
      byteLength += 3;
    }
    prevCodePoint = codePoint;
  }

  return byteLength;
};

var truncate$1 = truncate$2;
var getLength = browser$1;
var browser = truncate$1.bind(null, getLength);

/*jshint node:true*/

/**
 * Replaces characters in strings that are illegal/unsafe for filenames.
 * Unsafe characters are either removed or replaced by a substitute set
 * in the optional `options` object.
 *
 * Illegal Characters on Various Operating Systems
 * / ? < > \ : * | "
 * https://kb.acronis.com/content/39790
 *
 * Unicode Control codes
 * C0 0x00-0x1f & C1 (0x80-0x9f)
 * http://en.wikipedia.org/wiki/C0_and_C1_control_codes
 *
 * Reserved filenames on Unix-based systems (".", "..")
 * Reserved filenames in Windows ("CON", "PRN", "AUX", "NUL", "COM1",
 * "COM2", "COM3", "COM4", "COM5", "COM6", "COM7", "COM8", "COM9",
 * "LPT1", "LPT2", "LPT3", "LPT4", "LPT5", "LPT6", "LPT7", "LPT8", and
 * "LPT9") case-insesitively and with or without filename extensions.
 *
 * Capped at 255 characters in length.
 * http://unix.stackexchange.com/questions/32795/what-is-the-maximum-allowed-filename-and-folder-size-with-ecryptfs
 *
 * @param  {String} input   Original filename
 * @param  {Object} options {replacement: String | Function }
 * @return {String}         Sanitized filename
 */

var truncate = browser;

var illegalRe = /[\/\?<>\\:\*\|"]/g;
var controlRe = /[\x00-\x1f\x80-\x9f]/g;
var reservedRe = /^\.+$/;
var windowsReservedRe = /^(con|prn|aux|nul|com[0-9]|lpt[0-9])(\..*)?$/i;
var windowsTrailingRe = /[\. ]+$/;

function sanitize(input, replacement) {
  if (typeof input !== 'string') {
    throw new Error('Input must be string');
  }
  var sanitized = input
    .replace(illegalRe, replacement)
    .replace(controlRe, replacement)
    .replace(reservedRe, replacement)
    .replace(windowsReservedRe, replacement)
    .replace(windowsTrailingRe, replacement);
  return truncate(sanitized, 255);
}

var sanitizeFilename = function (input, options) {
  var replacement = (options && options.replacement) || '';
  var output = sanitize(input, replacement);
  if (replacement === '') {
    return output;
  }
  return sanitize(output, '');
};

var sanitize$1 = /*@__PURE__*/getDefaultExportFromCjs(sanitizeFilename);

var codes$3;
(function (codes) {
    codes["ERR_INVALID_PARAMETERS"] = "ERR_INVALID_PARAMETERS";
    codes["ERR_INVALID_KEY_NAME"] = "ERR_INVALID_KEY_NAME";
    codes["ERR_INVALID_KEY_TYPE"] = "ERR_INVALID_KEY_TYPE";
    codes["ERR_KEY_ALREADY_EXISTS"] = "ERR_KEY_ALREADY_EXISTS";
    codes["ERR_INVALID_KEY_SIZE"] = "ERR_INVALID_KEY_SIZE";
    codes["ERR_KEY_NOT_FOUND"] = "ERR_KEY_NOT_FOUND";
    codes["ERR_OLD_KEY_NAME_INVALID"] = "ERR_OLD_KEY_NAME_INVALID";
    codes["ERR_NEW_KEY_NAME_INVALID"] = "ERR_NEW_KEY_NAME_INVALID";
    codes["ERR_PASSWORD_REQUIRED"] = "ERR_PASSWORD_REQUIRED";
    codes["ERR_PEM_REQUIRED"] = "ERR_PEM_REQUIRED";
    codes["ERR_CANNOT_READ_KEY"] = "ERR_CANNOT_READ_KEY";
    codes["ERR_MISSING_PRIVATE_KEY"] = "ERR_MISSING_PRIVATE_KEY";
    codes["ERR_INVALID_OLD_PASS_TYPE"] = "ERR_INVALID_OLD_PASS_TYPE";
    codes["ERR_INVALID_NEW_PASS_TYPE"] = "ERR_INVALID_NEW_PASS_TYPE";
    codes["ERR_INVALID_PASS_LENGTH"] = "ERR_INVALID_PASS_LENGTH";
})(codes$3 || (codes$3 = {}));

/* eslint max-nested-callbacks: ["error", 5] */
const log$k = logger$3('libp2p:keychain');
const keyPrefix = '/pkcs8/';
const infoPrefix = '/info/';
const privates = new WeakMap();
// NIST SP 800-132
const NIST = {
    minKeyLength: 112 / 8,
    minSaltLength: 128 / 8,
    minIterationCount: 1000
};
const defaultOptions$6 = {
    // See https://cryptosense.com/parametesr-choice-for-pbkdf2/
    dek: {
        keyLength: 512 / 8,
        iterationCount: 10000,
        salt: 'you should override this value with a crypto secure random number',
        hash: 'sha2-512'
    }
};
function validateKeyName(name) {
    if (name == null) {
        return false;
    }
    if (typeof name !== 'string') {
        return false;
    }
    return name === sanitize$1(name.trim()) && name.length > 0;
}
/**
 * Throws an error after a delay
 *
 * This assumes than an error indicates that the keychain is under attack. Delay returning an
 * error to make brute force attacks harder.
 */
async function randomDelay() {
    const min = 200;
    const max = 1000;
    const delay = Math.random() * (max - min) + min;
    await new Promise(resolve => setTimeout(resolve, delay));
}
/**
 * Converts a key name into a datastore name
 */
function DsName(name) {
    return new Key(keyPrefix + name);
}
/**
 * Converts a key name into a datastore info name
 */
function DsInfoName(name) {
    return new Key(infoPrefix + name);
}
/**
 * Manages the lifecycle of a key. Keys are encrypted at rest using PKCS #8.
 *
 * A key in the store has two entries
 * - '/info/*key-name*', contains the KeyInfo for the key
 * - '/pkcs8/*key-name*', contains the PKCS #8 for the key
 *
 */
class DefaultKeyChain {
    components;
    init;
    /**
     * Creates a new instance of a key chain
     */
    constructor(components, init) {
        this.components = components;
        this.init = mergeOptions$1(defaultOptions$6, init);
        // Enforce NIST SP 800-132
        if (this.init.pass != null && this.init.pass?.length < 20) {
            throw new Error('pass must be least 20 characters');
        }
        if (this.init.dek?.keyLength != null && this.init.dek.keyLength < NIST.minKeyLength) {
            throw new Error(`dek.keyLength must be least ${NIST.minKeyLength} bytes`);
        }
        if (this.init.dek?.salt?.length != null && this.init.dek.salt.length < NIST.minSaltLength) {
            throw new Error(`dek.saltLength must be least ${NIST.minSaltLength} bytes`);
        }
        if (this.init.dek?.iterationCount != null && this.init.dek.iterationCount < NIST.minIterationCount) {
            throw new Error(`dek.iterationCount must be least ${NIST.minIterationCount}`);
        }
        const dek = this.init.pass != null && this.init.dek?.salt != null
            ? pbkdf2(this.init.pass, this.init.dek?.salt, this.init.dek?.iterationCount, this.init.dek?.keyLength, this.init.dek?.hash)
            : '';
        privates.set(this, { dek });
    }
    /**
     * Generates the options for a keychain.  A random salt is produced.
     *
     * @returns {object}
     */
    static generateOptions() {
        const options = Object.assign({}, defaultOptions$6);
        const saltLength = Math.ceil(NIST.minSaltLength / 3) * 3; // no base64 padding
        options.dek.salt = toString$9(randomBytes$2(saltLength), 'base64');
        return options;
    }
    /**
     * Gets an object that can encrypt/decrypt protected data.
     * The default options for a keychain.
     *
     * @returns {object}
     */
    static get options() {
        return defaultOptions$6;
    }
    /**
     * Create a new key.
     *
     * @param {string} name - The local key name; cannot already exist.
     * @param {string} type - One of the key types; 'rsa'.
     * @param {number} [size = 2048] - The key size in bits. Used for rsa keys only
     */
    async createKey(name, type, size = 2048) {
        if (!validateKeyName(name) || name === 'self') {
            await randomDelay();
            throw new CodeError$3('Invalid key name', codes$3.ERR_INVALID_KEY_NAME);
        }
        if (typeof type !== 'string') {
            await randomDelay();
            throw new CodeError$3('Invalid key type', codes$3.ERR_INVALID_KEY_TYPE);
        }
        const dsname = DsName(name);
        const exists = await this.components.datastore.has(dsname);
        if (exists) {
            await randomDelay();
            throw new CodeError$3('Key name already exists', codes$3.ERR_KEY_ALREADY_EXISTS);
        }
        switch (type.toLowerCase()) {
            case 'rsa':
                if (!Number.isSafeInteger(size) || size < 2048) {
                    await randomDelay();
                    throw new CodeError$3('Invalid RSA key size', codes$3.ERR_INVALID_KEY_SIZE);
                }
                break;
        }
        let keyInfo;
        try {
            const keypair = await generateKeyPair$7(type, size);
            const kid = await keypair.id();
            const cached = privates.get(this);
            if (cached == null) {
                throw new CodeError$3('dek missing', codes$3.ERR_INVALID_PARAMETERS);
            }
            const dek = cached.dek;
            const pem = await keypair.export(dek);
            keyInfo = {
                name,
                id: kid
            };
            const batch = this.components.datastore.batch();
            batch.put(dsname, fromString$3(pem));
            batch.put(DsInfoName(name), fromString$3(JSON.stringify(keyInfo)));
            await batch.commit();
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
        return keyInfo;
    }
    /**
     * List all the keys.
     *
     * @returns {Promise<KeyInfo[]>}
     */
    async listKeys() {
        const query = {
            prefix: infoPrefix
        };
        const info = [];
        for await (const value of this.components.datastore.query(query)) {
            info.push(JSON.parse(toString$9(value.value)));
        }
        return info;
    }
    /**
     * Find a key by it's id
     */
    async findKeyById(id) {
        try {
            const keys = await this.listKeys();
            const key = keys.find((k) => k.id === id);
            if (key == null) {
                throw new CodeError$3(`Key with id '${id}' does not exist.`, codes$3.ERR_KEY_NOT_FOUND);
            }
            return key;
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
    }
    /**
     * Find a key by it's name.
     *
     * @param {string} name - The local key name.
     * @returns {Promise<KeyInfo>}
     */
    async findKeyByName(name) {
        if (!validateKeyName(name)) {
            await randomDelay();
            throw new CodeError$3(`Invalid key name '${name}'`, codes$3.ERR_INVALID_KEY_NAME);
        }
        const dsname = DsInfoName(name);
        try {
            const res = await this.components.datastore.get(dsname);
            return JSON.parse(toString$9(res));
        }
        catch (err) {
            await randomDelay();
            log$k.error(err);
            throw new CodeError$3(`Key '${name}' does not exist.`, codes$3.ERR_KEY_NOT_FOUND);
        }
    }
    /**
     * Remove an existing key.
     *
     * @param {string} name - The local key name; must already exist.
     * @returns {Promise<KeyInfo>}
     */
    async removeKey(name) {
        if (!validateKeyName(name) || name === 'self') {
            await randomDelay();
            throw new CodeError$3(`Invalid key name '${name}'`, codes$3.ERR_INVALID_KEY_NAME);
        }
        const dsname = DsName(name);
        const keyInfo = await this.findKeyByName(name);
        const batch = this.components.datastore.batch();
        batch.delete(dsname);
        batch.delete(DsInfoName(name));
        await batch.commit();
        return keyInfo;
    }
    /**
     * Rename a key
     *
     * @param {string} oldName - The old local key name; must already exist.
     * @param {string} newName - The new local key name; must not already exist.
     * @returns {Promise<KeyInfo>}
     */
    async renameKey(oldName, newName) {
        if (!validateKeyName(oldName) || oldName === 'self') {
            await randomDelay();
            throw new CodeError$3(`Invalid old key name '${oldName}'`, codes$3.ERR_OLD_KEY_NAME_INVALID);
        }
        if (!validateKeyName(newName) || newName === 'self') {
            await randomDelay();
            throw new CodeError$3(`Invalid new key name '${newName}'`, codes$3.ERR_NEW_KEY_NAME_INVALID);
        }
        const oldDsname = DsName(oldName);
        const newDsname = DsName(newName);
        const oldInfoName = DsInfoName(oldName);
        const newInfoName = DsInfoName(newName);
        const exists = await this.components.datastore.has(newDsname);
        if (exists) {
            await randomDelay();
            throw new CodeError$3(`Key '${newName}' already exists`, codes$3.ERR_KEY_ALREADY_EXISTS);
        }
        try {
            const pem = await this.components.datastore.get(oldDsname);
            const res = await this.components.datastore.get(oldInfoName);
            const keyInfo = JSON.parse(toString$9(res));
            keyInfo.name = newName;
            const batch = this.components.datastore.batch();
            batch.put(newDsname, pem);
            batch.put(newInfoName, fromString$3(JSON.stringify(keyInfo)));
            batch.delete(oldDsname);
            batch.delete(oldInfoName);
            await batch.commit();
            return keyInfo;
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
    }
    /**
     * Export an existing key as a PEM encrypted PKCS #8 string
     */
    async exportKey(name, password) {
        if (!validateKeyName(name)) {
            await randomDelay();
            throw new CodeError$3(`Invalid key name '${name}'`, codes$3.ERR_INVALID_KEY_NAME);
        }
        if (password == null) {
            await randomDelay();
            throw new CodeError$3('Password is required', codes$3.ERR_PASSWORD_REQUIRED);
        }
        const dsname = DsName(name);
        try {
            const res = await this.components.datastore.get(dsname);
            const pem = toString$9(res);
            const cached = privates.get(this);
            if (cached == null) {
                throw new CodeError$3('dek missing', codes$3.ERR_INVALID_PARAMETERS);
            }
            const dek = cached.dek;
            const privateKey = await importKey(pem, dek);
            const keyString = await privateKey.export(password);
            return keyString;
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
    }
    /**
     * Export an existing key as a PeerId
     */
    async exportPeerId(name) {
        const password = 'temporary-password';
        const pem = await this.exportKey(name, password);
        const privateKey = await importKey(pem, password);
        return peerIdFromKeys(privateKey.public.bytes, privateKey.bytes);
    }
    /**
     * Import a new key from a PEM encoded PKCS #8 string
     *
     * @param {string} name - The local key name; must not already exist.
     * @param {string} pem - The PEM encoded PKCS #8 string
     * @param {string} password - The password.
     * @returns {Promise<KeyInfo>}
     */
    async importKey(name, pem, password) {
        if (!validateKeyName(name) || name === 'self') {
            await randomDelay();
            throw new CodeError$3(`Invalid key name '${name}'`, codes$3.ERR_INVALID_KEY_NAME);
        }
        if (pem == null) {
            await randomDelay();
            throw new CodeError$3('PEM encoded key is required', codes$3.ERR_PEM_REQUIRED);
        }
        const dsname = DsName(name);
        const exists = await this.components.datastore.has(dsname);
        if (exists) {
            await randomDelay();
            throw new CodeError$3(`Key '${name}' already exists`, codes$3.ERR_KEY_ALREADY_EXISTS);
        }
        let privateKey;
        try {
            privateKey = await importKey(pem, password);
        }
        catch (err) {
            await randomDelay();
            throw new CodeError$3('Cannot read the key, most likely the password is wrong', codes$3.ERR_CANNOT_READ_KEY);
        }
        let kid;
        try {
            kid = await privateKey.id();
            const cached = privates.get(this);
            if (cached == null) {
                throw new CodeError$3('dek missing', codes$3.ERR_INVALID_PARAMETERS);
            }
            const dek = cached.dek;
            pem = await privateKey.export(dek);
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
        const keyInfo = {
            name,
            id: kid
        };
        const batch = this.components.datastore.batch();
        batch.put(dsname, fromString$3(pem));
        batch.put(DsInfoName(name), fromString$3(JSON.stringify(keyInfo)));
        await batch.commit();
        return keyInfo;
    }
    /**
     * Import a peer key
     */
    async importPeer(name, peer) {
        try {
            if (!validateKeyName(name)) {
                throw new CodeError$3(`Invalid key name '${name}'`, codes$3.ERR_INVALID_KEY_NAME);
            }
            if (peer == null) {
                throw new CodeError$3('PeerId is required', codes$3.ERR_MISSING_PRIVATE_KEY);
            }
            if (peer.privateKey == null) {
                throw new CodeError$3('PeerId.privKey is required', codes$3.ERR_MISSING_PRIVATE_KEY);
            }
            const privateKey = await unmarshalPrivateKey$3(peer.privateKey);
            const dsname = DsName(name);
            const exists = await this.components.datastore.has(dsname);
            if (exists) {
                await randomDelay();
                throw new CodeError$3(`Key '${name}' already exists`, codes$3.ERR_KEY_ALREADY_EXISTS);
            }
            const cached = privates.get(this);
            if (cached == null) {
                throw new CodeError$3('dek missing', codes$3.ERR_INVALID_PARAMETERS);
            }
            const dek = cached.dek;
            const pem = await privateKey.export(dek);
            const keyInfo = {
                name,
                id: peer.toString()
            };
            const batch = this.components.datastore.batch();
            batch.put(dsname, fromString$3(pem));
            batch.put(DsInfoName(name), fromString$3(JSON.stringify(keyInfo)));
            await batch.commit();
            return keyInfo;
        }
        catch (err) {
            await randomDelay();
            throw err;
        }
    }
    /**
     * Gets the private key as PEM encoded PKCS #8 string
     */
    async getPrivateKey(name) {
        if (!validateKeyName(name)) {
            await randomDelay();
            throw new CodeError$3(`Invalid key name '${name}'`, codes$3.ERR_INVALID_KEY_NAME);
        }
        try {
            const dsname = DsName(name);
            const res = await this.components.datastore.get(dsname);
            return toString$9(res);
        }
        catch (err) {
            await randomDelay();
            log$k.error(err);
            throw new CodeError$3(`Key '${name}' does not exist.`, codes$3.ERR_KEY_NOT_FOUND);
        }
    }
    /**
     * Rotate keychain password and re-encrypt all associated keys
     */
    async rotateKeychainPass(oldPass, newPass) {
        if (typeof oldPass !== 'string') {
            await randomDelay();
            throw new CodeError$3(`Invalid old pass type '${typeof oldPass}'`, codes$3.ERR_INVALID_OLD_PASS_TYPE);
        }
        if (typeof newPass !== 'string') {
            await randomDelay();
            throw new CodeError$3(`Invalid new pass type '${typeof newPass}'`, codes$3.ERR_INVALID_NEW_PASS_TYPE);
        }
        if (newPass.length < 20) {
            await randomDelay();
            throw new CodeError$3(`Invalid pass length ${newPass.length}`, codes$3.ERR_INVALID_PASS_LENGTH);
        }
        log$k('recreating keychain');
        const cached = privates.get(this);
        if (cached == null) {
            throw new CodeError$3('dek missing', codes$3.ERR_INVALID_PARAMETERS);
        }
        const oldDek = cached.dek;
        this.init.pass = newPass;
        const newDek = newPass != null && this.init.dek?.salt != null
            ? pbkdf2(newPass, this.init.dek.salt, this.init.dek?.iterationCount, this.init.dek?.keyLength, this.init.dek?.hash)
            : '';
        privates.set(this, { dek: newDek });
        const keys = await this.listKeys();
        for (const key of keys) {
            const res = await this.components.datastore.get(DsName(key.name));
            const pem = toString$9(res);
            const privateKey = await importKey(pem, oldDek);
            const password = newDek.toString();
            const keyAsPEM = await privateKey.export(password);
            // Update stored key
            const batch = this.components.datastore.batch();
            const keyInfo = {
                name: key.name,
                id: key.id
            };
            batch.put(DsName(key.name), fromString$3(keyAsPEM));
            batch.put(DsInfoName(key.name), fromString$3(JSON.stringify(keyInfo)));
            await batch.commit();
        }
        log$k('keychain reconstructed');
    }
}

const base32$2 = rfc4648$5({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

rfc4648$5({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

rfc4648$5({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

rfc4648$5({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

rfc4648$5({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

rfc4648$5({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

rfc4648$5({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

rfc4648$5({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

rfc4648$5({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc$5.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$2.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64$5.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
debug.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger$2(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
function logger$2(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger$2(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (debug.enabled(`${name}:trace`) && debug.names.map(r => r.toString()).find(n => n.includes(':trace')) != null) {
        trace = debug(`${name}:trace`);
    }
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace
    });
}

/**
 * Calls the passed map function on every entry of the passed iterable iterator
 */
function mapIterable(iter, map) {
    const iterator = {
        [Symbol.iterator]: () => {
            return iterator;
        },
        next: () => {
            const next = iter.next();
            const val = next.value;
            if (next.done === true || val == null) {
                const result = {
                    done: true,
                    value: undefined
                };
                return result;
            }
            return {
                done: false,
                value: map(val)
            };
        }
    };
    return iterator;
}

/**
 * We can't use PeerIds as map keys because map keys are
 * compared using same-value-zero equality, so this is just
 * a map that stringifies the PeerIds before storing them.
 *
 * PeerIds cache stringified versions of themselves so this
 * should be a cheap operation.
 *
 * @example
 *
 * ```JavaScript
 * import { peerMap } from '@libp2p/peer-collections'
 *
 * const map = peerMap<string>()
 * map.set(peerId, 'value')
 * ```
 */
class PeerMap {
    map;
    constructor(map) {
        this.map = new Map();
        if (map != null) {
            for (const [key, value] of map.entries()) {
                this.map.set(key.toString(), value);
            }
        }
    }
    [Symbol.iterator]() {
        return this.entries();
    }
    clear() {
        this.map.clear();
    }
    delete(peer) {
        this.map.delete(peer.toString());
    }
    entries() {
        return mapIterable(this.map.entries(), (val) => {
            return [peerIdFromString(val[0]), val[1]];
        });
    }
    forEach(fn) {
        this.map.forEach((value, key) => {
            fn(value, peerIdFromString(key), this);
        });
    }
    get(peer) {
        return this.map.get(peer.toString());
    }
    has(peer) {
        return this.map.has(peer.toString());
    }
    set(peer, value) {
        this.map.set(peer.toString(), value);
    }
    keys() {
        return mapIterable(this.map.keys(), (val) => {
            return peerIdFromString(val);
        });
    }
    values() {
        return this.map.values();
    }
    get size() {
        return this.map.size;
    }
}

/**
 * We can't use PeerIds as set entries because set entries are
 * compared using same-value-zero equality, so this is just
 * a map that stringifies the PeerIds before storing them.
 *
 * PeerIds cache stringified versions of themselves so this
 * should be a cheap operation.
 *
 * @example
 *
 * ```JavaScript
 * import { peerSet } from '@libp2p/peer-collections'
 *
 * const set = peerSet()
 * set.add(peerId)
 * ```
 */
class PeerSet {
    set;
    constructor(set) {
        this.set = new Set();
        if (set != null) {
            for (const key of set) {
                this.set.add(key.toString());
            }
        }
    }
    get size() {
        return this.set.size;
    }
    [Symbol.iterator]() {
        return this.values();
    }
    add(peer) {
        this.set.add(peer.toString());
    }
    clear() {
        this.set.clear();
    }
    delete(peer) {
        this.set.delete(peer.toString());
    }
    entries() {
        return mapIterable(this.set.entries(), (val) => {
            const peerId = peerIdFromString(val[0]);
            return [peerId, peerId];
        });
    }
    forEach(predicate) {
        this.set.forEach((str) => {
            const id = peerIdFromString(str);
            predicate(id, id, this);
        });
    }
    has(peer) {
        return this.set.has(peer.toString());
    }
    values() {
        return mapIterable(this.set.values(), (val) => {
            return peerIdFromString(val);
        });
    }
    intersection(other) {
        const output = new PeerSet();
        for (const peerId of other) {
            if (this.has(peerId)) {
                output.add(peerId);
            }
        }
        return output;
    }
    difference(other) {
        const output = new PeerSet();
        for (const peerId of this) {
            if (!other.has(peerId)) {
                output.add(peerId);
            }
        }
        return output;
    }
    union(other) {
        const output = new PeerSet();
        for (const peerId of other) {
            output.add(peerId);
        }
        for (const peerId of this) {
            output.add(peerId);
        }
        return output;
    }
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$3 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$3 = base$3;

var _brrp__multiformats_scope_baseX$3 = src$3;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$3 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$3 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$3 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$3(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$3 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$3(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$3 = (left, right) => new ComposedDecoder$3(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$3 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$3(name, prefix, baseEncode);
    this.decoder = new Decoder$3(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$5 = ({ name, prefix, encode, decode }) =>
  new Codec$3(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$3 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$3(alphabet, name);
  return from$5({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$3(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$5 = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$8 = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$3 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$5({
    prefix,
    name,
    encode (input) {
      return encode$8(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$5(input, alphabet, bitsPerChar, name)
    }
  })
};

const base58btc$3 = baseX$3({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$3({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var encode_1$1 = encode$7;

var MSB$2 = 0x80
  , REST$2 = 0x7F
  , MSBALL$1 = ~REST$2
  , INT$1 = Math.pow(2, 31);

function encode$7(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT$1) {
    out[offset++] = (num & 0xFF) | MSB$2;
    num /= 128;
  }
  while(num & MSBALL$1) {
    out[offset++] = (num & 0xFF) | MSB$2;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$7.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$4 = read$2;

var MSB$1$1 = 0x80
  , REST$1$1 = 0x7F;

function read$2(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$2.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1$1) << shift
      : (b & REST$1$1) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1$1)

  read$2.bytes = counter - offset;

  return res
}

var N1$1 = Math.pow(2,  7);
var N2$1 = Math.pow(2, 14);
var N3$1 = Math.pow(2, 21);
var N4$1 = Math.pow(2, 28);
var N5$1 = Math.pow(2, 35);
var N6$1 = Math.pow(2, 42);
var N7$1 = Math.pow(2, 49);
var N8$1 = Math.pow(2, 56);
var N9$1 = Math.pow(2, 63);

var length$1 = function (value) {
  return (
    value < N1$1 ? 1
  : value < N2$1 ? 2
  : value < N3$1 ? 3
  : value < N4$1 ? 4
  : value < N5$1 ? 5
  : value < N6$1 ? 6
  : value < N7$1 ? 7
  : value < N8$1 ? 8
  : value < N9$1 ? 9
  :              10
  )
};

var varint$1 = {
    encode: encode_1$1
  , decode: decode$4
  , encodingLength: length$1
};

var _brrp_varint$1 = varint$1;

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo$1 = (int, target, offset = 0) => {
  _brrp_varint$1.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength$1 = (int) => {
  return _brrp_varint$1.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$3 = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength$1(code);
  const digestOffset = sizeOffset + encodingLength$1(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo$1(code, bytes, 0);
  encodeTo$1(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest$1(code, size, digest, bytes)
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
let Digest$1 = class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
};

const code$1 = 0x0;
const name$1 = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$6 = coerce$3;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest$1 = (input) => create$3(code$1, encode$6(input));

const identity$1 = { code: code$1, name: name$1, encode: encode$6, digest: digest$1 };

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$4 = ({ name, code, encode }) => new Hasher$1(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
let Hasher$1 = class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$3(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$3(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
};

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */


/**
 * @param {AlgorithmIdentifier} name
 */
const sha$1 = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256$1 = from$4({
  name: 'sha2-256',
  code: 0x12,
  encode: sha$1('SHA-256')
});

const PUBLIC_KEY_BYTE_LENGTH$1 = 32;
const PRIVATE_KEY_BYTE_LENGTH$1 = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH$1 = 32;
async function generateKey$5() {
    // the actual private key (32 bytes)
    const privateKeyRaw = ed25519.utils.randomPrivateKey();
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys$1(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
async function generateKeyFromSeed$1(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH$1) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    const privateKey = concatKeys$1(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSign$5(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH$1);
    return ed25519.sign(msg, privateKeyRaw);
}
async function hashAndVerify$5(publicKey, sig, msg) {
    return ed25519.verify(sig, msg, publicKey);
}
function concatKeys$1(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH$1);
    for (let i = 0; i < KEYS_BYTE_LENGTH$1; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH$1 + i] = publicKey[i];
    }
    return privateKey;
}

// @ts-check


const base64$3 = rfc4648$3({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$3({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$3({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$3({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto$1 = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto == null || nativeCrypto.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p-crypto/blob/master/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

// WebKit on Linux does not support deriving a key from an empty PBKDF2 key.
// So, as a workaround, we provide the generated key as a constant. We test that
// this generated key is accurate in test/workaround.spec.ts
// Generated via:
// await crypto.subtle.exportKey('jwk',
//   await crypto.subtle.deriveKey(
//     { name: 'PBKDF2', salt: new Uint8Array(16), iterations: 32767, hash: { name: 'SHA-256' } },
//     await crypto.subtle.importKey('raw', new Uint8Array(0), { name: 'PBKDF2' }, false, ['deriveKey']),
//     { name: 'AES-GCM', length: 128 }, true, ['encrypt', 'decrypt'])
// )
const derivedEmptyPasswordKey$1 = { alg: 'A128GCM', ext: true, k: 'scm9jmO_4BJAgdwWGVulLg', key_ops: ['encrypt', 'decrypt'], kty: 'oct' };
// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create$2(opts) {
    const algorithm = opts?.algorithm ?? 'AES-GCM';
    let keyLength = opts?.keyLength ?? 16;
    const nonceLength = opts?.nonceLength ?? 12;
    const digest = opts?.digest ?? 'SHA-256';
    const saltLength = opts?.saltLength ?? 16;
    const iterations = opts?.iterations ?? 32767;
    const crypto = webcrypto$1.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$1, { name: 'AES-GCM' }, true, ['encrypt']);
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['encrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$1, { name: 'AES-GCM' }, true, ['encrypt']);
            }
        }
        else {
            // Derive a key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        }
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat$1([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['decrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey$1, { name: 'AES-GCM' }, true, ['decrypt']);
            }
        }
        else {
            // Derive the key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        }
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter$1(privateKey, password) {
    const cipher = create$2();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64$3.encode(encryptedKey);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType$1;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType$1 || (KeyType$1 = {}));
var __KeyTypeValues$1;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues$1 || (__KeyTypeValues$1 = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues$1);
    };
})(KeyType$1 || (KeyType$1 = {}));
var PublicKey$1;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$1.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$1.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$1(buf, PublicKey.codec());
    };
})(PublicKey$1 || (PublicKey$1 = {}));
var PrivateKey$1;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType$1.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType$1.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$1(buf, PrivateKey.codec());
    };
})(PrivateKey$1 || (PrivateKey$1 = {}));

let Ed25519PublicKey$1 = class Ed25519PublicKey {
    _key;
    constructor(key) {
        this._key = ensureKey$1(key, PUBLIC_KEY_BYTE_LENGTH$1);
    }
    async verify(data, sig) {
        return hashAndVerify$5(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey$1.encode({
            Type: KeyType$1.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$1.digest(this.bytes);
        return bytes;
    }
};
let Ed25519PrivateKey$1 = class Ed25519PrivateKey {
    _key;
    _publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey$1(key, PRIVATE_KEY_BYTE_LENGTH$1);
        this._publicKey = ensureKey$1(publicKey, PUBLIC_KEY_BYTE_LENGTH$1);
    }
    async sign(message) {
        return hashAndSign$5(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey$1(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$1.encode({
            Type: KeyType$1.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$1.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity$1.digest(this.public.bytes);
        return base58btc$3.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$1(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalEd25519PrivateKey$1(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH$1) {
        bytes = ensureKey$1(bytes, PRIVATE_KEY_BYTE_LENGTH$1 + PUBLIC_KEY_BYTE_LENGTH$1);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$1);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH$1, bytes.length);
        return new Ed25519PrivateKey$1(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey$1(bytes, PRIVATE_KEY_BYTE_LENGTH$1);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH$1);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH$1);
    return new Ed25519PrivateKey$1(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey$1(bytes) {
    bytes = ensureKey$1(bytes, PUBLIC_KEY_BYTE_LENGTH$1);
    return new Ed25519PublicKey$1(bytes);
}
async function generateKeyPair$6() {
    const { privateKey, publicKey } = await generateKey$5();
    return new Ed25519PrivateKey$1(privateKey, publicKey);
}
async function generateKeyPairFromSeed$1(seed) {
    const { privateKey, publicKey } = await generateKeyFromSeed$1(seed);
    return new Ed25519PrivateKey$1(privateKey, publicKey);
}
function ensureKey$1(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError$3(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey$1,
    Ed25519PublicKey: Ed25519PublicKey$1,
    generateKeyPair: generateKeyPair$6,
    generateKeyPairFromSeed: generateKeyPairFromSeed$1,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey$1,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey$1
});

function bigIntegerToUintBase64url$1(num, len) {
    // Call `.abs()` to convert to unsigned
    let buf = Uint8Array.from(num.abs().toByteArray()); // toByteArray converts to big endian
    // toByteArray() gives us back a signed array, which will include a leading 0
    // byte if the most significant bit of the number is 1:
    // https://docs.microsoft.com/en-us/windows/win32/seccertenroll/about-integer
    // Our number will always be positive so we should remove the leading padding.
    buf = buf[0] === 0 ? buf.subarray(1) : buf;
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return toString$9(buf, 'base64url');
}
// Convert a base64url encoded string to a BigInteger
function base64urlToBigInteger$1(str) {
    const buf = base64urlToBuffer$1(str);
    return new forge$n.jsbn.BigInteger(toString$9(buf, 'base16'), 16);
}
function base64urlToBuffer$1(str, len) {
    let buf = fromString$3(str, 'base64urlpad');
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return buf;
}

const bits$1 = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes$1 = Object.keys(bits$1);
curveTypes$1.join(' / ');

function randomBytes$1(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError$3('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return randomBytes$8(length);
}

function convert$1(key, types) {
    return types.map(t => base64urlToBigInteger$1(key[t]));
}
function jwk2priv$1(key) {
    return forge$n.pki.setRsaPrivateKey(...convert$1(key, ['n', 'e', 'd', 'p', 'q', 'dp', 'dq', 'qi']));
}
function jwk2pub$1(key) {
    return forge$n.pki.setRsaPublicKey(...convert$1(key, ['n', 'e']));
}

// Convert a PKCS#1 in ASN1 DER format to a JWK key
function pkcs1ToJwk$1(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
    // https://tools.ietf.org/html/rfc7518#section-6.3.1
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$1(privateKey.n),
        e: bigIntegerToUintBase64url$1(privateKey.e),
        d: bigIntegerToUintBase64url$1(privateKey.d),
        p: bigIntegerToUintBase64url$1(privateKey.p),
        q: bigIntegerToUintBase64url$1(privateKey.q),
        dp: bigIntegerToUintBase64url$1(privateKey.dP),
        dq: bigIntegerToUintBase64url$1(privateKey.dQ),
        qi: bigIntegerToUintBase64url$1(privateKey.qInv),
        alg: 'RS256'
    };
}
// Convert a JWK key into PKCS#1 in ASN1 DER format
function jwkToPkcs1$1(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.privateKeyToAsn1({
        n: base64urlToBigInteger$1(jwk.n),
        e: base64urlToBigInteger$1(jwk.e),
        d: base64urlToBigInteger$1(jwk.d),
        p: base64urlToBigInteger$1(jwk.p),
        q: base64urlToBigInteger$1(jwk.q),
        dP: base64urlToBigInteger$1(jwk.dp),
        dQ: base64urlToBigInteger$1(jwk.dq),
        qInv: base64urlToBigInteger$1(jwk.qi)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}
// Convert a PKCIX in ASN1 DER format to a JWK key
function pkixToJwk$1(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const publicKey = forge$n.pki.publicKeyFromAsn1(asn1);
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url$1(publicKey.n),
        e: bigIntegerToUintBase64url$1(publicKey.e)
    };
}
// Convert a JWK key to PKCIX in ASN1 DER format
function jwkToPkix$1(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.publicKeyToAsn1({
        n: base64urlToBigInteger$1(jwk.n),
        e: base64urlToBigInteger$1(jwk.e)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}

async function generateKey$4(bits) {
    const pair = await webcrypto$1.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey$1(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$2(key) {
    const privateKey = await webcrypto$1.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate$1(key)
    ];
    const keys = await exportKey$1({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$4(key, msg) {
    const privateKey = await webcrypto$1.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto$1.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, Uint8Array.from(msg));
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$4(key, sig, msg) {
    const publicKey = await webcrypto$1.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return webcrypto$1.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg);
}
async function exportKey$1(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError$3('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return Promise.all([
        webcrypto$1.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto$1.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate$1(jwKey) {
    return webcrypto$1.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
/*

RSA encryption/decryption for the browser with webcrypto workaround
"bloody dark magic. webcrypto's why."

Explanation:
  - Convert JWK to nodeForge
  - Convert msg Uint8Array to nodeForge buffer: ByteBuffer is a "binary-string backed buffer", so let's make our Uint8Array a binary string
  - Convert resulting nodeForge buffer to Uint8Array: it returns a binary string, turn that into a Uint8Array

*/
function convertKey$1(key, pub, msg, handle) {
    const fkey = pub ? jwk2pub$1(key) : jwk2priv$1(key);
    const fmsg = toString$9(Uint8Array.from(msg), 'ascii');
    const fomsg = handle(fmsg, fkey);
    return fromString$3(fomsg, 'ascii');
}
function encrypt$1(key, msg) {
    return convertKey$1(key, true, msg, (msg, key) => key.encrypt(msg));
}
function decrypt$1(key, msg) {
    return convertKey$1(key, false, msg, (msg, key) => key.decrypt(msg));
}
function keySize$1(jwk) {
    if (jwk.kty !== 'RSA') {
        throw new CodeError$3('invalid key type', 'ERR_INVALID_KEY_TYPE');
    }
    else if (jwk.n == null) {
        throw new CodeError$3('invalid key modulus', 'ERR_INVALID_KEY_MODULUS');
    }
    const bytes = fromString$3(jwk.n, 'base64url');
    return bytes.length * 8;
}

const MAX_KEY_SIZE$1 = 8192;
let RsaPublicKey$1 = class RsaPublicKey {
    _key;
    constructor(key) {
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$4(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix$1(this._key);
    }
    get bytes() {
        return PublicKey$1.encode({
            Type: KeyType$1.RSA,
            Data: this.marshal()
        }).subarray();
    }
    encrypt(bytes) {
        return encrypt$1(this._key, bytes);
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$1.digest(this.bytes);
        return bytes;
    }
};
let RsaPrivateKey$1 = class RsaPrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes$1(16);
    }
    async sign(message) {
        return hashAndSign$4(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError$3('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey$1(this._publicKey);
    }
    decrypt(bytes) {
        return decrypt$1(this._key, bytes);
    }
    marshal() {
        return jwkToPkcs1$1(this._key);
    }
    get bytes() {
        return PrivateKey$1.encode({
            Type: KeyType$1.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$1.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected PEM format
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            const buffer = new forge$n.util.ByteBuffer(this.marshal());
            const asn1 = forge$n.asn1.fromDer(buffer);
            const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
            const options = {
                algorithm: 'aes256',
                count: 10000,
                saltSize: 128 / 8,
                prfAlgorithm: 'sha512'
            };
            return forge$n.pki.encryptRsaPrivateKey(privateKey, password, options);
        }
        else if (format === 'libp2p-key') {
            return exporter$1(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
async function unmarshalRsaPrivateKey$1(bytes) {
    const jwk = pkcs1ToJwk$1(bytes);
    if (keySize$1(jwk) > MAX_KEY_SIZE$1) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$2(jwk);
    return new RsaPrivateKey$1(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey$1(bytes) {
    const jwk = pkixToJwk$1(bytes);
    if (keySize$1(jwk) > MAX_KEY_SIZE$1) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    return new RsaPublicKey$1(jwk);
}
async function fromJwk$1(jwk) {
    if (keySize$1(jwk) > MAX_KEY_SIZE$1) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$2(jwk);
    return new RsaPrivateKey$1(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$5(bits) {
    if (bits > MAX_KEY_SIZE$1) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await generateKey$4(bits);
    return new RsaPrivateKey$1(keys.privateKey, keys.publicKey);
}

var RSA$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MAX_KEY_SIZE: MAX_KEY_SIZE$1,
    RsaPrivateKey: RsaPrivateKey$1,
    RsaPublicKey: RsaPublicKey$1,
    fromJwk: fromJwk$1,
    generateKeyPair: generateKeyPair$5,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey$1,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey$1
});

function generateKey$3() {
    return secp256k1.utils.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
async function hashAndSign$3(key, msg) {
    const { digest } = await sha256$1.digest(msg);
    try {
        const signature = secp256k1.sign(digest, key);
        return signature.toDERRawBytes();
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
async function hashAndVerify$3(key, sig, msg) {
    try {
        const { digest } = await sha256$1.digest(msg);
        return secp256k1.verify(sig, digest, key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey$1(key) {
    const point = secp256k1.ProjectivePoint.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey$1(key) {
    try {
        secp256k1.getPublicKey(key, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey$1(key) {
    try {
        secp256k1.ProjectivePoint.fromHex(key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey$1(privateKey) {
    try {
        return secp256k1.getPublicKey(privateKey, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

let Secp256k1PublicKey$1 = class Secp256k1PublicKey {
    _key;
    constructor(key) {
        validatePublicKey$1(key);
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$3(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey$1(this._key);
    }
    get bytes() {
        return PublicKey$1.encode({
            Type: KeyType$1.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$1.digest(this.bytes);
        return bytes;
    }
};
let Secp256k1PrivateKey$1 = class Secp256k1PrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey$1(key);
        validatePrivateKey$1(this._key);
        validatePublicKey$1(this._publicKey);
    }
    async sign(message) {
        return hashAndSign$3(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey$1(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey$1.encode({
            Type: KeyType$1.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256$1.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter$1(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
};
function unmarshalSecp256k1PrivateKey$1(bytes) {
    return new Secp256k1PrivateKey$1(bytes);
}
function unmarshalSecp256k1PublicKey$1(bytes) {
    return new Secp256k1PublicKey$1(bytes);
}
async function generateKeyPair$4() {
    const privateKeyBytes = generateKey$3();
    return new Secp256k1PrivateKey$1(privateKeyBytes);
}

var Secp256k1$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey$1,
    Secp256k1PublicKey: Secp256k1PublicKey$1,
    generateKeyPair: generateKeyPair$4,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey$1,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey$1
});

const supportedKeys$1 = {
    rsa: RSA$1,
    ed25519: Ed25519$1,
    secp256k1: Secp256k1$1
};
function unsupportedKey$1(type) {
    const supported = Object.keys(supportedKeys$1).join(' / ');
    return new CodeError$3(`invalid or unsupported key type ${type}. Must be ${supported}`, 'ERR_UNSUPPORTED_KEY_TYPE');
}
function typeToKey(type) {
    type = type.toLowerCase();
    if (type === 'rsa' || type === 'ed25519' || type === 'secp256k1') {
        return supportedKeys$1[type];
    }
    throw unsupportedKey$1(type);
}
// Generates a keypair of the given type and bitsize
async function generateKeyPair$3(type, bits) {
    return typeToKey(type).generateKeyPair(bits ?? 2048);
}
// Converts a public key object into a protobuf serialized public key
function marshalPublicKey(key, type) {
    type = (type ?? 'rsa').toLowerCase();
    typeToKey(type); // check type
    return key.bytes;
}
// Converts a private key object into a protobuf serialized private key
function marshalPrivateKey(key, type) {
    type = (type ?? 'rsa').toLowerCase();
    typeToKey(type); // check type
    return key.bytes;
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var PeerIdProto;
(function (PeerIdProto) {
    let _codec;
    PeerIdProto.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.id != null) {
                    w.uint32(10);
                    w.bytes(obj.id);
                }
                if (obj.pubKey != null) {
                    w.uint32(18);
                    w.bytes(obj.pubKey);
                }
                if (obj.privKey != null) {
                    w.uint32(26);
                    w.bytes(obj.privKey);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.id = reader.bytes();
                            break;
                        case 2:
                            obj.pubKey = reader.bytes();
                            break;
                        case 3:
                            obj.privKey = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerIdProto.encode = (obj) => {
        return encodeMessage(obj, PeerIdProto.codec());
    };
    PeerIdProto.decode = (buf) => {
        return decodeMessage$1(buf, PeerIdProto.codec());
    };
})(PeerIdProto || (PeerIdProto = {}));

const createEd25519PeerId = async () => {
    const key = await generateKeyPair$3('Ed25519');
    const id = await createFromPrivKey(key);
    if (id.type === 'Ed25519') {
        return id;
    }
    throw new Error(`Generated unexpected PeerId type "${id.type}"`);
};
async function createFromPrivKey(privateKey) {
    return peerIdFromKeys(marshalPublicKey(privateKey.public), marshalPrivateKey(privateKey));
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$2 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$2 = base$2;

var _brrp__multiformats_scope_baseX$2 = src$2;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$2 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$2 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$2 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$2(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$2 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$2(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$2 = (left, right) => new ComposedDecoder$2(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$2 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$2(name, prefix, baseEncode);
    this.decoder = new Decoder$2(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$3 = ({ name, prefix, encode, decode }) =>
  new Codec$2(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$2 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$2(alphabet, name);
  return from$3({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$2(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$3 = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$5 = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$2 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$3({
    prefix,
    name,
    encode (input) {
      return encode$5(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$3(input, alphabet, bitsPerChar, name)
    }
  })
};

const base32$1 = rfc4648$2({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

rfc4648$2({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

rfc4648$2({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

rfc4648$2({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

rfc4648$2({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

rfc4648$2({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

rfc4648$2({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

rfc4648$2({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

rfc4648$2({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

const base58btc$2 = baseX$2({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$2({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

// @ts-check


const base64$2 = rfc4648$2({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$2({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$2({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$2({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc$2.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32$1.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64$2.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
debug.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger$1(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
function logger$1(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger$1(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (debug.enabled(`${name}:trace`) && debug.names.map(r => r.toString()).find(n => n.includes(':trace')) != null) {
        trace = debug(`${name}:trace`);
    }
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace
    });
}

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base$1 (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src$1 = base$1;

var _brrp__multiformats_scope_baseX$1 = src$1;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce$1 = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
let Encoder$1 = class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
};

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
let Decoder$1 = class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$1(this, decoder)
  }
};

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
let ComposedDecoder$1 = class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or$1(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
};

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or$1 = (left, right) => new ComposedDecoder$1(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
let Codec$1 = class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder$1(name, prefix, baseEncode);
    this.decoder = new Decoder$1(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
};

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from$2 = ({ name, prefix, encode, decode }) =>
  new Codec$1(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX$1 = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX$1(alphabet, name);
  return from$2({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce$1(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode$2 = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$4 = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648$1 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from$2({
    prefix,
    name,
    encode (input) {
      return encode$4(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode$2(input, alphabet, bitsPerChar, name)
    }
  })
};

const base58btc$1 = baseX$1({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX$1({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

var encode_1 = encode$3;

var MSB = 0x80
  , REST = 0x7F
  , MSBALL = ~REST
  , INT = Math.pow(2, 31);

function encode$3(num, out, offset) {
  out = out || [];
  offset = offset || 0;
  var oldOffset = offset;

  while(num >= INT) {
    out[offset++] = (num & 0xFF) | MSB;
    num /= 128;
  }
  while(num & MSBALL) {
    out[offset++] = (num & 0xFF) | MSB;
    num >>>= 7;
  }
  out[offset] = num | 0;
  
  encode$3.bytes = offset - oldOffset + 1;
  
  return out
}

var decode$1 = read$1;

var MSB$1 = 0x80
  , REST$1 = 0x7F;

function read$1(buf, offset) {
  var res    = 0
    , offset = offset || 0
    , shift  = 0
    , counter = offset
    , b
    , l = buf.length;

  do {
    if (counter >= l) {
      read$1.bytes = 0;
      throw new RangeError('Could not decode varint')
    }
    b = buf[counter++];
    res += shift < 28
      ? (b & REST$1) << shift
      : (b & REST$1) * Math.pow(2, shift);
    shift += 7;
  } while (b >= MSB$1)

  read$1.bytes = counter - offset;

  return res
}

var N1 = Math.pow(2,  7);
var N2 = Math.pow(2, 14);
var N3 = Math.pow(2, 21);
var N4 = Math.pow(2, 28);
var N5 = Math.pow(2, 35);
var N6 = Math.pow(2, 42);
var N7 = Math.pow(2, 49);
var N8 = Math.pow(2, 56);
var N9 = Math.pow(2, 63);

var length = function (value) {
  return (
    value < N1 ? 1
  : value < N2 ? 2
  : value < N3 ? 3
  : value < N4 ? 4
  : value < N5 ? 5
  : value < N6 ? 6
  : value < N7 ? 7
  : value < N8 ? 8
  : value < N9 ? 9
  :              10
  )
};

var varint = {
    encode: encode_1
  , decode: decode$1
  , encodingLength: length
};

var _brrp_varint = varint;

/**
 * @param {number} int
 * @param {Uint8Array} target
 * @param {number} [offset=0]
 */
const encodeTo = (int, target, offset = 0) => {
  _brrp_varint.encode(int, target, offset);
  return target
};

/**
 * @param {number} int
 * @returns {number}
 */
const encodingLength = (int) => {
  return _brrp_varint.encodingLength(int)
};

/**
 * Creates a multihash digest.
 *
 * @template {number} Code
 * @param {Code} code
 * @param {Uint8Array} digest
 */
const create$1 = (code, digest) => {
  const size = digest.byteLength;
  const sizeOffset = encodingLength(code);
  const digestOffset = sizeOffset + encodingLength(size);

  const bytes = new Uint8Array(digestOffset + size);
  encodeTo(code, bytes, 0);
  encodeTo(size, bytes, sizeOffset);
  bytes.set(digest, digestOffset);

  return new Digest(code, size, digest, bytes)
};

/**
 * @typedef {import('./interface.js').MultihashDigest} MultihashDigest
 */

/**
 * Represents a multihash digest which carries information about the
 * hashing algorithm and an actual hash digest.
 *
 * @template {number} Code
 * @template {number} Size
 * @class
 * @implements {MultihashDigest}
 */
class Digest {
  /**
   * Creates a multihash digest.
   *
   * @param {Code} code
   * @param {Size} size
   * @param {Uint8Array} digest
   * @param {Uint8Array} bytes
   */
  constructor (code, size, digest, bytes) {
    this.code = code;
    this.size = size;
    this.digest = digest;
    this.bytes = bytes;
  }
}

const code = 0x0;
const name = 'identity';

/** @type {(input:Uint8Array) => Uint8Array} */
const encode$2 = coerce$1;

/**
 * @param {Uint8Array} input
 * @returns {Digest.Digest<typeof code, number>}
 */
const digest = (input) => create$1(code, encode$2(input));

const identity = { code, name, encode: encode$2, digest };

/**
 * @template {string} Name
 * @template {number} Code
 * @param {object} options
 * @param {Name} options.name
 * @param {Code} options.code
 * @param {(input: Uint8Array) => Await<Uint8Array>} options.encode
 */
const from$1 = ({ name, code, encode }) => new Hasher(name, code, encode);

/**
 * Hasher represents a hashing algorithm implementation that produces as
 * `MultihashDigest`.
 *
 * @template {string} Name
 * @template {number} Code
 * @class
 * @implements {MultihashHasher<Code>}
 */
class Hasher {
  /**
   *
   * @param {Name} name
   * @param {Code} code
   * @param {(input: Uint8Array) => Await<Uint8Array>} encode
   */
  constructor (name, code, encode) {
    this.name = name;
    this.code = code;
    this.encode = encode;
  }

  /**
   * @param {Uint8Array} input
   * @returns {Await<Digest.Digest<Code, number>>}
   */
  digest (input) {
    if (input instanceof Uint8Array) {
      const result = this.encode(input);
      return result instanceof Uint8Array
        ? create$1(this.code, result)
        /* c8 ignore next 1 */
        : result.then(digest => create$1(this.code, digest))
    } else {
      throw Error('Unknown type, must be binary type')
      /* c8 ignore next 1 */
    }
  }
}

/**
 * @template {number} Alg
 * @typedef {import('./interface.js').MultihashHasher} MultihashHasher
 */

/**
 * @template T
 * @typedef {Promise<T>|T} Await
 */

/* global crypto */


/**
 * @param {AlgorithmIdentifier} name
 */
const sha = name =>
  /**
   * @param {Uint8Array} data
   */
  async data => new Uint8Array(await crypto.subtle.digest(name, data));

const sha256 = from$1({
  name: 'sha2-256',
  code: 0x12,
  encode: sha('SHA-256')
});

const PUBLIC_KEY_BYTE_LENGTH = 32;
const PRIVATE_KEY_BYTE_LENGTH = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys
const KEYS_BYTE_LENGTH = 32;
async function generateKey$2() {
    // the actual private key (32 bytes)
    const privateKeyRaw = ed25519.utils.randomPrivateKey();
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    // concatenated the public key to the private key
    const privateKey = concatKeys(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
/**
 * Generate keypair from a 32 byte uint8array
 */
async function generateKeyFromSeed(seed) {
    if (seed.length !== KEYS_BYTE_LENGTH) {
        throw new TypeError('"seed" must be 32 bytes in length.');
    }
    else if (!(seed instanceof Uint8Array)) {
        throw new TypeError('"seed" must be a node.js Buffer, or Uint8Array.');
    }
    // based on node forges algorithm, the seed is used directly as private key
    const privateKeyRaw = seed;
    const publicKey = ed25519.getPublicKey(privateKeyRaw);
    const privateKey = concatKeys(privateKeyRaw, publicKey);
    return {
        privateKey,
        publicKey
    };
}
async function hashAndSign$2(privateKey, msg) {
    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH);
    return ed25519.sign(msg, privateKeyRaw);
}
async function hashAndVerify$2(publicKey, sig, msg) {
    return ed25519.verify(sig, msg, publicKey);
}
function concatKeys(privateKeyRaw, publicKey) {
    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH);
    for (let i = 0; i < KEYS_BYTE_LENGTH; i++) {
        privateKey[i] = privateKeyRaw[i];
        privateKey[KEYS_BYTE_LENGTH + i] = publicKey[i];
    }
    return privateKey;
}

// @ts-check


const base64$1 = rfc4648$1({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648$1({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648$1({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648$1({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

/* eslint-env browser */
// Check native crypto exists and is enabled (In insecure context `self.crypto`
// exists but `self.crypto.subtle` does not).
var webcrypto = {
    get(win = globalThis) {
        const nativeCrypto = win.crypto;
        if (nativeCrypto == null || nativeCrypto.subtle == null) {
            throw Object.assign(new Error('Missing Web Crypto API. ' +
                'The most likely cause of this error is that this page is being accessed ' +
                'from an insecure context (i.e. not HTTPS). For more information and ' +
                'possible resolutions see ' +
                'https://github.com/libp2p/js-libp2p-crypto/blob/master/README.md#web-crypto-api'), { code: 'ERR_MISSING_WEB_CRYPTO' });
        }
        return nativeCrypto;
    }
};

// WebKit on Linux does not support deriving a key from an empty PBKDF2 key.
// So, as a workaround, we provide the generated key as a constant. We test that
// this generated key is accurate in test/workaround.spec.ts
// Generated via:
// await crypto.subtle.exportKey('jwk',
//   await crypto.subtle.deriveKey(
//     { name: 'PBKDF2', salt: new Uint8Array(16), iterations: 32767, hash: { name: 'SHA-256' } },
//     await crypto.subtle.importKey('raw', new Uint8Array(0), { name: 'PBKDF2' }, false, ['deriveKey']),
//     { name: 'AES-GCM', length: 128 }, true, ['encrypt', 'decrypt'])
// )
const derivedEmptyPasswordKey = { alg: 'A128GCM', ext: true, k: 'scm9jmO_4BJAgdwWGVulLg', key_ops: ['encrypt', 'decrypt'], kty: 'oct' };
// Based off of code from https://github.com/luke-park/SecureCompatibleEncryptionExamples
function create(opts) {
    const algorithm = opts?.algorithm ?? 'AES-GCM';
    let keyLength = opts?.keyLength ?? 16;
    const nonceLength = opts?.nonceLength ?? 12;
    const digest = opts?.digest ?? 'SHA-256';
    const saltLength = opts?.saltLength ?? 16;
    const iterations = opts?.iterations ?? 32767;
    const crypto = webcrypto.get();
    keyLength *= 8; // Browser crypto uses bits instead of bytes
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to encrypt the data.
     */
    async function encrypt(data, password) {
        const salt = crypto.getRandomValues(new Uint8Array(saltLength));
        const nonce = crypto.getRandomValues(new Uint8Array(nonceLength));
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey, { name: 'AES-GCM' }, true, ['encrypt']);
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['encrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey, { name: 'AES-GCM' }, true, ['encrypt']);
            }
        }
        else {
            // Derive a key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['encrypt']);
        }
        // Encrypt the string.
        const ciphertext = await crypto.subtle.encrypt(aesGcm, cryptoKey, data);
        return concat$1([salt, aesGcm.iv, new Uint8Array(ciphertext)]);
    }
    /**
     * Uses the provided password to derive a pbkdf2 key. The key
     * will then be used to decrypt the data. The options used to create
     * this decryption cipher must be the same as those used to create
     * the encryption cipher.
     */
    async function decrypt(data, password) {
        const salt = data.subarray(0, saltLength);
        const nonce = data.subarray(saltLength, saltLength + nonceLength);
        const ciphertext = data.subarray(saltLength + nonceLength);
        const aesGcm = { name: algorithm, iv: nonce };
        if (typeof password === 'string') {
            password = fromString$3(password);
        }
        let cryptoKey;
        if (password.length === 0) {
            try {
                const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
                const runtimeDerivedEmptyPassword = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
                cryptoKey = await crypto.subtle.deriveKey(deriveParams, runtimeDerivedEmptyPassword, { name: algorithm, length: keyLength }, true, ['decrypt']);
            }
            catch {
                cryptoKey = await crypto.subtle.importKey('jwk', derivedEmptyPasswordKey, { name: 'AES-GCM' }, true, ['decrypt']);
            }
        }
        else {
            // Derive the key using PBKDF2.
            const deriveParams = { name: 'PBKDF2', salt, iterations, hash: { name: digest } };
            const rawKey = await crypto.subtle.importKey('raw', password, { name: 'PBKDF2' }, false, ['deriveKey']);
            cryptoKey = await crypto.subtle.deriveKey(deriveParams, rawKey, { name: algorithm, length: keyLength }, true, ['decrypt']);
        }
        // Decrypt the string.
        const plaintext = await crypto.subtle.decrypt(aesGcm, cryptoKey, ciphertext);
        return new Uint8Array(plaintext);
    }
    const cipher = {
        encrypt,
        decrypt
    };
    return cipher;
}

/**
 * Exports the given PrivateKey as a base64 encoded string.
 * The PrivateKey is encrypted via a password derived PBKDF2 key
 * leveraging the aes-gcm cipher algorithm.
 */
async function exporter(privateKey, password) {
    const cipher = create();
    const encryptedKey = await cipher.encrypt(privateKey, password);
    return base64$1.encode(encryptedKey);
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var KeyType;
(function (KeyType) {
    KeyType["RSA"] = "RSA";
    KeyType["Ed25519"] = "Ed25519";
    KeyType["Secp256k1"] = "Secp256k1";
})(KeyType || (KeyType = {}));
var __KeyTypeValues;
(function (__KeyTypeValues) {
    __KeyTypeValues[__KeyTypeValues["RSA"] = 0] = "RSA";
    __KeyTypeValues[__KeyTypeValues["Ed25519"] = 1] = "Ed25519";
    __KeyTypeValues[__KeyTypeValues["Secp256k1"] = 2] = "Secp256k1";
})(__KeyTypeValues || (__KeyTypeValues = {}));
(function (KeyType) {
    KeyType.codec = () => {
        return enumeration(__KeyTypeValues);
    };
})(KeyType || (KeyType = {}));
var PublicKey;
(function (PublicKey) {
    let _codec;
    PublicKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PublicKey.encode = (obj) => {
        return encodeMessage(obj, PublicKey.codec());
    };
    PublicKey.decode = (buf) => {
        return decodeMessage$1(buf, PublicKey.codec());
    };
})(PublicKey || (PublicKey = {}));
var PrivateKey;
(function (PrivateKey) {
    let _codec;
    PrivateKey.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.Type != null) {
                    w.uint32(8);
                    KeyType.codec().encode(obj.Type, w);
                }
                if (obj.Data != null) {
                    w.uint32(18);
                    w.bytes(obj.Data);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {};
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.Type = KeyType.codec().decode(reader);
                            break;
                        case 2:
                            obj.Data = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PrivateKey.encode = (obj) => {
        return encodeMessage(obj, PrivateKey.codec());
    };
    PrivateKey.decode = (buf) => {
        return decodeMessage$1(buf, PrivateKey.codec());
    };
})(PrivateKey || (PrivateKey = {}));

class Ed25519PublicKey {
    _key;
    constructor(key) {
        this._key = ensureKey(key, PUBLIC_KEY_BYTE_LENGTH);
    }
    async verify(data, sig) {
        return hashAndVerify$2(this._key, sig, data);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
}
class Ed25519PrivateKey {
    _key;
    _publicKey;
    // key       - 64 byte Uint8Array containing private key
    // publicKey - 32 byte Uint8Array containing public key
    constructor(key, publicKey) {
        this._key = ensureKey(key, PRIVATE_KEY_BYTE_LENGTH);
        this._publicKey = ensureKey(publicKey, PUBLIC_KEY_BYTE_LENGTH);
    }
    async sign(message) {
        return hashAndSign$2(this._key, message);
    }
    get public() {
        return new Ed25519PublicKey(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.Ed25519,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the identity multihash containing its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     *
     * @returns {Promise<string>}
     */
    async id() {
        const encoding = identity.digest(this.public.bytes);
        return base58btc$1.encode(encoding.bytes).substring(1);
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
function unmarshalEd25519PrivateKey(bytes) {
    // Try the old, redundant public key version
    if (bytes.length > PRIVATE_KEY_BYTE_LENGTH) {
        bytes = ensureKey(bytes, PRIVATE_KEY_BYTE_LENGTH + PUBLIC_KEY_BYTE_LENGTH);
        const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH);
        const publicKeyBytes = bytes.subarray(PRIVATE_KEY_BYTE_LENGTH, bytes.length);
        return new Ed25519PrivateKey(privateKeyBytes, publicKeyBytes);
    }
    bytes = ensureKey(bytes, PRIVATE_KEY_BYTE_LENGTH);
    const privateKeyBytes = bytes.subarray(0, PRIVATE_KEY_BYTE_LENGTH);
    const publicKeyBytes = bytes.subarray(PUBLIC_KEY_BYTE_LENGTH);
    return new Ed25519PrivateKey(privateKeyBytes, publicKeyBytes);
}
function unmarshalEd25519PublicKey(bytes) {
    bytes = ensureKey(bytes, PUBLIC_KEY_BYTE_LENGTH);
    return new Ed25519PublicKey(bytes);
}
async function generateKeyPair$2() {
    const { privateKey, publicKey } = await generateKey$2();
    return new Ed25519PrivateKey(privateKey, publicKey);
}
async function generateKeyPairFromSeed(seed) {
    const { privateKey, publicKey } = await generateKeyFromSeed(seed);
    return new Ed25519PrivateKey(privateKey, publicKey);
}
function ensureKey(key, length) {
    key = Uint8Array.from(key ?? []);
    if (key.length !== length) {
        throw new CodeError$3(`Key must be a Uint8Array of length ${length}, got ${key.length}`, 'ERR_INVALID_KEY_TYPE');
    }
    return key;
}

var Ed25519 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Ed25519PrivateKey: Ed25519PrivateKey,
    Ed25519PublicKey: Ed25519PublicKey,
    generateKeyPair: generateKeyPair$2,
    generateKeyPairFromSeed: generateKeyPairFromSeed,
    unmarshalEd25519PrivateKey: unmarshalEd25519PrivateKey,
    unmarshalEd25519PublicKey: unmarshalEd25519PublicKey
});

function bigIntegerToUintBase64url(num, len) {
    // Call `.abs()` to convert to unsigned
    let buf = Uint8Array.from(num.abs().toByteArray()); // toByteArray converts to big endian
    // toByteArray() gives us back a signed array, which will include a leading 0
    // byte if the most significant bit of the number is 1:
    // https://docs.microsoft.com/en-us/windows/win32/seccertenroll/about-integer
    // Our number will always be positive so we should remove the leading padding.
    buf = buf[0] === 0 ? buf.subarray(1) : buf;
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return toString$9(buf, 'base64url');
}
// Convert a base64url encoded string to a BigInteger
function base64urlToBigInteger(str) {
    const buf = base64urlToBuffer(str);
    return new forge$n.jsbn.BigInteger(toString$9(buf, 'base16'), 16);
}
function base64urlToBuffer(str, len) {
    let buf = fromString$3(str, 'base64urlpad');
    if (len != null) {
        if (buf.length > len)
            throw new Error('byte array longer than desired length');
        buf = concat$1([new Uint8Array(len - buf.length), buf]);
    }
    return buf;
}

const bits = {
    'P-256': 256,
    'P-384': 384,
    'P-521': 521
};
const curveTypes = Object.keys(bits);
curveTypes.join(' / ');

function randomBytes(length) {
    if (isNaN(length) || length <= 0) {
        throw new CodeError$3('random bytes length must be a Number bigger than 0', 'ERR_INVALID_LENGTH');
    }
    return randomBytes$8(length);
}

function convert(key, types) {
    return types.map(t => base64urlToBigInteger(key[t]));
}
function jwk2priv(key) {
    return forge$n.pki.setRsaPrivateKey(...convert(key, ['n', 'e', 'd', 'p', 'q', 'dp', 'dq', 'qi']));
}
function jwk2pub(key) {
    return forge$n.pki.setRsaPublicKey(...convert(key, ['n', 'e']));
}

// Convert a PKCS#1 in ASN1 DER format to a JWK key
function pkcs1ToJwk(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
    // https://tools.ietf.org/html/rfc7518#section-6.3.1
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url(privateKey.n),
        e: bigIntegerToUintBase64url(privateKey.e),
        d: bigIntegerToUintBase64url(privateKey.d),
        p: bigIntegerToUintBase64url(privateKey.p),
        q: bigIntegerToUintBase64url(privateKey.q),
        dp: bigIntegerToUintBase64url(privateKey.dP),
        dq: bigIntegerToUintBase64url(privateKey.dQ),
        qi: bigIntegerToUintBase64url(privateKey.qInv),
        alg: 'RS256'
    };
}
// Convert a JWK key into PKCS#1 in ASN1 DER format
function jwkToPkcs1(jwk) {
    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.privateKeyToAsn1({
        n: base64urlToBigInteger(jwk.n),
        e: base64urlToBigInteger(jwk.e),
        d: base64urlToBigInteger(jwk.d),
        p: base64urlToBigInteger(jwk.p),
        q: base64urlToBigInteger(jwk.q),
        dP: base64urlToBigInteger(jwk.dp),
        dQ: base64urlToBigInteger(jwk.dq),
        qInv: base64urlToBigInteger(jwk.qi)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}
// Convert a PKCIX in ASN1 DER format to a JWK key
function pkixToJwk(bytes) {
    const asn1 = forge$n.asn1.fromDer(toString$9(bytes, 'ascii'));
    const publicKey = forge$n.pki.publicKeyFromAsn1(asn1);
    return {
        kty: 'RSA',
        n: bigIntegerToUintBase64url(publicKey.n),
        e: bigIntegerToUintBase64url(publicKey.e)
    };
}
// Convert a JWK key to PKCIX in ASN1 DER format
function jwkToPkix(jwk) {
    if (jwk.n == null || jwk.e == null) {
        throw new CodeError$3('JWK was missing components', 'ERR_INVALID_PARAMETERS');
    }
    const asn1 = forge$n.pki.publicKeyToAsn1({
        n: base64urlToBigInteger(jwk.n),
        e: base64urlToBigInteger(jwk.e)
    });
    return fromString$3(forge$n.asn1.toDer(asn1).getBytes(), 'ascii');
}

async function generateKey$1(bits) {
    const pair = await webcrypto.get().subtle.generateKey({
        name: 'RSASSA-PKCS1-v1_5',
        modulusLength: bits,
        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
        hash: { name: 'SHA-256' }
    }, true, ['sign', 'verify']);
    const keys = await exportKey(pair);
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
// Takes a jwk key
async function unmarshalPrivateKey$1(key) {
    const privateKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['sign']);
    const pair = [
        privateKey,
        await derivePublicFromPrivate(key)
    ];
    const keys = await exportKey({
        privateKey: pair[0],
        publicKey: pair[1]
    });
    return {
        privateKey: keys[0],
        publicKey: keys[1]
    };
}
async function hashAndSign$1(key, msg) {
    const privateKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['sign']);
    const sig = await webcrypto.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, Uint8Array.from(msg));
    return new Uint8Array(sig, 0, sig.byteLength);
}
async function hashAndVerify$1(key, sig, msg) {
    const publicKey = await webcrypto.get().subtle.importKey('jwk', key, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, false, ['verify']);
    return webcrypto.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg);
}
async function exportKey(pair) {
    if (pair.privateKey == null || pair.publicKey == null) {
        throw new CodeError$3('Private and public key are required', 'ERR_INVALID_PARAMETERS');
    }
    return Promise.all([
        webcrypto.get().subtle.exportKey('jwk', pair.privateKey),
        webcrypto.get().subtle.exportKey('jwk', pair.publicKey)
    ]);
}
async function derivePublicFromPrivate(jwKey) {
    return webcrypto.get().subtle.importKey('jwk', {
        kty: jwKey.kty,
        n: jwKey.n,
        e: jwKey.e
    }, {
        name: 'RSASSA-PKCS1-v1_5',
        hash: { name: 'SHA-256' }
    }, true, ['verify']);
}
/*

RSA encryption/decryption for the browser with webcrypto workaround
"bloody dark magic. webcrypto's why."

Explanation:
  - Convert JWK to nodeForge
  - Convert msg Uint8Array to nodeForge buffer: ByteBuffer is a "binary-string backed buffer", so let's make our Uint8Array a binary string
  - Convert resulting nodeForge buffer to Uint8Array: it returns a binary string, turn that into a Uint8Array

*/
function convertKey(key, pub, msg, handle) {
    const fkey = pub ? jwk2pub(key) : jwk2priv(key);
    const fmsg = toString$9(Uint8Array.from(msg), 'ascii');
    const fomsg = handle(fmsg, fkey);
    return fromString$3(fomsg, 'ascii');
}
function encrypt(key, msg) {
    return convertKey(key, true, msg, (msg, key) => key.encrypt(msg));
}
function decrypt(key, msg) {
    return convertKey(key, false, msg, (msg, key) => key.decrypt(msg));
}
function keySize(jwk) {
    if (jwk.kty !== 'RSA') {
        throw new CodeError$3('invalid key type', 'ERR_INVALID_KEY_TYPE');
    }
    else if (jwk.n == null) {
        throw new CodeError$3('invalid key modulus', 'ERR_INVALID_KEY_MODULUS');
    }
    const bytes = fromString$3(jwk.n, 'base64url');
    return bytes.length * 8;
}

const MAX_KEY_SIZE = 8192;
class RsaPublicKey {
    _key;
    constructor(key) {
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify$1(this._key, sig, data);
    }
    marshal() {
        return jwkToPkix(this._key);
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.RSA,
            Data: this.marshal()
        }).subarray();
    }
    encrypt(bytes) {
        return encrypt(this._key, bytes);
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
}
class RsaPrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey;
    }
    genSecret() {
        return randomBytes(16);
    }
    async sign(message) {
        return hashAndSign$1(this._key, message);
    }
    get public() {
        if (this._publicKey == null) {
            throw new CodeError$3('public key not provided', 'ERR_PUBKEY_NOT_PROVIDED');
        }
        return new RsaPublicKey(this._publicKey);
    }
    decrypt(bytes) {
        return decrypt(this._key, bytes);
    }
    marshal() {
        return jwkToPkcs1(this._key);
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.RSA,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected PEM format
     */
    async export(password, format = 'pkcs-8') {
        if (format === 'pkcs-8') {
            const buffer = new forge$n.util.ByteBuffer(this.marshal());
            const asn1 = forge$n.asn1.fromDer(buffer);
            const privateKey = forge$n.pki.privateKeyFromAsn1(asn1);
            const options = {
                algorithm: 'aes256',
                count: 10000,
                saltSize: 128 / 8,
                prfAlgorithm: 'sha512'
            };
            return forge$n.pki.encryptRsaPrivateKey(privateKey, password, options);
        }
        else if (format === 'libp2p-key') {
            return exporter(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
async function unmarshalRsaPrivateKey(bytes) {
    const jwk = pkcs1ToJwk(bytes);
    if (keySize(jwk) > MAX_KEY_SIZE) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$1(jwk);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}
function unmarshalRsaPublicKey(bytes) {
    const jwk = pkixToJwk(bytes);
    if (keySize(jwk) > MAX_KEY_SIZE) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    return new RsaPublicKey(jwk);
}
async function fromJwk(jwk) {
    if (keySize(jwk) > MAX_KEY_SIZE) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await unmarshalPrivateKey$1(jwk);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}
async function generateKeyPair$1(bits) {
    if (bits > MAX_KEY_SIZE) {
        throw new CodeError$3('key size is too large', 'ERR_KEY_SIZE_TOO_LARGE');
    }
    const keys = await generateKey$1(bits);
    return new RsaPrivateKey(keys.privateKey, keys.publicKey);
}

var RSA = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MAX_KEY_SIZE: MAX_KEY_SIZE,
    RsaPrivateKey: RsaPrivateKey,
    RsaPublicKey: RsaPublicKey,
    fromJwk: fromJwk,
    generateKeyPair: generateKeyPair$1,
    unmarshalRsaPrivateKey: unmarshalRsaPrivateKey,
    unmarshalRsaPublicKey: unmarshalRsaPublicKey
});

function generateKey() {
    return secp256k1.utils.randomPrivateKey();
}
/**
 * Hash and sign message with private key
 */
async function hashAndSign(key, msg) {
    const { digest } = await sha256.digest(msg);
    try {
        const signature = secp256k1.sign(digest, key);
        return signature.toDERRawBytes();
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
/**
 * Hash message and verify signature with public key
 */
async function hashAndVerify(key, sig, msg) {
    try {
        const { digest } = await sha256.digest(msg);
        return secp256k1.verify(sig, digest, key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_INPUT');
    }
}
function compressPublicKey(key) {
    const point = secp256k1.ProjectivePoint.fromHex(key).toRawBytes(true);
    return point;
}
function validatePrivateKey(key) {
    try {
        secp256k1.getPublicKey(key, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}
function validatePublicKey(key) {
    try {
        secp256k1.ProjectivePoint.fromHex(key);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PUBLIC_KEY');
    }
}
function computePublicKey(privateKey) {
    try {
        return secp256k1.getPublicKey(privateKey, true);
    }
    catch (err) {
        throw new CodeError$3(String(err), 'ERR_INVALID_PRIVATE_KEY');
    }
}

class Secp256k1PublicKey {
    _key;
    constructor(key) {
        validatePublicKey(key);
        this._key = key;
    }
    async verify(data, sig) {
        return hashAndVerify(this._key, sig, data);
    }
    marshal() {
        return compressPublicKey(this._key);
    }
    get bytes() {
        return PublicKey.encode({
            Type: KeyType.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
}
class Secp256k1PrivateKey {
    _key;
    _publicKey;
    constructor(key, publicKey) {
        this._key = key;
        this._publicKey = publicKey ?? computePublicKey(key);
        validatePrivateKey(this._key);
        validatePublicKey(this._publicKey);
    }
    async sign(message) {
        return hashAndSign(this._key, message);
    }
    get public() {
        return new Secp256k1PublicKey(this._publicKey);
    }
    marshal() {
        return this._key;
    }
    get bytes() {
        return PrivateKey.encode({
            Type: KeyType.Secp256k1,
            Data: this.marshal()
        }).subarray();
    }
    equals(key) {
        return equals$4(this.bytes, key.bytes);
    }
    async hash() {
        const { bytes } = await sha256.digest(this.bytes);
        return bytes;
    }
    /**
     * Gets the ID of the key.
     *
     * The key id is the base58 encoding of the SHA-256 multihash of its public key.
     * The public key is a protobuf encoding containing a type and the DER encoding
     * of the PKCS SubjectPublicKeyInfo.
     */
    async id() {
        const hash = await this.public.hash();
        return toString$9(hash, 'base58btc');
    }
    /**
     * Exports the key into a password protected `format`
     */
    async export(password, format = 'libp2p-key') {
        if (format === 'libp2p-key') {
            return exporter(this.bytes, password);
        }
        else {
            throw new CodeError$3(`export format '${format}' is not supported`, 'ERR_INVALID_EXPORT_FORMAT');
        }
    }
}
function unmarshalSecp256k1PrivateKey(bytes) {
    return new Secp256k1PrivateKey(bytes);
}
function unmarshalSecp256k1PublicKey(bytes) {
    return new Secp256k1PublicKey(bytes);
}
async function generateKeyPair() {
    const privateKeyBytes = generateKey();
    return new Secp256k1PrivateKey(privateKeyBytes);
}

var Secp256k1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Secp256k1PrivateKey: Secp256k1PrivateKey,
    Secp256k1PublicKey: Secp256k1PublicKey,
    generateKeyPair: generateKeyPair,
    unmarshalSecp256k1PrivateKey: unmarshalSecp256k1PrivateKey,
    unmarshalSecp256k1PublicKey: unmarshalSecp256k1PublicKey
});

const supportedKeys = {
    rsa: RSA,
    ed25519: Ed25519,
    secp256k1: Secp256k1
};
function unsupportedKey(type) {
    const supported = Object.keys(supportedKeys).join(' / ');
    return new CodeError$3(`invalid or unsupported key type ${type}. Must be ${supported}`, 'ERR_UNSUPPORTED_KEY_TYPE');
}
// Converts a protobuf serialized public key into its
// representative object
function unmarshalPublicKey(buf) {
    const decoded = PublicKey.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType.RSA:
            return supportedKeys.rsa.unmarshalRsaPublicKey(data);
        case KeyType.Ed25519:
            return supportedKeys.ed25519.unmarshalEd25519PublicKey(data);
        case KeyType.Secp256k1:
            return supportedKeys.secp256k1.unmarshalSecp256k1PublicKey(data);
        default:
            throw unsupportedKey(decoded.Type ?? 'RSA');
    }
}
// Converts a protobuf serialized private key into its
// representative object
async function unmarshalPrivateKey(buf) {
    const decoded = PrivateKey.decode(buf);
    const data = decoded.Data ?? new Uint8Array();
    switch (decoded.Type) {
        case KeyType.RSA:
            return supportedKeys.rsa.unmarshalRsaPrivateKey(data);
        case KeyType.Ed25519:
            return supportedKeys.ed25519.unmarshalEd25519PrivateKey(data);
        case KeyType.Secp256k1:
            return supportedKeys.secp256k1.unmarshalSecp256k1PrivateKey(data);
        default:
            throw unsupportedKey(decoded.Type ?? 'RSA');
    }
}

const codes$2 = {
    ERR_SIGNATURE_NOT_VALID: 'ERR_SIGNATURE_NOT_VALID'
};

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var Envelope;
(function (Envelope) {
    let _codec;
    Envelope.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.publicKey != null && obj.publicKey.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.publicKey);
                }
                if ((obj.payloadType != null && obj.payloadType.byteLength > 0)) {
                    w.uint32(18);
                    w.bytes(obj.payloadType);
                }
                if ((obj.payload != null && obj.payload.byteLength > 0)) {
                    w.uint32(26);
                    w.bytes(obj.payload);
                }
                if ((obj.signature != null && obj.signature.byteLength > 0)) {
                    w.uint32(42);
                    w.bytes(obj.signature);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    publicKey: new Uint8Array(0),
                    payloadType: new Uint8Array(0),
                    payload: new Uint8Array(0),
                    signature: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.publicKey = reader.bytes();
                            break;
                        case 2:
                            obj.payloadType = reader.bytes();
                            break;
                        case 3:
                            obj.payload = reader.bytes();
                            break;
                        case 5:
                            obj.signature = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Envelope.encode = (obj) => {
        return encodeMessage(obj, Envelope.codec());
    };
    Envelope.decode = (buf) => {
        return decodeMessage$1(buf, Envelope.codec());
    };
})(Envelope || (Envelope = {}));

class RecordEnvelope {
    /**
     * Unmarshal a serialized Envelope protobuf message
     */
    static createFromProtobuf = async (data) => {
        const envelopeData = Envelope.decode(data);
        const peerId = await peerIdFromKeys(envelopeData.publicKey);
        return new RecordEnvelope({
            peerId,
            payloadType: envelopeData.payloadType,
            payload: envelopeData.payload,
            signature: envelopeData.signature
        });
    };
    /**
     * Seal marshals the given Record, places the marshaled bytes inside an Envelope
     * and signs it with the given peerId's private key
     */
    static seal = async (record, peerId) => {
        if (peerId.privateKey == null) {
            throw new Error('Missing private key');
        }
        const domain = record.domain;
        const payloadType = record.codec;
        const payload = record.marshal();
        const signData = formatSignaturePayload(domain, payloadType, payload);
        const key = await unmarshalPrivateKey(peerId.privateKey);
        const signature = await key.sign(signData.subarray());
        return new RecordEnvelope({
            peerId,
            payloadType,
            payload,
            signature
        });
    };
    /**
     * Open and certify a given marshalled envelope.
     * Data is unmarshalled and the signature validated for the given domain.
     */
    static openAndCertify = async (data, domain) => {
        const envelope = await RecordEnvelope.createFromProtobuf(data);
        const valid = await envelope.validate(domain);
        if (!valid) {
            throw new CodeError$3('envelope signature is not valid for the given domain', codes$2.ERR_SIGNATURE_NOT_VALID);
        }
        return envelope;
    };
    peerId;
    payloadType;
    payload;
    signature;
    marshaled;
    /**
     * The Envelope is responsible for keeping an arbitrary signed record
     * by a libp2p peer.
     */
    constructor(init) {
        const { peerId, payloadType, payload, signature } = init;
        this.peerId = peerId;
        this.payloadType = payloadType;
        this.payload = payload;
        this.signature = signature;
    }
    /**
     * Marshal the envelope content
     */
    marshal() {
        if (this.peerId.publicKey == null) {
            throw new Error('Missing public key');
        }
        if (this.marshaled == null) {
            this.marshaled = Envelope.encode({
                publicKey: this.peerId.publicKey,
                payloadType: this.payloadType,
                payload: this.payload.subarray(),
                signature: this.signature
            });
        }
        return this.marshaled;
    }
    /**
     * Verifies if the other Envelope is identical to this one
     */
    equals(other) {
        return equals$4(this.marshal(), other.marshal());
    }
    /**
     * Validate envelope data signature for the given domain
     */
    async validate(domain) {
        const signData = formatSignaturePayload(domain, this.payloadType, this.payload);
        if (this.peerId.publicKey == null) {
            throw new Error('Missing public key');
        }
        const key = unmarshalPublicKey(this.peerId.publicKey);
        return key.verify(signData.subarray(), this.signature);
    }
}
/**
 * Helper function that prepares a Uint8Array to sign or verify a signature
 */
const formatSignaturePayload = (domain, payloadType, payload) => {
    // When signing, a peer will prepare a Uint8Array by concatenating the following:
    // - The length of the domain separation string string in bytes
    // - The domain separation string, encoded as UTF-8
    // - The length of the payload_type field in bytes
    // - The value of the payload_type field
    // - The length of the payload field in bytes
    // - The value of the payload field
    const domainUint8Array = fromString$3(domain);
    const domainLength = unsigned.encode(domainUint8Array.byteLength);
    const payloadTypeLength = unsigned.encode(payloadType.length);
    const payloadLength = unsigned.encode(payload.length);
    return new Uint8ArrayList(domainLength, domainUint8Array, payloadTypeLength, payloadType, payloadLength, payload);
};

/**
 * @packageDocumentation
 *
 * Provides strategies ensure arrays are equivalent.
 *
 * @example
 *
 * ```typescript
 * import { arrayEquals } from '@libp2p/utils/array-equals'
 * import { multiaddr } from '@multformats/multiaddr'
 *
 * const ma1 = multiaddr('/ip4/127.0.0.1/tcp/9000'),
 * const ma2 = multiaddr('/ip4/82.41.53.1/tcp/9000')
 *
 * console.info(arrayEquals([ma1], [ma1])) // true
 * console.info(arrayEquals([ma1], [ma2])) // false
 * ```
 */
/**
 * Verify if two arrays of non primitive types with the "equals" function are equal.
 * Compatible with multiaddr, peer-id and others.
 */
function arrayEquals(a, b) {
    const sort = (a, b) => a.toString().localeCompare(b.toString());
    if (a.length !== b.length) {
        return false;
    }
    b.sort(sort);
    return a.sort(sort).every((item, index) => b[index].equals(item));
}

// The domain string used for peer records contained in a Envelope.
const ENVELOPE_DOMAIN_PEER_RECORD = 'libp2p-peer-record';
// The type hint used to identify peer records in a Envelope.
// Defined in https://github.com/multiformats/multicodec/blob/master/table.csv
// with name "libp2p-peer-record"
const ENVELOPE_PAYLOAD_TYPE_PEER_RECORD = Uint8Array.from([3, 1]);

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var PeerRecord$1;
(function (PeerRecord) {
    (function (AddressInfo) {
        let _codec;
        AddressInfo.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.multiaddr != null && obj.multiaddr.byteLength > 0)) {
                        w.uint32(10);
                        w.bytes(obj.multiaddr);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        multiaddr: new Uint8Array(0)
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.multiaddr = reader.bytes();
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        AddressInfo.encode = (obj) => {
            return encodeMessage(obj, AddressInfo.codec());
        };
        AddressInfo.decode = (buf) => {
            return decodeMessage$1(buf, AddressInfo.codec());
        };
    })(PeerRecord.AddressInfo || (PeerRecord.AddressInfo = {}));
    let _codec;
    PeerRecord.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.peerId != null && obj.peerId.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.peerId);
                }
                if ((obj.seq != null && obj.seq !== 0n)) {
                    w.uint32(16);
                    w.uint64(obj.seq);
                }
                if (obj.addresses != null) {
                    for (const value of obj.addresses) {
                        w.uint32(26);
                        PeerRecord.AddressInfo.codec().encode(value, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    peerId: new Uint8Array(0),
                    seq: 0n,
                    addresses: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.peerId = reader.bytes();
                            break;
                        case 2:
                            obj.seq = reader.uint64();
                            break;
                        case 3:
                            obj.addresses.push(PeerRecord.AddressInfo.codec().decode(reader, reader.uint32()));
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    PeerRecord.encode = (obj) => {
        return encodeMessage(obj, PeerRecord.codec());
    };
    PeerRecord.decode = (buf) => {
        return decodeMessage$1(buf, PeerRecord.codec());
    };
})(PeerRecord$1 || (PeerRecord$1 = {}));

/**
 * The PeerRecord is used for distributing peer routing records across the network.
 * It contains the peer's reachable listen addresses.
 */
class PeerRecord {
    /**
     * Unmarshal Peer Record Protobuf
     */
    static createFromProtobuf = (buf) => {
        const peerRecord = PeerRecord$1.decode(buf);
        const peerId = peerIdFromBytes(peerRecord.peerId);
        const multiaddrs = (peerRecord.addresses ?? []).map((a) => multiaddr$1(a.multiaddr));
        const seqNumber = peerRecord.seq;
        return new PeerRecord({ peerId, multiaddrs, seqNumber });
    };
    static DOMAIN = ENVELOPE_DOMAIN_PEER_RECORD;
    static CODEC = ENVELOPE_PAYLOAD_TYPE_PEER_RECORD;
    peerId;
    multiaddrs;
    seqNumber;
    domain = PeerRecord.DOMAIN;
    codec = PeerRecord.CODEC;
    marshaled;
    constructor(init) {
        const { peerId, multiaddrs, seqNumber } = init;
        this.peerId = peerId;
        this.multiaddrs = multiaddrs ?? [];
        this.seqNumber = seqNumber ?? BigInt(Date.now());
    }
    /**
     * Marshal a record to be used in an envelope
     */
    marshal() {
        if (this.marshaled == null) {
            this.marshaled = PeerRecord$1.encode({
                peerId: this.peerId.toBytes(),
                seq: BigInt(this.seqNumber),
                addresses: this.multiaddrs.map((m) => ({
                    multiaddr: m.bytes
                }))
            });
        }
        return this.marshaled;
    }
    /**
     * Returns true if `this` record equals the `other`
     */
    equals(other) {
        if (!(other instanceof PeerRecord)) {
            return false;
        }
        // Validate PeerId
        if (!this.peerId.equals(other.peerId)) {
            return false;
        }
        // Validate seqNumber
        if (this.seqNumber !== other.seqNumber) {
            return false;
        }
        // Validate multiaddrs
        if (!arrayEquals(this.multiaddrs, other.multiaddrs)) {
            return false;
        }
        return true;
    }
}

var eventemitter3 = {exports: {}};

(function (module) {

	var has = Object.prototype.hasOwnProperty
	  , prefix = '~';

	/**
	 * Constructor to create a storage for our `EE` objects.
	 * An `Events` instance is a plain object whose properties are event names.
	 *
	 * @constructor
	 * @private
	 */
	function Events() {}

	//
	// We try to not inherit from `Object.prototype`. In some engines creating an
	// instance in this way is faster than calling `Object.create(null)` directly.
	// If `Object.create(null)` is not supported we prefix the event names with a
	// character to make sure that the built-in object properties are not
	// overridden or used as an attack vector.
	//
	if (Object.create) {
	  Events.prototype = Object.create(null);

	  //
	  // This hack is needed because the `__proto__` property is still inherited in
	  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.
	  //
	  if (!new Events().__proto__) prefix = false;
	}

	/**
	 * Representation of a single event listener.
	 *
	 * @param {Function} fn The listener function.
	 * @param {*} context The context to invoke the listener with.
	 * @param {Boolean} [once=false] Specify if the listener is a one-time listener.
	 * @constructor
	 * @private
	 */
	function EE(fn, context, once) {
	  this.fn = fn;
	  this.context = context;
	  this.once = once || false;
	}

	/**
	 * Add a listener for a given event.
	 *
	 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} context The context to invoke the listener with.
	 * @param {Boolean} once Specify if the listener is a one-time listener.
	 * @returns {EventEmitter}
	 * @private
	 */
	function addListener(emitter, event, fn, context, once) {
	  if (typeof fn !== 'function') {
	    throw new TypeError('The listener must be a function');
	  }

	  var listener = new EE(fn, context || emitter, once)
	    , evt = prefix ? prefix + event : event;

	  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;
	  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);
	  else emitter._events[evt] = [emitter._events[evt], listener];

	  return emitter;
	}

	/**
	 * Clear event by name.
	 *
	 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
	 * @param {(String|Symbol)} evt The Event name.
	 * @private
	 */
	function clearEvent(emitter, evt) {
	  if (--emitter._eventsCount === 0) emitter._events = new Events();
	  else delete emitter._events[evt];
	}

	/**
	 * Minimal `EventEmitter` interface that is molded against the Node.js
	 * `EventEmitter` interface.
	 *
	 * @constructor
	 * @public
	 */
	function EventEmitter() {
	  this._events = new Events();
	  this._eventsCount = 0;
	}

	/**
	 * Return an array listing the events for which the emitter has registered
	 * listeners.
	 *
	 * @returns {Array}
	 * @public
	 */
	EventEmitter.prototype.eventNames = function eventNames() {
	  var names = []
	    , events
	    , name;

	  if (this._eventsCount === 0) return names;

	  for (name in (events = this._events)) {
	    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);
	  }

	  if (Object.getOwnPropertySymbols) {
	    return names.concat(Object.getOwnPropertySymbols(events));
	  }

	  return names;
	};

	/**
	 * Return the listeners registered for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Array} The registered listeners.
	 * @public
	 */
	EventEmitter.prototype.listeners = function listeners(event) {
	  var evt = prefix ? prefix + event : event
	    , handlers = this._events[evt];

	  if (!handlers) return [];
	  if (handlers.fn) return [handlers.fn];

	  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {
	    ee[i] = handlers[i].fn;
	  }

	  return ee;
	};

	/**
	 * Return the number of listeners listening to a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Number} The number of listeners.
	 * @public
	 */
	EventEmitter.prototype.listenerCount = function listenerCount(event) {
	  var evt = prefix ? prefix + event : event
	    , listeners = this._events[evt];

	  if (!listeners) return 0;
	  if (listeners.fn) return 1;
	  return listeners.length;
	};

	/**
	 * Calls each of the listeners registered for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @returns {Boolean} `true` if the event had listeners, else `false`.
	 * @public
	 */
	EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {
	  var evt = prefix ? prefix + event : event;

	  if (!this._events[evt]) return false;

	  var listeners = this._events[evt]
	    , len = arguments.length
	    , args
	    , i;

	  if (listeners.fn) {
	    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);

	    switch (len) {
	      case 1: return listeners.fn.call(listeners.context), true;
	      case 2: return listeners.fn.call(listeners.context, a1), true;
	      case 3: return listeners.fn.call(listeners.context, a1, a2), true;
	      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;
	      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;
	      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;
	    }

	    for (i = 1, args = new Array(len -1); i < len; i++) {
	      args[i - 1] = arguments[i];
	    }

	    listeners.fn.apply(listeners.context, args);
	  } else {
	    var length = listeners.length
	      , j;

	    for (i = 0; i < length; i++) {
	      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);

	      switch (len) {
	        case 1: listeners[i].fn.call(listeners[i].context); break;
	        case 2: listeners[i].fn.call(listeners[i].context, a1); break;
	        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;
	        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;
	        default:
	          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {
	            args[j - 1] = arguments[j];
	          }

	          listeners[i].fn.apply(listeners[i].context, args);
	      }
	    }
	  }

	  return true;
	};

	/**
	 * Add a listener for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} [context=this] The context to invoke the listener with.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.on = function on(event, fn, context) {
	  return addListener(this, event, fn, context, false);
	};

	/**
	 * Add a one-time listener for a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn The listener function.
	 * @param {*} [context=this] The context to invoke the listener with.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.once = function once(event, fn, context) {
	  return addListener(this, event, fn, context, true);
	};

	/**
	 * Remove the listeners of a given event.
	 *
	 * @param {(String|Symbol)} event The event name.
	 * @param {Function} fn Only remove the listeners that match this function.
	 * @param {*} context Only remove the listeners that have this context.
	 * @param {Boolean} once Only remove one-time listeners.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {
	  var evt = prefix ? prefix + event : event;

	  if (!this._events[evt]) return this;
	  if (!fn) {
	    clearEvent(this, evt);
	    return this;
	  }

	  var listeners = this._events[evt];

	  if (listeners.fn) {
	    if (
	      listeners.fn === fn &&
	      (!once || listeners.once) &&
	      (!context || listeners.context === context)
	    ) {
	      clearEvent(this, evt);
	    }
	  } else {
	    for (var i = 0, events = [], length = listeners.length; i < length; i++) {
	      if (
	        listeners[i].fn !== fn ||
	        (once && !listeners[i].once) ||
	        (context && listeners[i].context !== context)
	      ) {
	        events.push(listeners[i]);
	      }
	    }

	    //
	    // Reset the array, or remove it completely if we have no more listeners.
	    //
	    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;
	    else clearEvent(this, evt);
	  }

	  return this;
	};

	/**
	 * Remove all listeners, or those of the specified event.
	 *
	 * @param {(String|Symbol)} [event] The event name.
	 * @returns {EventEmitter} `this`.
	 * @public
	 */
	EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {
	  var evt;

	  if (event) {
	    evt = prefix ? prefix + event : event;
	    if (this._events[evt]) clearEvent(this, evt);
	  } else {
	    this._events = new Events();
	    this._eventsCount = 0;
	  }

	  return this;
	};

	//
	// Alias methods names because people roll like that.
	//
	EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
	EventEmitter.prototype.addListener = EventEmitter.prototype.on;

	//
	// Expose the prefix.
	//
	EventEmitter.prefixed = prefix;

	//
	// Allow `EventEmitter` to be imported as module namespace.
	//
	EventEmitter.EventEmitter = EventEmitter;

	//
	// Expose the module.
	//
	{
	  module.exports = EventEmitter;
	} 
} (eventemitter3));

var eventemitter3Exports = eventemitter3.exports;
var EventEmitter = /*@__PURE__*/getDefaultExportFromCjs(eventemitter3Exports);

let TimeoutError$1 = class TimeoutError extends Error {
	constructor(message) {
		super(message);
		this.name = 'TimeoutError';
	}
};

/**
An error to be thrown when the request is aborted by AbortController.
DOMException is thrown instead of this Error when DOMException is available.
*/
let AbortError$2 = class AbortError extends Error {
	constructor(message) {
		super();
		this.name = 'AbortError';
		this.message = message;
	}
};

/**
TODO: Remove AbortError and just throw DOMException when targeting Node 18.
*/
const getDOMException$1 = errorMessage => globalThis.DOMException === undefined ?
	new AbortError$2(errorMessage) :
	new DOMException(errorMessage);

/**
TODO: Remove below function and just 'reject(signal.reason)' when targeting Node 18.
*/
const getAbortedReason$1 = signal => {
	const reason = signal.reason === undefined ?
		getDOMException$1('This operation was aborted.') :
		signal.reason;

	return reason instanceof Error ? reason : getDOMException$1(reason);
};

function pTimeout$1(promise, milliseconds, fallback, options) {
	let timer;

	const cancelablePromise = new Promise((resolve, reject) => {
		if (typeof milliseconds !== 'number' || Math.sign(milliseconds) !== 1) {
			throw new TypeError(`Expected \`milliseconds\` to be a positive number, got \`${milliseconds}\``);
		}

		if (milliseconds === Number.POSITIVE_INFINITY) {
			resolve(promise);
			return;
		}

		options = {
			customTimers: {setTimeout, clearTimeout},
			...options
		};

		if (options.signal) {
			const {signal} = options;
			if (signal.aborted) {
				reject(getAbortedReason$1(signal));
			}

			signal.addEventListener('abort', () => {
				reject(getAbortedReason$1(signal));
			});
		}

		timer = options.customTimers.setTimeout.call(undefined, () => {
			if (typeof fallback === 'function') {
				try {
					resolve(fallback());
				} catch (error) {
					reject(error);
				}

				return;
			}

			const message = typeof fallback === 'string' ? fallback : `Promise timed out after ${milliseconds} milliseconds`;
			const timeoutError = fallback instanceof Error ? fallback : new TimeoutError$1(message);

			if (typeof promise.cancel === 'function') {
				promise.cancel();
			}

			reject(timeoutError);
		}, milliseconds);

		(async () => {
			try {
				resolve(await promise);
			} catch (error) {
				reject(error);
			} finally {
				options.customTimers.clearTimeout.call(undefined, timer);
			}
		})();
	});

	cancelablePromise.clear = () => {
		clearTimeout(timer);
		timer = undefined;
	};

	return cancelablePromise;
}

// Port of lower_bound from https://en.cppreference.com/w/cpp/algorithm/lower_bound
// Used to compute insertion index to keep queue sorted after insertion
function lowerBound$1(array, value, comparator) {
    let first = 0;
    let count = array.length;
    while (count > 0) {
        const step = Math.trunc(count / 2);
        let it = first + step;
        if (comparator(array[it], value) <= 0) {
            first = ++it;
            count -= step + 1;
        }
        else {
            count = step;
        }
    }
    return first;
}

var __classPrivateFieldGet$1 = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var _PriorityQueue_queue;
class PriorityQueue {
    constructor() {
        _PriorityQueue_queue.set(this, []);
    }
    enqueue(run, options) {
        options = {
            priority: 0,
            ...options,
        };
        const element = {
            priority: options.priority,
            run,
        };
        if (this.size && __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f")[this.size - 1].priority >= options.priority) {
            __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").push(element);
            return;
        }
        const index = lowerBound$1(__classPrivateFieldGet$1(this, _PriorityQueue_queue, "f"), element, (a, b) => b.priority - a.priority);
        __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").splice(index, 0, element);
    }
    dequeue() {
        const item = __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").shift();
        return item === null || item === void 0 ? void 0 : item.run;
    }
    filter(options) {
        return __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").filter((element) => element.priority === options.priority).map((element) => element.run);
    }
    get size() {
        return __classPrivateFieldGet$1(this, _PriorityQueue_queue, "f").length;
    }
}
_PriorityQueue_queue = new WeakMap();

var __classPrivateFieldSet = (undefined && undefined.__classPrivateFieldSet) || function (receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return (kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;
};
var __classPrivateFieldGet = (undefined && undefined.__classPrivateFieldGet) || function (receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
};
var _PQueue_instances, _PQueue_carryoverConcurrencyCount, _PQueue_isIntervalIgnored, _PQueue_intervalCount, _PQueue_intervalCap, _PQueue_interval, _PQueue_intervalEnd, _PQueue_intervalId, _PQueue_timeoutId, _PQueue_queue, _PQueue_queueClass, _PQueue_pending, _PQueue_concurrency, _PQueue_isPaused, _PQueue_throwOnTimeout, _PQueue_doesIntervalAllowAnother_get, _PQueue_doesConcurrentAllowAnother_get, _PQueue_next, _PQueue_onResumeInterval, _PQueue_isIntervalPaused_get, _PQueue_tryToStartAnother, _PQueue_initializeIntervalIfNeeded, _PQueue_onInterval, _PQueue_processQueue, _PQueue_throwOnAbort, _PQueue_onEvent;
/**
The error thrown by `queue.add()` when a job is aborted before it is run. See `signal`.
*/
let AbortError$1 = class AbortError extends Error {
};
/**
Promise queue with concurrency control.
*/
class PQueue extends EventEmitter {
    // TODO: The `throwOnTimeout` option should affect the return types of `add()` and `addAll()`
    constructor(options) {
        var _a, _b, _c, _d;
        super();
        _PQueue_instances.add(this);
        _PQueue_carryoverConcurrencyCount.set(this, void 0);
        _PQueue_isIntervalIgnored.set(this, void 0);
        _PQueue_intervalCount.set(this, 0);
        _PQueue_intervalCap.set(this, void 0);
        _PQueue_interval.set(this, void 0);
        _PQueue_intervalEnd.set(this, 0);
        _PQueue_intervalId.set(this, void 0);
        _PQueue_timeoutId.set(this, void 0);
        _PQueue_queue.set(this, void 0);
        _PQueue_queueClass.set(this, void 0);
        _PQueue_pending.set(this, 0);
        // The `!` is needed because of https://github.com/microsoft/TypeScript/issues/32194
        _PQueue_concurrency.set(this, void 0);
        _PQueue_isPaused.set(this, void 0);
        _PQueue_throwOnTimeout.set(this, void 0);
        /**
        Per-operation timeout in milliseconds. Operations fulfill once `timeout` elapses if they haven't already.
    
        Applies to each future operation.
        */
        Object.defineProperty(this, "timeout", {
            enumerable: true,
            configurable: true,
            writable: true,
            value: void 0
        });
        // eslint-disable-next-line @typescript-eslint/consistent-type-assertions
        options = {
            carryoverConcurrencyCount: false,
            intervalCap: Number.POSITIVE_INFINITY,
            interval: 0,
            concurrency: Number.POSITIVE_INFINITY,
            autoStart: true,
            queueClass: PriorityQueue,
            ...options,
        };
        if (!(typeof options.intervalCap === 'number' && options.intervalCap >= 1)) {
            throw new TypeError(`Expected \`intervalCap\` to be a number from 1 and up, got \`${(_b = (_a = options.intervalCap) === null || _a === void 0 ? void 0 : _a.toString()) !== null && _b !== void 0 ? _b : ''}\` (${typeof options.intervalCap})`);
        }
        if (options.interval === undefined || !(Number.isFinite(options.interval) && options.interval >= 0)) {
            throw new TypeError(`Expected \`interval\` to be a finite number >= 0, got \`${(_d = (_c = options.interval) === null || _c === void 0 ? void 0 : _c.toString()) !== null && _d !== void 0 ? _d : ''}\` (${typeof options.interval})`);
        }
        __classPrivateFieldSet(this, _PQueue_carryoverConcurrencyCount, options.carryoverConcurrencyCount, "f");
        __classPrivateFieldSet(this, _PQueue_isIntervalIgnored, options.intervalCap === Number.POSITIVE_INFINITY || options.interval === 0, "f");
        __classPrivateFieldSet(this, _PQueue_intervalCap, options.intervalCap, "f");
        __classPrivateFieldSet(this, _PQueue_interval, options.interval, "f");
        __classPrivateFieldSet(this, _PQueue_queue, new options.queueClass(), "f");
        __classPrivateFieldSet(this, _PQueue_queueClass, options.queueClass, "f");
        this.concurrency = options.concurrency;
        this.timeout = options.timeout;
        __classPrivateFieldSet(this, _PQueue_throwOnTimeout, options.throwOnTimeout === true, "f");
        __classPrivateFieldSet(this, _PQueue_isPaused, options.autoStart === false, "f");
    }
    get concurrency() {
        return __classPrivateFieldGet(this, _PQueue_concurrency, "f");
    }
    set concurrency(newConcurrency) {
        if (!(typeof newConcurrency === 'number' && newConcurrency >= 1)) {
            throw new TypeError(`Expected \`concurrency\` to be a number from 1 and up, got \`${newConcurrency}\` (${typeof newConcurrency})`);
        }
        __classPrivateFieldSet(this, _PQueue_concurrency, newConcurrency, "f");
        __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_processQueue).call(this);
    }
    async add(function_, options = {}) {
        options = {
            timeout: this.timeout,
            throwOnTimeout: __classPrivateFieldGet(this, _PQueue_throwOnTimeout, "f"),
            ...options,
        };
        return new Promise((resolve, reject) => {
            __classPrivateFieldGet(this, _PQueue_queue, "f").enqueue(async () => {
                var _a;
                var _b, _c;
                __classPrivateFieldSet(this, _PQueue_pending, (_b = __classPrivateFieldGet(this, _PQueue_pending, "f"), _b++, _b), "f");
                __classPrivateFieldSet(this, _PQueue_intervalCount, (_c = __classPrivateFieldGet(this, _PQueue_intervalCount, "f"), _c++, _c), "f");
                try {
                    // TODO: Use options.signal?.throwIfAborted() when targeting Node.js 18
                    if ((_a = options.signal) === null || _a === void 0 ? void 0 : _a.aborted) {
                        // TODO: Use ABORT_ERR code when targeting Node.js 16 (https://nodejs.org/docs/latest-v16.x/api/errors.html#abort_err)
                        throw new AbortError$1('The task was aborted.');
                    }
                    let operation = function_({ signal: options.signal });
                    if (options.timeout) {
                        operation = pTimeout$1(Promise.resolve(operation), options.timeout);
                    }
                    if (options.signal) {
                        operation = Promise.race([operation, __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_throwOnAbort).call(this, options.signal)]);
                    }
                    const result = await operation;
                    resolve(result);
                    this.emit('completed', result);
                }
                catch (error) {
                    if (error instanceof TimeoutError$1 && !options.throwOnTimeout) {
                        resolve();
                        return;
                    }
                    reject(error);
                    this.emit('error', error);
                }
                finally {
                    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_next).call(this);
                }
            }, options);
            this.emit('add');
            __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_tryToStartAnother).call(this);
        });
    }
    async addAll(functions, options) {
        return Promise.all(functions.map(async (function_) => this.add(function_, options)));
    }
    /**
    Start (or resume) executing enqueued tasks within concurrency limit. No need to call this if queue is not paused (via `options.autoStart = false` or by `.pause()` method.)
    */
    start() {
        if (!__classPrivateFieldGet(this, _PQueue_isPaused, "f")) {
            return this;
        }
        __classPrivateFieldSet(this, _PQueue_isPaused, false, "f");
        __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_processQueue).call(this);
        return this;
    }
    /**
    Put queue execution on hold.
    */
    pause() {
        __classPrivateFieldSet(this, _PQueue_isPaused, true, "f");
    }
    /**
    Clear the queue.
    */
    clear() {
        __classPrivateFieldSet(this, _PQueue_queue, new (__classPrivateFieldGet(this, _PQueue_queueClass, "f"))(), "f");
    }
    /**
    Can be called multiple times. Useful if you for example add additional items at a later time.

    @returns A promise that settles when the queue becomes empty.
    */
    async onEmpty() {
        // Instantly resolve if the queue is empty
        if (__classPrivateFieldGet(this, _PQueue_queue, "f").size === 0) {
            return;
        }
        await __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onEvent).call(this, 'empty');
    }
    /**
    @returns A promise that settles when the queue size is less than the given limit: `queue.size < limit`.

    If you want to avoid having the queue grow beyond a certain size you can `await queue.onSizeLessThan()` before adding a new item.

    Note that this only limits the number of items waiting to start. There could still be up to `concurrency` jobs already running that this call does not include in its calculation.
    */
    async onSizeLessThan(limit) {
        // Instantly resolve if the queue is empty.
        if (__classPrivateFieldGet(this, _PQueue_queue, "f").size < limit) {
            return;
        }
        await __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onEvent).call(this, 'next', () => __classPrivateFieldGet(this, _PQueue_queue, "f").size < limit);
    }
    /**
    The difference with `.onEmpty` is that `.onIdle` guarantees that all work from the queue has finished. `.onEmpty` merely signals that the queue is empty, but it could mean that some promises haven't completed yet.

    @returns A promise that settles when the queue becomes empty, and all promises have completed; `queue.size === 0 && queue.pending === 0`.
    */
    async onIdle() {
        // Instantly resolve if none pending and if nothing else is queued
        if (__classPrivateFieldGet(this, _PQueue_pending, "f") === 0 && __classPrivateFieldGet(this, _PQueue_queue, "f").size === 0) {
            return;
        }
        await __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onEvent).call(this, 'idle');
    }
    /**
    Size of the queue, the number of queued items waiting to run.
    */
    get size() {
        return __classPrivateFieldGet(this, _PQueue_queue, "f").size;
    }
    /**
    Size of the queue, filtered by the given options.

    For example, this can be used to find the number of items remaining in the queue with a specific priority level.
    */
    sizeBy(options) {
        // eslint-disable-next-line unicorn/no-array-callback-reference
        return __classPrivateFieldGet(this, _PQueue_queue, "f").filter(options).length;
    }
    /**
    Number of running items (no longer in the queue).
    */
    get pending() {
        return __classPrivateFieldGet(this, _PQueue_pending, "f");
    }
    /**
    Whether the queue is currently paused.
    */
    get isPaused() {
        return __classPrivateFieldGet(this, _PQueue_isPaused, "f");
    }
}
_PQueue_carryoverConcurrencyCount = new WeakMap(), _PQueue_isIntervalIgnored = new WeakMap(), _PQueue_intervalCount = new WeakMap(), _PQueue_intervalCap = new WeakMap(), _PQueue_interval = new WeakMap(), _PQueue_intervalEnd = new WeakMap(), _PQueue_intervalId = new WeakMap(), _PQueue_timeoutId = new WeakMap(), _PQueue_queue = new WeakMap(), _PQueue_queueClass = new WeakMap(), _PQueue_pending = new WeakMap(), _PQueue_concurrency = new WeakMap(), _PQueue_isPaused = new WeakMap(), _PQueue_throwOnTimeout = new WeakMap(), _PQueue_instances = new WeakSet(), _PQueue_doesIntervalAllowAnother_get = function _PQueue_doesIntervalAllowAnother_get() {
    return __classPrivateFieldGet(this, _PQueue_isIntervalIgnored, "f") || __classPrivateFieldGet(this, _PQueue_intervalCount, "f") < __classPrivateFieldGet(this, _PQueue_intervalCap, "f");
}, _PQueue_doesConcurrentAllowAnother_get = function _PQueue_doesConcurrentAllowAnother_get() {
    return __classPrivateFieldGet(this, _PQueue_pending, "f") < __classPrivateFieldGet(this, _PQueue_concurrency, "f");
}, _PQueue_next = function _PQueue_next() {
    var _a;
    __classPrivateFieldSet(this, _PQueue_pending, (_a = __classPrivateFieldGet(this, _PQueue_pending, "f"), _a--, _a), "f");
    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_tryToStartAnother).call(this);
    this.emit('next');
}, _PQueue_onResumeInterval = function _PQueue_onResumeInterval() {
    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onInterval).call(this);
    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_initializeIntervalIfNeeded).call(this);
    __classPrivateFieldSet(this, _PQueue_timeoutId, undefined, "f");
}, _PQueue_isIntervalPaused_get = function _PQueue_isIntervalPaused_get() {
    const now = Date.now();
    if (__classPrivateFieldGet(this, _PQueue_intervalId, "f") === undefined) {
        const delay = __classPrivateFieldGet(this, _PQueue_intervalEnd, "f") - now;
        if (delay < 0) {
            // Act as the interval was done
            // We don't need to resume it here because it will be resumed on line 160
            __classPrivateFieldSet(this, _PQueue_intervalCount, (__classPrivateFieldGet(this, _PQueue_carryoverConcurrencyCount, "f")) ? __classPrivateFieldGet(this, _PQueue_pending, "f") : 0, "f");
        }
        else {
            // Act as the interval is pending
            if (__classPrivateFieldGet(this, _PQueue_timeoutId, "f") === undefined) {
                __classPrivateFieldSet(this, _PQueue_timeoutId, setTimeout(() => {
                    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onResumeInterval).call(this);
                }, delay), "f");
            }
            return true;
        }
    }
    return false;
}, _PQueue_tryToStartAnother = function _PQueue_tryToStartAnother() {
    if (__classPrivateFieldGet(this, _PQueue_queue, "f").size === 0) {
        // We can clear the interval ("pause")
        // Because we can redo it later ("resume")
        if (__classPrivateFieldGet(this, _PQueue_intervalId, "f")) {
            clearInterval(__classPrivateFieldGet(this, _PQueue_intervalId, "f"));
        }
        __classPrivateFieldSet(this, _PQueue_intervalId, undefined, "f");
        this.emit('empty');
        if (__classPrivateFieldGet(this, _PQueue_pending, "f") === 0) {
            this.emit('idle');
        }
        return false;
    }
    if (!__classPrivateFieldGet(this, _PQueue_isPaused, "f")) {
        const canInitializeInterval = !__classPrivateFieldGet(this, _PQueue_instances, "a", _PQueue_isIntervalPaused_get);
        if (__classPrivateFieldGet(this, _PQueue_instances, "a", _PQueue_doesIntervalAllowAnother_get) && __classPrivateFieldGet(this, _PQueue_instances, "a", _PQueue_doesConcurrentAllowAnother_get)) {
            const job = __classPrivateFieldGet(this, _PQueue_queue, "f").dequeue();
            if (!job) {
                return false;
            }
            this.emit('active');
            job();
            if (canInitializeInterval) {
                __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_initializeIntervalIfNeeded).call(this);
            }
            return true;
        }
    }
    return false;
}, _PQueue_initializeIntervalIfNeeded = function _PQueue_initializeIntervalIfNeeded() {
    if (__classPrivateFieldGet(this, _PQueue_isIntervalIgnored, "f") || __classPrivateFieldGet(this, _PQueue_intervalId, "f") !== undefined) {
        return;
    }
    __classPrivateFieldSet(this, _PQueue_intervalId, setInterval(() => {
        __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_onInterval).call(this);
    }, __classPrivateFieldGet(this, _PQueue_interval, "f")), "f");
    __classPrivateFieldSet(this, _PQueue_intervalEnd, Date.now() + __classPrivateFieldGet(this, _PQueue_interval, "f"), "f");
}, _PQueue_onInterval = function _PQueue_onInterval() {
    if (__classPrivateFieldGet(this, _PQueue_intervalCount, "f") === 0 && __classPrivateFieldGet(this, _PQueue_pending, "f") === 0 && __classPrivateFieldGet(this, _PQueue_intervalId, "f")) {
        clearInterval(__classPrivateFieldGet(this, _PQueue_intervalId, "f"));
        __classPrivateFieldSet(this, _PQueue_intervalId, undefined, "f");
    }
    __classPrivateFieldSet(this, _PQueue_intervalCount, __classPrivateFieldGet(this, _PQueue_carryoverConcurrencyCount, "f") ? __classPrivateFieldGet(this, _PQueue_pending, "f") : 0, "f");
    __classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_processQueue).call(this);
}, _PQueue_processQueue = function _PQueue_processQueue() {
    // eslint-disable-next-line no-empty
    while (__classPrivateFieldGet(this, _PQueue_instances, "m", _PQueue_tryToStartAnother).call(this)) { }
}, _PQueue_throwOnAbort = async function _PQueue_throwOnAbort(signal) {
    return new Promise((_resolve, reject) => {
        signal.addEventListener('abort', () => {
            // TODO: Reject with signal.throwIfAborted() when targeting Node.js 18
            // TODO: Use ABORT_ERR code when targeting Node.js 16 (https://nodejs.org/docs/latest-v16.x/api/errors.html#abort_err)
            reject(new AbortError$1('The task was aborted.'));
        }, { once: true });
    });
}, _PQueue_onEvent = async function _PQueue_onEvent(event, filter) {
    return new Promise(resolve => {
        const listener = () => {
            if (filter && !filter()) {
                return;
            }
            this.off(event, listener);
            resolve();
        };
        this.on(event, listener);
    });
};

class TimeoutError extends Error {
	constructor(message) {
		super(message);
		this.name = 'TimeoutError';
	}
}

/**
An error to be thrown when the request is aborted by AbortController.
DOMException is thrown instead of this Error when DOMException is available.
*/
class AbortError extends Error {
	constructor(message) {
		super();
		this.name = 'AbortError';
		this.message = message;
	}
}

/**
TODO: Remove AbortError and just throw DOMException when targeting Node 18.
*/
const getDOMException = errorMessage => globalThis.DOMException === undefined
	? new AbortError(errorMessage)
	: new DOMException(errorMessage);

/**
TODO: Remove below function and just 'reject(signal.reason)' when targeting Node 18.
*/
const getAbortedReason = signal => {
	const reason = signal.reason === undefined
		? getDOMException('This operation was aborted.')
		: signal.reason;

	return reason instanceof Error ? reason : getDOMException(reason);
};

function pTimeout(promise, options) {
	const {
		milliseconds,
		fallback,
		message,
		customTimers = {setTimeout, clearTimeout},
	} = options;

	let timer;

	const wrappedPromise = new Promise((resolve, reject) => {
		if (typeof milliseconds !== 'number' || Math.sign(milliseconds) !== 1) {
			throw new TypeError(`Expected \`milliseconds\` to be a positive number, got \`${milliseconds}\``);
		}

		if (options.signal) {
			const {signal} = options;
			if (signal.aborted) {
				reject(getAbortedReason(signal));
			}

			signal.addEventListener('abort', () => {
				reject(getAbortedReason(signal));
			});
		}

		if (milliseconds === Number.POSITIVE_INFINITY) {
			promise.then(resolve, reject);
			return;
		}

		// We create the error outside of `setTimeout` to preserve the stack trace.
		const timeoutError = new TimeoutError();

		timer = customTimers.setTimeout.call(undefined, () => {
			if (fallback) {
				try {
					resolve(fallback());
				} catch (error) {
					reject(error);
				}

				return;
			}

			if (typeof promise.cancel === 'function') {
				promise.cancel();
			}

			if (message === false) {
				resolve();
			} else if (message instanceof Error) {
				reject(message);
			} else {
				timeoutError.message = message ?? `Promise timed out after ${milliseconds} milliseconds`;
				reject(timeoutError);
			}
		}, milliseconds);

		(async () => {
			try {
				resolve(await promise);
			} catch (error) {
				reject(error);
			}
		})();
	});

	const cancelablePromise = wrappedPromise.finally(() => {
		cancelablePromise.clear();
	});

	cancelablePromise.clear = () => {
		customTimers.clearTimeout.call(undefined, timer);
		timer = undefined;
	};

	return cancelablePromise;
}

let nanoid = (size = 21) =>
  crypto.getRandomValues(new Uint8Array(size)).reduce((id, byte) => {
    byte &= 63;
    if (byte < 36) {
      id += byte.toString(36);
    } else if (byte < 62) {
      id += (byte - 26).toString(36).toUpperCase();
    } else if (byte > 62) {
      id += '-';
    } else {
      id += '_';
    }
    return id
  }, '');

const WORKER_REQUEST_READ_LOCK = 'lock:worker:request-read';
const WORKER_RELEASE_READ_LOCK = 'lock:worker:release-read';
const MASTER_GRANT_READ_LOCK = 'lock:master:grant-read';
const WORKER_REQUEST_WRITE_LOCK = 'lock:worker:request-write';
const WORKER_RELEASE_WRITE_LOCK = 'lock:worker:release-write';
const MASTER_GRANT_WRITE_LOCK = 'lock:master:grant-write';

const events = {};
const observable = (worker) => {
    worker.addEventListener('message', (event) => {
        observable.dispatchEvent('message', worker, event);
    });
    if (worker.port != null) {
        worker.port.addEventListener('message', (event) => {
            observable.dispatchEvent('message', worker, event);
        });
    }
};
observable.addEventListener = (type, fn) => {
    if (events[type] == null) {
        events[type] = [];
    }
    events[type].push(fn);
};
observable.removeEventListener = (type, fn) => {
    if (events[type] == null) {
        return;
    }
    events[type] = events[type]
        .filter(listener => listener === fn);
};
observable.dispatchEvent = function (type, worker, event) {
    if (events[type] == null) {
        return;
    }
    events[type].forEach(fn => fn(worker, event));
};

const handleWorkerLockRequest = (emitter, masterEvent, requestType, releaseType, grantType) => {
    return (worker, event) => {
        if (event.data.type !== requestType) {
            return;
        }
        const requestEvent = {
            type: event.data.type,
            name: event.data.name,
            identifier: event.data.identifier
        };
        emitter.dispatchEvent(new MessageEvent(masterEvent, {
            data: {
                name: requestEvent.name,
                handler: async () => {
                    // grant lock to worker
                    worker.postMessage({
                        type: grantType,
                        name: requestEvent.name,
                        identifier: requestEvent.identifier
                    });
                    // wait for worker to finish
                    return await new Promise((resolve) => {
                        const releaseEventListener = (event) => {
                            if (event == null || event.data == null) {
                                return;
                            }
                            const releaseEvent = {
                                type: event.data.type,
                                name: event.data.name,
                                identifier: event.data.identifier
                            };
                            if (releaseEvent.type === releaseType && releaseEvent.identifier === requestEvent.identifier) {
                                worker.removeEventListener('message', releaseEventListener);
                                resolve();
                            }
                        };
                        worker.addEventListener('message', releaseEventListener);
                    });
                }
            }
        }));
    };
};
const makeWorkerLockRequest = (name, requestType, grantType, releaseType) => {
    return async () => {
        const id = nanoid();
        globalThis.postMessage({
            type: requestType,
            identifier: id,
            name
        });
        return await new Promise((resolve) => {
            const listener = (event) => {
                if (event == null || event.data == null) {
                    return;
                }
                const responseEvent = {
                    type: event.data.type,
                    identifier: event.data.identifier
                };
                if (responseEvent.type === grantType && responseEvent.identifier === id) {
                    globalThis.removeEventListener('message', listener);
                    // grant lock
                    resolve(() => {
                        // release lock
                        globalThis.postMessage({
                            type: releaseType,
                            identifier: id,
                            name
                        });
                    });
                }
            };
            globalThis.addEventListener('message', listener);
        });
    };
};
const defaultOptions$5 = {
    singleProcess: false
};
var impl = (options) => {
    options = Object.assign({}, defaultOptions$5, options);
    const isPrimary = Boolean(globalThis.document) || options.singleProcess;
    if (isPrimary) {
        const emitter = new EventTarget();
        observable.addEventListener('message', handleWorkerLockRequest(emitter, 'requestReadLock', WORKER_REQUEST_READ_LOCK, WORKER_RELEASE_READ_LOCK, MASTER_GRANT_READ_LOCK));
        observable.addEventListener('message', handleWorkerLockRequest(emitter, 'requestWriteLock', WORKER_REQUEST_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK));
        return emitter;
    }
    return {
        isWorker: true,
        readLock: (name) => makeWorkerLockRequest(name, WORKER_REQUEST_READ_LOCK, MASTER_GRANT_READ_LOCK, WORKER_RELEASE_READ_LOCK),
        writeLock: (name) => makeWorkerLockRequest(name, WORKER_REQUEST_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK)
    };
};

const mutexes = {};
let implementation;
async function createReleaseable(queue, options) {
    let res;
    const p = new Promise((resolve) => {
        res = resolve;
    });
    void queue.add(async () => await pTimeout((async () => {
        return await new Promise((resolve) => {
            res(() => {
                resolve();
            });
        });
    })(), {
        milliseconds: options.timeout
    }));
    return await p;
}
const createMutex = (name, options) => {
    if (implementation.isWorker === true) {
        return {
            readLock: implementation.readLock(name, options),
            writeLock: implementation.writeLock(name, options)
        };
    }
    const masterQueue = new PQueue({ concurrency: 1 });
    let readQueue;
    return {
        async readLock() {
            // If there's already a read queue, just add the task to it
            if (readQueue != null) {
                return await createReleaseable(readQueue, options);
            }
            // Create a new read queue
            readQueue = new PQueue({
                concurrency: options.concurrency,
                autoStart: false
            });
            const localReadQueue = readQueue;
            // Add the task to the read queue
            const readPromise = createReleaseable(readQueue, options);
            void masterQueue.add(async () => {
                // Start the task only once the master queue has completed processing
                // any previous tasks
                localReadQueue.start();
                // Once all the tasks in the read queue have completed, remove it so
                // that the next read lock will occur after any write locks that were
                // started in the interim
                return await localReadQueue.onIdle()
                    .then(() => {
                    if (readQueue === localReadQueue) {
                        readQueue = null;
                    }
                });
            });
            return await readPromise;
        },
        async writeLock() {
            // Remove the read queue reference, so that any later read locks will be
            // added to a new queue that starts after this write lock has been
            // released
            readQueue = null;
            return await createReleaseable(masterQueue, options);
        }
    };
};
const defaultOptions$4 = {
    name: 'lock',
    concurrency: Infinity,
    timeout: 84600000,
    singleProcess: false
};
function createMortice(options) {
    const opts = Object.assign({}, defaultOptions$4, options);
    if (implementation == null) {
        implementation = impl(opts);
        if (implementation.isWorker !== true) {
            // we are master, set up worker requests
            implementation.addEventListener('requestReadLock', (event) => {
                if (mutexes[event.data.name] == null) {
                    return;
                }
                void mutexes[event.data.name].readLock()
                    .then(async (release) => await event.data.handler().finally(() => release()));
            });
            implementation.addEventListener('requestWriteLock', async (event) => {
                if (mutexes[event.data.name] == null) {
                    return;
                }
                void mutexes[event.data.name].writeLock()
                    .then(async (release) => await event.data.handler().finally(() => release()));
            });
        }
    }
    if (mutexes[opts.name] == null) {
        mutexes[opts.name] = createMutex(opts.name, opts);
    }
    return mutexes[opts.name];
}

const codes$1 = {
    ERR_INVALID_PARAMETERS: 'ERR_INVALID_PARAMETERS'
};

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var Peer;
(function (Peer) {
    (function (Peer$metadataEntry) {
        let _codec;
        Peer$metadataEntry.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.key != null && obj.key !== '')) {
                        w.uint32(10);
                        w.string(obj.key);
                    }
                    if ((obj.value != null && obj.value.byteLength > 0)) {
                        w.uint32(18);
                        w.bytes(obj.value);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        key: '',
                        value: new Uint8Array(0)
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.key = reader.string();
                                break;
                            case 2:
                                obj.value = reader.bytes();
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        Peer$metadataEntry.encode = (obj) => {
            return encodeMessage(obj, Peer$metadataEntry.codec());
        };
        Peer$metadataEntry.decode = (buf) => {
            return decodeMessage$1(buf, Peer$metadataEntry.codec());
        };
    })(Peer.Peer$metadataEntry || (Peer.Peer$metadataEntry = {}));
    (function (Peer$tagsEntry) {
        let _codec;
        Peer$tagsEntry.codec = () => {
            if (_codec == null) {
                _codec = message$1((obj, w, opts = {}) => {
                    if (opts.lengthDelimited !== false) {
                        w.fork();
                    }
                    if ((obj.key != null && obj.key !== '')) {
                        w.uint32(10);
                        w.string(obj.key);
                    }
                    if (obj.value != null) {
                        w.uint32(18);
                        Tag.codec().encode(obj.value, w);
                    }
                    if (opts.lengthDelimited !== false) {
                        w.ldelim();
                    }
                }, (reader, length) => {
                    const obj = {
                        key: ''
                    };
                    const end = length == null ? reader.len : reader.pos + length;
                    while (reader.pos < end) {
                        const tag = reader.uint32();
                        switch (tag >>> 3) {
                            case 1:
                                obj.key = reader.string();
                                break;
                            case 2:
                                obj.value = Tag.codec().decode(reader, reader.uint32());
                                break;
                            default:
                                reader.skipType(tag & 7);
                                break;
                        }
                    }
                    return obj;
                });
            }
            return _codec;
        };
        Peer$tagsEntry.encode = (obj) => {
            return encodeMessage(obj, Peer$tagsEntry.codec());
        };
        Peer$tagsEntry.decode = (buf) => {
            return decodeMessage$1(buf, Peer$tagsEntry.codec());
        };
    })(Peer.Peer$tagsEntry || (Peer.Peer$tagsEntry = {}));
    let _codec;
    Peer.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.addresses != null) {
                    for (const value of obj.addresses) {
                        w.uint32(10);
                        Address.codec().encode(value, w);
                    }
                }
                if (obj.protocols != null) {
                    for (const value of obj.protocols) {
                        w.uint32(18);
                        w.string(value);
                    }
                }
                if (obj.publicKey != null) {
                    w.uint32(34);
                    w.bytes(obj.publicKey);
                }
                if (obj.peerRecordEnvelope != null) {
                    w.uint32(42);
                    w.bytes(obj.peerRecordEnvelope);
                }
                if (obj.metadata != null && obj.metadata.size !== 0) {
                    for (const [key, value] of obj.metadata.entries()) {
                        w.uint32(50);
                        Peer.Peer$metadataEntry.codec().encode({ key, value }, w);
                    }
                }
                if (obj.tags != null && obj.tags.size !== 0) {
                    for (const [key, value] of obj.tags.entries()) {
                        w.uint32(58);
                        Peer.Peer$tagsEntry.codec().encode({ key, value }, w);
                    }
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    addresses: [],
                    protocols: [],
                    metadata: new Map(),
                    tags: new Map()
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.addresses.push(Address.codec().decode(reader, reader.uint32()));
                            break;
                        case 2:
                            obj.protocols.push(reader.string());
                            break;
                        case 4:
                            obj.publicKey = reader.bytes();
                            break;
                        case 5:
                            obj.peerRecordEnvelope = reader.bytes();
                            break;
                        case 6: {
                            const entry = Peer.Peer$metadataEntry.codec().decode(reader, reader.uint32());
                            obj.metadata.set(entry.key, entry.value);
                            break;
                        }
                        case 7: {
                            const entry = Peer.Peer$tagsEntry.codec().decode(reader, reader.uint32());
                            obj.tags.set(entry.key, entry.value);
                            break;
                        }
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Peer.encode = (obj) => {
        return encodeMessage(obj, Peer.codec());
    };
    Peer.decode = (buf) => {
        return decodeMessage$1(buf, Peer.codec());
    };
})(Peer || (Peer = {}));
var Address;
(function (Address) {
    let _codec;
    Address.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.multiaddr != null && obj.multiaddr.byteLength > 0)) {
                    w.uint32(10);
                    w.bytes(obj.multiaddr);
                }
                if (obj.isCertified != null) {
                    w.uint32(16);
                    w.bool(obj.isCertified);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    multiaddr: new Uint8Array(0)
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.multiaddr = reader.bytes();
                            break;
                        case 2:
                            obj.isCertified = reader.bool();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Address.encode = (obj) => {
        return encodeMessage(obj, Address.codec());
    };
    Address.decode = (buf) => {
        return decodeMessage$1(buf, Address.codec());
    };
})(Address || (Address = {}));
var Tag;
(function (Tag) {
    let _codec;
    Tag.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if ((obj.value != null && obj.value !== 0)) {
                    w.uint32(8);
                    w.uint32(obj.value);
                }
                if (obj.expiry != null) {
                    w.uint32(16);
                    w.uint64(obj.expiry);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    value: 0
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 1:
                            obj.value = reader.uint32();
                            break;
                        case 2:
                            obj.expiry = reader.uint64();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Tag.encode = (obj) => {
        return encodeMessage(obj, Tag.codec());
    };
    Tag.decode = (buf) => {
        return decodeMessage$1(buf, Tag.codec());
    };
})(Tag || (Tag = {}));

function bytesToPeer(peerId, buf) {
    const peer = Peer.decode(buf);
    if (peer.publicKey != null && peerId.publicKey == null) {
        peerId = peerIdFromPeerId({
            ...peerId,
            publicKey: peerId.publicKey
        });
    }
    const tags = new Map();
    // remove any expired tags
    const now = BigInt(Date.now());
    for (const [key, tag] of peer.tags.entries()) {
        if (tag.expiry != null && tag.expiry < now) {
            continue;
        }
        tags.set(key, tag);
    }
    return {
        ...peer,
        id: peerId,
        addresses: peer.addresses.map(({ multiaddr: ma, isCertified }) => {
            return {
                multiaddr: multiaddr$1(ma),
                isCertified: isCertified ?? false
            };
        }),
        metadata: peer.metadata,
        peerRecordEnvelope: peer.peerRecordEnvelope ?? undefined,
        tags
    };
}

const NAMESPACE_COMMON = '/peers/';
function peerIdToDatastoreKey(peerId) {
    if (!isPeerId(peerId) || peerId.type == null) {
        throw new CodeError$3('Invalid PeerId', codes$1.ERR_INVALID_PARAMETERS);
    }
    const b32key = peerId.toCID().toString();
    return new Key(`${NAMESPACE_COMMON}${b32key}`);
}

async function dedupeFilterAndSortAddresses(peerId, filter, addresses) {
    const addressMap = new Map();
    for (const addr of addresses) {
        if (addr == null) {
            continue;
        }
        if (addr.multiaddr instanceof Uint8Array) {
            addr.multiaddr = multiaddr$1(addr.multiaddr);
        }
        if (!isMultiaddr$1(addr.multiaddr)) {
            throw new CodeError$3('Multiaddr was invalid', codes$1.ERR_INVALID_PARAMETERS);
        }
        if (!(await filter(peerId, addr.multiaddr))) {
            continue;
        }
        const isCertified = addr.isCertified ?? false;
        const maStr = addr.multiaddr.toString();
        const existingAddr = addressMap.get(maStr);
        if (existingAddr != null) {
            addr.isCertified = existingAddr.isCertified || isCertified;
        }
        else {
            addressMap.set(maStr, {
                multiaddr: addr.multiaddr,
                isCertified
            });
        }
    }
    return [...addressMap.values()]
        .sort((a, b) => {
        return a.multiaddr.toString().localeCompare(b.multiaddr.toString());
    })
        .map(({ isCertified, multiaddr }) => ({
        isCertified,
        multiaddr: multiaddr.bytes
    }));
}

async function toPeerPB(peerId, data, strategy, options) {
    if (data == null) {
        throw new CodeError$3('Invalid PeerData', codes$1.ERR_INVALID_PARAMETERS);
    }
    if (data.publicKey != null && peerId.publicKey != null && !equals$4(data.publicKey, peerId.publicKey)) {
        throw new CodeError$3('publicKey bytes do not match peer id publicKey bytes', codes$1.ERR_INVALID_PARAMETERS);
    }
    const existingPeer = options.existingPeer;
    if (existingPeer != null && !peerId.equals(existingPeer.id)) {
        throw new CodeError$3('peer id did not match existing peer id', codes$1.ERR_INVALID_PARAMETERS);
    }
    let addresses = existingPeer?.addresses ?? [];
    let protocols = new Set(existingPeer?.protocols ?? []);
    let metadata = existingPeer?.metadata ?? new Map();
    let tags = existingPeer?.tags ?? new Map();
    let peerRecordEnvelope = existingPeer?.peerRecordEnvelope;
    // when patching, we replace the original fields with passed values
    if (strategy === 'patch') {
        if (data.multiaddrs != null || data.addresses != null) {
            addresses = [];
            if (data.multiaddrs != null) {
                addresses.push(...data.multiaddrs.map(multiaddr => ({
                    isCertified: false,
                    multiaddr
                })));
            }
            if (data.addresses != null) {
                addresses.push(...data.addresses);
            }
        }
        if (data.protocols != null) {
            protocols = new Set(data.protocols);
        }
        if (data.metadata != null) {
            const metadataEntries = data.metadata instanceof Map ? [...data.metadata.entries()] : Object.entries(data.metadata);
            metadata = createSortedMap(metadataEntries, {
                validate: validateMetadata
            });
        }
        if (data.tags != null) {
            const tagsEntries = data.tags instanceof Map ? [...data.tags.entries()] : Object.entries(data.tags);
            tags = createSortedMap(tagsEntries, {
                validate: validateTag,
                map: mapTag
            });
        }
        if (data.peerRecordEnvelope != null) {
            peerRecordEnvelope = data.peerRecordEnvelope;
        }
    }
    // when merging, we join the original fields with passed values
    if (strategy === 'merge') {
        if (data.multiaddrs != null) {
            addresses.push(...data.multiaddrs.map(multiaddr => ({
                isCertified: false,
                multiaddr
            })));
        }
        if (data.addresses != null) {
            addresses.push(...data.addresses);
        }
        if (data.protocols != null) {
            protocols = new Set([...protocols, ...data.protocols]);
        }
        if (data.metadata != null) {
            const metadataEntries = data.metadata instanceof Map ? [...data.metadata.entries()] : Object.entries(data.metadata);
            for (const [key, value] of metadataEntries) {
                if (value == null) {
                    metadata.delete(key);
                }
                else {
                    metadata.set(key, value);
                }
            }
            metadata = createSortedMap([...metadata.entries()], {
                validate: validateMetadata
            });
        }
        if (data.tags != null) {
            const tagsEntries = data.tags instanceof Map ? [...data.tags.entries()] : Object.entries(data.tags);
            const mergedTags = new Map(tags);
            for (const [key, value] of tagsEntries) {
                if (value == null) {
                    mergedTags.delete(key);
                }
                else {
                    mergedTags.set(key, value);
                }
            }
            tags = createSortedMap([...mergedTags.entries()], {
                validate: validateTag,
                map: mapTag
            });
        }
        if (data.peerRecordEnvelope != null) {
            peerRecordEnvelope = data.peerRecordEnvelope;
        }
    }
    const output = {
        addresses: await dedupeFilterAndSortAddresses(peerId, options.addressFilter ?? (async () => true), addresses),
        protocols: [...protocols.values()].sort((a, b) => {
            return a.localeCompare(b);
        }),
        metadata,
        tags,
        publicKey: existingPeer?.id.publicKey ?? data.publicKey ?? peerId.publicKey,
        peerRecordEnvelope
    };
    // Ed25519 and secp256k1 have their public key embedded in them so no need to duplicate it
    if (peerId.type !== 'RSA') {
        delete output.publicKey;
    }
    return output;
}
/**
 * In JS maps are ordered by insertion order so create a new map with the
 * keys inserted in alphabetical order.
 */
function createSortedMap(entries, options) {
    const output = new Map();
    for (const [key, value] of entries) {
        if (value == null) {
            continue;
        }
        options.validate(key, value);
    }
    for (const [key, value] of entries.sort(([a], [b]) => {
        return a.localeCompare(b);
    })) {
        if (value != null) {
            output.set(key, options.map?.(key, value) ?? value);
        }
    }
    return output;
}
function validateMetadata(key, value) {
    if (typeof key !== 'string') {
        throw new CodeError$3('Metadata key must be a string', codes$1.ERR_INVALID_PARAMETERS);
    }
    if (!(value instanceof Uint8Array)) {
        throw new CodeError$3('Metadata value must be a Uint8Array', codes$1.ERR_INVALID_PARAMETERS);
    }
}
function validateTag(key, tag) {
    if (typeof key !== 'string') {
        throw new CodeError$3('Tag name must be a string', codes$1.ERR_INVALID_PARAMETERS);
    }
    if (tag.value != null) {
        if (parseInt(`${tag.value}`, 10) !== tag.value) {
            throw new CodeError$3('Tag value must be an integer', codes$1.ERR_INVALID_PARAMETERS);
        }
        if (tag.value < 0 || tag.value > 100) {
            throw new CodeError$3('Tag value must be between 0-100', codes$1.ERR_INVALID_PARAMETERS);
        }
    }
    if (tag.ttl != null) {
        if (parseInt(`${tag.ttl}`, 10) !== tag.ttl) {
            throw new CodeError$3('Tag ttl must be an integer', codes$1.ERR_INVALID_PARAMETERS);
        }
        if (tag.ttl < 0) {
            throw new CodeError$3('Tag ttl must be between greater than 0', codes$1.ERR_INVALID_PARAMETERS);
        }
    }
}
function mapTag(key, tag) {
    let expiry;
    if (tag.expiry != null) {
        expiry = tag.expiry;
    }
    if (tag.ttl != null) {
        expiry = BigInt(Date.now() + Number(tag.ttl));
    }
    return {
        value: tag.value ?? 0,
        expiry
    };
}

function decodePeer(key, value, cache) {
    // /peers/${peer-id-as-libp2p-key-cid-string-in-base-32}
    const base32Str = key.toString().split('/')[2];
    const buf = base32$1.decode(base32Str);
    const peerId = peerIdFromBytes(buf);
    const cached = cache.get(peerId);
    if (cached != null) {
        return cached;
    }
    const peer = bytesToPeer(peerId, value);
    cache.set(peerId, peer);
    return peer;
}
function mapQuery(query, cache) {
    if (query == null) {
        return {};
    }
    return {
        prefix: NAMESPACE_COMMON,
        filters: (query.filters ?? []).map(fn => ({ key, value }) => {
            return fn(decodePeer(key, value, cache));
        }),
        orders: (query.orders ?? []).map(fn => (a, b) => {
            return fn(decodePeer(a.key, a.value, cache), decodePeer(b.key, b.value, cache));
        })
    };
}
class PersistentStore {
    peerId;
    datastore;
    lock;
    addressFilter;
    constructor(components, init = {}) {
        this.peerId = components.peerId;
        this.datastore = components.datastore;
        this.addressFilter = init.addressFilter;
        this.lock = createMortice({
            name: 'peer-store',
            singleProcess: true
        });
    }
    async has(peerId) {
        return this.datastore.has(peerIdToDatastoreKey(peerId));
    }
    async delete(peerId) {
        if (this.peerId.equals(peerId)) {
            throw new CodeError$3('Cannot delete self peer', codes$1.ERR_INVALID_PARAMETERS);
        }
        await this.datastore.delete(peerIdToDatastoreKey(peerId));
    }
    async load(peerId) {
        const buf = await this.datastore.get(peerIdToDatastoreKey(peerId));
        return bytesToPeer(peerId, buf);
    }
    async save(peerId, data) {
        const { existingBuf, existingPeer } = await this.#findExistingPeer(peerId);
        const peerPb = await toPeerPB(peerId, data, 'patch', {
            addressFilter: this.addressFilter
        });
        return this.#saveIfDifferent(peerId, peerPb, existingBuf, existingPeer);
    }
    async patch(peerId, data) {
        const { existingBuf, existingPeer } = await this.#findExistingPeer(peerId);
        const peerPb = await toPeerPB(peerId, data, 'patch', {
            addressFilter: this.addressFilter,
            existingPeer
        });
        return this.#saveIfDifferent(peerId, peerPb, existingBuf, existingPeer);
    }
    async merge(peerId, data) {
        const { existingBuf, existingPeer } = await this.#findExistingPeer(peerId);
        const peerPb = await toPeerPB(peerId, data, 'merge', {
            addressFilter: this.addressFilter,
            existingPeer
        });
        return this.#saveIfDifferent(peerId, peerPb, existingBuf, existingPeer);
    }
    async *all(query) {
        const peerCache = new PeerMap();
        for await (const { key, value } of this.datastore.query(mapQuery(query ?? {}, peerCache))) {
            const peer = decodePeer(key, value, peerCache);
            if (peer.id.equals(this.peerId)) {
                // Skip self peer if present
                continue;
            }
            yield peer;
        }
    }
    async #findExistingPeer(peerId) {
        try {
            const existingBuf = await this.datastore.get(peerIdToDatastoreKey(peerId));
            const existingPeer = bytesToPeer(peerId, existingBuf);
            return {
                existingBuf,
                existingPeer
            };
        }
        catch (err) {
            if (err.code !== 'ERR_NOT_FOUND') {
                throw err;
            }
        }
        return {};
    }
    async #saveIfDifferent(peerId, peer, existingBuf, existingPeer) {
        const buf = Peer.encode(peer);
        if (existingBuf != null && equals$4(buf, existingBuf)) {
            return {
                peer: bytesToPeer(peerId, buf),
                previous: existingPeer,
                updated: false
            };
        }
        await this.datastore.put(peerIdToDatastoreKey(peerId), buf);
        return {
            peer: bytesToPeer(peerId, buf),
            previous: existingPeer,
            updated: true
        };
    }
}

const log$j = logger$1('libp2p:peer-store');
/**
 * An implementation of PeerStore that stores data in a Datastore
 */
class PersistentPeerStore {
    store;
    events;
    peerId;
    constructor(components, init = {}) {
        this.events = components.events;
        this.peerId = components.peerId;
        this.store = new PersistentStore(components, init);
    }
    async forEach(fn, query) {
        log$j.trace('forEach await read lock');
        const release = await this.store.lock.readLock();
        log$j.trace('forEach got read lock');
        try {
            for await (const peer of this.store.all(query)) {
                fn(peer);
            }
        }
        finally {
            log$j.trace('forEach release read lock');
            release();
        }
    }
    async all(query) {
        log$j.trace('all await read lock');
        const release = await this.store.lock.readLock();
        log$j.trace('all got read lock');
        try {
            return await all$1(this.store.all(query));
        }
        finally {
            log$j.trace('all release read lock');
            release();
        }
    }
    async delete(peerId) {
        log$j.trace('delete await write lock');
        const release = await this.store.lock.writeLock();
        log$j.trace('delete got write lock');
        try {
            await this.store.delete(peerId);
        }
        finally {
            log$j.trace('delete release write lock');
            release();
        }
    }
    async has(peerId) {
        log$j.trace('has await read lock');
        const release = await this.store.lock.readLock();
        log$j.trace('has got read lock');
        try {
            return await this.store.has(peerId);
        }
        finally {
            log$j.trace('has release read lock');
            release();
        }
    }
    async get(peerId) {
        log$j.trace('get await read lock');
        const release = await this.store.lock.readLock();
        log$j.trace('get got read lock');
        try {
            return await this.store.load(peerId);
        }
        finally {
            log$j.trace('get release read lock');
            release();
        }
    }
    async save(id, data) {
        log$j.trace('save await write lock');
        const release = await this.store.lock.writeLock();
        log$j.trace('save got write lock');
        try {
            const result = await this.store.save(id, data);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            log$j.trace('save release write lock');
            release();
        }
    }
    async patch(id, data) {
        log$j.trace('patch await write lock');
        const release = await this.store.lock.writeLock();
        log$j.trace('patch got write lock');
        try {
            const result = await this.store.patch(id, data);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            log$j.trace('patch release write lock');
            release();
        }
    }
    async merge(id, data) {
        log$j.trace('merge await write lock');
        const release = await this.store.lock.writeLock();
        log$j.trace('merge got write lock');
        try {
            const result = await this.store.merge(id, data);
            this.#emitIfUpdated(id, result);
            return result.peer;
        }
        finally {
            log$j.trace('merge release write lock');
            release();
        }
    }
    async consumePeerRecord(buf, expectedPeer) {
        const envelope = await RecordEnvelope.openAndCertify(buf, PeerRecord.DOMAIN);
        if (expectedPeer?.equals(envelope.peerId) === false) {
            log$j('envelope peer id was not the expected peer id - expected: %p received: %p', expectedPeer, envelope.peerId);
            return false;
        }
        const peerRecord = PeerRecord.createFromProtobuf(envelope.payload);
        let peer;
        try {
            peer = await this.get(envelope.peerId);
        }
        catch (err) {
            if (err.code !== 'ERR_NOT_FOUND') {
                throw err;
            }
        }
        // ensure seq is greater than, or equal to, the last received
        if (peer?.peerRecordEnvelope != null) {
            const storedEnvelope = await RecordEnvelope.createFromProtobuf(peer.peerRecordEnvelope);
            const storedRecord = PeerRecord.createFromProtobuf(storedEnvelope.payload);
            if (storedRecord.seqNumber >= peerRecord.seqNumber) {
                log$j('sequence number was lower or equal to existing sequence number - stored: %d received: %d', storedRecord.seqNumber, peerRecord.seqNumber);
                return false;
            }
        }
        await this.patch(peerRecord.peerId, {
            peerRecordEnvelope: buf,
            addresses: peerRecord.multiaddrs.map(multiaddr => ({
                isCertified: true,
                multiaddr
            }))
        });
        return true;
    }
    #emitIfUpdated(id, result) {
        if (!result.updated) {
            return;
        }
        if (this.peerId.equals(id)) {
            this.events.safeDispatchEvent('self:peer:update', { detail: result });
        }
        else {
            this.events.safeDispatchEvent('peer:update', { detail: result });
        }
    }
}

function isAsyncIterable$6(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function drain(source) {
    if (isAsyncIterable$6(source)) {
        return (async () => {
            for await (const _ of source) { } // eslint-disable-line no-unused-vars,no-empty,@typescript-eslint/no-unused-vars
        })();
    }
    else {
        for (const _ of source) { } // eslint-disable-line no-unused-vars,no-empty,@typescript-eslint/no-unused-vars
    }
}

function peekable(iterable) {
    // @ts-expect-error can't use Symbol.asyncIterator to index iterable since it might be Iterable
    const [iterator, symbol] = iterable[Symbol.asyncIterator] != null
        // @ts-expect-error can't use Symbol.asyncIterator to index iterable since it might be Iterable
        ? [iterable[Symbol.asyncIterator](), Symbol.asyncIterator]
        // @ts-expect-error can't use Symbol.iterator to index iterable since it might be AsyncIterable
        : [iterable[Symbol.iterator](), Symbol.iterator];
    const queue = [];
    // @ts-expect-error can't use symbol to index peekable
    return {
        peek: () => {
            return iterator.next();
        },
        push: (value) => {
            queue.push(value);
        },
        next: () => {
            if (queue.length > 0) {
                return {
                    done: false,
                    value: queue.shift()
                };
            }
            return iterator.next();
        },
        [symbol]() {
            return this;
        }
    };
}

function isAsyncIterable$5(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function filter$1(source, fn) {
    if (isAsyncIterable$5(source)) {
        return (async function* () {
            for await (const entry of source) {
                if (await fn(entry)) {
                    yield entry;
                }
            }
        })();
    }
    // if mapping function returns a promise we have to return an async generator
    const peekable$1 = peekable(source);
    const { value, done } = peekable$1.next();
    if (done === true) {
        return (function* () { }());
    }
    const res = fn(value);
    // @ts-expect-error .then is not present on O
    if (typeof res.then === 'function') {
        return (async function* () {
            if (await res) {
                yield value;
            }
            for await (const entry of peekable$1) {
                if (await fn(entry)) {
                    yield entry;
                }
            }
        })();
    }
    const func = fn;
    return (function* () {
        if (res === true) {
            yield value;
        }
        for (const entry of peekable$1) {
            if (func(entry)) {
                yield entry;
            }
        }
    })();
}

function isAsyncIterable$4(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function sort(source, sorter) {
    if (isAsyncIterable$4(source)) {
        return (async function* () {
            const arr = await all$1(source);
            yield* arr.sort(sorter);
        })();
    }
    return (function* () {
        const arr = all$1(source);
        yield* arr.sort(sorter);
    })();
}

function isAsyncIterable$3(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function take(source, limit) {
    if (isAsyncIterable$3(source)) {
        return (async function* () {
            let items = 0;
            if (limit < 1) {
                return;
            }
            for await (const entry of source) {
                yield entry;
                items++;
                if (items === limit) {
                    return;
                }
            }
        })();
    }
    return (function* () {
        let items = 0;
        if (limit < 1) {
            return;
        }
        for (const entry of source) {
            yield entry;
            items++;
            if (items === limit) {
                return;
            }
        }
    })();
}

class BaseDatastore {
    put(key, val, options) {
        return Promise.reject(new Error('.put is not implemented'));
    }
    get(key, options) {
        return Promise.reject(new Error('.get is not implemented'));
    }
    has(key, options) {
        return Promise.reject(new Error('.has is not implemented'));
    }
    delete(key, options) {
        return Promise.reject(new Error('.delete is not implemented'));
    }
    async *putMany(source, options = {}) {
        for await (const { key, value } of source) {
            await this.put(key, value, options);
            yield key;
        }
    }
    async *getMany(source, options = {}) {
        for await (const key of source) {
            yield {
                key,
                value: await this.get(key, options)
            };
        }
    }
    async *deleteMany(source, options = {}) {
        for await (const key of source) {
            await this.delete(key, options);
            yield key;
        }
    }
    batch() {
        let puts = [];
        let dels = [];
        return {
            put(key, value) {
                puts.push({ key, value });
            },
            delete(key) {
                dels.push(key);
            },
            commit: async (options) => {
                await drain(this.putMany(puts, options));
                puts = [];
                await drain(this.deleteMany(dels, options));
                dels = [];
            }
        };
    }
    /**
     * Extending classes should override `query` or implement this method
     */
    // eslint-disable-next-line require-yield
    async *_all(q, options) {
        throw new Error('._all is not implemented');
    }
    /**
     * Extending classes should override `queryKeys` or implement this method
     */
    // eslint-disable-next-line require-yield
    async *_allKeys(q, options) {
        throw new Error('._allKeys is not implemented');
    }
    query(q, options) {
        let it = this._all(q, options);
        if (q.prefix != null) {
            const prefix = q.prefix;
            it = filter$1(it, (e) => e.key.toString().startsWith(prefix));
        }
        if (Array.isArray(q.filters)) {
            it = q.filters.reduce((it, f) => filter$1(it, f), it);
        }
        if (Array.isArray(q.orders)) {
            it = q.orders.reduce((it, f) => sort(it, f), it);
        }
        if (q.offset != null) {
            let i = 0;
            const offset = q.offset;
            it = filter$1(it, () => i++ >= offset);
        }
        if (q.limit != null) {
            it = take(it, q.limit);
        }
        return it;
    }
    queryKeys(q, options) {
        let it = this._allKeys(q, options);
        if (q.prefix != null) {
            const prefix = q.prefix;
            it = filter$1(it, (key) => key.toString().startsWith(prefix));
        }
        if (Array.isArray(q.filters)) {
            it = q.filters.reduce((it, f) => filter$1(it, f), it);
        }
        if (Array.isArray(q.orders)) {
            it = q.orders.reduce((it, f) => sort(it, f), it);
        }
        if (q.offset != null) {
            const offset = q.offset;
            let i = 0;
            it = filter$1(it, () => i++ >= offset);
        }
        if (q.limit != null) {
            it = take(it, q.limit);
        }
        return it;
    }
}

function notFoundError(err) {
    err = err ?? new Error('Not Found');
    return errCode$1(err, 'ERR_NOT_FOUND');
}

class MemoryDatastore extends BaseDatastore {
    data;
    constructor() {
        super();
        this.data = new Map();
    }
    put(key, val) {
        this.data.set(key.toString(), val);
        return key;
    }
    get(key) {
        const result = this.data.get(key.toString());
        if (result == null) {
            throw notFoundError();
        }
        return result;
    }
    has(key) {
        return this.data.has(key.toString());
    }
    delete(key) {
        this.data.delete(key.toString());
    }
    *_all() {
        for (const [key, value] of this.data.entries()) {
            yield { key: new Key(key), value };
        }
    }
    *_allKeys() {
        for (const key of this.data.keys()) {
            yield new Key(key);
        }
    }
}

function debounce(func, wait) {
    let timeout;
    return function () {
        const later = function () {
            timeout = undefined;
            func();
        };
        clearTimeout(timeout);
        timeout = setTimeout(later, wait);
    };
}

const log$i = logger$2('libp2p:address-manager');
const defaultAddressFilter = (addrs) => addrs;
/**
 * If the passed multiaddr contains the passed peer id, remove it
 */
function stripPeerId(ma, peerId) {
    const observedPeerIdStr = ma.getPeerId();
    // strip our peer id if it has been passed
    if (observedPeerIdStr != null) {
        const observedPeerId = peerIdFromString(observedPeerIdStr);
        // use same encoding for comparison
        if (observedPeerId.equals(peerId)) {
            ma = ma.decapsulate(multiaddr$1(`/p2p/${peerId.toString()}`));
        }
    }
    return ma;
}
class DefaultAddressManager {
    components;
    // this is an array to allow for duplicates, e.g. multiples of `/ip4/0.0.0.0/tcp/0`
    listen;
    announce;
    observed;
    announceFilter;
    /**
     * Responsible for managing the peer addresses.
     * Peers can specify their listen and announce addresses.
     * The listen addresses will be used by the libp2p transports to listen for new connections,
     * while the announce addresses will be used for the peer addresses' to other peers in the network.
     */
    constructor(components, init = {}) {
        const { listen = [], announce = [] } = init;
        this.components = components;
        this.listen = listen.map(ma => ma.toString());
        this.announce = new Set(announce.map(ma => ma.toString()));
        this.observed = new Map();
        this.announceFilter = init.announceFilter ?? defaultAddressFilter;
        // this method gets called repeatedly on startup when transports start listening so
        // debounce it so we don't cause multiple self:peer:update events to be emitted
        this._updatePeerStoreAddresses = debounce(this._updatePeerStoreAddresses.bind(this), 1000);
        // update our stored addresses when new transports listen
        components.events.addEventListener('transport:listening', () => {
            this._updatePeerStoreAddresses();
        });
        // update our stored addresses when existing transports stop listening
        components.events.addEventListener('transport:close', () => {
            this._updatePeerStoreAddresses();
        });
    }
    _updatePeerStoreAddresses() {
        // if announce addresses have been configured, ensure they make it into our peer
        // record for things like identify
        const addrs = this.getAnnounceAddrs()
            .concat(this.components.transportManager.getAddrs())
            .concat([...this.observed.entries()]
            .filter(([_, metadata]) => metadata.confident)
            .map(([str]) => multiaddr$1(str))).map(ma => {
            // strip our peer id if it is present
            if (ma.getPeerId() === this.components.peerId.toString()) {
                return ma.decapsulate(`/p2p/${this.components.peerId.toString()}`);
            }
            return ma;
        });
        this.components.peerStore.patch(this.components.peerId, {
            multiaddrs: addrs
        })
            .catch(err => { log$i.error('error updating addresses', err); });
    }
    /**
     * Get peer listen multiaddrs
     */
    getListenAddrs() {
        return Array.from(this.listen).map((a) => multiaddr$1(a));
    }
    /**
     * Get peer announcing multiaddrs
     */
    getAnnounceAddrs() {
        return Array.from(this.announce).map((a) => multiaddr$1(a));
    }
    /**
     * Get observed multiaddrs
     */
    getObservedAddrs() {
        return Array.from(this.observed).map(([a]) => multiaddr$1(a));
    }
    /**
     * Add peer observed addresses
     */
    addObservedAddr(addr) {
        addr = stripPeerId(addr, this.components.peerId);
        const addrString = addr.toString();
        // do not trigger the change:addresses event if we already know about this address
        if (this.observed.has(addrString)) {
            return;
        }
        this.observed.set(addrString, {
            confident: false
        });
    }
    confirmObservedAddr(addr) {
        addr = stripPeerId(addr, this.components.peerId);
        const addrString = addr.toString();
        const metadata = this.observed.get(addrString) ?? {
            confident: false
        };
        const startingConfidence = metadata.confident;
        this.observed.set(addrString, {
            confident: true
        });
        // only trigger the 'self:peer:update' event if our confidence in an address has changed
        if (!startingConfidence) {
            this._updatePeerStoreAddresses();
        }
    }
    removeObservedAddr(addr) {
        addr = stripPeerId(addr, this.components.peerId);
        const addrString = addr.toString();
        this.observed.delete(addrString);
    }
    getAddresses() {
        let addrs = this.getAnnounceAddrs().map(ma => ma.toString());
        if (addrs.length === 0) {
            // no configured announce addrs, add configured listen addresses
            addrs = this.components.transportManager.getAddrs().map(ma => ma.toString());
        }
        // add observed addresses we are confident in
        addrs = addrs.concat(Array.from(this.observed)
            .filter(([ma, metadata]) => metadata.confident)
            .map(([ma]) => ma));
        // dedupe multiaddrs
        const addrSet = new Set(addrs);
        // Create advertising list
        return this.announceFilter(Array.from(addrSet)
            .map(str => multiaddr$1(str)))
            .map(ma => {
            // do not append our peer id to a path multiaddr as it will become invalid
            if (ma.protos().pop()?.path === true) {
                return ma;
            }
            if (ma.getPeerId() === this.components.peerId.toString()) {
                return ma;
            }
            return ma.encapsulate(`/p2p/${this.components.peerId.toString()}`);
        });
    }
}

function isStartable(obj) {
    return obj != null && typeof obj.start === 'function' && typeof obj.stop === 'function';
}

class DefaultComponents {
    components = {};
    _started = false;
    constructor(init = {}) {
        this.components = {};
        for (const [key, value] of Object.entries(init)) {
            this.components[key] = value;
        }
    }
    isStarted() {
        return this._started;
    }
    async _invokeStartableMethod(methodName) {
        await Promise.all(Object.values(this.components)
            .filter(obj => isStartable(obj))
            .map(async (startable) => {
            await startable[methodName]?.();
        }));
    }
    async beforeStart() {
        await this._invokeStartableMethod('beforeStart');
    }
    async start() {
        await this._invokeStartableMethod('start');
        this._started = true;
    }
    async afterStart() {
        await this._invokeStartableMethod('afterStart');
    }
    async beforeStop() {
        await this._invokeStartableMethod('beforeStop');
    }
    async stop() {
        await this._invokeStartableMethod('stop');
        this._started = false;
    }
    async afterStop() {
        await this._invokeStartableMethod('afterStop');
    }
}
const OPTIONAL_SERVICES = [
    'metrics',
    'connectionProtector'
];
const NON_SERVICE_PROPERTIES = [
    'components',
    'isStarted',
    'beforeStart',
    'start',
    'afterStart',
    'beforeStop',
    'stop',
    'afterStop',
    'then',
    '_invokeStartableMethod'
];
function defaultComponents(init = {}) {
    const components = new DefaultComponents(init);
    const proxy = new Proxy(components, {
        get(target, prop, receiver) {
            if (typeof prop === 'string' && !NON_SERVICE_PROPERTIES.includes(prop)) {
                const service = components.components[prop];
                if (service == null && !OPTIONAL_SERVICES.includes(prop)) {
                    throw new CodeError$3(`${prop} not set`, 'ERR_SERVICE_MISSING');
                }
                return service;
            }
            return Reflect.get(target, prop, receiver);
        },
        set(target, prop, value) {
            if (typeof prop === 'string') {
                components.components[prop] = value;
            }
            else {
                Reflect.set(target, prop, value);
            }
            return true;
        }
    });
    // @ts-expect-error component keys are proxied
    return proxy;
}

var Netmask_1;
// Generated by CoffeeScript 1.12.7
(function() {
  var Netmask, atob, chr, chr0, chrA, chra, ip2long, long2ip;

  long2ip = function(long) {
    var a, b, c, d;
    a = (long & (0xff << 24)) >>> 24;
    b = (long & (0xff << 16)) >>> 16;
    c = (long & (0xff << 8)) >>> 8;
    d = long & 0xff;
    return [a, b, c, d].join('.');
  };

  ip2long = function(ip) {
    var b, c, i, j, n, ref;
    b = [];
    for (i = j = 0; j <= 3; i = ++j) {
      if (ip.length === 0) {
        break;
      }
      if (i > 0) {
        if (ip[0] !== '.') {
          throw new Error('Invalid IP');
        }
        ip = ip.substring(1);
      }
      ref = atob(ip), n = ref[0], c = ref[1];
      ip = ip.substring(c);
      b.push(n);
    }
    if (ip.length !== 0) {
      throw new Error('Invalid IP');
    }
    switch (b.length) {
      case 1:
        if (b[0] > 0xFFFFFFFF) {
          throw new Error('Invalid IP');
        }
        return b[0] >>> 0;
      case 2:
        if (b[0] > 0xFF || b[1] > 0xFFFFFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1]) >>> 0;
      case 3:
        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFFFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1] << 16 | b[2]) >>> 0;
      case 4:
        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFF || b[3] > 0xFF) {
          throw new Error('Invalid IP');
        }
        return (b[0] << 24 | b[1] << 16 | b[2] << 8 | b[3]) >>> 0;
      default:
        throw new Error('Invalid IP');
    }
  };

  chr = function(b) {
    return b.charCodeAt(0);
  };

  chr0 = chr('0');

  chra = chr('a');

  chrA = chr('A');

  atob = function(s) {
    var base, dmax, i, n, start;
    n = 0;
    base = 10;
    dmax = '9';
    i = 0;
    if (s.length > 1 && s[i] === '0') {
      if (s[i + 1] === 'x' || s[i + 1] === 'X') {
        i += 2;
        base = 16;
      } else if ('0' <= s[i + 1] && s[i + 1] <= '9') {
        i++;
        base = 8;
        dmax = '7';
      }
    }
    start = i;
    while (i < s.length) {
      if ('0' <= s[i] && s[i] <= dmax) {
        n = (n * base + (chr(s[i]) - chr0)) >>> 0;
      } else if (base === 16) {
        if ('a' <= s[i] && s[i] <= 'f') {
          n = (n * base + (10 + chr(s[i]) - chra)) >>> 0;
        } else if ('A' <= s[i] && s[i] <= 'F') {
          n = (n * base + (10 + chr(s[i]) - chrA)) >>> 0;
        } else {
          break;
        }
      } else {
        break;
      }
      if (n > 0xFFFFFFFF) {
        throw new Error('too large');
      }
      i++;
    }
    if (i === start) {
      throw new Error('empty octet');
    }
    return [n, i];
  };

  Netmask = (function() {
    function Netmask(net, mask) {
      var i, j, ref;
      if (typeof net !== 'string') {
        throw new Error("Missing `net' parameter");
      }
      if (!mask) {
        ref = net.split('/', 2), net = ref[0], mask = ref[1];
      }
      if (!mask) {
        mask = 32;
      }
      if (typeof mask === 'string' && mask.indexOf('.') > -1) {
        try {
          this.maskLong = ip2long(mask);
        } catch (error1) {
          throw new Error("Invalid mask: " + mask);
        }
        for (i = j = 32; j >= 0; i = --j) {
          if (this.maskLong === (0xffffffff << (32 - i)) >>> 0) {
            this.bitmask = i;
            break;
          }
        }
      } else if (mask || mask === 0) {
        this.bitmask = parseInt(mask, 10);
        this.maskLong = 0;
        if (this.bitmask > 0) {
          this.maskLong = (0xffffffff << (32 - this.bitmask)) >>> 0;
        }
      } else {
        throw new Error("Invalid mask: empty");
      }
      try {
        this.netLong = (ip2long(net) & this.maskLong) >>> 0;
      } catch (error1) {
        throw new Error("Invalid net address: " + net);
      }
      if (!(this.bitmask <= 32)) {
        throw new Error("Invalid mask for ip4: " + mask);
      }
      this.size = Math.pow(2, 32 - this.bitmask);
      this.base = long2ip(this.netLong);
      this.mask = long2ip(this.maskLong);
      this.hostmask = long2ip(~this.maskLong);
      this.first = this.bitmask <= 30 ? long2ip(this.netLong + 1) : this.base;
      this.last = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 2) : long2ip(this.netLong + this.size - 1);
      this.broadcast = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 1) : void 0;
    }

    Netmask.prototype.contains = function(ip) {
      if (typeof ip === 'string' && (ip.indexOf('/') > 0 || ip.split('.').length !== 4)) {
        ip = new Netmask(ip);
      }
      if (ip instanceof Netmask) {
        return this.contains(ip.base) && this.contains(ip.broadcast || ip.last);
      } else {
        return (ip2long(ip) & this.maskLong) >>> 0 === (this.netLong & this.maskLong) >>> 0;
      }
    };

    Netmask.prototype.next = function(count) {
      if (count == null) {
        count = 1;
      }
      return new Netmask(long2ip(this.netLong + (this.size * count)), this.mask);
    };

    Netmask.prototype.forEach = function(fn) {
      var index, lastLong, long;
      long = ip2long(this.first);
      lastLong = ip2long(this.last);
      index = 0;
      while (long <= lastLong) {
        fn(long2ip(long), long, index);
        index++;
        long++;
      }
    };

    Netmask.prototype.toString = function() {
      return this.base + "/" + this.bitmask;
    };

    return Netmask;

  })();

  Netmask_1 = Netmask;

}).call(commonjsGlobal);

const word = '[a-fA-F\\d:]';

const boundry = options => options && options.includeBoundaries
	? `(?:(?<=\\s|^)(?=${word})|(?<=${word})(?=\\s|$))`
	: '';

const v4 = '(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]\\d|\\d)(?:\\.(?:25[0-5]|2[0-4]\\d|1\\d\\d|[1-9]\\d|\\d)){3}';

const v6segment = '[a-fA-F\\d]{1,4}';

const v6 = `
(?:
(?:${v6segment}:){7}(?:${v6segment}|:)|                                    // 1:2:3:4:5:6:7::  1:2:3:4:5:6:7:8
(?:${v6segment}:){6}(?:${v4}|:${v6segment}|:)|                             // 1:2:3:4:5:6::    1:2:3:4:5:6::8   1:2:3:4:5:6::8  1:2:3:4:5:6::1.2.3.4
(?:${v6segment}:){5}(?::${v4}|(?::${v6segment}){1,2}|:)|                   // 1:2:3:4:5::      1:2:3:4:5::7:8   1:2:3:4:5::8    1:2:3:4:5::7:1.2.3.4
(?:${v6segment}:){4}(?:(?::${v6segment}){0,1}:${v4}|(?::${v6segment}){1,3}|:)| // 1:2:3:4::        1:2:3:4::6:7:8   1:2:3:4::8      1:2:3:4::6:7:1.2.3.4
(?:${v6segment}:){3}(?:(?::${v6segment}){0,2}:${v4}|(?::${v6segment}){1,4}|:)| // 1:2:3::          1:2:3::5:6:7:8   1:2:3::8        1:2:3::5:6:7:1.2.3.4
(?:${v6segment}:){2}(?:(?::${v6segment}){0,3}:${v4}|(?::${v6segment}){1,5}|:)| // 1:2::            1:2::4:5:6:7:8   1:2::8          1:2::4:5:6:7:1.2.3.4
(?:${v6segment}:){1}(?:(?::${v6segment}){0,4}:${v4}|(?::${v6segment}){1,6}|:)| // 1::              1::3:4:5:6:7:8   1::8            1::3:4:5:6:7:1.2.3.4
(?::(?:(?::${v6segment}){0,5}:${v4}|(?::${v6segment}){1,7}|:))             // ::2:3:4:5:6:7:8  ::2:3:4:5:6:7:8  ::8             ::1.2.3.4
)(?:%[0-9a-zA-Z]{1,})?                                             // %eth0            %1
`.replace(/\s*\/\/.*$/gm, '').replace(/\n/g, '').trim();

// Pre-compile only the exact regexes because adding a global flag make regexes stateful
const v46Exact = new RegExp(`(?:^${v4}$)|(?:^${v6}$)`);
const v4exact = new RegExp(`^${v4}$`);
const v6exact = new RegExp(`^${v6}$`);

const ipRegex = options => options && options.exact
	? v46Exact
	: new RegExp(`(?:${boundry(options)}${v4}${boundry(options)})|(?:${boundry(options)}${v6}${boundry(options)})`, 'g');

ipRegex.v4 = options => options && options.exact ? v4exact : new RegExp(`${boundry(options)}${v4}${boundry(options)}`, 'g');
ipRegex.v6 = options => options && options.exact ? v6exact : new RegExp(`${boundry(options)}${v6}${boundry(options)}`, 'g');

var ipaddr$1 = {exports: {}};

(function (module) {
	(function (root) {
	    // A list of regular expressions that match arbitrary IPv4 addresses,
	    // for which a number of weird notations exist.
	    // Note that an address like 0010.0xa5.1.1 is considered legal.
	    const ipv4Part = '(0?\\d+|0x[a-f0-9]+)';
	    const ipv4Regexes = {
	        fourOctet: new RegExp(`^${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}$`, 'i'),
	        threeOctet: new RegExp(`^${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}$`, 'i'),
	        twoOctet: new RegExp(`^${ipv4Part}\\.${ipv4Part}$`, 'i'),
	        longValue: new RegExp(`^${ipv4Part}$`, 'i')
	    };

	    // Regular Expression for checking Octal numbers
	    const octalRegex = new RegExp(`^0[0-7]+$`, 'i');
	    const hexRegex = new RegExp(`^0x[a-f0-9]+$`, 'i');

	    const zoneIndex = '%[0-9a-z]{1,}';

	    // IPv6-matching regular expressions.
	    // For IPv6, the task is simpler: it is enough to match the colon-delimited
	    // hexadecimal IPv6 and a transitional variant with dotted-decimal IPv4 at
	    // the end.
	    const ipv6Part = '(?:[0-9a-f]+::?)+';
	    const ipv6Regexes = {
	        zoneIndex: new RegExp(zoneIndex, 'i'),
	        'native': new RegExp(`^(::)?(${ipv6Part})?([0-9a-f]+)?(::)?(${zoneIndex})?$`, 'i'),
	        deprecatedTransitional: new RegExp(`^(?:::)(${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}(${zoneIndex})?)$`, 'i'),
	        transitional: new RegExp(`^((?:${ipv6Part})|(?:::)(?:${ipv6Part})?)${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}\\.${ipv4Part}(${zoneIndex})?$`, 'i')
	    };

	    // Expand :: in an IPv6 address or address part consisting of `parts` groups.
	    function expandIPv6 (string, parts) {
	        // More than one '::' means invalid adddress
	        if (string.indexOf('::') !== string.lastIndexOf('::')) {
	            return null;
	        }

	        let colonCount = 0;
	        let lastColon = -1;
	        let zoneId = (string.match(ipv6Regexes.zoneIndex) || [])[0];
	        let replacement, replacementCount;

	        // Remove zone index and save it for later
	        if (zoneId) {
	            zoneId = zoneId.substring(1);
	            string = string.replace(/%.+$/, '');
	        }

	        // How many parts do we already have?
	        while ((lastColon = string.indexOf(':', lastColon + 1)) >= 0) {
	            colonCount++;
	        }

	        // 0::0 is two parts more than ::
	        if (string.substr(0, 2) === '::') {
	            colonCount--;
	        }

	        if (string.substr(-2, 2) === '::') {
	            colonCount--;
	        }

	        // The following loop would hang if colonCount > parts
	        if (colonCount > parts) {
	            return null;
	        }

	        // replacement = ':' + '0:' * (parts - colonCount)
	        replacementCount = parts - colonCount;
	        replacement = ':';
	        while (replacementCount--) {
	            replacement += '0:';
	        }

	        // Insert the missing zeroes
	        string = string.replace('::', replacement);

	        // Trim any garbage which may be hanging around if :: was at the edge in
	        // the source strin
	        if (string[0] === ':') {
	            string = string.slice(1);
	        }

	        if (string[string.length - 1] === ':') {
	            string = string.slice(0, -1);
	        }

	        parts = (function () {
	            const ref = string.split(':');
	            const results = [];

	            for (let i = 0; i < ref.length; i++) {
	                results.push(parseInt(ref[i], 16));
	            }

	            return results;
	        })();

	        return {
	            parts: parts,
	            zoneId: zoneId
	        };
	    }

	    // A generic CIDR (Classless Inter-Domain Routing) RFC1518 range matcher.
	    function matchCIDR (first, second, partSize, cidrBits) {
	        if (first.length !== second.length) {
	            throw new Error('ipaddr: cannot match CIDR for objects with different lengths');
	        }

	        let part = 0;
	        let shift;

	        while (cidrBits > 0) {
	            shift = partSize - cidrBits;
	            if (shift < 0) {
	                shift = 0;
	            }

	            if (first[part] >> shift !== second[part] >> shift) {
	                return false;
	            }

	            cidrBits -= partSize;
	            part += 1;
	        }

	        return true;
	    }

	    function parseIntAuto (string) {
	        // Hexadedimal base 16 (0x#)
	        if (hexRegex.test(string)) {
	            return parseInt(string, 16);
	        }
	        // While octal representation is discouraged by ECMAScript 3
	        // and forbidden by ECMAScript 5, we silently allow it to
	        // work only if the rest of the string has numbers less than 8.
	        if (string[0] === '0' && !isNaN(parseInt(string[1], 10))) {
	        if (octalRegex.test(string)) {
	            return parseInt(string, 8);
	        }
	            throw new Error(`ipaddr: cannot parse ${string} as octal`);
	        }
	        // Always include the base 10 radix!
	        return parseInt(string, 10);
	    }

	    function padPart (part, length) {
	        while (part.length < length) {
	            part = `0${part}`;
	        }

	        return part;
	    }

	    const ipaddr = {};

	    // An IPv4 address (RFC791).
	    ipaddr.IPv4 = (function () {
	        // Constructs a new IPv4 address from an array of four octets
	        // in network order (MSB first)
	        // Verifies the input.
	        function IPv4 (octets) {
	            if (octets.length !== 4) {
	                throw new Error('ipaddr: ipv4 octet count should be 4');
	            }

	            let i, octet;

	            for (i = 0; i < octets.length; i++) {
	                octet = octets[i];
	                if (!((0 <= octet && octet <= 255))) {
	                    throw new Error('ipaddr: ipv4 octet should fit in 8 bits');
	                }
	            }

	            this.octets = octets;
	        }

	        // Special IPv4 address ranges.
	        // See also https://en.wikipedia.org/wiki/Reserved_IP_addresses
	        IPv4.prototype.SpecialRanges = {
	            unspecified: [[new IPv4([0, 0, 0, 0]), 8]],
	            broadcast: [[new IPv4([255, 255, 255, 255]), 32]],
	            // RFC3171
	            multicast: [[new IPv4([224, 0, 0, 0]), 4]],
	            // RFC3927
	            linkLocal: [[new IPv4([169, 254, 0, 0]), 16]],
	            // RFC5735
	            loopback: [[new IPv4([127, 0, 0, 0]), 8]],
	            // RFC6598
	            carrierGradeNat: [[new IPv4([100, 64, 0, 0]), 10]],
	            // RFC1918
	            'private': [
	                [new IPv4([10, 0, 0, 0]), 8],
	                [new IPv4([172, 16, 0, 0]), 12],
	                [new IPv4([192, 168, 0, 0]), 16]
	            ],
	            // Reserved and testing-only ranges; RFCs 5735, 5737, 2544, 1700
	            reserved: [
	                [new IPv4([192, 0, 0, 0]), 24],
	                [new IPv4([192, 0, 2, 0]), 24],
	                [new IPv4([192, 88, 99, 0]), 24],
	                [new IPv4([198, 51, 100, 0]), 24],
	                [new IPv4([203, 0, 113, 0]), 24],
	                [new IPv4([240, 0, 0, 0]), 4]
	            ]
	        };

	        // The 'kind' method exists on both IPv4 and IPv6 classes.
	        IPv4.prototype.kind = function () {
	            return 'ipv4';
	        };

	        // Checks if this address matches other one within given CIDR range.
	        IPv4.prototype.match = function (other, cidrRange) {
	            let ref;
	            if (cidrRange === undefined) {
	                ref = other;
	                other = ref[0];
	                cidrRange = ref[1];
	            }

	            if (other.kind() !== 'ipv4') {
	                throw new Error('ipaddr: cannot match ipv4 address with non-ipv4 one');
	            }

	            return matchCIDR(this.octets, other.octets, 8, cidrRange);
	        };

	        // returns a number of leading ones in IPv4 address, making sure that
	        // the rest is a solid sequence of 0's (valid netmask)
	        // returns either the CIDR length or null if mask is not valid
	        IPv4.prototype.prefixLengthFromSubnetMask = function () {
	            let cidr = 0;
	            // non-zero encountered stop scanning for zeroes
	            let stop = false;
	            // number of zeroes in octet
	            const zerotable = {
	                0: 8,
	                128: 7,
	                192: 6,
	                224: 5,
	                240: 4,
	                248: 3,
	                252: 2,
	                254: 1,
	                255: 0
	            };
	            let i, octet, zeros;

	            for (i = 3; i >= 0; i -= 1) {
	                octet = this.octets[i];
	                if (octet in zerotable) {
	                    zeros = zerotable[octet];
	                    if (stop && zeros !== 0) {
	                        return null;
	                    }

	                    if (zeros !== 8) {
	                        stop = true;
	                    }

	                    cidr += zeros;
	                } else {
	                    return null;
	                }
	            }

	            return 32 - cidr;
	        };

	        // Checks if the address corresponds to one of the special ranges.
	        IPv4.prototype.range = function () {
	            return ipaddr.subnetMatch(this, this.SpecialRanges);
	        };

	        // Returns an array of byte-sized values in network order (MSB first)
	        IPv4.prototype.toByteArray = function () {
	            return this.octets.slice(0);
	        };

	        // Converts this IPv4 address to an IPv4-mapped IPv6 address.
	        IPv4.prototype.toIPv4MappedAddress = function () {
	            return ipaddr.IPv6.parse(`::ffff:${this.toString()}`);
	        };

	        // Symmetrical method strictly for aligning with the IPv6 methods.
	        IPv4.prototype.toNormalizedString = function () {
	            return this.toString();
	        };

	        // Returns the address in convenient, decimal-dotted format.
	        IPv4.prototype.toString = function () {
	            return this.octets.join('.');
	        };

	        return IPv4;
	    })();

	    // A utility function to return broadcast address given the IPv4 interface and prefix length in CIDR notation
	    ipaddr.IPv4.broadcastAddressFromCIDR = function (string) {

	        try {
	            const cidr = this.parseCIDR(string);
	            const ipInterfaceOctets = cidr[0].toByteArray();
	            const subnetMaskOctets = this.subnetMaskFromPrefixLength(cidr[1]).toByteArray();
	            const octets = [];
	            let i = 0;
	            while (i < 4) {
	                // Broadcast address is bitwise OR between ip interface and inverted mask
	                octets.push(parseInt(ipInterfaceOctets[i], 10) | parseInt(subnetMaskOctets[i], 10) ^ 255);
	                i++;
	            }

	            return new this(octets);
	        } catch (e) {
	            throw new Error('ipaddr: the address does not have IPv4 CIDR format');
	        }
	    };

	    // Checks if a given string is formatted like IPv4 address.
	    ipaddr.IPv4.isIPv4 = function (string) {
	        return this.parser(string) !== null;
	    };

	    // Checks if a given string is a valid IPv4 address.
	    ipaddr.IPv4.isValid = function (string) {
	        try {
	            new this(this.parser(string));
	            return true;
	        } catch (e) {
	            return false;
	        }
	    };

	    // Checks if a given string is a full four-part IPv4 Address.
	    ipaddr.IPv4.isValidFourPartDecimal = function (string) {
	        if (ipaddr.IPv4.isValid(string) && string.match(/^(0|[1-9]\d*)(\.(0|[1-9]\d*)){3}$/)) {
	            return true;
	        } else {
	            return false;
	        }
	    };

	    // A utility function to return network address given the IPv4 interface and prefix length in CIDR notation
	    ipaddr.IPv4.networkAddressFromCIDR = function (string) {
	        let cidr, i, ipInterfaceOctets, octets, subnetMaskOctets;

	        try {
	            cidr = this.parseCIDR(string);
	            ipInterfaceOctets = cidr[0].toByteArray();
	            subnetMaskOctets = this.subnetMaskFromPrefixLength(cidr[1]).toByteArray();
	            octets = [];
	            i = 0;
	            while (i < 4) {
	                // Network address is bitwise AND between ip interface and mask
	                octets.push(parseInt(ipInterfaceOctets[i], 10) & parseInt(subnetMaskOctets[i], 10));
	                i++;
	            }

	            return new this(octets);
	        } catch (e) {
	            throw new Error('ipaddr: the address does not have IPv4 CIDR format');
	        }
	    };

	    // Tries to parse and validate a string with IPv4 address.
	    // Throws an error if it fails.
	    ipaddr.IPv4.parse = function (string) {
	        const parts = this.parser(string);

	        if (parts === null) {
	            throw new Error('ipaddr: string is not formatted like an IPv4 Address');
	        }

	        return new this(parts);
	    };

	    // Parses the string as an IPv4 Address with CIDR Notation.
	    ipaddr.IPv4.parseCIDR = function (string) {
	        let match;

	        if ((match = string.match(/^(.+)\/(\d+)$/))) {
	            const maskLength = parseInt(match[2]);
	            if (maskLength >= 0 && maskLength <= 32) {
	                const parsed = [this.parse(match[1]), maskLength];
	                Object.defineProperty(parsed, 'toString', {
	                    value: function () {
	                        return this.join('/');
	                    }
	                });
	                return parsed;
	            }
	        }

	        throw new Error('ipaddr: string is not formatted like an IPv4 CIDR range');
	    };

	    // Classful variants (like a.b, where a is an octet, and b is a 24-bit
	    // value representing last three octets; this corresponds to a class C
	    // address) are omitted due to classless nature of modern Internet.
	    ipaddr.IPv4.parser = function (string) {
	        let match, part, value;

	        // parseInt recognizes all that octal & hexadecimal weirdness for us
	        if ((match = string.match(ipv4Regexes.fourOctet))) {
	            return (function () {
	                const ref = match.slice(1, 6);
	                const results = [];

	                for (let i = 0; i < ref.length; i++) {
	                    part = ref[i];
	                    results.push(parseIntAuto(part));
	                }

	                return results;
	            })();
	        } else if ((match = string.match(ipv4Regexes.longValue))) {
	            value = parseIntAuto(match[1]);
	            if (value > 0xffffffff || value < 0) {
	                throw new Error('ipaddr: address outside defined range');
	            }

	            return ((function () {
	                const results = [];
	                let shift;

	                for (shift = 0; shift <= 24; shift += 8) {
	                    results.push((value >> shift) & 0xff);
	                }

	                return results;
	            })()).reverse();
	        } else if ((match = string.match(ipv4Regexes.twoOctet))) {
	            return (function () {
	                const ref = match.slice(1, 4);
	                const results = [];

	                value = parseIntAuto(ref[1]);
	                if (value > 0xffffff || value < 0) {
	                    throw new Error('ipaddr: address outside defined range');
	                }

	                results.push(parseIntAuto(ref[0]));
	                results.push((value >> 16) & 0xff);
	                results.push((value >>  8) & 0xff);
	                results.push( value        & 0xff);

	                return results;
	            })();
	        } else if ((match = string.match(ipv4Regexes.threeOctet))) {
	            return (function () {
	                const ref = match.slice(1, 5);
	                const results = [];

	                value = parseIntAuto(ref[2]);
	                if (value > 0xffff || value < 0) {
	                    throw new Error('ipaddr: address outside defined range');
	                }

	                results.push(parseIntAuto(ref[0]));
	                results.push(parseIntAuto(ref[1]));
	                results.push((value >> 8) & 0xff);
	                results.push( value       & 0xff);

	                return results;
	            })();
	        } else {
	            return null;
	        }
	    };

	    // A utility function to return subnet mask in IPv4 format given the prefix length
	    ipaddr.IPv4.subnetMaskFromPrefixLength = function (prefix) {
	        prefix = parseInt(prefix);
	        if (prefix < 0 || prefix > 32) {
	            throw new Error('ipaddr: invalid IPv4 prefix length');
	        }

	        const octets = [0, 0, 0, 0];
	        let j = 0;
	        const filledOctetCount = Math.floor(prefix / 8);

	        while (j < filledOctetCount) {
	            octets[j] = 255;
	            j++;
	        }

	        if (filledOctetCount < 4) {
	            octets[filledOctetCount] = Math.pow(2, prefix % 8) - 1 << 8 - (prefix % 8);
	        }

	        return new this(octets);
	    };

	    // An IPv6 address (RFC2460)
	    ipaddr.IPv6 = (function () {
	        // Constructs an IPv6 address from an array of eight 16 - bit parts
	        // or sixteen 8 - bit parts in network order(MSB first).
	        // Throws an error if the input is invalid.
	        function IPv6 (parts, zoneId) {
	            let i, part;

	            if (parts.length === 16) {
	                this.parts = [];
	                for (i = 0; i <= 14; i += 2) {
	                    this.parts.push((parts[i] << 8) | parts[i + 1]);
	                }
	            } else if (parts.length === 8) {
	                this.parts = parts;
	            } else {
	                throw new Error('ipaddr: ipv6 part count should be 8 or 16');
	            }

	            for (i = 0; i < this.parts.length; i++) {
	                part = this.parts[i];
	                if (!((0 <= part && part <= 0xffff))) {
	                    throw new Error('ipaddr: ipv6 part should fit in 16 bits');
	                }
	            }

	            if (zoneId) {
	                this.zoneId = zoneId;
	            }
	        }

	        // Special IPv6 ranges
	        IPv6.prototype.SpecialRanges = {
	            // RFC4291, here and after
	            unspecified: [new IPv6([0, 0, 0, 0, 0, 0, 0, 0]), 128],
	            linkLocal: [new IPv6([0xfe80, 0, 0, 0, 0, 0, 0, 0]), 10],
	            multicast: [new IPv6([0xff00, 0, 0, 0, 0, 0, 0, 0]), 8],
	            loopback: [new IPv6([0, 0, 0, 0, 0, 0, 0, 1]), 128],
	            uniqueLocal: [new IPv6([0xfc00, 0, 0, 0, 0, 0, 0, 0]), 7],
	            ipv4Mapped: [new IPv6([0, 0, 0, 0, 0, 0xffff, 0, 0]), 96],
	            // RFC6145
	            rfc6145: [new IPv6([0, 0, 0, 0, 0xffff, 0, 0, 0]), 96],
	            // RFC6052
	            rfc6052: [new IPv6([0x64, 0xff9b, 0, 0, 0, 0, 0, 0]), 96],
	            // RFC3056
	            '6to4': [new IPv6([0x2002, 0, 0, 0, 0, 0, 0, 0]), 16],
	            // RFC6052, RFC6146
	            teredo: [new IPv6([0x2001, 0, 0, 0, 0, 0, 0, 0]), 32],
	            // RFC4291
	            reserved: [[new IPv6([0x2001, 0xdb8, 0, 0, 0, 0, 0, 0]), 32]]
	        };

	        // Checks if this address is an IPv4-mapped IPv6 address.
	        IPv6.prototype.isIPv4MappedAddress = function () {
	            return this.range() === 'ipv4Mapped';
	        };

	        // The 'kind' method exists on both IPv4 and IPv6 classes.
	        IPv6.prototype.kind = function () {
	            return 'ipv6';
	        };

	        // Checks if this address matches other one within given CIDR range.
	        IPv6.prototype.match = function (other, cidrRange) {
	            let ref;

	            if (cidrRange === undefined) {
	                ref = other;
	                other = ref[0];
	                cidrRange = ref[1];
	            }

	            if (other.kind() !== 'ipv6') {
	                throw new Error('ipaddr: cannot match ipv6 address with non-ipv6 one');
	            }

	            return matchCIDR(this.parts, other.parts, 16, cidrRange);
	        };

	        // returns a number of leading ones in IPv6 address, making sure that
	        // the rest is a solid sequence of 0's (valid netmask)
	        // returns either the CIDR length or null if mask is not valid
	        IPv6.prototype.prefixLengthFromSubnetMask = function () {
	            let cidr = 0;
	            // non-zero encountered stop scanning for zeroes
	            let stop = false;
	            // number of zeroes in octet
	            const zerotable = {
	                0: 16,
	                32768: 15,
	                49152: 14,
	                57344: 13,
	                61440: 12,
	                63488: 11,
	                64512: 10,
	                65024: 9,
	                65280: 8,
	                65408: 7,
	                65472: 6,
	                65504: 5,
	                65520: 4,
	                65528: 3,
	                65532: 2,
	                65534: 1,
	                65535: 0
	            };
	            let part, zeros;

	            for (let i = 7; i >= 0; i -= 1) {
	                part = this.parts[i];
	                if (part in zerotable) {
	                    zeros = zerotable[part];
	                    if (stop && zeros !== 0) {
	                        return null;
	                    }

	                    if (zeros !== 16) {
	                        stop = true;
	                    }

	                    cidr += zeros;
	                } else {
	                    return null;
	                }
	            }

	            return 128 - cidr;
	        };


	        // Checks if the address corresponds to one of the special ranges.
	        IPv6.prototype.range = function () {
	            return ipaddr.subnetMatch(this, this.SpecialRanges);
	        };

	        // Returns an array of byte-sized values in network order (MSB first)
	        IPv6.prototype.toByteArray = function () {
	            let part;
	            const bytes = [];
	            const ref = this.parts;
	            for (let i = 0; i < ref.length; i++) {
	                part = ref[i];
	                bytes.push(part >> 8);
	                bytes.push(part & 0xff);
	            }

	            return bytes;
	        };

	        // Returns the address in expanded format with all zeroes included, like
	        // 2001:0db8:0008:0066:0000:0000:0000:0001
	        IPv6.prototype.toFixedLengthString = function () {
	            const addr = ((function () {
	                const results = [];
	                for (let i = 0; i < this.parts.length; i++) {
	                    results.push(padPart(this.parts[i].toString(16), 4));
	                }

	                return results;
	            }).call(this)).join(':');

	            let suffix = '';

	            if (this.zoneId) {
	                suffix = `%${this.zoneId}`;
	            }

	            return addr + suffix;
	        };

	        // Converts this address to IPv4 address if it is an IPv4-mapped IPv6 address.
	        // Throws an error otherwise.
	        IPv6.prototype.toIPv4Address = function () {
	            if (!this.isIPv4MappedAddress()) {
	                throw new Error('ipaddr: trying to convert a generic ipv6 address to ipv4');
	            }

	            const ref = this.parts.slice(-2);
	            const high = ref[0];
	            const low = ref[1];

	            return new ipaddr.IPv4([high >> 8, high & 0xff, low >> 8, low & 0xff]);
	        };

	        // Returns the address in expanded format with all zeroes included, like
	        // 2001:db8:8:66:0:0:0:1
	        //
	        // Deprecated: use toFixedLengthString() instead.
	        IPv6.prototype.toNormalizedString = function () {
	            const addr = ((function () {
	                const results = [];

	                for (let i = 0; i < this.parts.length; i++) {
	                    results.push(this.parts[i].toString(16));
	                }

	                return results;
	            }).call(this)).join(':');

	            let suffix = '';

	            if (this.zoneId) {
	                suffix = `%${this.zoneId}`;
	            }

	            return addr + suffix;
	        };

	        // Returns the address in compact, human-readable format like
	        // 2001:db8:8:66::1
	        // in line with RFC 5952 (see https://tools.ietf.org/html/rfc5952#section-4)
	        IPv6.prototype.toRFC5952String = function () {
	            const regex = /((^|:)(0(:|$)){2,})/g;
	            const string = this.toNormalizedString();
	            let bestMatchIndex = 0;
	            let bestMatchLength = -1;
	            let match;

	            while ((match = regex.exec(string))) {
	                if (match[0].length > bestMatchLength) {
	                    bestMatchIndex = match.index;
	                    bestMatchLength = match[0].length;
	                }
	            }

	            if (bestMatchLength < 0) {
	                return string;
	            }

	            return `${string.substring(0, bestMatchIndex)}::${string.substring(bestMatchIndex + bestMatchLength)}`;
	        };

	        // Returns the address in compact, human-readable format like
	        // 2001:db8:8:66::1
	        //
	        // Deprecated: use toRFC5952String() instead.
	        IPv6.prototype.toString = function () {
	            // Replace the first sequence of 1 or more '0' parts with '::'
	            return this.toNormalizedString().replace(/((^|:)(0(:|$))+)/, '::');
	        };

	        return IPv6;

	    })();

	    // A utility function to return broadcast address given the IPv6 interface and prefix length in CIDR notation
	    ipaddr.IPv6.broadcastAddressFromCIDR = function (string) {
	        try {
	            const cidr = this.parseCIDR(string);
	            const ipInterfaceOctets = cidr[0].toByteArray();
	            const subnetMaskOctets = this.subnetMaskFromPrefixLength(cidr[1]).toByteArray();
	            const octets = [];
	            let i = 0;
	            while (i < 16) {
	                // Broadcast address is bitwise OR between ip interface and inverted mask
	                octets.push(parseInt(ipInterfaceOctets[i], 10) | parseInt(subnetMaskOctets[i], 10) ^ 255);
	                i++;
	            }

	            return new this(octets);
	        } catch (e) {
	            throw new Error(`ipaddr: the address does not have IPv6 CIDR format (${e})`);
	        }
	    };

	    // Checks if a given string is formatted like IPv6 address.
	    ipaddr.IPv6.isIPv6 = function (string) {
	        return this.parser(string) !== null;
	    };

	    // Checks to see if string is a valid IPv6 Address
	    ipaddr.IPv6.isValid = function (string) {

	        // Since IPv6.isValid is always called first, this shortcut
	        // provides a substantial performance gain.
	        if (typeof string === 'string' && string.indexOf(':') === -1) {
	            return false;
	        }

	        try {
	            const addr = this.parser(string);
	            new this(addr.parts, addr.zoneId);
	            return true;
	        } catch (e) {
	            return false;
	        }
	    };

	    // A utility function to return network address given the IPv6 interface and prefix length in CIDR notation
	    ipaddr.IPv6.networkAddressFromCIDR = function (string) {
	        let cidr, i, ipInterfaceOctets, octets, subnetMaskOctets;

	        try {
	            cidr = this.parseCIDR(string);
	            ipInterfaceOctets = cidr[0].toByteArray();
	            subnetMaskOctets = this.subnetMaskFromPrefixLength(cidr[1]).toByteArray();
	            octets = [];
	            i = 0;
	            while (i < 16) {
	                // Network address is bitwise AND between ip interface and mask
	                octets.push(parseInt(ipInterfaceOctets[i], 10) & parseInt(subnetMaskOctets[i], 10));
	                i++;
	            }

	            return new this(octets);
	        } catch (e) {
	            throw new Error(`ipaddr: the address does not have IPv6 CIDR format (${e})`);
	        }
	    };

	    // Tries to parse and validate a string with IPv6 address.
	    // Throws an error if it fails.
	    ipaddr.IPv6.parse = function (string) {
	        const addr = this.parser(string);

	        if (addr.parts === null) {
	            throw new Error('ipaddr: string is not formatted like an IPv6 Address');
	        }

	        return new this(addr.parts, addr.zoneId);
	    };

	    ipaddr.IPv6.parseCIDR = function (string) {
	        let maskLength, match, parsed;

	        if ((match = string.match(/^(.+)\/(\d+)$/))) {
	            maskLength = parseInt(match[2]);
	            if (maskLength >= 0 && maskLength <= 128) {
	                parsed = [this.parse(match[1]), maskLength];
	                Object.defineProperty(parsed, 'toString', {
	                    value: function () {
	                        return this.join('/');
	                    }
	                });
	                return parsed;
	            }
	        }

	        throw new Error('ipaddr: string is not formatted like an IPv6 CIDR range');
	    };

	    // Parse an IPv6 address.
	    ipaddr.IPv6.parser = function (string) {
	        let addr, i, match, octet, octets, zoneId;

	        if ((match = string.match(ipv6Regexes.deprecatedTransitional))) {
	            return this.parser(`::ffff:${match[1]}`);
	        }
	        if (ipv6Regexes.native.test(string)) {
	            return expandIPv6(string, 8);
	        }
	        if ((match = string.match(ipv6Regexes.transitional))) {
	            zoneId = match[6] || '';
	            addr = expandIPv6(match[1].slice(0, -1) + zoneId, 6);
	            if (addr.parts) {
	                octets = [
	                    parseInt(match[2]),
	                    parseInt(match[3]),
	                    parseInt(match[4]),
	                    parseInt(match[5])
	                ];
	                for (i = 0; i < octets.length; i++) {
	                    octet = octets[i];
	                    if (!((0 <= octet && octet <= 255))) {
	                        return null;
	                    }
	                }

	                addr.parts.push(octets[0] << 8 | octets[1]);
	                addr.parts.push(octets[2] << 8 | octets[3]);
	                return {
	                    parts: addr.parts,
	                    zoneId: addr.zoneId
	                };
	            }
	        }

	        return null;
	    };

	    // A utility function to return subnet mask in IPv6 format given the prefix length
	    ipaddr.IPv6.subnetMaskFromPrefixLength = function (prefix) {
	        prefix = parseInt(prefix);
	        if (prefix < 0 || prefix > 128) {
	            throw new Error('ipaddr: invalid IPv6 prefix length');
	        }

	        const octets = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];
	        let j = 0;
	        const filledOctetCount = Math.floor(prefix / 8);

	        while (j < filledOctetCount) {
	            octets[j] = 255;
	            j++;
	        }

	        if (filledOctetCount < 16) {
	            octets[filledOctetCount] = Math.pow(2, prefix % 8) - 1 << 8 - (prefix % 8);
	        }

	        return new this(octets);
	    };

	    // Try to parse an array in network order (MSB first) for IPv4 and IPv6
	    ipaddr.fromByteArray = function (bytes) {
	        const length = bytes.length;

	        if (length === 4) {
	            return new ipaddr.IPv4(bytes);
	        } else if (length === 16) {
	            return new ipaddr.IPv6(bytes);
	        } else {
	            throw new Error('ipaddr: the binary input is neither an IPv6 nor IPv4 address');
	        }
	    };

	    // Checks if the address is valid IP address
	    ipaddr.isValid = function (string) {
	        return ipaddr.IPv6.isValid(string) || ipaddr.IPv4.isValid(string);
	    };


	    // Attempts to parse an IP Address, first through IPv6 then IPv4.
	    // Throws an error if it could not be parsed.
	    ipaddr.parse = function (string) {
	        if (ipaddr.IPv6.isValid(string)) {
	            return ipaddr.IPv6.parse(string);
	        } else if (ipaddr.IPv4.isValid(string)) {
	            return ipaddr.IPv4.parse(string);
	        } else {
	            throw new Error('ipaddr: the address has neither IPv6 nor IPv4 format');
	        }
	    };

	    // Attempt to parse CIDR notation, first through IPv6 then IPv4.
	    // Throws an error if it could not be parsed.
	    ipaddr.parseCIDR = function (string) {
	        try {
	            return ipaddr.IPv6.parseCIDR(string);
	        } catch (e) {
	            try {
	                return ipaddr.IPv4.parseCIDR(string);
	            } catch (e2) {
	                throw new Error('ipaddr: the address has neither IPv6 nor IPv4 CIDR format');
	            }
	        }
	    };

	    // Parse an address and return plain IPv4 address if it is an IPv4-mapped address
	    ipaddr.process = function (string) {
	        const addr = this.parse(string);

	        if (addr.kind() === 'ipv6' && addr.isIPv4MappedAddress()) {
	            return addr.toIPv4Address();
	        } else {
	            return addr;
	        }
	    };

	    // An utility function to ease named range matching. See examples below.
	    // rangeList can contain both IPv4 and IPv6 subnet entries and will not throw errors
	    // on matching IPv4 addresses to IPv6 ranges or vice versa.
	    ipaddr.subnetMatch = function (address, rangeList, defaultName) {
	        let i, rangeName, rangeSubnets, subnet;

	        if (defaultName === undefined || defaultName === null) {
	            defaultName = 'unicast';
	        }

	        for (rangeName in rangeList) {
	            if (Object.prototype.hasOwnProperty.call(rangeList, rangeName)) {
	                rangeSubnets = rangeList[rangeName];
	                // ECMA5 Array.isArray isn't available everywhere
	                if (rangeSubnets[0] && !(rangeSubnets[0] instanceof Array)) {
	                    rangeSubnets = [rangeSubnets];
	                }

	                for (i = 0; i < rangeSubnets.length; i++) {
	                    subnet = rangeSubnets[i];
	                    if (address.kind() === subnet[0].kind() && address.match.apply(address, subnet)) {
	                        return rangeName;
	                    }
	                }
	            }
	        }

	        return defaultName;
	    };

	    // Export for both the CommonJS and browser-like environment
	    if (module.exports) {
	        module.exports = ipaddr;

	    } else {
	        root.ipaddr = ipaddr;
	    }

	}(commonjsGlobal)); 
} (ipaddr$1));

var ipaddrExports = ipaddr$1.exports;
var ipaddr = /*@__PURE__*/getDefaultExportFromCjs(ipaddrExports);

const { isValid: is_valid, parse } = ipaddr;
const PRIVATE_IP_RANGES = [
    '0.0.0.0/8',
    '10.0.0.0/8',
    '100.64.0.0/10',
    '127.0.0.0/8',
    '169.254.0.0/16',
    '172.16.0.0/12',
    '192.0.0.0/24',
    '192.0.0.0/29',
    '192.0.0.8/32',
    '192.0.0.9/32',
    '192.0.0.10/32',
    '192.0.0.170/32',
    '192.0.0.171/32',
    '192.0.2.0/24',
    '192.31.196.0/24',
    '192.52.193.0/24',
    '192.88.99.0/24',
    '192.168.0.0/16',
    '192.175.48.0/24',
    '198.18.0.0/15',
    '198.51.100.0/24',
    '203.0.113.0/24',
    '240.0.0.0/4',
    '255.255.255.255/32'
];
const NETMASK_RANGES = PRIVATE_IP_RANGES.map(ip_range => new Netmask_1(ip_range));
function ipv4_check(ip_addr) {
    for (let r of NETMASK_RANGES) {
        if (r.contains(ip_addr))
            return true;
    }
    return false;
}
function ipv6_check(ip_addr) {
    return /^::$/.test(ip_addr) ||
        /^::1$/.test(ip_addr) ||
        /^::f{4}:([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ip_addr) ||
        /^::f{4}:0.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ip_addr) ||
        /^64:ff9b::([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})\.([0-9]{1,3})$/.test(ip_addr) ||
        /^100::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^2001::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^2001:2[0-9a-fA-F]:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^2001:db8:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^2002:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ip_addr) ||
        /^f[c-d]([0-9a-fA-F]{2,2}):/i.test(ip_addr) ||
        /^fe[8-9a-bA-B][0-9a-fA-F]:/i.test(ip_addr) ||
        /^ff([0-9a-fA-F]{2,2}):/i.test(ip_addr);
}
var is_ip_private = (ip) => {
    if (is_valid(ip)) {
        const parsed = parse(ip);
        if (parsed.kind() === 'ipv4')
            return ipv4_check(parsed.toNormalizedString());
        else if (parsed.kind() === 'ipv6')
            return ipv6_check(ip);
    }
    else if (isIP(ip) && ipRegex.v6().test(ip))
        return ipv6_check(ip);
    return undefined;
};

/**
 * Returns a connection gater that disallows dialling private addresses by
 * default. Browsers are severely limited in their resource usage so don't
 * waste time trying to dial undiallable addresses.
 */
function connectionGater(gater = {}) {
    return {
        denyDialPeer: async () => false,
        denyDialMultiaddr: async (multiaddr) => {
            const tuples = multiaddr.stringTuples();
            if (tuples[0][0] === 4 || tuples[0][0] === 41) {
                return Boolean(is_ip_private(`${tuples[0][1]}`));
            }
            return false;
        },
        denyInboundConnection: async () => false,
        denyOutboundConnection: async () => false,
        denyInboundEncryptedConnection: async () => false,
        denyOutboundEncryptedConnection: async () => false,
        denyInboundUpgradedConnection: async () => false,
        denyOutboundUpgradedConnection: async () => false,
        filterMultiaddrForPeer: async () => true,
        ...gater
    };
}

/**
 * Check if a given multiaddr has a private address.
 */
function isPrivate(ma) {
    try {
        const { address } = ma.nodeAddress();
        return Boolean(is_ip_private(address));
    }
    catch {
        return true;
    }
}

/**
 * @packageDocumentation
 *
 * Provides strategies to sort a list of multiaddrs.
 *
 * @example
 *
 * ```typescript
 * import { publicAddressesFirst } from '@libp2p/utils/address-sort'
 * import { multiaddr } from '@multformats/multiaddr'
 *
 *
 * const addresses = [
 *   multiaddr('/ip4/127.0.0.1/tcp/9000'),
 *   multiaddr('/ip4/82.41.53.1/tcp/9000')
 * ].sort(publicAddressesFirst)
 *
 * console.info(addresses)
 * // ['/ip4/82.41.53.1/tcp/9000', '/ip4/127.0.0.1/tcp/9000']
 * ```
 */
/**
 * Compare function for array.sort().
 * This sort aims to move the private addresses to the end of the array.
 * In case of equality, a certified address will come first.
 */
function publicAddressesFirst(a, b) {
    const isAPrivate = isPrivate(a.multiaddr);
    const isBPrivate = isPrivate(b.multiaddr);
    if (isAPrivate && !isBPrivate) {
        return 1;
    }
    else if (!isAPrivate && isBPrivate) {
        return -1;
    }
    // Check certified?
    if (a.isCertified && !b.isCertified) {
        return -1;
    }
    else if (!a.isCertified && b.isCertified) {
        return 1;
    }
    return 0;
}

var receptacle = Receptacle;
var toMS = requireMs();
var cache = Receptacle.prototype;
var counter = new Date() % 1e9;

function getUID () { return (Math.random() * 1e9 >>> 0) + (counter++) }

/**
 * Creates a cache with a maximum key size.
 *
 * @constructor
 * @param {Object} options
 * @param {Number} [options.max=Infinity] the maximum number of keys allowed in the cache (lru).
 * @param {Array} [options.items=[]] the default items in the cache.
 */
function Receptacle (options) {
  options = options || {};
  this.id = options.id || getUID();
  this.max = options.max || Infinity;
  this.items = options.items || [];
  this._lookup = {};
  this.size = this.items.length;
  this.lastModified = new Date(options.lastModified || new Date());

  // Setup initial timers and indexes for the cache.
  for (var item, ttl, i = this.items.length; i--;) {
    item = this.items[i];
    ttl = new Date(item.expires) - new Date();
    this._lookup[item.key] = item;
    if (ttl > 0) this.expire(item.key, ttl);
    else if (ttl <= 0) this.delete(item.key);
  }
}

/**
 * Tests if a key is currently in the cache.
 * Does not check if slot is empty.
 *
 * @param {String} key - the key to retrieve from the cache.
 * @return {Boolean}
 */
cache.has = function (key) {
  return key in this._lookup
};

/**
 * Retrieves a key from the cache and marks it as recently used.
 *
 * @param {String} key - the key to retrieve from the cache.
 * @return {*}
 */
cache.get = function (key) {
  if (!this.has(key)) return null
  var record = this._lookup[key];
  // Update expiry for "refresh" keys
  if (record.refresh) this.expire(key, record.refresh);
  // Move to front of the line.
  this.items.splice(this.items.indexOf(record), 1);
  this.items.push(record);
  return record.value
};

/**
 * Retrieves user meta data for a cached item.
 *
 * @param {String} key - the key to retrieve meta data from the cache.
 * @return {*}
 */
cache.meta = function (key) {
  if (!this.has(key)) return null
  var record = this._lookup[key];
  if (!('meta' in record)) return null
  return record.meta
};

/**
 * Puts a key into the cache with an optional expiry time.
 *
 * @param {String} key - the key for the value in the cache.
 * @param {*} value - the value to place at the key.
 * @param {Number} [options.ttl] - a time after which the key will be removed.
 * @return {Receptacle}
 */
cache.set = function (key, value, options) {
  var oldRecord = this._lookup[key];
  var record = this._lookup[key] = { key: key, value: value };
  // Mark cache as modified.
  this.lastModified = new Date();

  if (oldRecord) {
    // Replace an old key.
    clearTimeout(oldRecord.timeout);
    this.items.splice(this.items.indexOf(oldRecord), 1, record);
  } else {
    // Remove least used item if needed.
    if (this.size >= this.max) this.delete(this.items[0].key);
    // Add a new key.
    this.items.push(record);
    this.size++;
  }

  if (options) {
    // Setup key expiry.
    if ('ttl' in options) this.expire(key, options.ttl);
    // Store user options in the record.
    if ('meta' in options) record.meta = options.meta;
    // Mark a auto refresh key.
    if (options.refresh) record.refresh = options.ttl;
  }

  return this
};

/**
 * Deletes an item from the cache.
 *
 * @param {String} key - the key to remove.
 * @return {Receptacle}
 */
cache.delete = function (key) {
  var record = this._lookup[key];
  if (!record) return false
  this.lastModified = new Date();
  this.items.splice(this.items.indexOf(record), 1);
  clearTimeout(record.timeout);
  delete this._lookup[key];
  this.size--;
  return this
};

/**
 * Utility to register a key that will be removed after some time.
 *
 * @param {String} key - the key to remove.
 * @param {Number} [ms] - the timeout before removal.
 * @return {Receptacle}
 */
cache.expire = function (key, ttl) {
  var ms = ttl || 0;
  var record = this._lookup[key];
  if (!record) return this
  if (typeof ms === 'string') ms = toMS(ttl);
  if (typeof ms !== 'number') throw new TypeError('Expiration time must be a string or number.')
  clearTimeout(record.timeout);
  record.timeout = setTimeout(this.delete.bind(this, record.key), ms);
  record.expires = Number(new Date()) + ms;
  return this
};

/**
 * Deletes all items from the cache.
 * @return {Receptacle}
 */
cache.clear = function () {
  for (var i = this.items.length; i--;) this.delete(this.items[i].key);
  return this
};

/**
 * Fixes serialization issues in polyfilled environments.
 * Ensures non-cyclical serialized object.
 */
cache.toJSON = function () {
  var items = new Array(this.items.length);
  var item;
  for (var i = items.length; i--;) {
    item = this.items[i];
    items[i] = {
      key: item.key,
      meta: item.meta,
      value: item.value,
      expires: item.expires,
      refresh: item.refresh
    };
  }

  return {
    id: this.id,
    max: isFinite(this.max) ? this.max : undefined,
    lastModified: this.lastModified,
    items: items
  }
};

var Receptacle$1 = /*@__PURE__*/getDefaultExportFromCjs(receptacle);

const globalFetch = globalThis.fetch;
const globalHeaders = globalThis.Headers;

/**
 * Build fetch resource for request
 */
function buildResource(serverResolver, hostname, recordType) {
    return `${serverResolver}?name=${hostname}&type=${recordType}`;
}
/**
 * Use fetch to find the record
 */
async function request(resource, signal) {
    const req = await globalFetch(resource, {
        headers: new globalHeaders({
            accept: 'application/dns-json'
        }),
        signal
    });
    const res = await req.json();
    return res;
}
/**
 * Creates cache key composed by recordType and hostname
 *
 * @param {string} hostname
 * @param {string} recordType
 */
function getCacheKey(hostname, recordType) {
    return `${recordType}_${hostname}`;
}

const log$h = Object.assign(debug('dns-over-http-resolver'), {
    error: debug('dns-over-http-resolver:error')
});
/**
 * DNS over HTTP resolver.
 * Uses a list of servers to resolve DNS records with HTTP requests.
 */
class Resolver {
    /**
     * @class
     * @param {object} [options]
     * @param {number} [options.maxCache = 100] - maximum number of cached dns records
     * @param {Request} [options.request] - function to return DNSJSON
     */
    constructor(options = {}) {
        this._cache = new Receptacle$1({ max: options?.maxCache ?? 100 });
        this._TXTcache = new Receptacle$1({ max: options?.maxCache ?? 100 });
        this._servers = [
            'https://cloudflare-dns.com/dns-query',
            'https://dns.google/resolve'
        ];
        this._request = options.request ?? request;
        this._abortControllers = [];
    }
    /**
     * Cancel all outstanding DNS queries made by this resolver. Any outstanding
     * requests will be aborted and promises rejected.
     */
    cancel() {
        this._abortControllers.forEach(controller => controller.abort());
    }
    /**
     * Get an array of the IP addresses currently configured for DNS resolution.
     * These addresses are formatted according to RFC 5952. It can include a custom port.
     */
    getServers() {
        return this._servers;
    }
    /**
     * Get a shuffled array of the IP addresses currently configured for DNS resolution.
     * These addresses are formatted according to RFC 5952. It can include a custom port.
     */
    _getShuffledServers() {
        const newServers = [...this._servers];
        for (let i = newServers.length - 1; i > 0; i--) {
            const j = Math.floor(Math.random() * i);
            const temp = newServers[i];
            newServers[i] = newServers[j];
            newServers[j] = temp;
        }
        return newServers;
    }
    /**
     * Sets the IP address and port of servers to be used when performing DNS resolution.
     *
     * @param {string[]} servers - array of RFC 5952 formatted addresses.
     */
    setServers(servers) {
        this._servers = servers;
    }
    /**
     * Uses the DNS protocol to resolve the given host name into the appropriate DNS record
     *
     * @param {string} hostname - host name to resolve
     * @param {string} [rrType = 'A'] - resource record type
     */
    async resolve(hostname, rrType = 'A') {
        switch (rrType) {
            case 'A':
                return await this.resolve4(hostname);
            case 'AAAA':
                return await this.resolve6(hostname);
            case 'TXT':
                return await this.resolveTxt(hostname);
            default:
                throw new Error(`${rrType} is not supported`);
        }
    }
    /**
     * Uses the DNS protocol to resolve the given host name into IPv4 addresses
     *
     * @param {string} hostname - host name to resolve
     */
    async resolve4(hostname) {
        const recordType = 'A';
        const cached = this._cache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => a.data);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._cache.set(getCacheKey(hostname, recordType), data, { ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$h.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryA ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    /**
     * Uses the DNS protocol to resolve the given host name into IPv6 addresses
     *
     * @param {string} hostname - host name to resolve
     */
    async resolve6(hostname) {
        const recordType = 'AAAA';
        const cached = this._cache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => a.data);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._cache.set(getCacheKey(hostname, recordType), data, { ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$h.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryAaaa ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    /**
     * Uses the DNS protocol to resolve the given host name into a Text record
     *
     * @param {string} hostname - host name to resolve
     */
    async resolveTxt(hostname) {
        const recordType = 'TXT';
        const cached = this._TXTcache.get(getCacheKey(hostname, recordType));
        if (cached != null) {
            return cached;
        }
        let aborted = false;
        for (const server of this._getShuffledServers()) {
            const controller = new AbortController();
            this._abortControllers.push(controller);
            try {
                const response = await this._request(buildResource(server, hostname, recordType), controller.signal);
                const data = response.Answer.map(a => [a.data.replace(/['"]+/g, '')]);
                const ttl = Math.min(...response.Answer.map(a => a.TTL));
                this._TXTcache.set(getCacheKey(hostname, recordType), data, { ttl });
                return data;
            }
            catch (err) {
                if (controller.signal.aborted) {
                    aborted = true;
                }
                log$h.error(`${server} could not resolve ${hostname} record ${recordType}`);
            }
            finally {
                this._abortControllers = this._abortControllers.filter(c => c !== controller);
            }
        }
        if (aborted) {
            throw Object.assign(new Error('queryTxt ECANCELLED'), {
                code: 'ECANCELLED'
            });
        }
        throw new Error(`Could not resolve ${hostname} record ${recordType}`);
    }
    clearCache() {
        this._cache.clear();
        this._TXTcache.clear();
    }
}

/**
 * @packageDocumentation
 *
 * Provides strategies for resolving multiaddrs.
 */
const { code: dnsaddrCode } = getProtocol$1('dnsaddr');
/**
 * Resolver for dnsaddr addresses.
 *
 * @example
 *
 * ```typescript
 * import { dnsaddrResolver } from '@multiformats/multiaddr/resolvers'
 * import { multiaddr } from '@multiformats/multiaddr'
 *
 * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')
 * const addresses = await dnsaddrResolver(ma)
 *
 * console.info(addresses)
 * //[
 * //  '/dnsaddr/am6.bootstrap.libp2p.io/p2p/QmbLHAnMoJPWSCR5Zhtx6BHJX9KiKNN6tpvbUcqanj75Nb',
 * //  '/dnsaddr/ny5.bootstrap.libp2p.io/p2p/QmQCU2EcMqAqQPR2i9bChDtGNJchTbq5TbXJJ16u19uLTa',
 * //  '/dnsaddr/sg1.bootstrap.libp2p.io/p2p/QmcZf59bWwK5XFi76CZX8cbJ4BhTzzA3gU1ZjYZcYW3dwt',
 * //  '/dnsaddr/sv15.bootstrap.libp2p.io/p2p/QmNnooDu7bfjPFoTZYxMNLWUQJyrVwtbZg5gBMjTezGAJN'
 * //]
 * ```
 */
async function dnsaddrResolver(addr, options = {}) {
    const resolver = new Resolver();
    if (options.signal != null) {
        options.signal.addEventListener('abort', () => {
            resolver.cancel();
        });
    }
    const peerId = addr.getPeerId();
    const [, hostname] = addr.stringTuples().find(([proto]) => proto === dnsaddrCode) ?? [];
    if (hostname == null) {
        throw new Error('No hostname found in multiaddr');
    }
    const records = await resolver.resolveTxt(`_dnsaddr.${hostname}`);
    let addresses = records.flat().map((a) => a.split('=')[1]).filter(Boolean);
    if (peerId != null) {
        addresses = addresses.filter((entry) => entry.includes(peerId));
    }
    return addresses;
}

var messages;
(function (messages) {
    messages["NOT_STARTED_YET"] = "The libp2p node is not started yet";
    messages["DHT_DISABLED"] = "DHT is not available";
    messages["PUBSUB_DISABLED"] = "PubSub is not available";
    messages["CONN_ENCRYPTION_REQUIRED"] = "At least one connection encryption module is required";
    messages["ERR_TRANSPORTS_REQUIRED"] = "At least one transport module is required";
    messages["ERR_PROTECTOR_REQUIRED"] = "Private network is enforced, but no protector was provided";
    messages["NOT_FOUND"] = "Not found";
})(messages || (messages = {}));
var codes;
(function (codes) {
    codes["DHT_DISABLED"] = "ERR_DHT_DISABLED";
    codes["ERR_PUBSUB_DISABLED"] = "ERR_PUBSUB_DISABLED";
    codes["PUBSUB_NOT_STARTED"] = "ERR_PUBSUB_NOT_STARTED";
    codes["DHT_NOT_STARTED"] = "ERR_DHT_NOT_STARTED";
    codes["CONN_ENCRYPTION_REQUIRED"] = "ERR_CONN_ENCRYPTION_REQUIRED";
    codes["ERR_TRANSPORTS_REQUIRED"] = "ERR_TRANSPORTS_REQUIRED";
    codes["ERR_PROTECTOR_REQUIRED"] = "ERR_PROTECTOR_REQUIRED";
    codes["ERR_PEER_DIAL_INTERCEPTED"] = "ERR_PEER_DIAL_INTERCEPTED";
    codes["ERR_CONNECTION_INTERCEPTED"] = "ERR_CONNECTION_INTERCEPTED";
    codes["ERR_INVALID_PROTOCOLS_FOR_STREAM"] = "ERR_INVALID_PROTOCOLS_FOR_STREAM";
    codes["ERR_CONNECTION_ENDED"] = "ERR_CONNECTION_ENDED";
    codes["ERR_CONNECTION_FAILED"] = "ERR_CONNECTION_FAILED";
    codes["ERR_NODE_NOT_STARTED"] = "ERR_NODE_NOT_STARTED";
    codes["ERR_ALREADY_ABORTED"] = "ERR_ALREADY_ABORTED";
    codes["ERR_TOO_MANY_ADDRESSES"] = "ERR_TOO_MANY_ADDRESSES";
    codes["ERR_NO_VALID_ADDRESSES"] = "ERR_NO_VALID_ADDRESSES";
    codes["ERR_RELAYED_DIAL"] = "ERR_RELAYED_DIAL";
    codes["ERR_DIALED_SELF"] = "ERR_DIALED_SELF";
    codes["ERR_DISCOVERED_SELF"] = "ERR_DISCOVERED_SELF";
    codes["ERR_DUPLICATE_TRANSPORT"] = "ERR_DUPLICATE_TRANSPORT";
    codes["ERR_ENCRYPTION_FAILED"] = "ERR_ENCRYPTION_FAILED";
    codes["ERR_HOP_REQUEST_FAILED"] = "ERR_HOP_REQUEST_FAILED";
    codes["ERR_INVALID_KEY"] = "ERR_INVALID_KEY";
    codes["ERR_INVALID_MESSAGE"] = "ERR_INVALID_MESSAGE";
    codes["ERR_INVALID_PARAMETERS"] = "ERR_INVALID_PARAMETERS";
    codes["ERR_INVALID_PEER"] = "ERR_INVALID_PEER";
    codes["ERR_MUXER_UNAVAILABLE"] = "ERR_MUXER_UNAVAILABLE";
    codes["ERR_NOT_FOUND"] = "ERR_NOT_FOUND";
    codes["ERR_TIMEOUT"] = "ERR_TIMEOUT";
    codes["ERR_TRANSPORT_UNAVAILABLE"] = "ERR_TRANSPORT_UNAVAILABLE";
    codes["ERR_TRANSPORT_DIAL_FAILED"] = "ERR_TRANSPORT_DIAL_FAILED";
    codes["ERR_UNSUPPORTED_PROTOCOL"] = "ERR_UNSUPPORTED_PROTOCOL";
    codes["ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED"] = "ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED";
    codes["ERR_INVALID_MULTIADDR"] = "ERR_INVALID_MULTIADDR";
    codes["ERR_SIGNATURE_NOT_VALID"] = "ERR_SIGNATURE_NOT_VALID";
    codes["ERR_FIND_SELF"] = "ERR_FIND_SELF";
    codes["ERR_NO_ROUTERS_AVAILABLE"] = "ERR_NO_ROUTERS_AVAILABLE";
    codes["ERR_CONNECTION_NOT_MULTIPLEXED"] = "ERR_CONNECTION_NOT_MULTIPLEXED";
    codes["ERR_NO_DIAL_TOKENS"] = "ERR_NO_DIAL_TOKENS";
    codes["ERR_KEYCHAIN_REQUIRED"] = "ERR_KEYCHAIN_REQUIRED";
    codes["ERR_INVALID_CMS"] = "ERR_INVALID_CMS";
    codes["ERR_MISSING_KEYS"] = "ERR_MISSING_KEYS";
    codes["ERR_NO_KEY"] = "ERR_NO_KEY";
    codes["ERR_INVALID_KEY_NAME"] = "ERR_INVALID_KEY_NAME";
    codes["ERR_INVALID_KEY_TYPE"] = "ERR_INVALID_KEY_TYPE";
    codes["ERR_KEY_ALREADY_EXISTS"] = "ERR_KEY_ALREADY_EXISTS";
    codes["ERR_INVALID_KEY_SIZE"] = "ERR_INVALID_KEY_SIZE";
    codes["ERR_KEY_NOT_FOUND"] = "ERR_KEY_NOT_FOUND";
    codes["ERR_OLD_KEY_NAME_INVALID"] = "ERR_OLD_KEY_NAME_INVALID";
    codes["ERR_NEW_KEY_NAME_INVALID"] = "ERR_NEW_KEY_NAME_INVALID";
    codes["ERR_PASSWORD_REQUIRED"] = "ERR_PASSWORD_REQUIRED";
    codes["ERR_PEM_REQUIRED"] = "ERR_PEM_REQUIRED";
    codes["ERR_CANNOT_READ_KEY"] = "ERR_CANNOT_READ_KEY";
    codes["ERR_MISSING_PRIVATE_KEY"] = "ERR_MISSING_PRIVATE_KEY";
    codes["ERR_MISSING_PUBLIC_KEY"] = "ERR_MISSING_PUBLIC_KEY";
    codes["ERR_INVALID_OLD_PASS_TYPE"] = "ERR_INVALID_OLD_PASS_TYPE";
    codes["ERR_INVALID_NEW_PASS_TYPE"] = "ERR_INVALID_NEW_PASS_TYPE";
    codes["ERR_INVALID_PASS_LENGTH"] = "ERR_INVALID_PASS_LENGTH";
    codes["ERR_NOT_IMPLEMENTED"] = "ERR_NOT_IMPLEMENTED";
    codes["ERR_WRONG_PING_ACK"] = "ERR_WRONG_PING_ACK";
    codes["ERR_INVALID_RECORD"] = "ERR_INVALID_RECORD";
    codes["ERR_ALREADY_SUCCEEDED"] = "ERR_ALREADY_SUCCEEDED";
    codes["ERR_NO_HANDLER_FOR_PROTOCOL"] = "ERR_NO_HANDLER_FOR_PROTOCOL";
    codes["ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS"] = "ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS";
    codes["ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS"] = "ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS";
    codes["ERR_CONNECTION_DENIED"] = "ERR_CONNECTION_DENIED";
    codes["ERR_TRANSFER_LIMIT_EXCEEDED"] = "ERR_TRANSFER_LIMIT_EXCEEDED";
})(codes || (codes = {}));

const DefaultConfig = {
    addresses: {
        listen: [],
        announce: [],
        noAnnounce: [],
        announceFilter: (multiaddrs) => multiaddrs
    },
    connectionManager: {
        resolvers: {
            dnsaddr: dnsaddrResolver
        },
        addressSorter: publicAddressesFirst
    },
    transportManager: {
        faultTolerance: FaultTolerance.FATAL_ALL
    }
};
function validateConfig(opts) {
    const resultingOptions = mergeOptions$1(DefaultConfig, opts);
    if (resultingOptions.transports == null || resultingOptions.transports.length < 1) {
        throw new CodeError$3(messages.ERR_TRANSPORTS_REQUIRED, codes.ERR_TRANSPORTS_REQUIRED);
    }
    if (resultingOptions.connectionProtector === null && globalThis.process?.env?.LIBP2P_FORCE_PNET != null) { // eslint-disable-line no-undef
        throw new CodeError$3(messages.ERR_PROTECTOR_REQUIRED, codes.ERR_PROTECTOR_REQUIRED);
    }
    return resultingOptions;
}

const KEEP_ALIVE = 'keep-alive';

var RateLimiterAbstract_1 = class RateLimiterAbstract {
  /**
   *
   * @param opts Object Defaults {
   *   points: 4, // Number of points
   *   duration: 1, // Per seconds
   *   blockDuration: 0, // Block if consumed more than points in current duration for blockDuration seconds
   *   execEvenly: false, // Execute allowed actions evenly over duration
   *   execEvenlyMinDelayMs: duration * 1000 / points, // ms, works with execEvenly=true option
   *   keyPrefix: 'rlflx',
   * }
   */
  constructor(opts = {}) {
    this.points = opts.points;
    this.duration = opts.duration;
    this.blockDuration = opts.blockDuration;
    this.execEvenly = opts.execEvenly;
    this.execEvenlyMinDelayMs = opts.execEvenlyMinDelayMs;
    this.keyPrefix = opts.keyPrefix;
  }

  get points() {
    return this._points;
  }

  set points(value) {
    this._points = value >= 0 ? value : 4;
  }

  get duration() {
    return this._duration;
  }

  set duration(value) {
    this._duration = typeof value === 'undefined' ? 1 : value;
  }

  get msDuration() {
    return this.duration * 1000;
  }

  get blockDuration() {
    return this._blockDuration;
  }

  set blockDuration(value) {
    this._blockDuration = typeof value === 'undefined' ? 0 : value;
  }

  get msBlockDuration() {
    return this.blockDuration * 1000;
  }

  get execEvenly() {
    return this._execEvenly;
  }

  set execEvenly(value) {
    this._execEvenly = typeof value === 'undefined' ? false : Boolean(value);
  }

  get execEvenlyMinDelayMs() {
    return this._execEvenlyMinDelayMs;
  }

  set execEvenlyMinDelayMs(value) {
    this._execEvenlyMinDelayMs = typeof value === 'undefined' ? Math.ceil(this.msDuration / this.points) : value;
  }

  get keyPrefix() {
    return this._keyPrefix;
  }

  set keyPrefix(value) {
    if (typeof value === 'undefined') {
      value = 'rlflx';
    }
    if (typeof value !== 'string') {
      throw new Error('keyPrefix must be string');
    }
    this._keyPrefix = value;
  }

  _getKeySecDuration(options = {}) {
    return options && options.customDuration >= 0
      ? options.customDuration
      : this.duration;
  }

  getKey(key) {
    return this.keyPrefix.length > 0 ? `${this.keyPrefix}:${key}` : key;
  }

  parseKey(rlKey) {
    return rlKey.substring(this.keyPrefix.length);
  }

  consume() {
    throw new Error("You have to implement the method 'consume'!");
  }

  penalty() {
    throw new Error("You have to implement the method 'penalty'!");
  }

  reward() {
    throw new Error("You have to implement the method 'reward'!");
  }

  get() {
    throw new Error("You have to implement the method 'get'!");
  }

  set() {
    throw new Error("You have to implement the method 'set'!");
  }

  block() {
    throw new Error("You have to implement the method 'block'!");
  }

  delete() {
    throw new Error("You have to implement the method 'delete'!");
  }
};

var BlockedKeys_1$1 = class BlockedKeys {
  constructor() {
    this._keys = {}; // {'key': 1526279430331}
    this._addedKeysAmount = 0;
  }

  collectExpired() {
    const now = Date.now();

    Object.keys(this._keys).forEach((key) => {
      if (this._keys[key] <= now) {
        delete this._keys[key];
      }
    });

    this._addedKeysAmount = Object.keys(this._keys).length;
  }

  /**
   * Add new blocked key
   *
   * @param key String
   * @param sec Number
   */
  add(key, sec) {
    this.addMs(key, sec * 1000);
  }

  /**
   * Add new blocked key for ms
   *
   * @param key String
   * @param ms Number
   */
  addMs(key, ms) {
    this._keys[key] = Date.now() + ms;
    this._addedKeysAmount++;
    if (this._addedKeysAmount > 999) {
      this.collectExpired();
    }
  }

  /**
   * 0 means not blocked
   *
   * @param key
   * @returns {number}
   */
  msBeforeExpire(key) {
    const expire = this._keys[key];

    if (expire && expire >= Date.now()) {
      this.collectExpired();
      const now = Date.now();
      return expire >= now ? expire - now : 0;
    }

    return 0;
  }

  /**
   * If key is not given, delete all data in memory
   * 
   * @param {string|undefined} key
   */
  delete(key) {
    if (key) {
      delete this._keys[key];
    } else {
      Object.keys(this._keys).forEach((key) => {
        delete this._keys[key];
      });
    }
  }
};

const BlockedKeys$1 = BlockedKeys_1$1;

var BlockedKeys_1 = BlockedKeys$1;

var RateLimiterRes_1 = class RateLimiterRes {
  constructor(remainingPoints, msBeforeNext, consumedPoints, isFirstInDuration) {
    this.remainingPoints = typeof remainingPoints === 'undefined' ? 0 : remainingPoints; // Remaining points in current duration
    this.msBeforeNext = typeof msBeforeNext === 'undefined' ? 0 : msBeforeNext; // Milliseconds before next action
    this.consumedPoints = typeof consumedPoints === 'undefined' ? 0 : consumedPoints; // Consumed points in current duration
    this.isFirstInDuration = typeof isFirstInDuration === 'undefined' ? false : isFirstInDuration;
  }

  get msBeforeNext() {
    return this._msBeforeNext;
  }

  set msBeforeNext(ms) {
    this._msBeforeNext = ms;
    return this;
  }

  get remainingPoints() {
    return this._remainingPoints;
  }

  set remainingPoints(p) {
    this._remainingPoints = p;
    return this;
  }

  get consumedPoints() {
    return this._consumedPoints;
  }

  set consumedPoints(p) {
    this._consumedPoints = p;
    return this;
  }

  get isFirstInDuration() {
    return this._isFirstInDuration;
  }

  set isFirstInDuration(value) {
    this._isFirstInDuration = Boolean(value);
  }

  _getDecoratedProperties() {
    return {
      remainingPoints: this.remainingPoints,
      msBeforeNext: this.msBeforeNext,
      consumedPoints: this.consumedPoints,
      isFirstInDuration: this.isFirstInDuration,
    };
  }

  [Symbol.for("nodejs.util.inspect.custom")]() {
    return this._getDecoratedProperties();
  }

  toString() {
    return JSON.stringify(this._getDecoratedProperties());
  }

  toJSON() {
    return this._getDecoratedProperties();
  }
};

const RateLimiterAbstract$3 = RateLimiterAbstract_1;
const BlockedKeys = BlockedKeys_1;
const RateLimiterRes$b = RateLimiterRes_1;

var RateLimiterStoreAbstract_1 = class RateLimiterStoreAbstract extends RateLimiterAbstract$3 {
  /**
   *
   * @param opts Object Defaults {
   *   ... see other in RateLimiterAbstract
   *
   *   inMemoryBlockOnConsumed: 40, // Number of points when key is blocked
   *   inMemoryBlockDuration: 10, // Block duration in seconds
   *   insuranceLimiter: RateLimiterAbstract
   * }
   */
  constructor(opts = {}) {
    super(opts);

    this.inMemoryBlockOnConsumed = opts.inMemoryBlockOnConsumed;
    this.inMemoryBlockDuration = opts.inMemoryBlockDuration;
    this.insuranceLimiter = opts.insuranceLimiter;
    this._inMemoryBlockedKeys = new BlockedKeys();
  }

  get client() {
    return this._client;
  }

  set client(value) {
    if (typeof value === 'undefined') {
      throw new Error('storeClient is not set');
    }
    this._client = value;
  }

  /**
   * Have to be launched after consume
   * It blocks key and execute evenly depending on result from store
   *
   * It uses _getRateLimiterRes function to prepare RateLimiterRes from store result
   *
   * @param resolve
   * @param reject
   * @param rlKey
   * @param changedPoints
   * @param storeResult
   * @param {Object} options
   * @private
   */
  _afterConsume(resolve, reject, rlKey, changedPoints, storeResult, options = {}) {
    const res = this._getRateLimiterRes(rlKey, changedPoints, storeResult);

    if (this.inMemoryBlockOnConsumed > 0 && !(this.inMemoryBlockDuration > 0)
      && res.consumedPoints >= this.inMemoryBlockOnConsumed
    ) {
      this._inMemoryBlockedKeys.addMs(rlKey, res.msBeforeNext);
      if (res.consumedPoints > this.points) {
        return reject(res);
      } else {
        return resolve(res)
      }
    } else if (res.consumedPoints > this.points) {
      let blockPromise = Promise.resolve();
      // Block only first time when consumed more than points
      if (this.blockDuration > 0 && res.consumedPoints <= (this.points + changedPoints)) {
        res.msBeforeNext = this.msBlockDuration;
        blockPromise = this._block(rlKey, res.consumedPoints, this.msBlockDuration, options);
      }

      if (this.inMemoryBlockOnConsumed > 0 && res.consumedPoints >= this.inMemoryBlockOnConsumed) {
        // Block key for this.inMemoryBlockDuration seconds
        this._inMemoryBlockedKeys.add(rlKey, this.inMemoryBlockDuration);
        res.msBeforeNext = this.msInMemoryBlockDuration;
      }

      blockPromise
        .then(() => {
          reject(res);
        })
        .catch((err) => {
          reject(err);
        });
    } else if (this.execEvenly && res.msBeforeNext > 0 && !res.isFirstInDuration) {
      let delay = Math.ceil(res.msBeforeNext / (res.remainingPoints + 2));
      if (delay < this.execEvenlyMinDelayMs) {
        delay = res.consumedPoints * this.execEvenlyMinDelayMs;
      }

      setTimeout(resolve, delay, res);
    } else {
      resolve(res);
    }
  }

  _handleError(err, funcName, resolve, reject, key, data = false, options = {}) {
    if (!(this.insuranceLimiter instanceof RateLimiterAbstract$3)) {
      reject(err);
    } else {
      this.insuranceLimiter[funcName](key, data, options)
        .then((res) => {
          resolve(res);
        })
        .catch((res) => {
          reject(res);
        });
    }
  }

  getInMemoryBlockMsBeforeExpire(rlKey) {
    if (this.inMemoryBlockOnConsumed > 0) {
      return this._inMemoryBlockedKeys.msBeforeExpire(rlKey);
    }

    return 0;
  }

  get inMemoryBlockOnConsumed() {
    return this._inMemoryBlockOnConsumed;
  }

  set inMemoryBlockOnConsumed(value) {
    this._inMemoryBlockOnConsumed = value ? parseInt(value) : 0;
    if (this.inMemoryBlockOnConsumed > 0 && this.points > this.inMemoryBlockOnConsumed) {
      throw new Error('inMemoryBlockOnConsumed option must be greater or equal "points" option');
    }
  }

  get inMemoryBlockDuration() {
    return this._inMemoryBlockDuration;
  }

  set inMemoryBlockDuration(value) {
    this._inMemoryBlockDuration = value ? parseInt(value) : 0;
    if (this.inMemoryBlockDuration > 0 && this.inMemoryBlockOnConsumed === 0) {
      throw new Error('inMemoryBlockOnConsumed option must be set up');
    }
  }

  get msInMemoryBlockDuration() {
    return this._inMemoryBlockDuration * 1000;
  }

  get insuranceLimiter() {
    return this._insuranceLimiter;
  }

  set insuranceLimiter(value) {
    if (typeof value !== 'undefined' && !(value instanceof RateLimiterAbstract$3)) {
      throw new Error('insuranceLimiter must be instance of RateLimiterAbstract');
    }
    this._insuranceLimiter = value;
    if (this._insuranceLimiter) {
      this._insuranceLimiter.blockDuration = this.blockDuration;
      this._insuranceLimiter.execEvenly = this.execEvenly;
    }
  }

  /**
   * Block any key for secDuration seconds
   *
   * @param key
   * @param secDuration
   * @param {Object} options
   *
   * @return Promise<RateLimiterRes>
   */
  block(key, secDuration, options = {}) {
    const msDuration = secDuration * 1000;
    return this._block(this.getKey(key), this.points + 1, msDuration, options);
  }

  /**
   * Set points by key for any duration
   *
   * @param key
   * @param points
   * @param secDuration
   * @param {Object} options
   *
   * @return Promise<RateLimiterRes>
   */
  set(key, points, secDuration, options = {}) {
    const msDuration = (secDuration >= 0 ? secDuration : this.duration) * 1000;
    return this._block(this.getKey(key), points, msDuration, options);
  }

  /**
   *
   * @param key
   * @param pointsToConsume
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const rlKey = this.getKey(key);

      const inMemoryBlockMsBeforeExpire = this.getInMemoryBlockMsBeforeExpire(rlKey);
      if (inMemoryBlockMsBeforeExpire > 0) {
        return reject(new RateLimiterRes$b(0, inMemoryBlockMsBeforeExpire));
      }

      this._upsert(rlKey, pointsToConsume, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          this._afterConsume(resolve, reject, rlKey, pointsToConsume, res);
        })
        .catch((err) => {
          this._handleError(err, 'consume', resolve, reject, key, pointsToConsume, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param points
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  penalty(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, points, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          resolve(this._getRateLimiterRes(rlKey, points, res));
        })
        .catch((err) => {
          this._handleError(err, 'penalty', resolve, reject, key, points, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param points
   * @param {Object} options
   * @returns Promise<RateLimiterRes>
   */
  reward(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, -points, this._getKeySecDuration(options) * 1000, false, options)
        .then((res) => {
          resolve(this._getRateLimiterRes(rlKey, -points, res));
        })
        .catch((err) => {
          this._handleError(err, 'reward', resolve, reject, key, points, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param {Object} options
   * @returns Promise<RateLimiterRes>|null
   */
  get(key, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._get(rlKey, options)
        .then((res) => {
          if (res === null || typeof res === 'undefined') {
            resolve(null);
          } else {
            resolve(this._getRateLimiterRes(rlKey, 0, res));
          }
        })
        .catch((err) => {
          this._handleError(err, 'get', resolve, reject, key, options);
        });
    });
  }

  /**
   *
   * @param key
   * @param {Object} options
   * @returns Promise<boolean>
   */
  delete(key, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve, reject) => {
      this._delete(rlKey, options)
        .then((res) => {
          this._inMemoryBlockedKeys.delete(rlKey);
          resolve(res);
        })
        .catch((err) => {
          this._handleError(err, 'delete', resolve, reject, key, options);
        });
    });
  }

  /**
   * Cleanup keys no-matter expired or not.
   */
  deleteInMemoryBlockedAll() {
    this._inMemoryBlockedKeys.delete();
  }

  /**
   * Get RateLimiterRes object filled depending on storeResult, which specific for exact store
   *
   * @param rlKey
   * @param changedPoints
   * @param storeResult
   * @private
   */
  _getRateLimiterRes(rlKey, changedPoints, storeResult) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_getRateLimiterRes'!");
  }

  /**
   * Block key for this.msBlockDuration milliseconds
   * Usually, it just prolongs lifetime of key
   *
   * @param rlKey
   * @param initPoints
   * @param msDuration
   * @param {Object} options
   *
   * @return Promise<any>
   */
  _block(rlKey, initPoints, msDuration, options = {}) {
    return new Promise((resolve, reject) => {
      this._upsert(rlKey, initPoints, msDuration, true, options)
        .then(() => {
          resolve(new RateLimiterRes$b(0, msDuration > 0 ? msDuration : -1, initPoints));
        })
        .catch((err) => {
          this._handleError(err, 'block', resolve, reject, this.parseKey(rlKey), msDuration / 1000, options);
        });
    });
  }

  /**
   * Have to be implemented in every limiter
   * Resolve with raw result from Store OR null if rlKey is not set
   * or Reject with error
   *
   * @param rlKey
   * @param {Object} options
   * @private
   *
   * @return Promise<any>
   */
  _get(rlKey, options = {}) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_get'!");
  }

  /**
   * Have to be implemented
   * Resolve with true OR false if rlKey doesn't exist
   * or Reject with error
   *
   * @param rlKey
   * @param {Object} options
   * @private
   *
   * @return Promise<any>
   */
  _delete(rlKey, options = {}) { // eslint-disable-line no-unused-vars
    throw new Error("You have to implement the method '_delete'!");
  }

  /**
   * Have to be implemented
   * Resolve with object used for {@link _getRateLimiterRes} to generate {@link RateLimiterRes}
   *
   * @param {string} rlKey
   * @param {number} points
   * @param {number} msDuration
   * @param {boolean} forceExpire
   * @param {Object} options
   * @abstract
   *
   * @return Promise<Object>
   */
  _upsert(rlKey, points, msDuration, forceExpire = false, options = {}) {
    throw new Error("You have to implement the method '_upsert'!");
  }
};

const RateLimiterStoreAbstract$4 = RateLimiterStoreAbstract_1;
const RateLimiterRes$a = RateLimiterRes_1;

const incrTtlLuaScript = `redis.call('set', KEYS[1], 0, 'EX', ARGV[2], 'NX') \
local consumed = redis.call('incrby', KEYS[1], ARGV[1]) \
local ttl = redis.call('pttl', KEYS[1]) \
if ttl == -1 then \
  redis.call('expire', KEYS[1], ARGV[2]) \
  ttl = 1000 * ARGV[2] \
end \
return {consumed, ttl} \
`;

let RateLimiterRedis$1 = class RateLimiterRedis extends RateLimiterStoreAbstract$4 {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   redis: RedisClient
   *   rejectIfRedisNotReady: boolean = false - reject / invoke insuranceLimiter immediately when redis connection is not "ready"
   * }
   */
  constructor(opts) {
    super(opts);
    this.client = opts.storeClient;

    this._rejectIfRedisNotReady = !!opts.rejectIfRedisNotReady;

    this.useRedisPackage = opts.useRedisPackage;
    this.useRedis3AndLowerPackage = opts.useRedis3AndLowerPackage;
    if (typeof this.client.defineCommand === 'function') {
      this.client.defineCommand("rlflxIncr", {
        numberOfKeys: 1,
        lua: incrTtlLuaScript,
      });
    }
  }

  /**
   * Prevent actual redis call if redis connection is not ready
   * Because of different connection state checks for ioredis and node-redis, only this clients would be actually checked.
   * For any other clients all the requests would be passed directly to redis client
   * @return {boolean}
   * @private
   */
  _isRedisReady() {
    if (!this._rejectIfRedisNotReady) {
      return true;
    }
    // ioredis client
    if (this.client.status && this.client.status !== 'ready') {
      return false;
    }
    // node-redis client
    if (typeof this.client.isReady === 'function' && !this.client.isReady()) {
      return false;
    }
    return true;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    let [consumed, resTtlMs] = result;
    // Support ioredis results format
    if (Array.isArray(consumed)) {
      [, consumed] = consumed;
      [, resTtlMs] = resTtlMs;
    }

    const res = new RateLimiterRes$a();
    res.consumedPoints = parseInt(consumed);
    res.isFirstInDuration = res.consumedPoints === changedPoints;
    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = resTtlMs;

    return res;
  }

  async _upsert(rlKey, points, msDuration, forceExpire = false) {
    if (!this._isRedisReady()) {
      throw new Error('Redis connection is not ready');
    }

    const secDuration = Math.floor(msDuration / 1000);
    const multi = this.client.multi();

    if (forceExpire) {
      if (secDuration > 0) {
        if(!this.useRedisPackage && !this.useRedis3AndLowerPackage){
          multi.set(rlKey, points, "EX", secDuration);
        }else {
          multi.set(rlKey, points, { EX: secDuration });
        }
      } else {
        multi.set(rlKey, points);
      }

      if(!this.useRedisPackage && !this.useRedis3AndLowerPackage){
        return multi.pttl(rlKey).exec(true);
      }
      return multi.pTTL(rlKey).exec(true);
    }

    if (secDuration > 0) {
      if(!this.useRedisPackage && !this.useRedis3AndLowerPackage){
        return this.client.rlflxIncr(
          [rlKey].concat([String(points), String(secDuration)]));
      }
      if (this.useRedis3AndLowerPackage) {
        return new Promise((resolve, reject) => {
          const incrCallback = function (err, result) {
            if (err) {
              return reject(err);
            }

            return resolve(result);
          };

          if (typeof this.client.rlflxIncr === 'function') {
            this.client.rlflxIncr(rlKey, points, secDuration, incrCallback);
          } else {
            this.client.eval(incrTtlLuaScript, 1, rlKey, points, secDuration, incrCallback);
          }
        });
      } else {
        return this.client.eval(incrTtlLuaScript, {
          keys: [rlKey],
          arguments: [String(points), String(secDuration)],
        });
      }
    } else {
      if(!this.useRedisPackage && !this.useRedis3AndLowerPackage){
        return multi.incrby(rlKey, points).pttl(rlKey).exec(true);
      }

      return multi.incrBy(rlKey, points).pTTL(rlKey).exec(true);
    }
  }

  async _get(rlKey) {
    if (!this._isRedisReady()) {
      throw new Error('Redis connection is not ready');
    }
    if(!this.useRedisPackage && !this.useRedis3AndLowerPackage){
      return this.client
        .multi()
        .get(rlKey)
        .pttl(rlKey)
        .exec()
        .then((result) => {
          const [[,points]] = result;
          if (points === null) return null;
          return result;
        });
    }

    return this.client
      .multi()
      .get(rlKey)
      .pTTL(rlKey)
      .exec(true)
      .then((result) => {
        const [points] = result;
        if (points === null) return null;
        return result;
      });
  }

  _delete(rlKey) {
    return this.client
      .del(rlKey)
      .then(result => result > 0);
  }
};

var RateLimiterRedis_1 = RateLimiterRedis$1;

const RateLimiterStoreAbstract$3 = RateLimiterStoreAbstract_1;
const RateLimiterRes$9 = RateLimiterRes_1;

/**
 * Get MongoDB driver version as upsert options differ
 * @params {Object} Client instance
 * @returns {Object} Version Object containing major, feature & minor versions.
 */
function getDriverVersion(client) {
  try {
    const _client = client.client ? client.client : client;

    const { version } = _client.topology.s.options.metadata.driver;
    const _v = version.split('.').map(v => parseInt(v));

    return {
      major: _v[0],
      feature: _v[1],
      patch: _v[2],
    };
  } catch (err) {
    return { major: 0, feature: 0, patch: 0 };
  }
}

let RateLimiterMongo$1 = class RateLimiterMongo extends RateLimiterStoreAbstract$3 {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   indexKeyPrefix: {attr1: 1, attr2: 1}
   *   ... see other in RateLimiterStoreAbstract
   *
   *   mongo: MongoClient
   * }
   */
  constructor(opts) {
    super(opts);

    this.dbName = opts.dbName;
    this.tableName = opts.tableName;
    this.indexKeyPrefix = opts.indexKeyPrefix;

    if (opts.mongo) {
      this.client = opts.mongo;
    } else {
      this.client = opts.storeClient;
    }
    if (typeof this.client.then === 'function') {
      // If Promise
      this.client
        .then((conn) => {
          this.client = conn;
          this._initCollection();
          this._driverVersion = getDriverVersion(this.client);
        });
    } else {
      this._initCollection();
      this._driverVersion = getDriverVersion(this.client);
    }
  }

  get dbName() {
    return this._dbName;
  }

  set dbName(value) {
    this._dbName = typeof value === 'undefined' ? RateLimiterMongo.getDbName() : value;
  }

  static getDbName() {
    return 'node-rate-limiter-flexible';
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get client() {
    return this._client;
  }

  set client(value) {
    if (typeof value === 'undefined') {
      throw new Error('mongo is not set');
    }
    this._client = value;
  }

  get indexKeyPrefix() {
    return this._indexKeyPrefix;
  }

  set indexKeyPrefix(obj) {
    this._indexKeyPrefix = obj || {};
  }

  _initCollection() {
    const db = typeof this.client.db === 'function'
      ? this.client.db(this.dbName)
      : this.client;

    const collection = db.collection(this.tableName);
    collection.createIndex({ expire: -1 }, { expireAfterSeconds: 0 });
    collection.createIndex(Object.assign({}, this.indexKeyPrefix, { key: 1 }), { unique: true });

    this._collection = collection;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$9();

    let doc;
    if (typeof result.value === 'undefined') {
      doc = result;
    } else {
      doc = result.value;
    }

    res.isFirstInDuration = doc.points === changedPoints;
    res.consumedPoints = doc.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = doc.expire !== null
      ? Math.max(new Date(doc.expire).getTime() - Date.now(), 0)
      : -1;

    return res;
  }

  _upsert(key, points, msDuration, forceExpire = false, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};

    let where;
    let upsertData;
    if (forceExpire) {
      where = { key };
      where = Object.assign(where, docAttrs);
      upsertData = {
        $set: {
          key,
          points,
          expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
        },
      };
      upsertData.$set = Object.assign(upsertData.$set, docAttrs);
    } else {
      where = {
        $or: [
          { expire: { $gt: new Date() } },
          { expire: { $eq: null } },
        ],
        key,
      };
      where = Object.assign(where, docAttrs);
      upsertData = {
        $setOnInsert: {
          key,
          expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
        },
        $inc: { points },
      };
      upsertData.$setOnInsert = Object.assign(upsertData.$setOnInsert, docAttrs);
    }

    // Options for collection updates differ between driver versions
    const upsertOptions = {
      upsert: true,
    };
    if ((this._driverVersion.major >= 4) ||
        (this._driverVersion.major === 3 &&
          (this._driverVersion.feature >=7) || 
          (this._driverVersion.feature >= 6 && 
              this._driverVersion.patch >= 7 ))) 
    {
      upsertOptions.returnDocument = 'after';
    } else {
      upsertOptions.returnOriginal = false;
    }

    /*
     * 1. Find actual limit and increment points
     * 2. If limit expired, but Mongo doesn't clean doc by TTL yet, try to replace limit doc completely
     * 3. If 2 or more Mongo threads try to insert the new limit doc, only the first succeed
     * 4. Try to upsert from step 1. Actual limit is created now, points are incremented without problems
     */
    return new Promise((resolve, reject) => {
      this._collection.findOneAndUpdate(
        where,
        upsertData,
        upsertOptions
      ).then((res) => {
        resolve(res);
      }).catch((errUpsert) => {
        if (errUpsert && errUpsert.code === 11000) { // E11000 duplicate key error collection
          const replaceWhere = Object.assign({ // try to replace OLD limit doc
            $or: [
              { expire: { $lte: new Date() } },
              { expire: { $eq: null } },
            ],
            key,
          }, docAttrs);

          const replaceTo = {
            $set: Object.assign({
              key,
              points,
              expire: msDuration > 0 ? new Date(Date.now() + msDuration) : null,
            }, docAttrs)
          };

          this._collection.findOneAndUpdate(
            replaceWhere,
            replaceTo,
            upsertOptions
          ).then((res) => {
            resolve(res);
          }).catch((errReplace) => {
            if (errReplace && errReplace.code === 11000) { // E11000 duplicate key error collection
              this._upsert(key, points, msDuration, forceExpire)
                .then(res => resolve(res))
                .catch(err => reject(err));
            } else {
              reject(errReplace);
            }
          });
        } else {
          reject(errUpsert);
        }
      });
    });
  }

  _get(rlKey, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};

    const where = Object.assign({
      key: rlKey,
      $or: [
        { expire: { $gt: new Date() } },
        { expire: { $eq: null } },
      ],
    }, docAttrs);

    return this._collection.findOne(where);
  }

  _delete(rlKey, options = {}) {
    if (!this._collection) {
      return Promise.reject(Error('Mongo connection is not established'));
    }

    const docAttrs = options.attrs || {};
    const where = Object.assign({ key: rlKey }, docAttrs);

    return this._collection.deleteOne(where)
      .then(res => res.deletedCount > 0);
  }
};

var RateLimiterMongo_1 = RateLimiterMongo$1;

const RateLimiterStoreAbstract$2 = RateLimiterStoreAbstract_1;
const RateLimiterRes$8 = RateLimiterRes_1;

let RateLimiterMySQL$1 = class RateLimiterMySQL extends RateLimiterStoreAbstract$2 {
  /**
   * @callback callback
   * @param {Object} err
   *
   * @param {Object} opts
   * @param {callback} cb
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: anySqlClient,
   *   storeType: 'knex', // required only for Knex instance
   *   dbName: 'string',
   *   tableName: 'string',
   * }
   */
  constructor(opts, cb = null) {
    super(opts);

    this.client = opts.storeClient;
    this.clientType = opts.storeType;

    this.dbName = opts.dbName;
    this.tableName = opts.tableName;

    this.clearExpiredByTimeout = opts.clearExpiredByTimeout;

    this.tableCreated = opts.tableCreated;
    if (!this.tableCreated) {
      this._createDbAndTable()
        .then(() => {
          this.tableCreated = true;
          if (this.clearExpiredByTimeout) {
            this._clearExpiredHourAgo();
          }
          if (typeof cb === 'function') {
            cb();
          }
        })
        .catch((err) => {
          if (typeof cb === 'function') {
            cb(err);
          } else {
            throw err;
          }
        });
    } else {
      if (this.clearExpiredByTimeout) {
        this._clearExpiredHourAgo();
      }
      if (typeof cb === 'function') {
        cb();
      }
    }
  }

  clearExpired(expire) {
    return new Promise((resolve) => {
      this._getConnection()
        .then((conn) => {
          conn.query(`DELETE FROM ??.?? WHERE expire < ?`, [this.dbName, this.tableName, expire], () => {
            this._releaseConnection(conn);
            resolve();
          });
        })
        .catch(() => {
          resolve();
        });
    });
  }

  _clearExpiredHourAgo() {
    if (this._clearExpiredTimeoutId) {
      clearTimeout(this._clearExpiredTimeoutId);
    }
    this._clearExpiredTimeoutId = setTimeout(() => {
      this.clearExpired(Date.now() - 3600000) // Never rejected
        .then(() => {
          this._clearExpiredHourAgo();
        });
    }, 300000);
    this._clearExpiredTimeoutId.unref();
  }

  /**
   *
   * @return Promise<any>
   * @private
   */
  _getConnection() {
    switch (this.clientType) {
      case 'pool':
        return new Promise((resolve, reject) => {
          this.client.getConnection((errConn, conn) => {
            if (errConn) {
              return reject(errConn);
            }

            resolve(conn);
          });
        });
      case 'sequelize':
        return this.client.connectionManager.getConnection();
      case 'knex':
        return this.client.client.acquireConnection();
      default:
        return Promise.resolve(this.client);
    }
  }

  _releaseConnection(conn) {
    switch (this.clientType) {
      case 'pool':
        return conn.release();
      case 'sequelize':
        return this.client.connectionManager.releaseConnection(conn);
      case 'knex':
        return this.client.client.releaseConnection(conn);
      default:
        return true;
    }
  }

  /**
   *
   * @returns {Promise<any>}
   * @private
   */
  _createDbAndTable() {
    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(`CREATE DATABASE IF NOT EXISTS \`${this.dbName}\`;`, (errDb) => {
            if (errDb) {
              this._releaseConnection(conn);
              return reject(errDb);
            }
            conn.query(this._getCreateTableStmt(), (err) => {
              if (err) {
                this._releaseConnection(conn);
                return reject(err);
              }
              this._releaseConnection(conn);
              resolve();
            });
          });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _getCreateTableStmt() {
    return `CREATE TABLE IF NOT EXISTS \`${this.dbName}\`.\`${this.tableName}\` (` +
      '`key` VARCHAR(255) CHARACTER SET utf8 NOT NULL,' +
      '`points` INT(9) NOT NULL default 0,' +
      '`expire` BIGINT UNSIGNED,' +
      'PRIMARY KEY (`key`)' +
      ') ENGINE = INNODB;';
  }

  get clientType() {
    return this._clientType;
  }

  set clientType(value) {
    if (typeof value === 'undefined') {
      if (this.client.constructor.name === 'Connection') {
        value = 'connection';
      } else if (this.client.constructor.name === 'Pool') {
        value = 'pool';
      } else if (this.client.constructor.name === 'Sequelize') {
        value = 'sequelize';
      } else {
        throw new Error('storeType is not defined');
      }
    }
    this._clientType = value.toLowerCase();
  }

  get dbName() {
    return this._dbName;
  }

  set dbName(value) {
    this._dbName = typeof value === 'undefined' ? 'rtlmtrflx' : value;
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get tableCreated() {
    return this._tableCreated
  }

  set tableCreated(value) {
    this._tableCreated = typeof value === 'undefined' ? false : !!value;
  }

  get clearExpiredByTimeout() {
    return this._clearExpiredByTimeout;
  }

  set clearExpiredByTimeout(value) {
    this._clearExpiredByTimeout = typeof value === 'undefined' ? true : Boolean(value);
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$8();
    const [row] = result;

    res.isFirstInDuration = changedPoints === row.points;
    res.consumedPoints = res.isFirstInDuration ? changedPoints : row.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = row.expire
      ? Math.max(row.expire - Date.now(), 0)
      : -1;

    return res;
  }

  _upsertTransaction(conn, key, points, msDuration, forceExpire) {
    return new Promise((resolve, reject) => {
      conn.query('BEGIN', (errBegin) => {
        if (errBegin) {
          conn.rollback();

          return reject(errBegin);
        }

        const dateNow = Date.now();
        const newExpire = msDuration > 0 ? dateNow + msDuration : null;

        let q;
        let values;
        if (forceExpire) {
          q = `INSERT INTO ??.?? VALUES (?, ?, ?)
          ON DUPLICATE KEY UPDATE 
            points = ?, 
            expire = ?;`;
          values = [
            this.dbName, this.tableName, key, points, newExpire,
            points,
            newExpire,
          ];
        } else {
          q = `INSERT INTO ??.?? VALUES (?, ?, ?)
          ON DUPLICATE KEY UPDATE 
            points = IF(expire <= ?, ?, points + (?)), 
            expire = IF(expire <= ?, ?, expire);`;
          values = [
            this.dbName, this.tableName, key, points, newExpire,
            dateNow, points, points,
            dateNow, newExpire,
          ];
        }

        conn.query(q, values, (errUpsert) => {
          if (errUpsert) {
            conn.rollback();

            return reject(errUpsert);
          }
          conn.query('SELECT points, expire FROM ??.?? WHERE `key` = ?;', [this.dbName, this.tableName, key], (errSelect, res) => {
            if (errSelect) {
              conn.rollback();

              return reject(errSelect);
            }

            conn.query('COMMIT', (err) => {
              if (err) {
                conn.rollback();

                return reject(err);
              }

              resolve(res);
            });
          });
        });
      });
    });
  }

  _upsert(key, points, msDuration, forceExpire = false) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          this._upsertTransaction(conn, key, points, msDuration, forceExpire)
            .then((res) => {
              resolve(res);
              this._releaseConnection(conn);
            })
            .catch((err) => {
              reject(err);
              this._releaseConnection(conn);
            });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _get(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(
            'SELECT points, expire FROM ??.?? WHERE `key` = ? AND (`expire` > ? OR `expire` IS NULL)',
            [this.dbName, this.tableName, rlKey, Date.now()],
            (err, res) => {
              if (err) {
                reject(err);
              } else if (res.length === 0) {
                resolve(null);
              } else {
                resolve(res);
              }

              this._releaseConnection(conn);
            } // eslint-disable-line
          );
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _delete(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(
            'DELETE FROM ??.?? WHERE `key` = ?',
            [this.dbName, this.tableName, rlKey],
            (err, res) => {
              if (err) {
                reject(err);
              } else {
                resolve(res.affectedRows > 0);
              }

              this._releaseConnection(conn);
            } // eslint-disable-line
          );
        })
        .catch((err) => {
          reject(err);
        });
    });
  }
};

var RateLimiterMySQL_1 = RateLimiterMySQL$1;

const RateLimiterStoreAbstract$1 = RateLimiterStoreAbstract_1;
const RateLimiterRes$7 = RateLimiterRes_1;

let RateLimiterPostgres$1 = class RateLimiterPostgres extends RateLimiterStoreAbstract$1 {
  /**
   * @callback callback
   * @param {Object} err
   *
   * @param {Object} opts
   * @param {callback} cb
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: postgresClient,
   *   storeType: 'knex', // required only for Knex instance
   *   tableName: 'string',
   * }
   */
  constructor(opts, cb = null) {
    super(opts);

    this.client = opts.storeClient;
    this.clientType = opts.storeType;

    this.tableName = opts.tableName;

    this.clearExpiredByTimeout = opts.clearExpiredByTimeout;

    this.tableCreated = opts.tableCreated;
    if (!this.tableCreated) {
      this._createTable()
        .then(() => {
          this.tableCreated = true;
          if (this.clearExpiredByTimeout) {
            this._clearExpiredHourAgo();
          }
          if (typeof cb === 'function') {
            cb();
          }
        })
        .catch((err) => {
          if (typeof cb === 'function') {
            cb(err);
          } else {
            throw err;
          }
        });
    } else {
      if (typeof cb === 'function') {
        cb();
      }
    }
  }

  clearExpired(expire) {
    return new Promise((resolve) => {
      const q = {
        name: 'rlflx-clear-expired',
        text: `DELETE FROM ${this.tableName} WHERE expire < $1`,
        values: [expire],
      };
      this._query(q)
        .then(() => {
          resolve();
        })
        .catch(() => {
          // Deleting expired query is not critical
          resolve();
        });
    });
  }

  /**
   * Delete all rows expired 1 hour ago once per 5 minutes
   *
   * @private
   */
  _clearExpiredHourAgo() {
    if (this._clearExpiredTimeoutId) {
      clearTimeout(this._clearExpiredTimeoutId);
    }
    this._clearExpiredTimeoutId = setTimeout(() => {
      this.clearExpired(Date.now() - 3600000) // Never rejected
        .then(() => {
          this._clearExpiredHourAgo();
        });
    }, 300000);
    this._clearExpiredTimeoutId.unref();
  }

  /**
   *
   * @return Promise<any>
   * @private
   */
  _getConnection() {
    switch (this.clientType) {
      case 'pool':
        return Promise.resolve(this.client);
      case 'sequelize':
        return this.client.connectionManager.getConnection();
      case 'knex':
        return this.client.client.acquireConnection();
      case 'typeorm':
        return Promise.resolve(this.client.driver.master);
      default:
        return Promise.resolve(this.client);
    }
  }

  _releaseConnection(conn) {
    switch (this.clientType) {
      case 'pool':
        return true;
      case 'sequelize':
        return this.client.connectionManager.releaseConnection(conn);
      case 'knex':
        return this.client.client.releaseConnection(conn);
      case 'typeorm':
        return true;
      default:
        return true;
    }
  }

  /**
   *
   * @returns {Promise<any>}
   * @private
   */
  _createTable() {
    return new Promise((resolve, reject) => {
      this._query({
        text: this._getCreateTableStmt(),
      })
        .then(() => {
          resolve();
        })
        .catch((err) => {
          if (err.code === '23505') {
            // Error: duplicate key value violates unique constraint "pg_type_typname_nsp_index"
            // Postgres doesn't handle concurrent table creation
            // It is supposed, that table is created by another worker
            resolve();
          } else {
            reject(err);
          }
        });
    });
  }

  _getCreateTableStmt() {
    return `CREATE TABLE IF NOT EXISTS ${this.tableName} ( 
      key varchar(255) PRIMARY KEY,
      points integer NOT NULL DEFAULT 0,
      expire bigint
    );`;
  }

  get clientType() {
    return this._clientType;
  }

  set clientType(value) {
    const constructorName = this.client.constructor.name;

    if (typeof value === 'undefined') {
      if (constructorName === 'Client') {
        value = 'client';
      } else if (
        constructorName === 'Pool' ||
        constructorName === 'BoundPool'
      ) {
        value = 'pool';
      } else if (constructorName === 'Sequelize') {
        value = 'sequelize';
      } else {
        throw new Error('storeType is not defined');
      }
    }

    this._clientType = value.toLowerCase();
  }

  get tableName() {
    return this._tableName;
  }

  set tableName(value) {
    this._tableName = typeof value === 'undefined' ? this.keyPrefix : value;
  }

  get tableCreated() {
    return this._tableCreated
  }

  set tableCreated(value) {
    this._tableCreated = typeof value === 'undefined' ? false : !!value;
  }

  get clearExpiredByTimeout() {
    return this._clearExpiredByTimeout;
  }

  set clearExpiredByTimeout(value) {
    this._clearExpiredByTimeout = typeof value === 'undefined' ? true : Boolean(value);
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$7();
    const row = result.rows[0];

    res.isFirstInDuration = changedPoints === row.points;
    res.consumedPoints = res.isFirstInDuration ? changedPoints : row.points;

    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = row.expire
      ? Math.max(row.expire - Date.now(), 0)
      : -1;

    return res;
  }

  _query(q) {
    const prefix = this.tableName.toLowerCase();
    const queryObj = { name: `${prefix}:${q.name}`, text: q.text, values: q.values };
    return new Promise((resolve, reject) => {
      this._getConnection()
        .then((conn) => {
          conn.query(queryObj)
            .then((res) => {
              resolve(res);
              this._releaseConnection(conn);
            })
            .catch((err) => {
              reject(err);
              this._releaseConnection(conn);
            });
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _upsert(key, points, msDuration, forceExpire = false) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    const newExpire = msDuration > 0 ? Date.now() + msDuration : null;
    const expireQ = forceExpire
      ? ' $3 '
      : ` CASE
             WHEN ${this.tableName}.expire <= $4 THEN $3
             ELSE ${this.tableName}.expire
            END `;

    return this._query({
      name: forceExpire ? 'rlflx-upsert-force' : 'rlflx-upsert',
      text: `
            INSERT INTO ${this.tableName} VALUES ($1, $2, $3)
              ON CONFLICT(key) DO UPDATE SET
                points = CASE
                          WHEN (${this.tableName}.expire <= $4 OR 1=${forceExpire ? 1 : 0}) THEN $2
                          ELSE ${this.tableName}.points + ($2)
                         END,
                expire = ${expireQ}
            RETURNING points, expire;`,
      values: [key, points, newExpire, Date.now()],
    });
  }

  _get(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return new Promise((resolve, reject) => {
      this._query({
        name: 'rlflx-get',
        text: `
            SELECT points, expire FROM ${this.tableName} WHERE key = $1 AND (expire > $2 OR expire IS NULL);`,
        values: [rlKey, Date.now()],
      })
        .then((res) => {
          if (res.rowCount === 0) {
            res = null;
          }
          resolve(res);
        })
        .catch((err) => {
          reject(err);
        });
    });
  }

  _delete(rlKey) {
    if (!this.tableCreated) {
      return Promise.reject(Error('Table is not created yet'));
    }

    return this._query({
      name: 'rlflx-delete',
      text: `DELETE FROM ${this.tableName} WHERE key = $1`,
      values: [rlKey],
    })
      .then(res => res.rowCount > 0);
  }
};

var RateLimiterPostgres_1 = RateLimiterPostgres$1;

var Record_1 = class Record {
  /**
   *
   * @param value int
   * @param expiresAt Date|int
   * @param timeoutId
   */
  constructor(value, expiresAt, timeoutId = null) {
    this.value = value;
    this.expiresAt = expiresAt;
    this.timeoutId = timeoutId;
  }

  get value() {
    return this._value;
  }

  set value(value) {
    this._value = parseInt(value);
  }

  get expiresAt() {
    return this._expiresAt;
  }

  set expiresAt(value) {
    if (!(value instanceof Date) && Number.isInteger(value)) {
      value = new Date(value);
    }
    this._expiresAt = value;
  }

  get timeoutId() {
    return this._timeoutId;
  }

  set timeoutId(value) {
    this._timeoutId = value;
  }
};

const Record = Record_1;
const RateLimiterRes$6 = RateLimiterRes_1;

var MemoryStorage_1 = class MemoryStorage {
  constructor() {
    /**
     * @type {Object.<string, Record>}
     * @private
     */
    this._storage = {};
  }

  incrby(key, value, durationSec) {
    if (this._storage[key]) {
      const msBeforeExpires = this._storage[key].expiresAt
        ? this._storage[key].expiresAt.getTime() - new Date().getTime()
        : -1;
      if (msBeforeExpires !== 0) {
        // Change value
        this._storage[key].value = this._storage[key].value + value;

        return new RateLimiterRes$6(0, msBeforeExpires, this._storage[key].value, false);
      }

      return this.set(key, value, durationSec);
    }
    return this.set(key, value, durationSec);
  }

  set(key, value, durationSec) {
    const durationMs = durationSec * 1000;

    if (this._storage[key] && this._storage[key].timeoutId) {
      clearTimeout(this._storage[key].timeoutId);
    }

    this._storage[key] = new Record(
      value,
      durationMs > 0 ? new Date(Date.now() + durationMs) : null
    );
    if (durationMs > 0) {
      this._storage[key].timeoutId = setTimeout(() => {
        delete this._storage[key];
      }, durationMs);
      if (this._storage[key].timeoutId.unref) {
        this._storage[key].timeoutId.unref();
      }
    }

    return new RateLimiterRes$6(0, durationMs === 0 ? -1 : durationMs, this._storage[key].value, true);
  }

  /**
   *
   * @param key
   * @returns {*}
   */
  get(key) {
    if (this._storage[key]) {
      const msBeforeExpires = this._storage[key].expiresAt
        ? this._storage[key].expiresAt.getTime() - new Date().getTime()
        : -1;
      return new RateLimiterRes$6(0, msBeforeExpires, this._storage[key].value, false);
    }
    return null;
  }

  /**
   *
   * @param key
   * @returns {boolean}
   */
  delete(key) {
    if (this._storage[key]) {
      if (this._storage[key].timeoutId) {
        clearTimeout(this._storage[key].timeoutId);
      }
      delete this._storage[key];
      return true;
    }
    return false;
  }
};

const RateLimiterAbstract$2 = RateLimiterAbstract_1;
const MemoryStorage = MemoryStorage_1;
const RateLimiterRes$5 = RateLimiterRes_1;

let RateLimiterMemory$2 = class RateLimiterMemory extends RateLimiterAbstract$2 {
  constructor(opts = {}) {
    super(opts);

    this._memoryStorage = new MemoryStorage();
  }
  /**
   *
   * @param key
   * @param pointsToConsume
   * @param {Object} options
   * @returns {Promise<RateLimiterRes>}
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const rlKey = this.getKey(key);
      const secDuration = this._getKeySecDuration(options);
      let res = this._memoryStorage.incrby(rlKey, pointsToConsume, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);

      if (res.consumedPoints > this.points) {
        // Block only first time when consumed more than points
        if (this.blockDuration > 0 && res.consumedPoints <= (this.points + pointsToConsume)) {
          // Block key
          res = this._memoryStorage.set(rlKey, res.consumedPoints, this.blockDuration);
        }
        reject(res);
      } else if (this.execEvenly && res.msBeforeNext > 0 && !res.isFirstInDuration) {
        // Execute evenly
        let delay = Math.ceil(res.msBeforeNext / (res.remainingPoints + 2));
        if (delay < this.execEvenlyMinDelayMs) {
          delay = res.consumedPoints * this.execEvenlyMinDelayMs;
        }

        setTimeout(resolve, delay, res);
      } else {
        resolve(res);
      }
    });
  }

  penalty(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve) => {
      const secDuration = this._getKeySecDuration(options);
      const res = this._memoryStorage.incrby(rlKey, points, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
      resolve(res);
    });
  }

  reward(key, points = 1, options = {}) {
    const rlKey = this.getKey(key);
    return new Promise((resolve) => {
      const secDuration = this._getKeySecDuration(options);
      const res = this._memoryStorage.incrby(rlKey, -points, secDuration);
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
      resolve(res);
    });
  }

  /**
   * Block any key for secDuration seconds
   *
   * @param key
   * @param secDuration
   */
  block(key, secDuration) {
    const msDuration = secDuration * 1000;
    const initPoints = this.points + 1;

    this._memoryStorage.set(this.getKey(key), initPoints, secDuration);
    return Promise.resolve(
      new RateLimiterRes$5(0, msDuration === 0 ? -1 : msDuration, initPoints)
    );
  }

  set(key, points, secDuration) {
    const msDuration = (secDuration >= 0 ? secDuration : this.duration) * 1000;

    this._memoryStorage.set(this.getKey(key), points, secDuration);
    return Promise.resolve(
      new RateLimiterRes$5(0, msDuration === 0 ? -1 : msDuration, points)
    );
  }

  get(key) {
    const res = this._memoryStorage.get(this.getKey(key));
    if (res !== null) {
      res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    }

    return Promise.resolve(res);
  }

  delete(key) {
    return Promise.resolve(this._memoryStorage.delete(this.getKey(key)));
  }
};

var RateLimiterMemory_1 = RateLimiterMemory$2;

/**
 * Implements rate limiting in cluster using built-in IPC
 *
 * Two classes are described here: master and worker
 * Master have to be create in the master process without any options.
 * Any number of rate limiters can be created in workers, but each rate limiter must be with unique keyPrefix
 *
 * Workflow:
 * 1. master rate limiter created in master process
 * 2. worker rate limiter sends 'init' message with necessary options during creating
 * 3. master receives options and adds new rate limiter by keyPrefix if it isn't created yet
 * 4. master sends 'init' back to worker's rate limiter
 * 5. worker can process requests immediately,
 *    but they will be postponed by 'workerWaitInit' until master sends 'init' to worker
 * 6. every request to worker rate limiter creates a promise
 * 7. if master doesn't response for 'timeout', promise is rejected
 * 8. master sends 'resolve' or 'reject' command to worker
 * 9. worker resolves or rejects promise depending on message from master
 *
 */

const cluster = require$$1;
const crypto$1 = require$$1;
const RateLimiterAbstract$1 = RateLimiterAbstract_1;
const RateLimiterMemory$1 = RateLimiterMemory_1;
const RateLimiterRes$4 = RateLimiterRes_1;

const channel = 'rate_limiter_flexible';
let masterInstance = null;

const masterSendToWorker = function (worker, msg, type, res) {
  let data;
  if (res === null || res === true || res === false) {
    data = res;
  } else {
    data = {
      remainingPoints: res.remainingPoints,
      msBeforeNext: res.msBeforeNext,
      consumedPoints: res.consumedPoints,
      isFirstInDuration: res.isFirstInDuration,
    };
  }
  worker.send({
    channel,
    keyPrefix: msg.keyPrefix, // which rate limiter exactly
    promiseId: msg.promiseId,
    type,
    data,
  });
};

const workerWaitInit = function (payload) {
  setTimeout(() => {
    if (this._initiated) {
      process.send(payload);
      // Promise will be removed by timeout if too long
    } else if (typeof this._promises[payload.promiseId] !== 'undefined') {
      workerWaitInit.call(this, payload);
    }
  }, 30);
};

const workerSendToMaster = function (func, promiseId, key, arg, opts) {
  const payload = {
    channel,
    keyPrefix: this.keyPrefix,
    func,
    promiseId,
    data: {
      key,
      arg,
      opts,
    },
  };

  if (!this._initiated) {
    // Wait init before sending messages to master
    workerWaitInit.call(this, payload);
  } else {
    process.send(payload);
  }
};

const masterProcessMsg = function (worker, msg) {
  if (!msg || msg.channel !== channel || typeof this._rateLimiters[msg.keyPrefix] === 'undefined') {
    return false;
  }

  let promise;

  switch (msg.func) {
    case 'consume':
      promise = this._rateLimiters[msg.keyPrefix].consume(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'penalty':
      promise = this._rateLimiters[msg.keyPrefix].penalty(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'reward':
      promise = this._rateLimiters[msg.keyPrefix].reward(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'block':
      promise = this._rateLimiters[msg.keyPrefix].block(msg.data.key, msg.data.arg, msg.data.opts);
      break;
    case 'get':
      promise = this._rateLimiters[msg.keyPrefix].get(msg.data.key, msg.data.opts);
      break;
    case 'delete':
      promise = this._rateLimiters[msg.keyPrefix].delete(msg.data.key, msg.data.opts);
      break;
    default:
      return false;
  }

  if (promise) {
    promise
      .then((res) => {
        masterSendToWorker(worker, msg, 'resolve', res);
      })
      .catch((rejRes) => {
        masterSendToWorker(worker, msg, 'reject', rejRes);
      });
  }
};

const workerProcessMsg = function (msg) {
  if (!msg || msg.channel !== channel || msg.keyPrefix !== this.keyPrefix) {
    return false;
  }

  if (this._promises[msg.promiseId]) {
    clearTimeout(this._promises[msg.promiseId].timeoutId);
    let res;
    if (msg.data === null || msg.data === true || msg.data === false) {
      res = msg.data;
    } else {
      res = new RateLimiterRes$4(
        msg.data.remainingPoints,
        msg.data.msBeforeNext,
        msg.data.consumedPoints,
        msg.data.isFirstInDuration // eslint-disable-line comma-dangle
      );
    }

    switch (msg.type) {
      case 'resolve':
        this._promises[msg.promiseId].resolve(res);
        break;
      case 'reject':
        this._promises[msg.promiseId].reject(res);
        break;
      default:
        throw new Error(`RateLimiterCluster: no such message type '${msg.type}'`);
    }

    delete this._promises[msg.promiseId];
  }
};
/**
 * Prepare options to send to master
 * Master will create rate limiter depending on options
 *
 * @returns {{points: *, duration: *, blockDuration: *, execEvenly: *, execEvenlyMinDelayMs: *, keyPrefix: *}}
 */
const getOpts = function () {
  return {
    points: this.points,
    duration: this.duration,
    blockDuration: this.blockDuration,
    execEvenly: this.execEvenly,
    execEvenlyMinDelayMs: this.execEvenlyMinDelayMs,
    keyPrefix: this.keyPrefix,
  };
};

const savePromise = function (resolve, reject) {
  const hrtime = process.hrtime();
  let promiseId = hrtime[0].toString() + hrtime[1].toString();

  if (typeof this._promises[promiseId] !== 'undefined') {
    promiseId += crypto$1.randomBytes(12).toString('base64');
  }

  this._promises[promiseId] = {
    resolve,
    reject,
    timeoutId: setTimeout(() => {
      delete this._promises[promiseId];
      reject(new Error('RateLimiterCluster timeout: no answer from master in time'));
    }, this.timeoutMs),
  };

  return promiseId;
};

let RateLimiterClusterMaster$1 = class RateLimiterClusterMaster {
  constructor() {
    if (masterInstance) {
      return masterInstance;
    }

    this._rateLimiters = {};

    cluster.setMaxListeners(0);

    cluster.on('message', (worker, msg) => {
      if (msg && msg.channel === channel && msg.type === 'init') {
        // If init request, check or create rate limiter by key prefix and send 'init' back to worker
        if (typeof this._rateLimiters[msg.opts.keyPrefix] === 'undefined') {
          this._rateLimiters[msg.opts.keyPrefix] = new RateLimiterMemory$1(msg.opts);
        }

        worker.send({
          channel,
          type: 'init',
          keyPrefix: msg.opts.keyPrefix,
        });
      } else {
        masterProcessMsg.call(this, worker, msg);
      }
    });

    masterInstance = this;
  }
};

let RateLimiterClusterMasterPM2$1 = class RateLimiterClusterMasterPM2 {
  constructor(pm2) {
    if (masterInstance) {
      return masterInstance;
    }

    this._rateLimiters = {};

    pm2.launchBus((err, pm2Bus) => {
      pm2Bus.on('process:msg', (packet) => {
        const msg = packet.raw;
        if (msg && msg.channel === channel && msg.type === 'init') {
          // If init request, check or create rate limiter by key prefix and send 'init' back to worker
          if (typeof this._rateLimiters[msg.opts.keyPrefix] === 'undefined') {
            this._rateLimiters[msg.opts.keyPrefix] = new RateLimiterMemory$1(msg.opts);
          }

          pm2.sendDataToProcessId(packet.process.pm_id, {
            data: {},
            topic: channel,
            channel,
            type: 'init',
            keyPrefix: msg.opts.keyPrefix,
          }, (sendErr, res) => {
            if (sendErr) {
              console.log(sendErr, res);
            }
          });
        } else {
          const worker = {
            send: (msgData) => {
              const pm2Message = msgData;
              pm2Message.topic = channel;
              if (typeof pm2Message.data === 'undefined') {
                pm2Message.data = {};
              }
              pm2.sendDataToProcessId(packet.process.pm_id, pm2Message, (sendErr, res) => {
                if (sendErr) {
                  console.log(sendErr, res);
                }
              });
            },
          };
          masterProcessMsg.call(this, worker, msg);
        }
      });
    });

    masterInstance = this;
  }
};

class RateLimiterClusterWorker extends RateLimiterAbstract$1 {
  get timeoutMs() {
    return this._timeoutMs;
  }

  set timeoutMs(value) {
    this._timeoutMs = typeof value === 'undefined' ? 5000 : Math.abs(parseInt(value));
  }

  constructor(opts = {}) {
    super(opts);

    process.setMaxListeners(0);

    this.timeoutMs = opts.timeoutMs;

    this._initiated = false;

    process.on('message', (msg) => {
      if (msg && msg.channel === channel && msg.type === 'init' && msg.keyPrefix === this.keyPrefix) {
        this._initiated = true;
      } else {
        workerProcessMsg.call(this, msg);
      }
    });

    // Create limiter on master with specific options
    process.send({
      channel,
      type: 'init',
      opts: getOpts.call(this),
    });

    this._promises = {};
  }

  consume(key, pointsToConsume = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'consume', promiseId, key, pointsToConsume, options);
    });
  }

  penalty(key, points = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'penalty', promiseId, key, points, options);
    });
  }

  reward(key, points = 1, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'reward', promiseId, key, points, options);
    });
  }

  block(key, secDuration, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'block', promiseId, key, secDuration, options);
    });
  }

  get(key, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'get', promiseId, key, options);
    });
  }

  delete(key, options = {}) {
    return new Promise((resolve, reject) => {
      const promiseId = savePromise.call(this, resolve, reject);

      workerSendToMaster.call(this, 'delete', promiseId, key, options);
    });
  }
}

var RateLimiterCluster$1 = {
  RateLimiterClusterMaster: RateLimiterClusterMaster$1,
  RateLimiterClusterMasterPM2: RateLimiterClusterMasterPM2$1,
  RateLimiterCluster: RateLimiterClusterWorker,
};

const RateLimiterStoreAbstract = RateLimiterStoreAbstract_1;
const RateLimiterRes$3 = RateLimiterRes_1;

let RateLimiterMemcache$1 = class RateLimiterMemcache extends RateLimiterStoreAbstract {
  /**
   *
   * @param {Object} opts
   * Defaults {
   *   ... see other in RateLimiterStoreAbstract
   *
   *   storeClient: memcacheClient
   * }
   */
  constructor(opts) {
    super(opts);

    this.client = opts.storeClient;
  }

  _getRateLimiterRes(rlKey, changedPoints, result) {
    const res = new RateLimiterRes$3();
    res.consumedPoints = parseInt(result.consumedPoints);
    res.isFirstInDuration = result.consumedPoints === changedPoints;
    res.remainingPoints = Math.max(this.points - res.consumedPoints, 0);
    res.msBeforeNext = result.msBeforeNext;

    return res;
  }

  _upsert(rlKey, points, msDuration, forceExpire = false, options = {}) {
    return new Promise((resolve, reject) => {
      const nowMs = Date.now();
      const secDuration = Math.floor(msDuration / 1000);

      if (forceExpire) {
        this.client.set(rlKey, points, secDuration, (err) => {
          if (!err) {
            this.client.set(
              `${rlKey}_expire`,
              secDuration > 0 ? nowMs + (secDuration * 1000) : -1,
              secDuration,
              () => {
                const res = {
                  consumedPoints: points,
                  msBeforeNext: secDuration > 0 ? secDuration * 1000 : -1,
                };
                resolve(res);
              }
            );
          } else {
            reject(err);
          }
        });
      } else {
        this.client.incr(rlKey, points, (err, consumedPoints) => {
          if (err || consumedPoints === false) {
            this.client.add(rlKey, points, secDuration, (errAddKey, createdNew) => {
              if (errAddKey || !createdNew) {
                // Try to upsert again in case of race condition
                if (typeof options.attemptNumber === 'undefined' || options.attemptNumber < 3) {
                  const nextOptions = Object.assign({}, options);
                  nextOptions.attemptNumber = nextOptions.attemptNumber ? (nextOptions.attemptNumber + 1) : 1;

                  this._upsert(rlKey, points, msDuration, forceExpire, nextOptions)
                    .then(resUpsert => resolve(resUpsert))
                    .catch(errUpsert => reject(errUpsert));
                } else {
                  reject(new Error('Can not add key'));
                }
              } else {
                this.client.add(
                  `${rlKey}_expire`,
                  secDuration > 0 ? nowMs + (secDuration * 1000) : -1,
                  secDuration,
                  () => {
                    const res = {
                      consumedPoints: points,
                      msBeforeNext: secDuration > 0 ? secDuration * 1000 : -1,
                    };
                    resolve(res);
                  }
                );
              }
            });
          } else {
            this.client.get(`${rlKey}_expire`, (errGetExpire, resGetExpireMs) => {
              if (errGetExpire) {
                reject(errGetExpire);
              } else {
                const expireMs = resGetExpireMs === false ? 0 : resGetExpireMs;
                const res = {
                  consumedPoints,
                  msBeforeNext: expireMs >= 0 ? Math.max(expireMs - nowMs, 0) : -1,
                };
                resolve(res);
              }
            });
          }
        });
      }
    });
  }

  _get(rlKey) {
    return new Promise((resolve, reject) => {
      const nowMs = Date.now();

      this.client.get(rlKey, (err, consumedPoints) => {
        if (!consumedPoints) {
          resolve(null);
        } else {
          this.client.get(`${rlKey}_expire`, (errGetExpire, resGetExpireMs) => {
            if (errGetExpire) {
              reject(errGetExpire);
            } else {
              const expireMs = resGetExpireMs === false ? 0 : resGetExpireMs;
              const res = {
                consumedPoints,
                msBeforeNext: expireMs >= 0 ? Math.max(expireMs - nowMs, 0) : -1,
              };
              resolve(res);
            }
          });
        }
      });
    });
  }

  _delete(rlKey) {
    return new Promise((resolve, reject) => {
      this.client.del(rlKey, (err, res) => {
        if (err) {
          reject(err);
        } else if (res === false) {
          resolve(res);
        } else {
          this.client.del(`${rlKey}_expire`, (errDelExpire) => {
            if (errDelExpire) {
              reject(errDelExpire);
            } else {
              resolve(res);
            }
          });
        }
      });
    });
  }
};

var RateLimiterMemcache_1 = RateLimiterMemcache$1;

const RateLimiterRes$2 = RateLimiterRes_1;

var RLWrapperBlackAndWhite_1 = class RLWrapperBlackAndWhite {
  constructor(opts = {}) {
    this.limiter = opts.limiter;
    this.blackList = opts.blackList;
    this.whiteList = opts.whiteList;
    this.isBlackListed = opts.isBlackListed;
    this.isWhiteListed = opts.isWhiteListed;
    this.runActionAnyway = opts.runActionAnyway;
  }

  get limiter() {
    return this._limiter;
  }

  set limiter(value) {
    if (typeof value === 'undefined') {
      throw new Error('limiter is not set');
    }

    this._limiter = value;
  }

  get runActionAnyway() {
    return this._runActionAnyway;
  }

  set runActionAnyway(value) {
    this._runActionAnyway = typeof value === 'undefined' ? false : value;
  }

  get blackList() {
    return this._blackList;
  }

  set blackList(value) {
    this._blackList = Array.isArray(value) ? value : [];
  }

  get isBlackListed() {
    return this._isBlackListed;
  }

  set isBlackListed(func) {
    if (typeof func === 'undefined') {
      func = () => false;
    }
    if (typeof func !== 'function') {
      throw new Error('isBlackListed must be function');
    }
    this._isBlackListed = func;
  }

  get whiteList() {
    return this._whiteList;
  }

  set whiteList(value) {
    this._whiteList = Array.isArray(value) ? value : [];
  }

  get isWhiteListed() {
    return this._isWhiteListed;
  }

  set isWhiteListed(func) {
    if (typeof func === 'undefined') {
      func = () => false;
    }
    if (typeof func !== 'function') {
      throw new Error('isWhiteListed must be function');
    }
    this._isWhiteListed = func;
  }

  isBlackListedSomewhere(key) {
    return this.blackList.indexOf(key) >= 0 || this.isBlackListed(key);
  }

  isWhiteListedSomewhere(key) {
    return this.whiteList.indexOf(key) >= 0 || this.isWhiteListed(key);
  }

  getBlackRes() {
    return new RateLimiterRes$2(0, Number.MAX_SAFE_INTEGER, 0, false);
  }

  getWhiteRes() {
    return new RateLimiterRes$2(Number.MAX_SAFE_INTEGER, 0, 0, false);
  }

  rejectBlack() {
    return Promise.reject(this.getBlackRes());
  }

  resolveBlack() {
    return Promise.resolve(this.getBlackRes());
  }

  resolveWhite() {
    return Promise.resolve(this.getWhiteRes());
  }

  consume(key, pointsToConsume = 1) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.rejectBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.consume(key, pointsToConsume);
    }

    if (this.runActionAnyway) {
      this.limiter.consume(key, pointsToConsume).catch(() => {});
    }
    return res;
  }

  block(key, secDuration) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.block(key, secDuration);
    }

    if (this.runActionAnyway) {
      this.limiter.block(key, secDuration).catch(() => {});
    }
    return res;
  }

  penalty(key, points) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.penalty(key, points);
    }

    if (this.runActionAnyway) {
      this.limiter.penalty(key, points).catch(() => {});
    }
    return res;
  }

  reward(key, points) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined') {
      return this.limiter.reward(key, points);
    }

    if (this.runActionAnyway) {
      this.limiter.reward(key, points).catch(() => {});
    }
    return res;
  }

  get(key) {
    let res;
    if (this.isWhiteListedSomewhere(key)) {
      res = this.resolveWhite();
    } else if (this.isBlackListedSomewhere(key)) {
      res = this.resolveBlack();
    }

    if (typeof res === 'undefined' || this.runActionAnyway) {
      return this.limiter.get(key);
    }

    return res;
  }

  delete(key) {
    return this.limiter.delete(key);
  }
};

const RateLimiterAbstract = RateLimiterAbstract_1;

var RateLimiterUnion_1 = class RateLimiterUnion {
  constructor(...limiters) {
    if (limiters.length < 1) {
      throw new Error('RateLimiterUnion: at least one limiter have to be passed');
    }
    limiters.forEach((limiter) => {
      if (!(limiter instanceof RateLimiterAbstract)) {
        throw new Error('RateLimiterUnion: all limiters have to be instance of RateLimiterAbstract');
      }
    });

    this._limiters = limiters;
  }

  consume(key, points = 1) {
    return new Promise((resolve, reject) => {
      const promises = [];
      this._limiters.forEach((limiter) => {
        promises.push(limiter.consume(key, points).catch(rej => ({ rejected: true, rej })));
      });

      Promise.all(promises)
        .then((res) => {
          const resObj = {};
          let rejected = false;

          res.forEach((item) => {
            if (item.rejected === true) {
              rejected = true;
            }
          });

          for (let i = 0; i < res.length; i++) {
            if (rejected && res[i].rejected === true) {
              resObj[this._limiters[i].keyPrefix] = res[i].rej;
            } else if (!rejected) {
              resObj[this._limiters[i].keyPrefix] = res[i];
            }
          }

          if (rejected) {
            reject(resObj);
          } else {
            resolve(resObj);
          }
        });
    });
  }
};

var RateLimiterQueueError_1 = class RateLimiterQueueError extends Error {
  constructor(message, extra) {
    super();
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, this.constructor);
    }
    this.name = 'CustomError';
    this.message = message;
    if (extra) {
      this.extra = extra;
    }
  }
};

const RateLimiterQueueError = RateLimiterQueueError_1;
const MAX_QUEUE_SIZE = 4294967295;
const KEY_DEFAULT = 'limiter';

var RateLimiterQueue_1 = class RateLimiterQueue {
  constructor(limiterFlexible, opts = {
    maxQueueSize: MAX_QUEUE_SIZE,
  }) {
    this._queueLimiters = {
      KEY_DEFAULT: new RateLimiterQueueInternal(limiterFlexible, opts)
    };
    this._limiterFlexible = limiterFlexible;
    this._maxQueueSize = opts.maxQueueSize;
  }

  getTokensRemaining(key = KEY_DEFAULT) {
    if (this._queueLimiters[key]) {
      return this._queueLimiters[key].getTokensRemaining()
    } else {
      return Promise.resolve(this._limiterFlexible.points)
    }
  }

  removeTokens(tokens, key = KEY_DEFAULT) {
    if (!this._queueLimiters[key]) {
      this._queueLimiters[key] = new RateLimiterQueueInternal(
        this._limiterFlexible, {
          key,
          maxQueueSize: this._maxQueueSize,
        });
    }

    return this._queueLimiters[key].removeTokens(tokens)
  }
};

class RateLimiterQueueInternal {

  constructor(limiterFlexible, opts = {
    maxQueueSize: MAX_QUEUE_SIZE,
    key: KEY_DEFAULT,
  }) {
    this._key = opts.key;
    this._waitTimeout = null;
    this._queue = [];
    this._limiterFlexible = limiterFlexible;

    this._maxQueueSize = opts.maxQueueSize;
  }

  getTokensRemaining() {
    return this._limiterFlexible.get(this._key)
      .then((rlRes) => {
        return rlRes !== null ? rlRes.remainingPoints : this._limiterFlexible.points;
      })
  }

  removeTokens(tokens) {
    const _this = this;

    return new Promise((resolve, reject) => {
      if (tokens > _this._limiterFlexible.points) {
        reject(new RateLimiterQueueError(`Requested tokens ${tokens} exceeds maximum ${_this._limiterFlexible.points} tokens per interval`));
        return
      }

      if (_this._queue.length > 0) {
        _this._queueRequest.call(_this, resolve, reject, tokens);
      } else {
        _this._limiterFlexible.consume(_this._key, tokens)
          .then((res) => {
            resolve(res.remainingPoints);
          })
          .catch((rej) => {
            if (rej instanceof Error) {
              reject(rej);
            } else {
              _this._queueRequest.call(_this, resolve, reject, tokens);
              if (_this._waitTimeout === null) {
                _this._waitTimeout = setTimeout(_this._processFIFO.bind(_this), rej.msBeforeNext);
              }
            }
          });
      }
    })
  }

  _queueRequest(resolve, reject, tokens) {
    const _this = this;
    if (_this._queue.length < _this._maxQueueSize) {
      _this._queue.push({resolve, reject, tokens});
    } else {
      reject(new RateLimiterQueueError(`Number of requests reached it's maximum ${_this._maxQueueSize}`));
    }
  }

  _processFIFO() {
    const _this = this;

    if (_this._waitTimeout !== null) {
      clearTimeout(_this._waitTimeout);
      _this._waitTimeout = null;
    }

    if (_this._queue.length === 0) {
      return;
    }

    const item = _this._queue.shift();
    _this._limiterFlexible.consume(_this._key, item.tokens)
      .then((res) => {
        item.resolve(res.remainingPoints);
        _this._processFIFO.call(_this);
      })
      .catch((rej) => {
        if (rej instanceof Error) {
          item.reject(rej);
          _this._processFIFO.call(_this);
        } else {
          _this._queue.unshift(item);
          if (_this._waitTimeout === null) {
            _this._waitTimeout = setTimeout(_this._processFIFO.bind(_this), rej.msBeforeNext);
          }
        }
      });
  }
}

const RateLimiterRes$1 = RateLimiterRes_1;

/**
 * Bursty rate limiter exposes only msBeforeNext time and doesn't expose points from bursty limiter by default
 * @type {BurstyRateLimiter}
 */
var BurstyRateLimiter_1 = class BurstyRateLimiter {
  constructor(rateLimiter, burstLimiter) {
    this._rateLimiter = rateLimiter;
    this._burstLimiter = burstLimiter;
  }

  /**
   * Merge rate limiter response objects. Responses can be null
   *
   * @param {RateLimiterRes} [rlRes] Rate limiter response
   * @param {RateLimiterRes} [blRes] Bursty limiter response
   */
  _combineRes(rlRes, blRes) {
    if (!rlRes) {
      return null
    }

    return new RateLimiterRes$1(
      rlRes.remainingPoints,
      Math.min(rlRes.msBeforeNext, blRes ? blRes.msBeforeNext : 0),
      rlRes.consumedPoints,
      rlRes.isFirstInDuration
    )
  }

  /**
   * @param key
   * @param pointsToConsume
   * @param options
   * @returns {Promise<any>}
   */
  consume(key, pointsToConsume = 1, options = {}) {
    return this._rateLimiter.consume(key, pointsToConsume, options)
      .catch((rlRej) => {
        if (rlRej instanceof RateLimiterRes$1) {
          return this._burstLimiter.consume(key, pointsToConsume, options)
            .then((blRes) => {
              return Promise.resolve(this._combineRes(rlRej, blRes))
            })
            .catch((blRej) => {
                if (blRej instanceof RateLimiterRes$1) {
                  return Promise.reject(this._combineRes(rlRej, blRej))
                } else {
                  return Promise.reject(blRej)
                }
              }
            )
        } else {
          return Promise.reject(rlRej)
        }
      })
  }

  /**
   * It doesn't expose available points from burstLimiter
   *
   * @param key
   * @returns {Promise<RateLimiterRes>}
   */
  get(key) {
    return Promise.all([
      this._rateLimiter.get(key),
      this._burstLimiter.get(key),
    ]).then(([rlRes, blRes]) => {
      return this._combineRes(rlRes, blRes);
    });
  }

  get points() {
    return this._rateLimiter.points;
  }
};

const RateLimiterRedis = RateLimiterRedis_1;
const RateLimiterMongo = RateLimiterMongo_1;
const RateLimiterMySQL = RateLimiterMySQL_1;
const RateLimiterPostgres = RateLimiterPostgres_1;
const {RateLimiterClusterMaster, RateLimiterClusterMasterPM2, RateLimiterCluster} = RateLimiterCluster$1;
const RateLimiterMemory = RateLimiterMemory_1;
const RateLimiterMemcache = RateLimiterMemcache_1;
const RLWrapperBlackAndWhite = RLWrapperBlackAndWhite_1;
const RateLimiterUnion = RateLimiterUnion_1;
const RateLimiterQueue = RateLimiterQueue_1;
const BurstyRateLimiter = BurstyRateLimiter_1;
const RateLimiterRes = RateLimiterRes_1;

var rateLimiterFlexible = {
  RateLimiterRedis,
  RateLimiterMongo,
  RateLimiterMySQL,
  RateLimiterPostgres,
  RateLimiterMemory,
  RateLimiterMemcache,
  RateLimiterClusterMaster,
  RateLimiterClusterMasterPM2,
  RateLimiterCluster,
  RLWrapperBlackAndWhite,
  RateLimiterUnion,
  RateLimiterQueue,
  BurstyRateLimiter,
  RateLimiterRes,
};

const log$g = logger$2('libp2p:get-peer');
/**
 * Extracts a PeerId and/or multiaddr from the passed PeerId or Multiaddr or an array of Multiaddrs
 */
function getPeerAddress(peer) {
    if (isPeerId(peer)) {
        return { peerId: peer, multiaddrs: [] };
    }
    if (!Array.isArray(peer)) {
        peer = [peer];
    }
    let peerId;
    if (peer.length > 0) {
        const peerIdStr = peer[0].getPeerId();
        peerId = peerIdStr == null ? undefined : peerIdFromString(peerIdStr);
        // ensure PeerId is either not set or is consistent
        peer.forEach(ma => {
            if (!isMultiaddr$1(ma)) {
                log$g.error('multiaddr %s was invalid', ma);
                throw new CodeError$3('Invalid Multiaddr', codes.ERR_INVALID_MULTIADDR);
            }
            const maPeerIdStr = ma.getPeerId();
            if (maPeerIdStr == null) {
                if (peerId != null) {
                    throw new CodeError$3('Multiaddrs must all have the same peer id or have no peer id', codes.ERR_INVALID_PARAMETERS);
                }
            }
            else {
                const maPeerId = peerIdFromString(maPeerIdStr);
                if (peerId == null || !peerId.equals(maPeerId)) {
                    throw new CodeError$3('Multiaddrs must all have the same peer id or have no peer id', codes.ERR_INVALID_PARAMETERS);
                }
            }
        });
    }
    return {
        peerId,
        multiaddrs: peer
    };
}

/* eslint-disable @typescript-eslint/no-non-null-assertion */
// Port of lower_bound from https://en.cppreference.com/w/cpp/algorithm/lower_bound
// Used to compute insertion index to keep queue sorted after insertion
function lowerBound(array, value, comparator) {
    let first = 0;
    let count = array.length;
    while (count > 0) {
        const step = Math.trunc(count / 2);
        let it = first + step;
        if (comparator(array[it], value) <= 0) {
            first = ++it;
            count -= step + 1;
        }
        else {
            count = step;
        }
    }
    return first;
}
/**
 * Port of https://github.com/sindresorhus/p-queue/blob/main/source/priority-queue.ts
 * that adds support for filtering jobs by peer id
 */
class PeerPriorityQueue {
    #queue = [];
    enqueue(run, options) {
        const peerId = options?.peerId;
        const priority = options?.priority ?? 0;
        if (peerId == null) {
            throw new CodeError$3('missing peer id', codes.ERR_INVALID_PARAMETERS);
        }
        const element = {
            priority,
            peerId,
            run
        };
        if (this.size > 0 && this.#queue[this.size - 1].priority >= priority) {
            this.#queue.push(element);
            return;
        }
        const index = lowerBound(this.#queue, element, (a, b) => b.priority - a.priority);
        this.#queue.splice(index, 0, element);
    }
    dequeue() {
        const item = this.#queue.shift();
        return item?.run;
    }
    filter(options) {
        if (options.peerId != null) {
            const peerId = options.peerId;
            return this.#queue.filter((element) => peerId.equals(element.peerId)).map((element) => element.run);
        }
        return this.#queue.filter((element) => element.priority === options.priority).map((element) => element.run);
    }
    get size() {
        return this.#queue.length;
    }
}
/**
 * Extends PQueue to add support for querying queued jobs by peer id
 */
class PeerJobQueue extends PQueue {
    constructor(options = {}) {
        super({
            ...options,
            queueClass: PeerPriorityQueue
        });
    }
    /**
     * Returns true if this queue has a job for the passed peer id that has not yet
     * started to run
     */
    hasJob(peerId) {
        return this.sizeBy({
            peerId
        }) > 0;
    }
}

/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#dialTimeout
 */
const DIAL_TIMEOUT = 30e3;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#inboundUpgradeTimeout
 */
const INBOUND_UPGRADE_TIMEOUT = 30e3;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxPeerAddrsToDial
 */
const MAX_PEER_ADDRS_TO_DIAL = 25;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxParallelDialsPerPeer
 */
const MAX_PARALLEL_DIALS_PER_PEER = 10;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#autoDialInterval
 */
const AUTO_DIAL_INTERVAL = 5000;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#autoDialPriority
 */
const AUTO_DIAL_PRIORITY = 0;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#autoDialMaxQueueLength
 */
const AUTO_DIAL_MAX_QUEUE_LENGTH = 100;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/libp2p.index.unknown.ConnectionManagerInit.html#autoDialPeerRetryThreshold
 */
const AUTO_DIAL_PEER_RETRY_THRESHOLD = 1000 * 60;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/libp2p.index.unknown.ConnectionManagerInit.html#autoDialDiscoveredPeersDebounce
 */
const AUTO_DIAL_DISCOVERED_PEERS_DEBOUNCE = 10;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#inboundConnectionThreshold
 */
const INBOUND_CONNECTION_THRESHOLD = 5;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxIncomingPendingConnections
 */
const MAX_INCOMING_PENDING_CONNECTIONS = 10;
/**
 * Store as part of the peer store metadata for a given peer, the value for this
 * key is a timestamp of the last time a dial attempted failed with the relevant
 * peer stored as a string.
 *
 * Used to insure we do not endlessly try to auto dial peers we have recently
 * failed to dial.
 */
const LAST_DIAL_FAILURE_KEY = 'last-dial-failure';

/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxParallelDials
 */
const MAX_PARALLEL_DIALS = 10;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#minConnections
 */
const MIN_CONNECTIONS = 5;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#maxConnections
 */
const MAX_CONNECTIONS = 100;
/**
 * @see https://libp2p.github.io/js-libp2p/interfaces/index._internal_.ConnectionManagerConfig.html#autoDialConcurrency
 */
const AUTO_DIAL_CONCURRENCY = 10;

const log$f = logger$2('libp2p:connection-manager:auto-dial');
const defaultOptions$3 = {
    minConnections: MIN_CONNECTIONS,
    maxQueueLength: AUTO_DIAL_MAX_QUEUE_LENGTH,
    autoDialConcurrency: AUTO_DIAL_CONCURRENCY,
    autoDialPriority: AUTO_DIAL_PRIORITY,
    autoDialInterval: AUTO_DIAL_INTERVAL,
    autoDialPeerRetryThreshold: AUTO_DIAL_PEER_RETRY_THRESHOLD,
    autoDialDiscoveredPeersDebounce: AUTO_DIAL_DISCOVERED_PEERS_DEBOUNCE
};
class AutoDial {
    connectionManager;
    peerStore;
    queue;
    minConnections;
    autoDialPriority;
    autoDialIntervalMs;
    autoDialMaxQueueLength;
    autoDialPeerRetryThresholdMs;
    autoDialDiscoveredPeersDebounce;
    autoDialInterval;
    started;
    running;
    /**
     * Proactively tries to connect to known peers stored in the PeerStore.
     * It will keep the number of connections below the upper limit and sort
     * the peers to connect based on whether we know their keys and protocols.
     */
    constructor(components, init) {
        this.connectionManager = components.connectionManager;
        this.peerStore = components.peerStore;
        this.minConnections = init.minConnections ?? defaultOptions$3.minConnections;
        this.autoDialPriority = init.autoDialPriority ?? defaultOptions$3.autoDialPriority;
        this.autoDialIntervalMs = init.autoDialInterval ?? defaultOptions$3.autoDialInterval;
        this.autoDialMaxQueueLength = init.maxQueueLength ?? defaultOptions$3.maxQueueLength;
        this.autoDialPeerRetryThresholdMs = init.autoDialPeerRetryThreshold ?? defaultOptions$3.autoDialPeerRetryThreshold;
        this.autoDialDiscoveredPeersDebounce = init.autoDialDiscoveredPeersDebounce ?? defaultOptions$3.autoDialDiscoveredPeersDebounce;
        this.started = false;
        this.running = false;
        this.queue = new PeerJobQueue({
            concurrency: init.autoDialConcurrency ?? defaultOptions$3.autoDialConcurrency
        });
        this.queue.addListener('error', (err) => {
            log$f.error('error during auto-dial', err);
        });
        // check the min connection limit whenever a peer disconnects
        components.events.addEventListener('connection:close', () => {
            this.autoDial()
                .catch(err => {
                log$f.error(err);
            });
        });
        // sometimes peers are discovered in quick succession so add a small
        // debounce to ensure all eligible peers are autodialed
        let debounce;
        // when new peers are discovered, dial them if we don't have
        // enough connections
        components.events.addEventListener('peer:discovery', () => {
            clearTimeout(debounce);
            debounce = setTimeout(() => {
                this.autoDial()
                    .catch(err => {
                    log$f.error(err);
                });
            }, this.autoDialDiscoveredPeersDebounce);
        });
    }
    isStarted() {
        return this.started;
    }
    start() {
        this.autoDialInterval = setTimeout(() => {
            this.autoDial()
                .catch(err => {
                log$f.error('error while autodialing', err);
            });
        }, this.autoDialIntervalMs);
        this.started = true;
    }
    afterStart() {
        this.autoDial()
            .catch(err => {
            log$f.error('error while autodialing', err);
        });
    }
    stop() {
        // clear the queue
        this.queue.clear();
        clearTimeout(this.autoDialInterval);
        this.started = false;
        this.running = false;
    }
    async autoDial() {
        if (!this.started) {
            return;
        }
        const connections = this.connectionManager.getConnectionsMap();
        const numConnections = connections.size;
        // Already has enough connections
        if (numConnections >= this.minConnections) {
            if (this.minConnections > 0) {
                log$f.trace('have enough connections %d/%d', numConnections, this.minConnections);
            }
            return;
        }
        if (this.queue.size > this.autoDialMaxQueueLength) {
            log$f('not enough connections %d/%d but auto dial queue is full', numConnections, this.minConnections);
            return;
        }
        if (this.running) {
            log$f('not enough connections %d/%d - but skipping autodial as it is already running', numConnections, this.minConnections);
            return;
        }
        this.running = true;
        log$f('not enough connections %d/%d - will dial peers to increase the number of connections', numConnections, this.minConnections);
        const dialQueue = new PeerSet(
        // @ts-expect-error boolean filter removes falsy peer IDs
        this.connectionManager.getDialQueue()
            .map(queue => queue.peerId)
            .filter(Boolean));
        // Sort peers on whether we know protocols or public keys for them
        const peers = await this.peerStore.all({
            filters: [
                // Remove some peers
                (peer) => {
                    // Remove peers without addresses
                    if (peer.addresses.length === 0) {
                        log$f.trace('not autodialing %p because they have no addresses');
                        return false;
                    }
                    // remove peers we are already connected to
                    if (connections.has(peer.id)) {
                        log$f.trace('not autodialing %p because they are already connected');
                        return false;
                    }
                    // remove peers we are already dialling
                    if (dialQueue.has(peer.id)) {
                        log$f.trace('not autodialing %p because they are already being dialed');
                        return false;
                    }
                    // remove peers already in the autodial queue
                    if (this.queue.hasJob(peer.id)) {
                        log$f.trace('not autodialing %p because they are already being autodialed');
                        return false;
                    }
                    return true;
                }
            ]
        });
        // shuffle the peers - this is so peers with the same tag values will be
        // dialled in a different order each time
        const shuffledPeers = peers.sort(() => Math.random() > 0.5 ? 1 : -1);
        // Sort shuffled peers by tag value
        const peerValues = new PeerMap();
        for (const peer of shuffledPeers) {
            if (peerValues.has(peer.id)) {
                continue;
            }
            // sum all tag values
            peerValues.set(peer.id, [...peer.tags.values()].reduce((acc, curr) => {
                return acc + curr.value;
            }, 0));
        }
        // sort by value, highest to lowest
        const sortedPeers = shuffledPeers.sort((a, b) => {
            const peerAValue = peerValues.get(a.id) ?? 0;
            const peerBValue = peerValues.get(b.id) ?? 0;
            if (peerAValue > peerBValue) {
                return -1;
            }
            if (peerAValue < peerBValue) {
                return 1;
            }
            return 0;
        });
        const peersThatHaveNotFailed = sortedPeers.filter(peer => {
            const lastDialFailure = peer.metadata.get(LAST_DIAL_FAILURE_KEY);
            if (lastDialFailure == null) {
                return true;
            }
            const lastDialFailureTimestamp = parseInt(toString$9(lastDialFailure));
            if (isNaN(lastDialFailureTimestamp)) {
                return true;
            }
            // only dial if the time since the last failure is above the retry threshold
            return Date.now() - lastDialFailureTimestamp > this.autoDialPeerRetryThresholdMs;
        });
        log$f('selected %d/%d peers to dial', peersThatHaveNotFailed.length, peers.length);
        for (const peer of peersThatHaveNotFailed) {
            this.queue.add(async () => {
                const numConnections = this.connectionManager.getConnectionsMap().size;
                // Check to see if we still need to auto dial
                if (numConnections >= this.minConnections) {
                    log$f('got enough connections now %d/%d', numConnections, this.minConnections);
                    this.queue.clear();
                    return;
                }
                log$f('connecting to a peerStore stored peer %p', peer.id);
                await this.connectionManager.openConnection(peer.id, {
                    priority: this.autoDialPriority
                });
            }, {
                peerId: peer.id
            }).catch(err => {
                log$f.error('could not connect to peerStore stored peer', err);
            });
        }
        this.running = false;
        if (this.started) {
            this.autoDialInterval = setTimeout(() => {
                this.autoDial()
                    .catch(err => {
                    log$f.error('error while autodialing', err);
                });
            }, this.autoDialIntervalMs);
        }
    }
}

const log$e = logger$2('libp2p:connection-manager:connection-pruner');
const defaultOptions$2 = {
    maxConnections: MAX_CONNECTIONS,
    allow: []
};
/**
 * If we go over the max connections limit, choose some connections to close
 */
class ConnectionPruner {
    maxConnections;
    connectionManager;
    peerStore;
    allow;
    events;
    constructor(components, init = {}) {
        this.maxConnections = init.maxConnections ?? defaultOptions$2.maxConnections;
        this.allow = init.allow ?? defaultOptions$2.allow;
        this.connectionManager = components.connectionManager;
        this.peerStore = components.peerStore;
        this.events = components.events;
        // check the max connection limit whenever a peer connects
        components.events.addEventListener('connection:open', () => {
            this.maybePruneConnections()
                .catch(err => {
                log$e.error(err);
            });
        });
    }
    /**
     * If we have more connections than our maximum, select some excess connections
     * to prune based on peer value
     */
    async maybePruneConnections() {
        const connections = this.connectionManager.getConnections();
        const numConnections = connections.length;
        const toPrune = Math.max(numConnections - this.maxConnections, 0);
        log$e('checking max connections limit %d/%d', numConnections, this.maxConnections);
        if (numConnections <= this.maxConnections) {
            return;
        }
        log$e('max connections limit exceeded %d/%d, pruning %d connection(s)', numConnections, this.maxConnections, toPrune);
        const peerValues = new PeerMap();
        // work out peer values
        for (const connection of connections) {
            const remotePeer = connection.remotePeer;
            if (peerValues.has(remotePeer)) {
                continue;
            }
            peerValues.set(remotePeer, 0);
            try {
                const peer = await this.peerStore.get(remotePeer);
                // sum all tag values
                peerValues.set(remotePeer, [...peer.tags.values()].reduce((acc, curr) => {
                    return acc + curr.value;
                }, 0));
            }
            catch (err) {
                if (err.code !== 'ERR_NOT_FOUND') {
                    log$e.error('error loading peer tags', err);
                }
            }
        }
        // sort by value, lowest to highest
        const sortedConnections = connections.sort((a, b) => {
            const peerAValue = peerValues.get(a.remotePeer) ?? 0;
            const peerBValue = peerValues.get(b.remotePeer) ?? 0;
            if (peerAValue > peerBValue) {
                return 1;
            }
            if (peerAValue < peerBValue) {
                return -1;
            }
            // if the peers have an equal tag value then we want to close short-lived connections first
            const connectionALifespan = a.timeline.open;
            const connectionBLifespan = b.timeline.open;
            if (connectionALifespan < connectionBLifespan) {
                return 1;
            }
            if (connectionALifespan > connectionBLifespan) {
                return -1;
            }
            return 0;
        });
        // close some connections
        const toClose = [];
        for (const connection of sortedConnections) {
            log$e('too many connections open - closing a connection to %p', connection.remotePeer);
            // check allow list
            const connectionInAllowList = this.allow.some((ma) => {
                return connection.remoteAddr.toString().startsWith(ma.toString());
            });
            // Connections in the allow list should be excluded from pruning
            if (!connectionInAllowList) {
                toClose.push(connection);
            }
            if (toClose.length === toPrune) {
                break;
            }
        }
        // close connections
        await Promise.all(toClose.map(async (connection) => {
            try {
                await connection.close();
            }
            catch (err) {
                log$e.error(err);
            }
        }));
        // despatch prune event
        this.events.safeDispatchEvent('connection:prune', { detail: toClose });
    }
}

/**
 * Takes an array of AbortSignals and returns a single signal.
 * If any signals are aborted, the returned signal will be aborted.
 */
function anySignal(signals) {
    const controller = new globalThis.AbortController();
    function onAbort() {
        controller.abort();
        for (const signal of signals) {
            if (signal?.removeEventListener != null) {
                signal.removeEventListener('abort', onAbort);
            }
        }
    }
    for (const signal of signals) {
        if (signal?.aborted === true) {
            onAbort();
            break;
        }
        if (signal?.addEventListener != null) {
            signal.addEventListener('abort', onAbort);
        }
    }
    function clear() {
        for (const signal of signals) {
            if (signal?.removeEventListener != null) {
                signal.removeEventListener('abort', onAbort);
            }
        }
    }
    const signal = controller.signal;
    signal.clear = clear;
    return signal;
}

const log$d = logger$2('libp2p:connection-manager:utils');
/**
 * Resolve multiaddr recursively
 */
async function resolveMultiaddrs(ma, options) {
    // TODO: recursive logic should live in multiaddr once dns4/dns6 support is in place
    // Now only supporting resolve for dnsaddr
    const resolvableProto = ma.protoNames().includes('dnsaddr');
    // Multiaddr is not resolvable? End recursion!
    if (!resolvableProto) {
        return [ma];
    }
    const resolvedMultiaddrs = await resolveRecord(ma, options);
    const recursiveMultiaddrs = await Promise.all(resolvedMultiaddrs.map(async (nm) => {
        return resolveMultiaddrs(nm, options);
    }));
    const addrs = recursiveMultiaddrs.flat();
    const output = addrs.reduce((array, newM) => {
        if (array.find(m => m.equals(newM)) == null) {
            array.push(newM);
        }
        return array;
    }, ([]));
    log$d('resolved %s to', ma, output.map(ma => ma.toString()));
    return output;
}
/**
 * Resolve a given multiaddr. If this fails, an empty array will be returned
 */
async function resolveRecord(ma, options) {
    try {
        ma = multiaddr$1(ma.toString()); // Use current multiaddr module
        const multiaddrs = await ma.resolve(options);
        return multiaddrs;
    }
    catch (err) {
        log$d.error(`multiaddr ${ma.toString()} could not be resolved`, err);
        return [];
    }
}
function combineSignals(...signals) {
    const sigs = [];
    for (const sig of signals) {
        if (sig != null) {
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, sig);
            }
            catch { }
            sigs.push(sig);
        }
    }
    // let any signal abort the dial
    const signal = anySignal(sigs);
    try {
        // fails on node < 15.4
        eventsExports.setMaxListeners?.(Infinity, signal);
    }
    catch { }
    return signal;
}

const log$c = logger$2('libp2p:connection-manager:dial-queue');
const defaultOptions$1 = {
    addressSorter: publicAddressesFirst,
    maxParallelDials: MAX_PARALLEL_DIALS,
    maxPeerAddrsToDial: MAX_PEER_ADDRS_TO_DIAL,
    maxParallelDialsPerPeer: MAX_PARALLEL_DIALS_PER_PEER,
    dialTimeout: DIAL_TIMEOUT,
    resolvers: {
        dnsaddr: dnsaddrResolver
    }
};
class DialQueue {
    pendingDials;
    queue;
    peerId;
    peerStore;
    connectionGater;
    transportManager;
    addressSorter;
    maxPeerAddrsToDial;
    maxParallelDialsPerPeer;
    dialTimeout;
    inProgressDialCount;
    pendingDialCount;
    shutDownController;
    constructor(components, init = {}) {
        this.addressSorter = init.addressSorter ?? defaultOptions$1.addressSorter;
        this.maxPeerAddrsToDial = init.maxPeerAddrsToDial ?? defaultOptions$1.maxPeerAddrsToDial;
        this.maxParallelDialsPerPeer = init.maxParallelDialsPerPeer ?? defaultOptions$1.maxParallelDialsPerPeer;
        this.dialTimeout = init.dialTimeout ?? defaultOptions$1.dialTimeout;
        this.peerId = components.peerId;
        this.peerStore = components.peerStore;
        this.connectionGater = components.connectionGater;
        this.transportManager = components.transportManager;
        this.shutDownController = new AbortController();
        try {
            // This emitter gets listened to a lot
            eventsExports.setMaxListeners?.(Infinity, this.shutDownController.signal);
        }
        catch { }
        this.pendingDialCount = components.metrics?.registerMetric('libp2p_dialler_pending_dials');
        this.inProgressDialCount = components.metrics?.registerMetric('libp2p_dialler_in_progress_dials');
        this.pendingDials = [];
        for (const [key, value] of Object.entries(init.resolvers ?? {})) {
            resolvers$2.set(key, value);
        }
        // controls dial concurrency
        this.queue = new PQueue({
            concurrency: init.maxParallelDials ?? defaultOptions$1.maxParallelDials
        });
        // a job was added to the queue
        this.queue.on('add', () => {
            this.pendingDialCount?.update(this.queue.size);
            this.inProgressDialCount?.update(this.queue.pending);
        });
        // a queued job started
        this.queue.on('active', () => {
            this.pendingDialCount?.update(this.queue.size);
            this.inProgressDialCount?.update(this.queue.pending);
        });
        // a started job completed without error
        this.queue.on('completed', () => {
            this.pendingDialCount?.update(this.queue.size);
            this.inProgressDialCount?.update(this.queue.pending);
        });
        // a started job errored
        this.queue.on('error', (err) => {
            log$c.error('error in dial queue', err);
            this.pendingDialCount?.update(this.queue.size);
            this.inProgressDialCount?.update(this.queue.pending);
        });
        // all queued jobs have been started
        this.queue.on('empty', () => {
            this.pendingDialCount?.update(this.queue.size);
            this.inProgressDialCount?.update(this.queue.pending);
        });
        // add started jobs have run and the queue is empty
        this.queue.on('idle', () => {
            this.pendingDialCount?.update(this.queue.size);
            this.inProgressDialCount?.update(this.queue.pending);
        });
    }
    /**
     * Clears any pending dials
     */
    stop() {
        this.shutDownController.abort();
    }
    /**
     * Connects to a given peer, multiaddr or list of multiaddrs.
     *
     * If a peer is passed, all known multiaddrs will be tried. If a multiaddr or
     * multiaddrs are passed only those will be dialled.
     *
     * Where a list of multiaddrs is passed, if any contain a peer id then all
     * multiaddrs in the list must contain the same peer id.
     *
     * The dial to the first address that is successfully able to upgrade a connection
     * will be used, all other dials will be aborted when that happens.
     */
    async dial(peerIdOrMultiaddr, options = {}) {
        const { peerId, multiaddrs } = getPeerAddress(peerIdOrMultiaddr);
        const addrs = multiaddrs.map(multiaddr => ({
            multiaddr,
            isCertified: false
        }));
        // create abort conditions - need to do this before `calculateMultiaddrs` as we may be about to
        // resolve a dns addr which can time out
        const signal = this.createDialAbortControllers(options.signal);
        let addrsToDial;
        try {
            // load addresses from address book, resolve and dnsaddrs, filter undiallables, add peer IDs, etc
            addrsToDial = await this.calculateMultiaddrs(peerId, addrs, {
                ...options,
                signal
            });
        }
        catch (err) {
            signal.clear();
            throw err;
        }
        // ready to dial, all async work finished - make sure we don't have any
        // pending dials in progress for this peer or set of multiaddrs
        const existingDial = this.pendingDials.find(dial => {
            // is the dial for the same peer id?
            if (dial.peerId != null && peerId != null && dial.peerId.equals(peerId)) {
                return true;
            }
            // is the dial for the same set of multiaddrs?
            if (addrsToDial.map(({ multiaddr }) => multiaddr.toString()).join() === dial.multiaddrs.map(multiaddr => multiaddr.toString()).join()) {
                return true;
            }
            return false;
        });
        if (existingDial != null) {
            log$c('joining existing dial target for %p', peerId);
            signal.clear();
            return existingDial.promise;
        }
        log$c('creating dial target for', addrsToDial.map(({ multiaddr }) => multiaddr.toString()));
        // @ts-expect-error .promise property is set below
        const pendingDial = {
            id: randomId(),
            status: 'queued',
            peerId,
            multiaddrs: addrsToDial.map(({ multiaddr }) => multiaddr)
        };
        pendingDial.promise = this.performDial(pendingDial, {
            ...options,
            signal
        })
            .finally(() => {
            // remove our pending dial entry
            this.pendingDials = this.pendingDials.filter(p => p.id !== pendingDial.id);
            // clean up abort signals/controllers
            signal.clear();
        })
            .catch(async (err) => {
            log$c.error('dial failed to %s', pendingDial.multiaddrs.map(ma => ma.toString()).join(', '), err);
            if (peerId != null) {
                // record the last failed dial
                try {
                    await this.peerStore.patch(peerId, {
                        metadata: {
                            [LAST_DIAL_FAILURE_KEY]: fromString$3(Date.now().toString())
                        }
                    });
                }
                catch (err) {
                    log$c.error('could not update last dial failure key for %p', peerId, err);
                }
            }
            // Error is a timeout
            if (signal.aborted) {
                const error = new CodeError$3(err.message, codes.ERR_TIMEOUT);
                throw error;
            }
            throw err;
        });
        // let other dials join this one
        this.pendingDials.push(pendingDial);
        return pendingDial.promise;
    }
    createDialAbortControllers(userSignal) {
        // let any signal abort the dial
        const signal = anySignal([AbortSignal.timeout(this.dialTimeout),
            this.shutDownController.signal,
            userSignal
        ]);
        try {
            // This emitter gets listened to a lot
            eventsExports.setMaxListeners?.(Infinity, signal);
        }
        catch { }
        return signal;
    }
    // eslint-disable-next-line complexity
    async calculateMultiaddrs(peerId, addrs = [], options = {}) {
        // if a peer id or multiaddr(s) with a peer id, make sure it isn't our peer id and that we are allowed to dial it
        if (peerId != null) {
            if (this.peerId.equals(peerId)) {
                throw new CodeError$3('Tried to dial self', codes.ERR_DIALED_SELF);
            }
            if ((await this.connectionGater.denyDialPeer?.(peerId)) === true) {
                throw new CodeError$3('The dial request is blocked by gater.allowDialPeer', codes.ERR_PEER_DIAL_INTERCEPTED);
            }
            // if just a peer id was passed, load available multiaddrs for this peer from the address book
            if (addrs.length === 0) {
                log$c('loading multiaddrs for %p', peerId);
                try {
                    const peer = await this.peerStore.get(peerId);
                    addrs.push(...peer.addresses);
                    log$c('loaded multiaddrs for %p', peerId, addrs.map(({ multiaddr }) => multiaddr.toString()));
                }
                catch (err) {
                    if (err.code !== codes.ERR_NOT_FOUND) {
                        throw err;
                    }
                }
            }
        }
        // resolve addresses - this can result in a one-to-many translation when dnsaddrs are resolved
        const resolvedAddresses = (await Promise.all(addrs.map(async (addr) => {
            const result = await resolveMultiaddrs(addr.multiaddr, options);
            if (result.length === 1 && result[0].equals(addr.multiaddr)) {
                return addr;
            }
            return result.map(multiaddr => ({
                multiaddr,
                isCertified: false
            }));
        })))
            .flat();
        const filteredAddrs = resolvedAddresses.filter(addr => {
            // filter out any multiaddrs that we do not have transports for
            if (this.transportManager.transportForMultiaddr(addr.multiaddr) == null) {
                return false;
            }
            // if the resolved multiaddr has a PeerID but it's the wrong one, ignore it
            // - this can happen with addresses like bootstrap.libp2p.io that resolve
            // to multiple different peers
            const addrPeerId = addr.multiaddr.getPeerId();
            if (peerId != null && addrPeerId != null) {
                return peerId.equals(addrPeerId);
            }
            return true;
        });
        // deduplicate addresses
        const dedupedAddrs = new Map();
        for (const addr of filteredAddrs) {
            const maStr = addr.multiaddr.toString();
            const existing = dedupedAddrs.get(maStr);
            if (existing != null) {
                existing.isCertified = existing.isCertified || addr.isCertified || false;
                continue;
            }
            dedupedAddrs.set(maStr, addr);
        }
        let dedupedMultiaddrs = [...dedupedAddrs.values()];
        if (dedupedMultiaddrs.length === 0 || dedupedMultiaddrs.length > this.maxPeerAddrsToDial) {
            log$c('addresses for %p before filtering', peerId ?? 'unknown peer', resolvedAddresses.map(({ multiaddr }) => multiaddr.toString()));
            log$c('addresses for %p after filtering', peerId ?? 'unknown peer', dedupedMultiaddrs.map(({ multiaddr }) => multiaddr.toString()));
        }
        // make sure we actually have some addresses to dial
        if (dedupedMultiaddrs.length === 0) {
            throw new CodeError$3('The dial request has no valid addresses', codes.ERR_NO_VALID_ADDRESSES);
        }
        // make sure we don't have too many addresses to dial
        if (dedupedMultiaddrs.length > this.maxPeerAddrsToDial) {
            throw new CodeError$3('dial with more addresses than allowed', codes.ERR_TOO_MANY_ADDRESSES);
        }
        // ensure the peer id is appended to the multiaddr
        if (peerId != null) {
            const peerIdMultiaddr = `/p2p/${peerId.toString()}`;
            dedupedMultiaddrs = dedupedMultiaddrs.map(addr => {
                const addressPeerId = addr.multiaddr.getPeerId();
                const lastProto = addr.multiaddr.protos().pop();
                // do not append peer id to path multiaddrs
                if (lastProto?.path === true) {
                    return addr;
                }
                // append peer id to multiaddr if it is not already present
                if (addressPeerId !== peerId.toString()) {
                    return {
                        multiaddr: addr.multiaddr.encapsulate(peerIdMultiaddr),
                        isCertified: addr.isCertified
                    };
                }
                return addr;
            });
        }
        const gatedAdrs = [];
        for (const addr of dedupedMultiaddrs) {
            if (this.connectionGater.denyDialMultiaddr != null && await this.connectionGater.denyDialMultiaddr(addr.multiaddr)) {
                continue;
            }
            gatedAdrs.push(addr);
        }
        const sortedGatedAddrs = gatedAdrs.sort(this.addressSorter);
        // make sure we actually have some addresses to dial
        if (sortedGatedAddrs.length === 0) {
            throw new CodeError$3('The connection gater denied all addresses in the dial request', codes.ERR_NO_VALID_ADDRESSES);
        }
        return sortedGatedAddrs;
    }
    async performDial(pendingDial, options = {}) {
        const dialAbortControllers = pendingDial.multiaddrs.map(() => new AbortController());
        try {
            // internal peer dial queue to ensure we only dial the configured number of addresses
            // per peer at the same time to prevent one peer with a lot of addresses swamping
            // the dial queue
            const peerDialQueue = new PQueue({
                concurrency: this.maxParallelDialsPerPeer
            });
            peerDialQueue.on('error', (err) => {
                log$c.error('error dialling', err);
            });
            const conn = await Promise.any(pendingDial.multiaddrs.map(async (addr, i) => {
                const controller = dialAbortControllers[i];
                if (controller == null) {
                    throw new CodeError$3('dialAction did not come with an AbortController', codes.ERR_INVALID_PARAMETERS);
                }
                // let any signal abort the dial
                const signal = combineSignals(controller.signal, options.signal);
                signal.addEventListener('abort', () => {
                    log$c('dial to %a aborted', addr);
                });
                const deferred = pDefer();
                await peerDialQueue.add(async () => {
                    if (signal.aborted) {
                        log$c('dial to %a was aborted before reaching the head of the peer dial queue', addr);
                        deferred.reject(new AbortError$8());
                        return;
                    }
                    // add the individual dial to the dial queue so we don't breach maxConcurrentDials
                    await this.queue.add(async () => {
                        try {
                            if (signal.aborted) {
                                log$c('dial to %a was aborted before reaching the head of the dial queue', addr);
                                deferred.reject(new AbortError$8());
                                return;
                            }
                            // update dial status
                            pendingDial.status = 'active';
                            const conn = await this.transportManager.dial(addr, {
                                ...options,
                                signal
                            });
                            if (controller.signal.aborted) {
                                // another dial succeeded faster than this one
                                log$c('multiple dials succeeded, closing superfluous connection');
                                conn.close().catch(err => {
                                    log$c.error('error closing superfluous connection', err);
                                });
                                deferred.reject(new AbortError$8());
                                return;
                            }
                            // remove the successful AbortController so it is not aborted
                            dialAbortControllers[i] = undefined;
                            // immediately abort any other dials
                            dialAbortControllers.forEach(c => {
                                if (c !== undefined) {
                                    c.abort();
                                }
                            });
                            log$c('dial to %a succeeded', addr);
                            // resolve the connection promise
                            deferred.resolve(conn);
                        }
                        catch (err) {
                            // something only went wrong if our signal was not aborted
                            log$c.error('error during dial of %a', addr, err);
                            deferred.reject(err);
                        }
                    }, {
                        ...options,
                        signal
                    }).catch(err => {
                        deferred.reject(err);
                    });
                }, {
                    signal
                }).catch(err => {
                    deferred.reject(err);
                }).finally(() => {
                    signal.clear();
                });
                return deferred.promise;
            }));
            // dial succeeded or failed
            if (conn == null) {
                throw new CodeError$3('successful dial led to empty object returned from peer dial queue', codes.ERR_TRANSPORT_DIAL_FAILED);
            }
            pendingDial.status = 'success';
            return conn;
        }
        catch (err) {
            pendingDial.status = 'error';
            // if we only dialled one address, unwrap the AggregateError to provide more
            // useful feedback to the user
            if (pendingDial.multiaddrs.length === 1 && err.name === 'AggregateError') {
                throw err.errors[0];
            }
            throw err;
        }
    }
}
/**
 * Returns a random string
 */
function randomId() {
    return `${(parseInt(String(Math.random() * 1e9), 10)).toString()}${Date.now()}`;
}

const log$b = logger$2('libp2p:connection-manager');
const DEFAULT_DIAL_PRIORITY = 50;
const defaultOptions = {
    minConnections: MIN_CONNECTIONS,
    maxConnections: MAX_CONNECTIONS,
    inboundConnectionThreshold: INBOUND_CONNECTION_THRESHOLD,
    maxIncomingPendingConnections: MAX_INCOMING_PENDING_CONNECTIONS,
    autoDialConcurrency: AUTO_DIAL_CONCURRENCY,
    autoDialPriority: AUTO_DIAL_PRIORITY,
    autoDialMaxQueueLength: AUTO_DIAL_MAX_QUEUE_LENGTH
};
/**
 * Responsible for managing known connections.
 */
class DefaultConnectionManager {
    started;
    connections;
    allow;
    deny;
    maxIncomingPendingConnections;
    incomingPendingConnections;
    maxConnections;
    dialQueue;
    autoDial;
    connectionPruner;
    inboundConnectionRateLimiter;
    peerStore;
    metrics;
    events;
    constructor(components, init = {}) {
        this.maxConnections = init.maxConnections ?? defaultOptions.maxConnections;
        const minConnections = init.minConnections ?? defaultOptions.minConnections;
        if (this.maxConnections < minConnections) {
            throw new CodeError$3('Connection Manager maxConnections must be greater than minConnections', codes.ERR_INVALID_PARAMETERS);
        }
        /**
         * Map of connections per peer
         */
        this.connections = new PeerMap();
        this.started = false;
        this.peerStore = components.peerStore;
        this.metrics = components.metrics;
        this.events = components.events;
        this.onConnect = this.onConnect.bind(this);
        this.onDisconnect = this.onDisconnect.bind(this);
        this.events.addEventListener('connection:open', this.onConnect);
        this.events.addEventListener('connection:close', this.onDisconnect);
        // allow/deny lists
        this.allow = (init.allow ?? []).map(ma => multiaddr$1(ma));
        this.deny = (init.deny ?? []).map(ma => multiaddr$1(ma));
        this.incomingPendingConnections = 0;
        this.maxIncomingPendingConnections = init.maxIncomingPendingConnections ?? defaultOptions.maxIncomingPendingConnections;
        // controls individual peers trying to dial us too quickly
        this.inboundConnectionRateLimiter = new rateLimiterFlexible.RateLimiterMemory({
            points: init.inboundConnectionThreshold ?? defaultOptions.inboundConnectionThreshold,
            duration: 1
        });
        // controls what happens when we don't have enough connections
        this.autoDial = new AutoDial({
            connectionManager: this,
            peerStore: components.peerStore,
            events: components.events
        }, {
            minConnections,
            autoDialConcurrency: init.autoDialConcurrency ?? defaultOptions.autoDialConcurrency,
            autoDialPriority: init.autoDialPriority ?? defaultOptions.autoDialPriority,
            maxQueueLength: init.autoDialMaxQueueLength ?? defaultOptions.autoDialMaxQueueLength
        });
        // controls what happens when we have too many connections
        this.connectionPruner = new ConnectionPruner({
            connectionManager: this,
            peerStore: components.peerStore,
            events: components.events
        }, {
            maxConnections: this.maxConnections,
            allow: this.allow
        });
        this.dialQueue = new DialQueue({
            peerId: components.peerId,
            metrics: components.metrics,
            peerStore: components.peerStore,
            transportManager: components.transportManager,
            connectionGater: components.connectionGater
        }, {
            addressSorter: init.addressSorter ?? publicAddressesFirst,
            maxParallelDials: init.maxParallelDials ?? MAX_PARALLEL_DIALS,
            maxPeerAddrsToDial: init.maxPeerAddrsToDial ?? MAX_PEER_ADDRS_TO_DIAL,
            dialTimeout: init.dialTimeout ?? DIAL_TIMEOUT,
            resolvers: init.resolvers ?? {
                dnsaddr: dnsaddrResolver
            }
        });
    }
    isStarted() {
        return this.started;
    }
    /**
     * Starts the Connection Manager. If Metrics are not enabled on libp2p
     * only event loop and connection limits will be monitored.
     */
    async start() {
        // track inbound/outbound connections
        this.metrics?.registerMetricGroup('libp2p_connection_manager_connections', {
            calculate: () => {
                const metric = {
                    inbound: 0,
                    outbound: 0
                };
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        if (conn.direction === 'inbound') {
                            metric.inbound++;
                        }
                        else {
                            metric.outbound++;
                        }
                    }
                }
                return metric;
            }
        });
        // track total number of streams per protocol
        this.metrics?.registerMetricGroup('libp2p_protocol_streams_total', {
            label: 'protocol',
            calculate: () => {
                const metric = {};
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        for (const stream of conn.streams) {
                            const key = `${stream.direction} ${stream.protocol ?? 'unnegotiated'}`;
                            metric[key] = (metric[key] ?? 0) + 1;
                        }
                    }
                }
                return metric;
            }
        });
        // track 90th percentile of streams per protocol
        this.metrics?.registerMetricGroup('libp2p_connection_manager_protocol_streams_per_connection_90th_percentile', {
            label: 'protocol',
            calculate: () => {
                const allStreams = {};
                for (const conns of this.connections.values()) {
                    for (const conn of conns) {
                        const streams = {};
                        for (const stream of conn.streams) {
                            const key = `${stream.direction} ${stream.protocol ?? 'unnegotiated'}`;
                            streams[key] = (streams[key] ?? 0) + 1;
                        }
                        for (const [protocol, count] of Object.entries(streams)) {
                            allStreams[protocol] = allStreams[protocol] ?? [];
                            allStreams[protocol].push(count);
                        }
                    }
                }
                const metric = {};
                for (let [protocol, counts] of Object.entries(allStreams)) {
                    counts = counts.sort((a, b) => a - b);
                    const index = Math.floor(counts.length * 0.9);
                    metric[protocol] = counts[index];
                }
                return metric;
            }
        });
        this.autoDial.start();
        this.started = true;
        log$b('started');
    }
    async afterStart() {
        // re-connect to any peers with the KEEP_ALIVE tag
        void Promise.resolve()
            .then(async () => {
            const keepAlivePeers = await this.peerStore.all({
                filters: [(peer) => {
                        return peer.tags.has(KEEP_ALIVE);
                    }]
            });
            await Promise.all(keepAlivePeers.map(async (peer) => {
                await this.openConnection(peer.id)
                    .catch(err => {
                    log$b.error(err);
                });
            }));
        })
            .catch(err => {
            log$b.error(err);
        });
        this.autoDial.afterStart();
    }
    /**
     * Stops the Connection Manager
     */
    async stop() {
        this.dialQueue.stop();
        this.autoDial.stop();
        // Close all connections we're tracking
        const tasks = [];
        for (const connectionList of this.connections.values()) {
            for (const connection of connectionList) {
                tasks.push((async () => {
                    try {
                        await connection.close();
                    }
                    catch (err) {
                        log$b.error(err);
                    }
                })());
            }
        }
        log$b('closing %d connections', tasks.length);
        await Promise.all(tasks);
        this.connections.clear();
        log$b('stopped');
    }
    onConnect(evt) {
        void this._onConnect(evt).catch(err => {
            log$b.error(err);
        });
    }
    /**
     * Tracks the incoming connection and check the connection limit
     */
    async _onConnect(evt) {
        const { detail: connection } = evt;
        if (!this.started) {
            // This can happen when we are in the process of shutting down the node
            await connection.close();
            return;
        }
        const peerId = connection.remotePeer;
        const storedConns = this.connections.get(peerId);
        let isNewPeer = false;
        if (storedConns != null) {
            storedConns.push(connection);
        }
        else {
            isNewPeer = true;
            this.connections.set(peerId, [connection]);
        }
        // only need to store RSA public keys, all other types are embedded in the peer id
        if (peerId.publicKey != null && peerId.type === 'RSA') {
            await this.peerStore.patch(peerId, {
                publicKey: peerId.publicKey
            });
        }
        if (isNewPeer) {
            this.events.safeDispatchEvent('peer:connect', { detail: connection.remotePeer });
        }
    }
    /**
     * Removes the connection from tracking
     */
    onDisconnect(evt) {
        const { detail: connection } = evt;
        if (!this.started) {
            // This can happen when we are in the process of shutting down the node
            return;
        }
        const peerId = connection.remotePeer;
        let storedConn = this.connections.get(peerId);
        if (storedConn != null && storedConn.length > 1) {
            storedConn = storedConn.filter((conn) => conn.id !== connection.id);
            this.connections.set(peerId, storedConn);
        }
        else if (storedConn != null) {
            this.connections.delete(peerId);
            this.events.safeDispatchEvent('peer:disconnect', { detail: connection.remotePeer });
        }
    }
    getConnections(peerId) {
        if (peerId != null) {
            return this.connections.get(peerId) ?? [];
        }
        let conns = [];
        for (const c of this.connections.values()) {
            conns = conns.concat(c);
        }
        return conns;
    }
    getConnectionsMap() {
        return this.connections;
    }
    async openConnection(peerIdOrMultiaddr, options = {}) {
        if (!this.isStarted()) {
            throw new CodeError$3('Not started', codes.ERR_NODE_NOT_STARTED);
        }
        options.signal?.throwIfAborted();
        const { peerId } = getPeerAddress(peerIdOrMultiaddr);
        if (peerId != null && options.force !== true) {
            log$b('dial %p', peerId);
            const existingConnections = this.getConnections(peerId);
            if (existingConnections.length > 0) {
                log$b('had an existing connection to %p', peerId);
                return existingConnections[0];
            }
        }
        const connection = await this.dialQueue.dial(peerIdOrMultiaddr, {
            ...options,
            priority: options.priority ?? DEFAULT_DIAL_PRIORITY
        });
        let peerConnections = this.connections.get(connection.remotePeer);
        if (peerConnections == null) {
            peerConnections = [];
            this.connections.set(connection.remotePeer, peerConnections);
        }
        // we get notified of connections via the Upgrader emitting "connection"
        // events, double check we aren't already tracking this connection before
        // storing it
        let trackedConnection = false;
        for (const conn of peerConnections) {
            if (conn.id === connection.id) {
                trackedConnection = true;
            }
        }
        if (!trackedConnection) {
            peerConnections.push(connection);
        }
        return connection;
    }
    async closeConnections(peerId, options = {}) {
        const connections = this.connections.get(peerId) ?? [];
        await Promise.all(connections.map(async (connection) => {
            try {
                await connection.close(options);
            }
            catch (err) {
                connection.abort(err);
            }
        }));
    }
    async acceptIncomingConnection(maConn) {
        // check deny list
        const denyConnection = this.deny.some(ma => {
            return maConn.remoteAddr.toString().startsWith(ma.toString());
        });
        if (denyConnection) {
            log$b('connection from %a refused - connection remote address was in deny list', maConn.remoteAddr);
            return false;
        }
        // check allow list
        const allowConnection = this.allow.some(ma => {
            return maConn.remoteAddr.toString().startsWith(ma.toString());
        });
        if (allowConnection) {
            this.incomingPendingConnections++;
            return true;
        }
        // check pending connections
        if (this.incomingPendingConnections === this.maxIncomingPendingConnections) {
            log$b('connection from %a refused - incomingPendingConnections exceeded by host', maConn.remoteAddr);
            return false;
        }
        if (maConn.remoteAddr.isThinWaistAddress()) {
            const host = maConn.remoteAddr.nodeAddress().address;
            try {
                await this.inboundConnectionRateLimiter.consume(host, 1);
            }
            catch {
                log$b('connection from %a refused - inboundConnectionThreshold exceeded by host %s', maConn.remoteAddr, host);
                return false;
            }
        }
        if (this.getConnections().length < this.maxConnections) {
            this.incomingPendingConnections++;
            return true;
        }
        log$b('connection from %a refused - maxConnections exceeded', maConn.remoteAddr);
        return false;
    }
    afterUpgradeInbound() {
        this.incomingPendingConnections--;
    }
    getDialQueue() {
        return this.dialQueue.pendingDials;
    }
}

function isAsyncIterable$2(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function filter(source, fn) {
    if (isAsyncIterable$2(source)) {
        return (async function* () {
            for await (const entry of source) {
                if (await fn(entry)) {
                    yield entry;
                }
            }
        })();
    }
    // if mapping function returns a promise we have to return an async generator
    const peekable$1 = peekable(source);
    const { value, done } = peekable$1.next();
    if (done === true) {
        return (function* () { }());
    }
    const res = fn(value);
    // @ts-expect-error .then is not present on O
    if (typeof res.then === 'function') {
        return (async function* () {
            if (await res) {
                yield value;
            }
            for await (const entry of peekable$1) {
                if (await fn(entry)) {
                    yield entry;
                }
            }
        })();
    }
    const func = fn;
    return (function* () {
        if (res === true) {
            yield value;
        }
        for (const entry of peekable$1) {
            if (func(entry)) {
                yield entry;
            }
        }
    })();
}

function isAsyncIterable$1(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function map(source, func) {
    if (isAsyncIterable$1(source)) {
        return (async function* () {
            for await (const val of source) {
                yield func(val);
            }
        })();
    }
    // if mapping function returns a promise we have to return an async generator
    const peekable$1 = peekable(source);
    const { value, done } = peekable$1.next();
    if (done === true) {
        return (function* () { }());
    }
    const res = func(value);
    // @ts-expect-error .then is not present on O
    if (typeof res.then === 'function') {
        return (async function* () {
            yield await res;
            for await (const val of peekable$1) {
                yield func(val);
            }
        })();
    }
    const fn = func;
    return (function* () {
        yield res;
        for (const val of peekable$1) {
            yield fn(val);
        }
    })();
}

/**
 * Store the multiaddrs from every peer in the passed peer store
 */
async function* storeAddresses(source, peerStore) {
    yield* map(source, async (peer) => {
        // ensure we have the addresses for a given peer
        await peerStore.merge(peer.id, {
            multiaddrs: peer.multiaddrs
        });
        return peer;
    });
}
/**
 * Filter peers by unique peer id
 */
function uniquePeers(source) {
    /** @type Set<string> */
    const seen = new Set();
    return filter(source, (peer) => {
        // dedupe by peer id
        if (seen.has(peer.id.toString())) {
            return false;
        }
        seen.add(peer.id.toString());
        return true;
    });
}
/**
 * Require at least `min` peers to be yielded from `source`
 */
async function* requirePeers(source, min = 1) {
    let seen = 0;
    for await (const peer of source) {
        seen++;
        yield peer;
    }
    if (seen < min) {
        throw new CodeError$3(`more peers required, seen: ${seen}  min: ${min}`, 'NOT_FOUND');
    }
}

class CompoundContentRouting {
    routers;
    started;
    components;
    constructor(components, init) {
        this.routers = init.routers ?? [];
        this.started = false;
        this.components = components;
    }
    isStarted() {
        return this.started;
    }
    async start() {
        this.started = true;
    }
    async stop() {
        this.started = false;
    }
    /**
     * Iterates over all content routers in parallel to find providers of the given key
     */
    async *findProviders(key, options = {}) {
        if (this.routers.length === 0) {
            throw new CodeError$3('No content routers available', codes.ERR_NO_ROUTERS_AVAILABLE);
        }
        yield* pipe(merge$1(...this.routers.map(router => router.findProviders(key, options))), (source) => storeAddresses(source, this.components.peerStore), (source) => uniquePeers(source), (source) => requirePeers(source));
    }
    /**
     * Iterates over all content routers in parallel to notify it is
     * a provider of the given key
     */
    async provide(key, options = {}) {
        if (this.routers.length === 0) {
            throw new CodeError$3('No content routers available', codes.ERR_NO_ROUTERS_AVAILABLE);
        }
        await Promise.all(this.routers.map(async (router) => { await router.provide(key, options); }));
    }
    /**
     * Store the given key/value pair in the available content routings
     */
    async put(key, value, options) {
        if (!this.isStarted()) {
            throw new CodeError$3(messages.NOT_STARTED_YET, codes.DHT_NOT_STARTED);
        }
        await Promise.all(this.routers.map(async (router) => {
            await router.put(key, value, options);
        }));
    }
    /**
     * Get the value to the given key.
     * Times out after 1 minute by default.
     */
    async get(key, options) {
        if (!this.isStarted()) {
            throw new CodeError$3(messages.NOT_STARTED_YET, codes.DHT_NOT_STARTED);
        }
        return Promise.any(this.routers.map(async (router) => {
            return router.get(key, options);
        }));
    }
}

function isAsyncIterable(thing) {
    return thing[Symbol.asyncIterator] != null;
}
function first(source) {
    if (isAsyncIterable(source)) {
        return (async () => {
            for await (const entry of source) { // eslint-disable-line no-unreachable-loop
                return entry;
            }
            return undefined;
        })();
    }
    for (const entry of source) { // eslint-disable-line no-unreachable-loop
        return entry;
    }
    return undefined;
}

const log$a = logger$2('libp2p:peer-routing');
class DefaultPeerRouting {
    components;
    routers;
    constructor(components, init) {
        this.components = components;
        this.routers = init.routers ?? [];
    }
    /**
     * Iterates over all peer routers in parallel to find the given peer
     */
    async findPeer(id, options) {
        if (this.routers.length === 0) {
            throw new CodeError$3('No peer routers available', codes.ERR_NO_ROUTERS_AVAILABLE);
        }
        if (id.toString() === this.components.peerId.toString()) {
            throw new CodeError$3('Should not try to find self', codes.ERR_FIND_SELF);
        }
        const output = await pipe(merge$1(...this.routers.map(router => (async function* () {
            try {
                yield await router.findPeer(id, options);
            }
            catch (err) {
                log$a.error(err);
            }
        })())), (source) => filter(source, Boolean), (source) => storeAddresses(source, this.components.peerStore), async (source) => first(source));
        if (output != null) {
            return output;
        }
        throw new CodeError$3(messages.NOT_FOUND, codes.ERR_NOT_FOUND);
    }
    /**
     * Attempt to find the closest peers on the network to the given key
     */
    async *getClosestPeers(key, options) {
        if (this.routers.length === 0) {
            throw new CodeError$3('No peer routers available', codes.ERR_NO_ROUTERS_AVAILABLE);
        }
        yield* pipe(merge$1(...this.routers.map(router => router.getClosestPeers(key, options))), (source) => storeAddresses(source, this.components.peerStore), (source) => uniquePeers(source), (source) => requirePeers(source));
    }
}

const log$9 = logger$2('libp2p:registrar');
const DEFAULT_MAX_INBOUND_STREAMS = 32;
const DEFAULT_MAX_OUTBOUND_STREAMS = 64;
/**
 * Responsible for notifying registered protocols of events in the network.
 */
class DefaultRegistrar {
    topologies;
    handlers;
    components;
    constructor(components) {
        this.topologies = new Map();
        this.handlers = new Map();
        this.components = components;
        this._onDisconnect = this._onDisconnect.bind(this);
        this._onPeerUpdate = this._onPeerUpdate.bind(this);
        this._onConnect = this._onConnect.bind(this);
        this.components.events.addEventListener('peer:disconnect', this._onDisconnect);
        this.components.events.addEventListener('peer:connect', this._onConnect);
        this.components.events.addEventListener('peer:update', this._onPeerUpdate);
    }
    getProtocols() {
        return Array.from(new Set([
            ...this.handlers.keys()
        ])).sort();
    }
    getHandler(protocol) {
        const handler = this.handlers.get(protocol);
        if (handler == null) {
            throw new CodeError$3(`No handler registered for protocol ${protocol}`, codes.ERR_NO_HANDLER_FOR_PROTOCOL);
        }
        return handler;
    }
    getTopologies(protocol) {
        const topologies = this.topologies.get(protocol);
        if (topologies == null) {
            return [];
        }
        return [
            ...topologies.values()
        ];
    }
    /**
     * Registers the `handler` for each protocol
     */
    async handle(protocol, handler, opts) {
        if (this.handlers.has(protocol)) {
            throw new CodeError$3(`Handler already registered for protocol ${protocol}`, codes.ERR_PROTOCOL_HANDLER_ALREADY_REGISTERED);
        }
        const options = mergeOptions$1.bind({ ignoreUndefined: true })({
            maxInboundStreams: DEFAULT_MAX_INBOUND_STREAMS,
            maxOutboundStreams: DEFAULT_MAX_OUTBOUND_STREAMS
        }, opts);
        this.handlers.set(protocol, {
            handler,
            options
        });
        // Add new protocol to self protocols in the peer store
        await this.components.peerStore.merge(this.components.peerId, {
            protocols: [protocol]
        });
    }
    /**
     * Removes the handler for each protocol. The protocol
     * will no longer be supported on streams.
     */
    async unhandle(protocols) {
        const protocolList = Array.isArray(protocols) ? protocols : [protocols];
        protocolList.forEach(protocol => {
            this.handlers.delete(protocol);
        });
        // Update self protocols in the peer store
        await this.components.peerStore.patch(this.components.peerId, {
            protocols: this.getProtocols()
        });
    }
    /**
     * Register handlers for a set of multicodecs given
     */
    async register(protocol, topology) {
        if (topology == null) {
            throw new CodeError$3('invalid topology', codes.ERR_INVALID_PARAMETERS);
        }
        // Create topology
        const id = `${(Math.random() * 1e9).toString(36)}${Date.now()}`;
        let topologies = this.topologies.get(protocol);
        if (topologies == null) {
            topologies = new Map();
            this.topologies.set(protocol, topologies);
        }
        topologies.set(id, topology);
        return id;
    }
    /**
     * Unregister topology
     */
    unregister(id) {
        for (const [protocol, topologies] of this.topologies.entries()) {
            if (topologies.has(id)) {
                topologies.delete(id);
                if (topologies.size === 0) {
                    this.topologies.delete(protocol);
                }
            }
        }
    }
    /**
     * Remove a disconnected peer from the record
     */
    _onDisconnect(evt) {
        const remotePeer = evt.detail;
        void this.components.peerStore.get(remotePeer)
            .then(peer => {
            for (const protocol of peer.protocols) {
                const topologies = this.topologies.get(protocol);
                if (topologies == null) {
                    // no topologies are interested in this protocol
                    continue;
                }
                for (const topology of topologies.values()) {
                    topology.onDisconnect?.(remotePeer);
                }
            }
        })
            .catch(err => {
            if (err.code === codes.ERR_NOT_FOUND) {
                // peer has not completed identify so they are not in the peer store
                return;
            }
            log$9.error('could not inform topologies of disconnecting peer %p', remotePeer, err);
        });
    }
    /**
     * On peer connected if we already have their protocols. Usually used for reconnects
     * as change:protocols event won't be emitted due to identical protocols.
     */
    _onConnect(evt) {
        const remotePeer = evt.detail;
        void this.components.peerStore.get(remotePeer)
            .then(peer => {
            const connection = this.components.connectionManager.getConnections(peer.id)[0];
            if (connection == null) {
                log$9('peer %p connected but the connection manager did not have a connection', peer);
                // peer disconnected while we were loading their details from the peer store
                return;
            }
            for (const protocol of peer.protocols) {
                const topologies = this.topologies.get(protocol);
                if (topologies == null) {
                    // no topologies are interested in this protocol
                    continue;
                }
                for (const topology of topologies.values()) {
                    topology.onConnect?.(remotePeer, connection);
                }
            }
        })
            .catch(err => {
            if (err.code === codes.ERR_NOT_FOUND) {
                // peer has not completed identify so they are not in the peer store
                return;
            }
            log$9.error('could not inform topologies of connecting peer %p', remotePeer, err);
        });
    }
    /**
     * Check if a new peer support the multicodecs for this topology
     */
    _onPeerUpdate(evt) {
        const { peer, previous } = evt.detail;
        const removed = (previous?.protocols ?? []).filter(protocol => !peer.protocols.includes(protocol));
        const added = peer.protocols.filter(protocol => !(previous?.protocols ?? []).includes(protocol));
        for (const protocol of removed) {
            const topologies = this.topologies.get(protocol);
            if (topologies == null) {
                // no topologies are interested in this protocol
                continue;
            }
            for (const topology of topologies.values()) {
                topology.onDisconnect?.(peer.id);
            }
        }
        for (const protocol of added) {
            const topologies = this.topologies.get(protocol);
            if (topologies == null) {
                // no topologies are interested in this protocol
                continue;
            }
            for (const topology of topologies.values()) {
                const connection = this.components.connectionManager.getConnections(peer.id)[0];
                if (connection == null) {
                    continue;
                }
                topology.onConnect?.(peer.id, connection);
            }
        }
    }
}

class TrackedMap extends Map {
    metric;
    constructor(init) {
        super();
        const { name, metrics } = init;
        this.metric = metrics.registerMetric(name);
        this.updateComponentMetric();
    }
    set(key, value) {
        super.set(key, value);
        this.updateComponentMetric();
        return this;
    }
    delete(key) {
        const deleted = super.delete(key);
        this.updateComponentMetric();
        return deleted;
    }
    clear() {
        super.clear();
        this.updateComponentMetric();
    }
    updateComponentMetric() {
        this.metric.update(this.size);
    }
}
function trackedMap(config) {
    const { name, metrics } = config;
    let map;
    if (metrics != null) {
        map = new TrackedMap({ name, metrics });
    }
    else {
        map = new Map();
    }
    return map;
}

const log$8 = logger$2('libp2p:transports');
class DefaultTransportManager {
    components;
    transports;
    listeners;
    faultTolerance;
    started;
    constructor(components, init = {}) {
        this.components = components;
        this.started = false;
        this.transports = new Map();
        this.listeners = trackedMap({
            name: 'libp2p_transport_manager_listeners',
            metrics: this.components.metrics
        });
        this.faultTolerance = init.faultTolerance ?? FaultTolerance.FATAL_ALL;
    }
    /**
     * Adds a `Transport` to the manager
     */
    add(transport) {
        const tag = transport[Symbol.toStringTag];
        if (tag == null) {
            throw new CodeError$3('Transport must have a valid tag', codes.ERR_INVALID_KEY);
        }
        if (this.transports.has(tag)) {
            throw new CodeError$3(`There is already a transport with the tag ${tag}`, codes.ERR_DUPLICATE_TRANSPORT);
        }
        log$8('adding transport %s', tag);
        this.transports.set(tag, transport);
        if (!this.listeners.has(tag)) {
            this.listeners.set(tag, []);
        }
    }
    isStarted() {
        return this.started;
    }
    start() {
        this.started = true;
    }
    async afterStart() {
        // Listen on the provided transports for the provided addresses
        const addrs = this.components.addressManager.getListenAddrs();
        await this.listen(addrs);
    }
    /**
     * Stops all listeners
     */
    async stop() {
        const tasks = [];
        for (const [key, listeners] of this.listeners) {
            log$8('closing listeners for %s', key);
            while (listeners.length > 0) {
                const listener = listeners.pop();
                if (listener == null) {
                    continue;
                }
                tasks.push(listener.close());
            }
        }
        await Promise.all(tasks);
        log$8('all listeners closed');
        for (const key of this.listeners.keys()) {
            this.listeners.set(key, []);
        }
        this.started = false;
    }
    /**
     * Dials the given Multiaddr over it's supported transport
     */
    async dial(ma, options) {
        const transport = this.transportForMultiaddr(ma);
        if (transport == null) {
            throw new CodeError$3(`No transport available for address ${String(ma)}`, codes.ERR_TRANSPORT_UNAVAILABLE);
        }
        try {
            return await transport.dial(ma, {
                ...options,
                upgrader: this.components.upgrader
            });
        }
        catch (err) {
            if (err.code == null) {
                err.code = codes.ERR_TRANSPORT_DIAL_FAILED;
            }
            throw err;
        }
    }
    /**
     * Returns all Multiaddr's the listeners are using
     */
    getAddrs() {
        let addrs = [];
        for (const listeners of this.listeners.values()) {
            for (const listener of listeners) {
                addrs = [...addrs, ...listener.getAddrs()];
            }
        }
        return addrs;
    }
    /**
     * Returns all the transports instances
     */
    getTransports() {
        return Array.of(...this.transports.values());
    }
    /**
     * Returns all the listener instances
     */
    getListeners() {
        return Array.of(...this.listeners.values()).flat();
    }
    /**
     * Finds a transport that matches the given Multiaddr
     */
    transportForMultiaddr(ma) {
        for (const transport of this.transports.values()) {
            const addrs = transport.filter([ma]);
            if (addrs.length > 0) {
                return transport;
            }
        }
    }
    /**
     * Starts listeners for each listen Multiaddr
     */
    async listen(addrs) {
        if (!this.isStarted()) {
            throw new CodeError$3('Not started', codes.ERR_NODE_NOT_STARTED);
        }
        if (addrs == null || addrs.length === 0) {
            log$8('no addresses were provided for listening, this node is dial only');
            return;
        }
        const couldNotListen = [];
        for (const [key, transport] of this.transports.entries()) {
            const supportedAddrs = transport.filter(addrs);
            const tasks = [];
            // For each supported multiaddr, create a listener
            for (const addr of supportedAddrs) {
                log$8('creating listener for %s on %a', key, addr);
                const listener = transport.createListener({
                    upgrader: this.components.upgrader
                });
                let listeners = this.listeners.get(key) ?? [];
                if (listeners == null) {
                    listeners = [];
                    this.listeners.set(key, listeners);
                }
                listeners.push(listener);
                // Track listen/close events
                listener.addEventListener('listening', () => {
                    this.components.events.safeDispatchEvent('transport:listening', {
                        detail: listener
                    });
                });
                listener.addEventListener('close', () => {
                    const index = listeners.findIndex(l => l === listener);
                    // remove the listener
                    listeners.splice(index, 1);
                    this.components.events.safeDispatchEvent('transport:close', {
                        detail: listener
                    });
                });
                // We need to attempt to listen on everything
                tasks.push(listener.listen(addr));
            }
            // Keep track of transports we had no addresses for
            if (tasks.length === 0) {
                couldNotListen.push(key);
                continue;
            }
            const results = await Promise.allSettled(tasks);
            // If we are listening on at least 1 address, succeed.
            // TODO: we should look at adding a retry (`p-retry`) here to better support
            // listening on remote addresses as they may be offline. We could then potentially
            // just wait for any (`p-any`) listener to succeed on each transport before returning
            const isListening = results.find(r => r.status === 'fulfilled');
            if ((isListening == null) && this.faultTolerance !== FaultTolerance.NO_FATAL) {
                throw new CodeError$3(`Transport (${key}) could not listen on any available address`, codes.ERR_NO_VALID_ADDRESSES);
            }
        }
        // If no transports were able to listen, throw an error. This likely
        // means we were given addresses we do not have transports for
        if (couldNotListen.length === this.transports.size) {
            const message = `no valid addresses were provided for transports [${couldNotListen.join(', ')}]`;
            if (this.faultTolerance === FaultTolerance.FATAL_ALL) {
                throw new CodeError$3(message, codes.ERR_NO_VALID_ADDRESSES);
            }
            log$8(`libp2p in dial mode only: ${message}`);
        }
    }
    /**
     * Removes the given transport from the manager.
     * If a transport has any running listeners, they will be closed.
     */
    async remove(key) {
        log$8('removing %s', key);
        // Close any running listeners
        for (const listener of this.listeners.get(key) ?? []) {
            await listener.close();
        }
        this.transports.delete(key);
        this.listeners.delete(key);
    }
    /**
     * Removes all transports from the manager.
     * If any listeners are running, they will be closed.
     *
     * @async
     */
    async removeAll() {
        const tasks = [];
        for (const key of this.transports.keys()) {
            tasks.push(this.remove(key));
        }
        await Promise.all(tasks);
    }
}

const PROTOCOL_ID = '/multistream/1.0.0';
// Conforming to go-libp2p
// See https://github.com/multiformats/go-multistream/blob/master/multistream.go#L297
const MAX_PROTOCOL_LENGTH = 1024;

// base-x encoding / decoding
// Copyright (c) 2018 base-x contributors
// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)
// Distributed under the MIT software license, see the accompanying
// file LICENSE or http://www.opensource.org/licenses/mit-license.php.
function base (ALPHABET, name) {
  if (ALPHABET.length >= 255) { throw new TypeError('Alphabet too long') }
  var BASE_MAP = new Uint8Array(256);
  for (var j = 0; j < BASE_MAP.length; j++) {
    BASE_MAP[j] = 255;
  }
  for (var i = 0; i < ALPHABET.length; i++) {
    var x = ALPHABET.charAt(i);
    var xc = x.charCodeAt(0);
    if (BASE_MAP[xc] !== 255) { throw new TypeError(x + ' is ambiguous') }
    BASE_MAP[xc] = i;
  }
  var BASE = ALPHABET.length;
  var LEADER = ALPHABET.charAt(0);
  var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up
  var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up
  function encode (source) {
    if (source instanceof Uint8Array) ; else if (ArrayBuffer.isView(source)) {
      source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);
    } else if (Array.isArray(source)) {
      source = Uint8Array.from(source);
    }
    if (!(source instanceof Uint8Array)) { throw new TypeError('Expected Uint8Array') }
    if (source.length === 0) { return '' }
        // Skip & count leading zeroes.
    var zeroes = 0;
    var length = 0;
    var pbegin = 0;
    var pend = source.length;
    while (pbegin !== pend && source[pbegin] === 0) {
      pbegin++;
      zeroes++;
    }
        // Allocate enough space in big-endian base58 representation.
    var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;
    var b58 = new Uint8Array(size);
        // Process the bytes.
    while (pbegin !== pend) {
      var carry = source[pbegin];
            // Apply "b58 = b58 * 256 + ch".
      var i = 0;
      for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {
        carry += (256 * b58[it1]) >>> 0;
        b58[it1] = (carry % BASE) >>> 0;
        carry = (carry / BASE) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      pbegin++;
    }
        // Skip leading zeroes in base58 result.
    var it2 = size - length;
    while (it2 !== size && b58[it2] === 0) {
      it2++;
    }
        // Translate the result into a string.
    var str = LEADER.repeat(zeroes);
    for (; it2 < size; ++it2) { str += ALPHABET.charAt(b58[it2]); }
    return str
  }
  function decodeUnsafe (source) {
    if (typeof source !== 'string') { throw new TypeError('Expected String') }
    if (source.length === 0) { return new Uint8Array() }
    var psz = 0;
        // Skip leading spaces.
    if (source[psz] === ' ') { return }
        // Skip and count leading '1's.
    var zeroes = 0;
    var length = 0;
    while (source[psz] === LEADER) {
      zeroes++;
      psz++;
    }
        // Allocate enough space in big-endian base256 representation.
    var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.
    var b256 = new Uint8Array(size);
        // Process the characters.
    while (source[psz]) {
            // Decode character
      var carry = BASE_MAP[source.charCodeAt(psz)];
            // Invalid character
      if (carry === 255) { return }
      var i = 0;
      for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {
        carry += (BASE * b256[it3]) >>> 0;
        b256[it3] = (carry % 256) >>> 0;
        carry = (carry / 256) >>> 0;
      }
      if (carry !== 0) { throw new Error('Non-zero carry') }
      length = i;
      psz++;
    }
        // Skip trailing spaces.
    if (source[psz] === ' ') { return }
        // Skip leading zeroes in b256.
    var it4 = size - length;
    while (it4 !== size && b256[it4] === 0) {
      it4++;
    }
    var vch = new Uint8Array(zeroes + (size - it4));
    var j = zeroes;
    while (it4 !== size) {
      vch[j++] = b256[it4++];
    }
    return vch
  }
  function decode (string) {
    var buffer = decodeUnsafe(string);
    if (buffer) { return buffer }
    throw new Error(`Non-${name} character`)
  }
  return {
    encode: encode,
    decodeUnsafe: decodeUnsafe,
    decode: decode
  }
}
var src = base;

var _brrp__multiformats_scope_baseX = src;

/**
 * @param {ArrayBufferView|ArrayBuffer|Uint8Array} o
 * @returns {Uint8Array}
 */
const coerce = o => {
  if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array') return o
  if (o instanceof ArrayBuffer) return new Uint8Array(o)
  if (ArrayBuffer.isView(o)) {
    return new Uint8Array(o.buffer, o.byteOffset, o.byteLength)
  }
  throw new Error('Unknown type, must be binary type')
};

/**
 * Class represents both BaseEncoder and MultibaseEncoder meaning it
 * can be used to encode to multibase or base encode without multibase
 * prefix.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.BaseEncoder}
 */
class Encoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   */
  constructor (name, prefix, baseEncode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
  }

  /**
   * @param {Uint8Array} bytes
   * @returns {API.Multibase<Prefix>}
   */
  encode (bytes) {
    if (bytes instanceof Uint8Array) {
      return `${this.prefix}${this.baseEncode(bytes)}`
    } else {
      throw Error('Unknown type, must be binary type')
    }
  }
}

/**
 * @template {string} Prefix
 */
/**
 * Class represents both BaseDecoder and MultibaseDecoder so it could be used
 * to decode multibases (with matching prefix) or just base decode strings
 * with corresponding base encoding.
 *
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.UnibaseDecoder<Prefix>}
 * @implements {API.BaseDecoder}
 */
class Decoder {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    /* c8 ignore next 3 */
    if (prefix.codePointAt(0) === undefined) {
      throw new Error('Invalid prefix character')
    }
    /** @private */
    this.prefixCodePoint = /** @type {number} */ (prefix.codePointAt(0));
    this.baseDecode = baseDecode;
  }

  /**
   * @param {string} text
   */
  decode (text) {
    if (typeof text === 'string') {
      if (text.codePointAt(0) !== this.prefixCodePoint) {
        throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`)
      }
      return this.baseDecode(text.slice(this.prefix.length))
    } else {
      throw Error('Can only multibase decode strings')
    }
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or(this, decoder)
  }
}

/**
 * @template {string} Prefix
 * @typedef {Record<Prefix, API.UnibaseDecoder<Prefix>>} Decoders
 */

/**
 * @template {string} Prefix
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.CombobaseDecoder<Prefix>}
 */
class ComposedDecoder {
  /**
   * @param {Decoders<Prefix>} decoders
   */
  constructor (decoders) {
    this.decoders = decoders;
  }

  /**
   * @template {string} OtherPrefix
   * @param {API.UnibaseDecoder<OtherPrefix>|ComposedDecoder<OtherPrefix>} decoder
   * @returns {ComposedDecoder<Prefix|OtherPrefix>}
   */
  or (decoder) {
    return or(this, decoder)
  }

  /**
   * @param {string} input
   * @returns {Uint8Array}
   */
  decode (input) {
    const prefix = /** @type {Prefix} */ (input[0]);
    const decoder = this.decoders[prefix];
    if (decoder) {
      return decoder.decode(input)
    } else {
      throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`)
    }
  }
}

/**
 * @template {string} L
 * @template {string} R
 * @param {API.UnibaseDecoder<L>|API.CombobaseDecoder<L>} left
 * @param {API.UnibaseDecoder<R>|API.CombobaseDecoder<R>} right
 * @returns {ComposedDecoder<L|R>}
 */
const or = (left, right) => new ComposedDecoder(/** @type {Decoders<L|R>} */({
  ...(left.decoders || { [/** @type API.UnibaseDecoder<L> */(left).prefix]: left }),
  ...(right.decoders || { [/** @type API.UnibaseDecoder<R> */(right).prefix]: right })
}));

/**
 * @class
 * @template {string} Base
 * @template {string} Prefix
 * @implements {API.MultibaseCodec<Prefix>}
 * @implements {API.MultibaseEncoder<Prefix>}
 * @implements {API.MultibaseDecoder<Prefix>}
 * @implements {API.BaseCodec}
 * @implements {API.BaseEncoder}
 * @implements {API.BaseDecoder}
 */
class Codec {
  /**
   * @param {Base} name
   * @param {Prefix} prefix
   * @param {(bytes:Uint8Array) => string} baseEncode
   * @param {(text:string) => Uint8Array} baseDecode
   */
  constructor (name, prefix, baseEncode, baseDecode) {
    this.name = name;
    this.prefix = prefix;
    this.baseEncode = baseEncode;
    this.baseDecode = baseDecode;
    this.encoder = new Encoder(name, prefix, baseEncode);
    this.decoder = new Decoder(name, prefix, baseDecode);
  }

  /**
   * @param {Uint8Array} input
   */
  encode (input) {
    return this.encoder.encode(input)
  }

  /**
   * @param {string} input
   */
  decode (input) {
    return this.decoder.decode(input)
  }
}

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {(bytes:Uint8Array) => string} options.encode
 * @param {(input:string) => Uint8Array} options.decode
 * @returns {Codec<Base, Prefix>}
 */
const from = ({ name, prefix, encode, decode }) =>
  new Codec(name, prefix, encode, decode);

/**
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @returns {Codec<Base, Prefix>}
 */
const baseX = ({ prefix, name, alphabet }) => {
  const { encode, decode } = _brrp__multiformats_scope_baseX(alphabet, name);
  return from({
    prefix,
    name,
    encode,
    /**
     * @param {string} text
     */
    decode: text => coerce(decode(text))
  })
};

/**
 * @param {string} string
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @param {string} name
 * @returns {Uint8Array}
 */
const decode = (string, alphabet, bitsPerChar, name) => {
  // Build the character lookup table:
  /** @type {Record<string, number>} */
  const codes = {};
  for (let i = 0; i < alphabet.length; ++i) {
    codes[alphabet[i]] = i;
  }

  // Count the padding bytes:
  let end = string.length;
  while (string[end - 1] === '=') {
    --end;
  }

  // Allocate the output:
  const out = new Uint8Array((end * bitsPerChar / 8) | 0);

  // Parse the data:
  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  let written = 0; // Next byte to write
  for (let i = 0; i < end; ++i) {
    // Read one character from the string:
    const value = codes[string[i]];
    if (value === undefined) {
      throw new SyntaxError(`Non-${name} character`)
    }

    // Append the bits to the buffer:
    buffer = (buffer << bitsPerChar) | value;
    bits += bitsPerChar;

    // Write out some bits if the buffer has a byte's worth:
    if (bits >= 8) {
      bits -= 8;
      out[written++] = 0xff & (buffer >> bits);
    }
  }

  // Verify that we have received just enough bits:
  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {
    throw new SyntaxError('Unexpected end of data')
  }

  return out
};

/**
 * @param {Uint8Array} data
 * @param {string} alphabet
 * @param {number} bitsPerChar
 * @returns {string}
 */
const encode$1 = (data, alphabet, bitsPerChar) => {
  const pad = alphabet[alphabet.length - 1] === '=';
  const mask = (1 << bitsPerChar) - 1;
  let out = '';

  let bits = 0; // Number of bits currently in the buffer
  let buffer = 0; // Bits waiting to be written out, MSB first
  for (let i = 0; i < data.length; ++i) {
    // Slurp data into the buffer:
    buffer = (buffer << 8) | data[i];
    bits += 8;

    // Write out as much as we can:
    while (bits > bitsPerChar) {
      bits -= bitsPerChar;
      out += alphabet[mask & (buffer >> bits)];
    }
  }

  // Partial character:
  if (bits) {
    out += alphabet[mask & (buffer << (bitsPerChar - bits))];
  }

  // Add padding characters until we hit a byte boundary:
  if (pad) {
    while ((out.length * bitsPerChar) & 7) {
      out += '=';
    }
  }

  return out
};

/**
 * RFC4648 Factory
 *
 * @template {string} Base
 * @template {string} Prefix
 * @param {object} options
 * @param {Base} options.name
 * @param {Prefix} options.prefix
 * @param {string} options.alphabet
 * @param {number} options.bitsPerChar
 */
const rfc4648 = ({ name, prefix, bitsPerChar, alphabet }) => {
  return from({
    prefix,
    name,
    encode (input) {
      return encode$1(input, alphabet, bitsPerChar)
    },
    decode (input) {
      return decode(input, alphabet, bitsPerChar, name)
    }
  })
};

const base32 = rfc4648({
  prefix: 'b',
  name: 'base32',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567',
  bitsPerChar: 5
});

rfc4648({
  prefix: 'B',
  name: 'base32upper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',
  bitsPerChar: 5
});

rfc4648({
  prefix: 'c',
  name: 'base32pad',
  alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',
  bitsPerChar: 5
});

rfc4648({
  prefix: 'C',
  name: 'base32padupper',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',
  bitsPerChar: 5
});

rfc4648({
  prefix: 'v',
  name: 'base32hex',
  alphabet: '0123456789abcdefghijklmnopqrstuv',
  bitsPerChar: 5
});

rfc4648({
  prefix: 'V',
  name: 'base32hexupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',
  bitsPerChar: 5
});

rfc4648({
  prefix: 't',
  name: 'base32hexpad',
  alphabet: '0123456789abcdefghijklmnopqrstuv=',
  bitsPerChar: 5
});

rfc4648({
  prefix: 'T',
  name: 'base32hexpadupper',
  alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',
  bitsPerChar: 5
});

rfc4648({
  prefix: 'h',
  name: 'base32z',
  alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',
  bitsPerChar: 5
});

const base58btc = baseX({
  name: 'base58btc',
  prefix: 'z',
  alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'
});

baseX({
  name: 'base58flickr',
  prefix: 'Z',
  alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'
});

// @ts-check


const base64 = rfc4648({
  prefix: 'm',
  name: 'base64',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',
  bitsPerChar: 6
});

rfc4648({
  prefix: 'M',
  name: 'base64pad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',
  bitsPerChar: 6
});

rfc4648({
  prefix: 'u',
  name: 'base64url',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',
  bitsPerChar: 6
});

rfc4648({
  prefix: 'U',
  name: 'base64urlpad',
  alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',
  bitsPerChar: 6
});

// Add a formatter for converting to a base58 string
debug.formatters.b = (v) => {
    return v == null ? 'undefined' : base58btc.baseEncode(v);
};
// Add a formatter for converting to a base32 string
debug.formatters.t = (v) => {
    return v == null ? 'undefined' : base32.baseEncode(v);
};
// Add a formatter for converting to a base64 string
debug.formatters.m = (v) => {
    return v == null ? 'undefined' : base64.baseEncode(v);
};
// Add a formatter for stringifying peer ids
debug.formatters.p = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying CIDs
debug.formatters.c = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Datastore keys
debug.formatters.k = (v) => {
    return v == null ? 'undefined' : v.toString();
};
// Add a formatter for stringifying Multiaddrs
debug.formatters.a = (v) => {
    return v == null ? 'undefined' : v.toString();
};
function createDisabledLogger(namespace) {
    const logger = () => { };
    logger.enabled = false;
    logger.color = '';
    logger.diff = 0;
    logger.log = () => { };
    logger.namespace = namespace;
    logger.destroy = () => true;
    logger.extend = () => logger;
    return logger;
}
function logger(name) {
    // trace logging is a no-op by default
    let trace = createDisabledLogger(`${name}:trace`);
    // look at all the debug names and see if trace logging has explicitly been enabled
    if (debug.enabled(`${name}:trace`) && debug.names.map(r => r.toString()).find(n => n.includes(':trace')) != null) {
        trace = debug(`${name}:trace`);
    }
    return Object.assign(debug(name), {
        error: debug(`${name}:error`),
        trace
    });
}

/**
 * Returns an `AsyncGenerator` that allows reading a set number of bytes from the passed source.
 *
 * @example
 *
 * ```javascript
 * import { reader } from 'it-reader'
 *
 * const stream = reader(source)
 *
 * // read 10 bytes from the stream
 * const { done, value } = await stream.next(10)
 *
 * if (done === true) {
 *   // stream finished
 * }
 *
 * if (value != null) {
 *   // do something with value
 * }
 * ```
 */
function reader(source) {
    const reader = (async function* () {
        // @ts-expect-error first yield in stream is ignored
        let bytes = yield; // Allows us to receive 8 when reader.next(8) is called
        let bl = new Uint8ArrayList();
        for await (const chunk of source) {
            if (bytes == null) {
                bl.append(chunk);
                bytes = yield bl;
                bl = new Uint8ArrayList();
                continue;
            }
            bl.append(chunk);
            while (bl.length >= bytes) {
                const data = bl.sublist(0, bytes);
                bl.consume(bytes);
                bytes = yield data;
                // If we no longer want a specific byte length, we yield the rest now
                if (bytes == null) {
                    if (bl.length > 0) {
                        bytes = yield bl;
                        bl = new Uint8ArrayList();
                    }
                    break; // bytes is null and/or no more buffer to yield
                }
            }
        }
        // Consumer wants more bytes but the source has ended and our buffer
        // is not big enough to satisfy.
        if (bytes != null) {
            throw Object.assign(new Error(`stream ended before ${bytes} bytes became available`), { code: 'ERR_UNDER_READ', buffer: bl });
        }
    })();
    void reader.next();
    return reader;
}

/**
 * @packageDocumentation
 *
 * @example
 *
 * ```js
 *
 * import { pipe } from 'it-pipe'
 * import { duplexPair } from 'it-pair/duplex'
 * import { handshake } from 'it-handshake'
 *
 * // Create connected duplex streams
 * const [client, server] = duplexPair()
 * const clientShake = handshake(client)
 * const serverShake = handshake(server)
 *
 * clientShake.write('hello')
 * console.log('client: %s', await serverShake.read())
 * // > client: hello
 * serverShake.write('hi')
 * serverShake.rest() // the server has finished the handshake
 * console.log('server: %s', await clientShake.read())
 * // > server: hi
 * clientShake.rest() // the client has finished the handshake
 *
 * // Make the server echo responses
 * pipe(
 *   serverShake.stream,
 *   async function * (source) {
 *     for await (const message of source) {
 *       yield message
 *     }
 *   },
 *   serverShake.stream
 * )
 *
 * // Send and receive an echo through the handshake stream
 * pipe(
 *   ['echo'],
 *   clientShake.stream,
 *   async function * (source) {
 *     for await (const bufferList of source) {
 *       console.log('Echo response: %s', bufferList.slice())
 *       // > Echo response: echo
 *     }
 *   }
 * )
 * ```
 */
// Convert a duplex stream into a reader and writer and rest stream
function handshake(stream) {
    const writer = pushable(); // Write bytes on demand to the sink
    const source = reader(stream.source); // Read bytes on demand from the source
    // Waits for a source to be passed to the rest stream's sink
    const sourcePromise = pDefer();
    let sinkErr;
    const sinkPromise = stream.sink((async function* () {
        yield* writer;
        const source = await sourcePromise.promise;
        yield* source;
    })());
    sinkPromise.catch(err => {
        sinkErr = err;
    });
    const rest = {
        sink: async (source) => {
            if (sinkErr != null) {
                await Promise.reject(sinkErr);
                return;
            }
            sourcePromise.resolve(source);
            await sinkPromise;
        },
        source
    };
    return {
        reader: source,
        writer,
        stream: rest,
        rest: () => writer.end(),
        write: writer.push,
        read: async () => {
            const res = await source.next();
            if (res.value != null) {
                return res.value;
            }
        }
    };
}

const log$7 = logger('libp2p:mss');
const NewLine = fromString$3('\n');
function encode(buffer) {
    const list = new Uint8ArrayList(buffer, NewLine);
    return encode$B.single(list);
}
/**
 * `write` encodes and writes a single buffer
 */
function write(writer, buffer, options = {}) {
    const encoded = encode(buffer);
    if (options.writeBytes === true) {
        writer.push(encoded.subarray());
    }
    else {
        writer.push(encoded);
    }
}
/**
 * `writeAll` behaves like `write`, except it encodes an array of items as a single write
 */
function writeAll(writer, buffers, options = {}) {
    const list = new Uint8ArrayList();
    for (const buf of buffers) {
        list.append(encode(buf));
    }
    if (options.writeBytes === true) {
        writer.push(list.subarray());
    }
    else {
        writer.push(list);
    }
}
async function read(reader, options) {
    let byteLength = 1; // Read single byte chunks until the length is known
    const varByteSource = {
        [Symbol.asyncIterator]: () => varByteSource,
        next: async () => reader.next(byteLength)
    };
    let input = varByteSource;
    // If we have been passed an abort signal, wrap the input source in an abortable
    // iterator that will throw if the operation is aborted
    if (options?.signal != null) {
        input = abortableSource(varByteSource, options.signal);
    }
    // Once the length has been parsed, read chunk for that length
    const onLength = (l) => {
        byteLength = l;
    };
    const buf = await pipe(input, (source) => decode$v(source, { onLength, maxDataLength: MAX_PROTOCOL_LENGTH }), async (source) => first(source));
    if (buf == null || buf.length === 0) {
        throw new CodeError$3('no buffer returned', 'ERR_INVALID_MULTISTREAM_SELECT_MESSAGE');
    }
    if (buf.get(buf.byteLength - 1) !== NewLine[0]) {
        log$7.error('Invalid mss message - missing newline - %s', buf.subarray());
        throw new CodeError$3('missing newline', 'ERR_INVALID_MULTISTREAM_SELECT_MESSAGE');
    }
    return buf.sublist(0, -1); // Remove newline
}
async function readString(reader, options) {
    const buf = await read(reader, options);
    return toString$9(buf.subarray());
}

const log$6 = logger('libp2p:mss:select');
async function select(stream, protocols, options = {}) {
    protocols = Array.isArray(protocols) ? [...protocols] : [protocols];
    const { reader, writer, rest, stream: shakeStream } = handshake(stream);
    const protocol = protocols.shift();
    if (protocol == null) {
        throw new Error('At least one protocol must be specified');
    }
    log$6.trace('select: write ["%s", "%s"]', PROTOCOL_ID, protocol);
    const p1 = fromString$3(PROTOCOL_ID);
    const p2 = fromString$3(protocol);
    writeAll(writer, [p1, p2], options);
    let response = await readString(reader, options);
    log$6.trace('select: read "%s"', response);
    // Read the protocol response if we got the protocolId in return
    if (response === PROTOCOL_ID) {
        response = await readString(reader, options);
        log$6.trace('select: read "%s"', response);
    }
    // We're done
    if (response === protocol) {
        rest();
        return { stream: shakeStream, protocol };
    }
    // We haven't gotten a valid ack, try the other protocols
    for (const protocol of protocols) {
        log$6.trace('select: write "%s"', protocol);
        write(writer, fromString$3(protocol), options);
        const response = await readString(reader, options);
        log$6.trace('select: read "%s" for "%s"', response, protocol);
        if (response === protocol) {
            rest(); // End our writer so others can start writing to stream
            return { stream: shakeStream, protocol };
        }
    }
    rest();
    throw new CodeError$3('protocol selection failed', 'ERR_UNSUPPORTED_PROTOCOL');
}

const log$5 = logger('libp2p:mss:handle');
async function handle(stream, protocols, options) {
    protocols = Array.isArray(protocols) ? protocols : [protocols];
    const { writer, reader, rest, stream: shakeStream } = handshake(stream);
    while (true) {
        const protocol = await readString(reader, options);
        log$5.trace('read "%s"', protocol);
        if (protocol === PROTOCOL_ID) {
            log$5.trace('respond with "%s" for "%s"', PROTOCOL_ID, protocol);
            write(writer, fromString$3(PROTOCOL_ID), options);
            continue;
        }
        if (protocols.includes(protocol)) {
            write(writer, fromString$3(protocol), options);
            log$5.trace('respond with "%s" for "%s"', protocol, protocol);
            rest();
            return { stream: shakeStream, protocol };
        }
        if (protocol === 'ls') {
            // <varint-msg-len><varint-proto-name-len><proto-name>\n<varint-proto-name-len><proto-name>\n\n
            write(writer, new Uint8ArrayList(...protocols.map(p => encode(fromString$3(p)))), options);
            // multistream.writeAll(writer, protocols.map(p => uint8ArrayFromString(p)))
            log$5.trace('respond with "%s" for %s', protocols, protocol);
            continue;
        }
        write(writer, fromString$3('na'), options);
        log$5('respond with "na" for "%s"', protocol);
    }
}

const symbol = Symbol.for('@libp2p/connection');

const log$4 = logger$2('libp2p:connection');
const CLOSE_TIMEOUT = 500;
/**
 * An implementation of the js-libp2p connection.
 * Any libp2p transport should use an upgrader to return this connection.
 */
class ConnectionImpl {
    /**
     * Connection identifier.
     */
    id;
    /**
     * Observed multiaddr of the remote peer
     */
    remoteAddr;
    /**
     * Remote peer id
     */
    remotePeer;
    direction;
    timeline;
    multiplexer;
    encryption;
    status;
    transient;
    /**
     * User provided tags
     *
     */
    tags;
    /**
     * Reference to the new stream function of the multiplexer
     */
    _newStream;
    /**
     * Reference to the close function of the raw connection
     */
    _close;
    _abort;
    /**
     * Reference to the getStreams function of the muxer
     */
    _getStreams;
    /**
     * An implementation of the js-libp2p connection.
     * Any libp2p transport should use an upgrader to return this connection.
     */
    constructor(init) {
        const { remoteAddr, remotePeer, newStream, close, abort, getStreams } = init;
        this.id = `${(parseInt(String(Math.random() * 1e9))).toString(36)}${Date.now()}`;
        this.remoteAddr = remoteAddr;
        this.remotePeer = remotePeer;
        this.direction = init.direction;
        this.status = 'open';
        this.timeline = init.timeline;
        this.multiplexer = init.multiplexer;
        this.encryption = init.encryption;
        this.transient = init.transient ?? false;
        this._newStream = newStream;
        this._close = close;
        this._abort = abort;
        this._getStreams = getStreams;
        this.tags = [];
    }
    [Symbol.toStringTag] = 'Connection';
    [symbol] = true;
    /**
     * Get all the streams of the muxer
     */
    get streams() {
        return this._getStreams();
    }
    /**
     * Create a new stream from this connection
     */
    async newStream(protocols, options) {
        if (this.status === 'closing') {
            throw new CodeError$3('the connection is being closed', 'ERR_CONNECTION_BEING_CLOSED');
        }
        if (this.status === 'closed') {
            throw new CodeError$3('the connection is closed', 'ERR_CONNECTION_CLOSED');
        }
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        if (this.transient && options?.runOnTransientConnection !== true) {
            throw new CodeError$3('Cannot open protocol stream on transient connection', 'ERR_TRANSIENT_CONNECTION');
        }
        const stream = await this._newStream(protocols, options);
        stream.direction = 'outbound';
        return stream;
    }
    /**
     * Close the connection
     */
    async close(options = {}) {
        if (this.status === 'closed' || this.status === 'closing') {
            return;
        }
        log$4('closing connection to %a', this.remoteAddr);
        this.status = 'closing';
        options.signal = options?.signal ?? AbortSignal.timeout(CLOSE_TIMEOUT);
        try {
            // fails on node < 15.4
            eventsExports.setMaxListeners?.(Infinity, options.signal);
        }
        catch { }
        try {
            // close all streams gracefully - this can throw if we're not multiplexed
            await Promise.all(this.streams.map(async (s) => s.close(options)));
            // Close raw connection
            await this._close(options);
            this.timeline.close = Date.now();
            this.status = 'closed';
        }
        catch (err) {
            log$4.error('error encountered during graceful close of connection to %a', this.remoteAddr, err);
            this.abort(err);
        }
    }
    abort(err) {
        log$4.error('aborting connection to %a due to error', this.remoteAddr, err);
        this.status = 'closing';
        this.streams.forEach(s => { s.abort(err); });
        log$4.error('all streams aborted', this.streams.length);
        // Abort raw connection
        this._abort(err);
        this.timeline.close = Date.now();
        this.status = 'closed';
    }
}
function createConnection(init) {
    return new ConnectionImpl(init);
}

const log$3 = logger$2('libp2p:upgrader');
function findIncomingStreamLimit(protocol, registrar) {
    try {
        const { options } = registrar.getHandler(protocol);
        return options.maxInboundStreams;
    }
    catch (err) {
        if (err.code !== codes.ERR_NO_HANDLER_FOR_PROTOCOL) {
            throw err;
        }
    }
    return DEFAULT_MAX_INBOUND_STREAMS;
}
function findOutgoingStreamLimit(protocol, registrar, options = {}) {
    try {
        const { options } = registrar.getHandler(protocol);
        if (options.maxOutboundStreams != null) {
            return options.maxOutboundStreams;
        }
    }
    catch (err) {
        if (err.code !== codes.ERR_NO_HANDLER_FOR_PROTOCOL) {
            throw err;
        }
    }
    return options.maxOutboundStreams ?? DEFAULT_MAX_OUTBOUND_STREAMS;
}
function countStreams(protocol, direction, connection) {
    let streamCount = 0;
    connection.streams.forEach(stream => {
        if (stream.direction === direction && stream.protocol === protocol) {
            streamCount++;
        }
    });
    return streamCount;
}
class DefaultUpgrader {
    components;
    connectionEncryption;
    muxers;
    inboundUpgradeTimeout;
    events;
    constructor(components, init) {
        this.components = components;
        this.connectionEncryption = new Map();
        init.connectionEncryption.forEach(encrypter => {
            this.connectionEncryption.set(encrypter.protocol, encrypter);
        });
        this.muxers = new Map();
        init.muxers.forEach(muxer => {
            this.muxers.set(muxer.protocol, muxer);
        });
        this.inboundUpgradeTimeout = init.inboundUpgradeTimeout ?? INBOUND_UPGRADE_TIMEOUT;
        this.events = components.events;
    }
    async shouldBlockConnection(remotePeer, maConn, connectionType) {
        const connectionGater = this.components.connectionGater[connectionType];
        if (connectionGater !== undefined) {
            if (await connectionGater(remotePeer, maConn)) {
                throw new CodeError$3(`The multiaddr connection is blocked by gater.${connectionType}`, codes.ERR_CONNECTION_INTERCEPTED);
            }
        }
    }
    /**
     * Upgrades an inbound connection
     */
    async upgradeInbound(maConn, opts) {
        const accept = await this.components.connectionManager.acceptIncomingConnection(maConn);
        if (!accept) {
            throw new CodeError$3('connection denied', codes.ERR_CONNECTION_DENIED);
        }
        let encryptedConn;
        let remotePeer;
        let upgradedConn;
        let muxerFactory;
        let cryptoProtocol;
        const signal = AbortSignal.timeout(this.inboundUpgradeTimeout);
        const onAbort = () => {
            maConn.abort(new CodeError$3('inbound upgrade timeout', codes.ERR_TIMEOUT));
        };
        signal.addEventListener('abort', onAbort, { once: true });
        try {
            // fails on node < 15.4
            eventsExports.setMaxListeners?.(Infinity, signal);
        }
        catch { }
        try {
            if ((await this.components.connectionGater.denyInboundConnection?.(maConn)) === true) {
                throw new CodeError$3('The multiaddr connection is blocked by gater.acceptConnection', codes.ERR_CONNECTION_INTERCEPTED);
            }
            this.components.metrics?.trackMultiaddrConnection(maConn);
            log$3('starting the inbound connection upgrade');
            // Protect
            let protectedConn = maConn;
            if (opts?.skipProtection !== true) {
                const protector = this.components.connectionProtector;
                if (protector != null) {
                    log$3('protecting the inbound connection');
                    protectedConn = await protector.protect(maConn);
                }
            }
            try {
                // Encrypt the connection
                encryptedConn = protectedConn;
                if (opts?.skipEncryption !== true) {
                    ({
                        conn: encryptedConn,
                        remotePeer,
                        protocol: cryptoProtocol
                    } = await this._encryptInbound(protectedConn));
                    const maConn = {
                        ...protectedConn,
                        ...encryptedConn
                    };
                    await this.shouldBlockConnection(remotePeer, maConn, 'denyInboundEncryptedConnection');
                }
                else {
                    const idStr = maConn.remoteAddr.getPeerId();
                    if (idStr == null) {
                        throw new CodeError$3('inbound connection that skipped encryption must have a peer id', codes.ERR_INVALID_MULTIADDR);
                    }
                    const remotePeerId = peerIdFromString(idStr);
                    cryptoProtocol = 'native';
                    remotePeer = remotePeerId;
                }
                upgradedConn = encryptedConn;
                if (opts?.muxerFactory != null) {
                    muxerFactory = opts.muxerFactory;
                }
                else if (this.muxers.size > 0) {
                    // Multiplex the connection
                    const multiplexed = await this._multiplexInbound({
                        ...protectedConn,
                        ...encryptedConn
                    }, this.muxers);
                    muxerFactory = multiplexed.muxerFactory;
                    upgradedConn = multiplexed.stream;
                }
            }
            catch (err) {
                log$3.error('Failed to upgrade inbound connection', err);
                throw err;
            }
            await this.shouldBlockConnection(remotePeer, maConn, 'denyInboundUpgradedConnection');
            log$3('Successfully upgraded inbound connection');
            return this._createConnection({
                cryptoProtocol,
                direction: 'inbound',
                maConn,
                upgradedConn,
                muxerFactory,
                remotePeer,
                transient: opts?.transient
            });
        }
        finally {
            signal.removeEventListener('abort', onAbort);
            this.components.connectionManager.afterUpgradeInbound();
        }
    }
    /**
     * Upgrades an outbound connection
     */
    async upgradeOutbound(maConn, opts) {
        const idStr = maConn.remoteAddr.getPeerId();
        let remotePeerId;
        if (idStr != null) {
            remotePeerId = peerIdFromString(idStr);
            await this.shouldBlockConnection(remotePeerId, maConn, 'denyOutboundConnection');
        }
        let encryptedConn;
        let remotePeer;
        let upgradedConn;
        let cryptoProtocol;
        let muxerFactory;
        this.components.metrics?.trackMultiaddrConnection(maConn);
        log$3('Starting the outbound connection upgrade');
        // If the transport natively supports encryption, skip connection
        // protector and encryption
        // Protect
        let protectedConn = maConn;
        if (opts?.skipProtection !== true) {
            const protector = this.components.connectionProtector;
            if (protector != null) {
                protectedConn = await protector.protect(maConn);
            }
        }
        try {
            // Encrypt the connection
            encryptedConn = protectedConn;
            if (opts?.skipEncryption !== true) {
                ({
                    conn: encryptedConn,
                    remotePeer,
                    protocol: cryptoProtocol
                } = await this._encryptOutbound(protectedConn, remotePeerId));
                const maConn = {
                    ...protectedConn,
                    ...encryptedConn
                };
                await this.shouldBlockConnection(remotePeer, maConn, 'denyOutboundEncryptedConnection');
            }
            else {
                if (remotePeerId == null) {
                    throw new CodeError$3('Encryption was skipped but no peer id was passed', codes.ERR_INVALID_PEER);
                }
                cryptoProtocol = 'native';
                remotePeer = remotePeerId;
            }
            upgradedConn = encryptedConn;
            if (opts?.muxerFactory != null) {
                muxerFactory = opts.muxerFactory;
            }
            else if (this.muxers.size > 0) {
                // Multiplex the connection
                const multiplexed = await this._multiplexOutbound({
                    ...protectedConn,
                    ...encryptedConn
                }, this.muxers);
                muxerFactory = multiplexed.muxerFactory;
                upgradedConn = multiplexed.stream;
            }
        }
        catch (err) {
            log$3.error('Failed to upgrade outbound connection', err);
            await maConn.close(err);
            throw err;
        }
        await this.shouldBlockConnection(remotePeer, maConn, 'denyOutboundUpgradedConnection');
        log$3('Successfully upgraded outbound connection');
        return this._createConnection({
            cryptoProtocol,
            direction: 'outbound',
            maConn,
            upgradedConn,
            muxerFactory,
            remotePeer,
            transient: opts?.transient
        });
    }
    /**
     * A convenience method for generating a new `Connection`
     */
    _createConnection(opts) {
        const { cryptoProtocol, direction, maConn, upgradedConn, remotePeer, muxerFactory, transient } = opts;
        let muxer;
        let newStream;
        let connection; // eslint-disable-line prefer-const
        if (muxerFactory != null) {
            // Create the muxer
            muxer = muxerFactory.createStreamMuxer({
                direction,
                // Run anytime a remote stream is created
                onIncomingStream: muxedStream => {
                    if (connection == null) {
                        return;
                    }
                    void Promise.resolve()
                        .then(async () => {
                        const protocols = this.components.registrar.getProtocols();
                        const { stream, protocol } = await handle(muxedStream, protocols);
                        log$3('%s: incoming stream opened on %s', direction, protocol);
                        if (connection == null) {
                            return;
                        }
                        const incomingLimit = findIncomingStreamLimit(protocol, this.components.registrar);
                        const streamCount = countStreams(protocol, 'inbound', connection);
                        if (streamCount === incomingLimit) {
                            const err = new CodeError$3(`Too many inbound protocol streams for protocol "${protocol}" - limit ${incomingLimit}`, codes.ERR_TOO_MANY_INBOUND_PROTOCOL_STREAMS);
                            muxedStream.abort(err);
                            throw err;
                        }
                        // after the handshake the returned stream can have early data so override
                        // the souce/sink
                        muxedStream.source = stream.source;
                        muxedStream.sink = stream.sink;
                        muxedStream.protocol = protocol;
                        // If a protocol stream has been successfully negotiated and is to be passed to the application,
                        // the peerstore should ensure that the peer is registered with that protocol
                        await this.components.peerStore.merge(remotePeer, {
                            protocols: [protocol]
                        });
                        this.components.metrics?.trackProtocolStream(muxedStream, connection);
                        this._onStream({ connection, stream: muxedStream, protocol });
                    })
                        .catch(async (err) => {
                        log$3.error(err);
                        if (muxedStream.timeline.close == null) {
                            await muxedStream.close();
                        }
                    });
                }
            });
            newStream = async (protocols, options = {}) => {
                if (muxer == null) {
                    throw new CodeError$3('Stream is not multiplexed', codes.ERR_MUXER_UNAVAILABLE);
                }
                log$3('%s: starting new stream on %s', direction, protocols);
                const muxedStream = await muxer.newStream();
                try {
                    if (options.signal == null) {
                        log$3('No abort signal was passed while trying to negotiate protocols %s falling back to default timeout', protocols);
                        options.signal = AbortSignal.timeout(30000);
                        try {
                            // fails on node < 15.4
                            eventsExports.setMaxListeners?.(Infinity, options.signal);
                        }
                        catch { }
                    }
                    const { stream, protocol } = await select(muxedStream, protocols, options);
                    const outgoingLimit = findOutgoingStreamLimit(protocol, this.components.registrar, options);
                    const streamCount = countStreams(protocol, 'outbound', connection);
                    if (streamCount >= outgoingLimit) {
                        const err = new CodeError$3(`Too many outbound protocol streams for protocol "${protocol}" - limit ${outgoingLimit}`, codes.ERR_TOO_MANY_OUTBOUND_PROTOCOL_STREAMS);
                        muxedStream.abort(err);
                        throw err;
                    }
                    // If a protocol stream has been successfully negotiated and is to be passed to the application,
                    // the peerstore should ensure that the peer is registered with that protocol
                    await this.components.peerStore.merge(remotePeer, {
                        protocols: [protocol]
                    });
                    // after the handshake the returned stream can have early data so override
                    // the souce/sink
                    muxedStream.source = stream.source;
                    muxedStream.sink = stream.sink;
                    muxedStream.protocol = protocol;
                    this.components.metrics?.trackProtocolStream(muxedStream, connection);
                    return muxedStream;
                }
                catch (err) {
                    log$3.error('could not create new stream', err);
                    if (muxedStream.timeline.close == null) {
                        muxedStream.abort(err);
                    }
                    if (err.code != null) {
                        throw err;
                    }
                    throw new CodeError$3(String(err), codes.ERR_UNSUPPORTED_PROTOCOL);
                }
            };
            // Pipe all data through the muxer
            void Promise.all([
                muxer.sink(upgradedConn.source),
                upgradedConn.sink(muxer.source)
            ]).catch(err => {
                log$3.error(err);
            });
        }
        const _timeline = maConn.timeline;
        maConn.timeline = new Proxy(_timeline, {
            set: (...args) => {
                if (connection != null && args[1] === 'close' && args[2] != null && _timeline.close == null) {
                    // Wait for close to finish before notifying of the closure
                    (async () => {
                        try {
                            if (connection.status === 'open') {
                                await connection.close();
                            }
                        }
                        catch (err) {
                            log$3.error(err);
                        }
                        finally {
                            this.events.safeDispatchEvent('connection:close', {
                                detail: connection
                            });
                        }
                    })().catch(err => {
                        log$3.error(err);
                    });
                }
                return Reflect.set(...args);
            }
        });
        maConn.timeline.upgraded = Date.now();
        const errConnectionNotMultiplexed = () => {
            throw new CodeError$3('connection is not multiplexed', codes.ERR_CONNECTION_NOT_MULTIPLEXED);
        };
        // Create the connection
        connection = createConnection({
            remoteAddr: maConn.remoteAddr,
            remotePeer,
            status: 'open',
            direction,
            timeline: maConn.timeline,
            multiplexer: muxer?.protocol,
            encryption: cryptoProtocol,
            transient,
            newStream: newStream ?? errConnectionNotMultiplexed,
            getStreams: () => { if (muxer != null) {
                return muxer.streams;
            }
            else {
                return [];
            } },
            close: async (options) => {
                await maConn.close(options);
                // Ensure remaining streams are closed gracefully
                if (muxer != null) {
                    await muxer.close(options);
                }
            },
            abort: (err) => {
                maConn.abort(err);
                // Ensure remaining streams are aborted
                if (muxer != null) {
                    muxer.abort(err);
                }
            }
        });
        this.events.safeDispatchEvent('connection:open', {
            detail: connection
        });
        return connection;
    }
    /**
     * Routes incoming streams to the correct handler
     */
    _onStream(opts) {
        const { connection, stream, protocol } = opts;
        const { handler, options } = this.components.registrar.getHandler(protocol);
        if (connection.transient && options.runOnTransientConnection !== true) {
            throw new CodeError$3('Cannot open protocol stream on transient connection', 'ERR_TRANSIENT_CONNECTION');
        }
        handler({ connection, stream });
    }
    /**
     * Attempts to encrypt the incoming `connection` with the provided `cryptos`
     */
    async _encryptInbound(connection) {
        const protocols = Array.from(this.connectionEncryption.keys());
        log$3('handling inbound crypto protocol selection', protocols);
        try {
            const { stream, protocol } = await handle(connection, protocols, {
                writeBytes: true
            });
            const encrypter = this.connectionEncryption.get(protocol);
            if (encrypter == null) {
                throw new Error(`no crypto module found for ${protocol}`);
            }
            log$3('encrypting inbound connection...');
            return {
                ...await encrypter.secureInbound(this.components.peerId, stream),
                protocol
            };
        }
        catch (err) {
            throw new CodeError$3(String(err), codes.ERR_ENCRYPTION_FAILED);
        }
    }
    /**
     * Attempts to encrypt the given `connection` with the provided connection encrypters.
     * The first `ConnectionEncrypter` module to succeed will be used
     */
    async _encryptOutbound(connection, remotePeerId) {
        const protocols = Array.from(this.connectionEncryption.keys());
        log$3('selecting outbound crypto protocol', protocols);
        try {
            const { stream, protocol } = await select(connection, protocols, {
                writeBytes: true
            });
            const encrypter = this.connectionEncryption.get(protocol);
            if (encrypter == null) {
                throw new Error(`no crypto module found for ${protocol}`);
            }
            log$3('encrypting outbound connection to %p', remotePeerId);
            return {
                ...await encrypter.secureOutbound(this.components.peerId, stream, remotePeerId),
                protocol
            };
        }
        catch (err) {
            throw new CodeError$3(String(err), codes.ERR_ENCRYPTION_FAILED);
        }
    }
    /**
     * Selects one of the given muxers via multistream-select. That
     * muxer will be used for all future streams on the connection.
     */
    async _multiplexOutbound(connection, muxers) {
        const protocols = Array.from(muxers.keys());
        log$3('outbound selecting muxer %s', protocols);
        try {
            const { stream, protocol } = await select(connection, protocols, {
                writeBytes: true
            });
            log$3('%s selected as muxer protocol', protocol);
            const muxerFactory = muxers.get(protocol);
            return { stream, muxerFactory };
        }
        catch (err) {
            log$3.error('error multiplexing outbound stream', err);
            throw new CodeError$3(String(err), codes.ERR_MUXER_UNAVAILABLE);
        }
    }
    /**
     * Registers support for one of the given muxers via multistream-select. The
     * selected muxer will be used for all future streams on the connection.
     */
    async _multiplexInbound(connection, muxers) {
        const protocols = Array.from(muxers.keys());
        log$3('inbound handling muxers %s', protocols);
        try {
            const { stream, protocol } = await handle(connection, protocols, {
                writeBytes: true
            });
            const muxerFactory = muxers.get(protocol);
            return { stream, muxerFactory };
        }
        catch (err) {
            log$3.error('error multiplexing inbound stream', err);
            throw new CodeError$3(String(err), codes.ERR_MUXER_UNAVAILABLE);
        }
    }
}

const log$2 = logger$2('libp2p');
class Libp2pNode extends EventEmitter$2 {
    peerId;
    peerStore;
    contentRouting;
    peerRouting;
    keychain;
    metrics;
    services;
    components;
    #started;
    constructor(init) {
        super();
        // event bus - components can listen to this emitter to be notified of system events
        // and also cause them to be emitted
        const events = new EventEmitter$2();
        const originalDispatch = events.dispatchEvent.bind(events);
        events.dispatchEvent = (evt) => {
            const internalResult = originalDispatch(evt);
            const externalResult = this.dispatchEvent(new CustomEvent(evt.type, { detail: evt.detail }));
            return internalResult || externalResult;
        };
        try {
            // This emitter gets listened to a lot
            eventsExports.setMaxListeners?.(Infinity, events);
        }
        catch { }
        this.#started = false;
        this.peerId = init.peerId;
        // @ts-expect-error {} may not be of type T
        this.services = {};
        const components = this.components = defaultComponents({
            peerId: init.peerId,
            events,
            datastore: init.datastore ?? new MemoryDatastore(),
            connectionGater: connectionGater(init.connectionGater)
        });
        this.peerStore = this.configureComponent('peerStore', new PersistentPeerStore(components, {
            addressFilter: this.components.connectionGater.filterMultiaddrForPeer,
            ...init.peerStore
        }));
        // Create Metrics
        if (init.metrics != null) {
            this.metrics = this.configureComponent('metrics', init.metrics(this.components));
        }
        components.events.addEventListener('peer:update', evt => {
            // if there was no peer previously in the peer store this is a new peer
            if (evt.detail.previous == null) {
                const peerInfo = {
                    id: evt.detail.peer.id,
                    multiaddrs: evt.detail.peer.addresses.map(a => a.multiaddr),
                    protocols: evt.detail.peer.protocols
                };
                components.events.safeDispatchEvent('peer:discovery', { detail: peerInfo });
            }
        });
        // Set up connection protector if configured
        if (init.connectionProtector != null) {
            this.configureComponent('connectionProtector', init.connectionProtector(components));
        }
        // Set up the Upgrader
        this.components.upgrader = new DefaultUpgrader(this.components, {
            connectionEncryption: (init.connectionEncryption ?? []).map((fn, index) => this.configureComponent(`connection-encryption-${index}`, fn(this.components))),
            muxers: (init.streamMuxers ?? []).map((fn, index) => this.configureComponent(`stream-muxers-${index}`, fn(this.components))),
            inboundUpgradeTimeout: init.connectionManager.inboundUpgradeTimeout
        });
        // Setup the transport manager
        this.configureComponent('transportManager', new DefaultTransportManager(this.components, init.transportManager));
        // Create the Connection Manager
        this.configureComponent('connectionManager', new DefaultConnectionManager(this.components, init.connectionManager));
        // Create the Registrar
        this.configureComponent('registrar', new DefaultRegistrar(this.components));
        // Addresses {listen, announce, noAnnounce}
        this.configureComponent('addressManager', new DefaultAddressManager(this.components, init.addresses));
        // Create keychain
        const keychainOpts = DefaultKeyChain.generateOptions();
        this.keychain = this.configureComponent('keyChain', new DefaultKeyChain(this.components, {
            ...keychainOpts,
            ...init.keychain
        }));
        // Peer routers
        const peerRouters = (init.peerRouters ?? []).map((fn, index) => this.configureComponent(`peer-router-${index}`, fn(this.components)));
        this.peerRouting = this.components.peerRouting = this.configureComponent('peerRouting', new DefaultPeerRouting(this.components, {
            routers: peerRouters
        }));
        // Content routers
        const contentRouters = (init.contentRouters ?? []).map((fn, index) => this.configureComponent(`content-router-${index}`, fn(this.components)));
        this.contentRouting = this.components.contentRouting = this.configureComponent('contentRouting', new CompoundContentRouting(this.components, {
            routers: contentRouters
        }));
        (init.peerDiscovery ?? []).forEach((fn, index) => {
            const service = this.configureComponent(`peer-discovery-${index}`, fn(this.components));
            service.addEventListener('peer', (evt) => {
                this.#onDiscoveryPeer(evt);
            });
        });
        // Transport modules
        init.transports.forEach((fn, index) => {
            this.components.transportManager.add(this.configureComponent(`transport-${index}`, fn(this.components)));
        });
        // User defined modules
        if (init.services != null) {
            for (const name of Object.keys(init.services)) {
                const createService = init.services[name];
                const service = createService(this.components);
                if (service == null) {
                    log$2.error('service factory %s returned null or undefined instance', name);
                    continue;
                }
                this.services[name] = service;
                this.configureComponent(name, service);
                if (service[contentRouting] != null) {
                    log$2('registering service %s for content routing', name);
                    contentRouters.push(service[contentRouting]);
                }
                if (service[peerRouting] != null) {
                    log$2('registering service %s for peer routing', name);
                    peerRouters.push(service[peerRouting]);
                }
                if (service[peerDiscovery] != null) {
                    log$2('registering service %s for peer discovery', name);
                    service[peerDiscovery].addEventListener('peer', (evt) => {
                        this.#onDiscoveryPeer(evt);
                    });
                }
            }
        }
    }
    configureComponent(name, component) {
        if (component == null) {
            log$2.error('component %s was null or undefined', name);
        }
        this.components[name] = component;
        return component;
    }
    /**
     * Starts the libp2p node and all its subsystems
     */
    async start() {
        if (this.#started) {
            return;
        }
        this.#started = true;
        log$2('libp2p is starting');
        const keys = await this.keychain.listKeys();
        if (keys.find(key => key.name === 'self') == null) {
            log$2('importing self key into keychain');
            await this.keychain.importPeer('self', this.components.peerId);
        }
        try {
            await this.components.beforeStart?.();
            await this.components.start();
            await this.components.afterStart?.();
            this.safeDispatchEvent('start', { detail: this });
            log$2('libp2p has started');
        }
        catch (err) {
            log$2.error('An error occurred starting libp2p', err);
            await this.stop();
            throw err;
        }
    }
    /**
     * Stop the libp2p node by closing its listeners and open connections
     */
    async stop() {
        if (!this.#started) {
            return;
        }
        log$2('libp2p is stopping');
        this.#started = false;
        await this.components.beforeStop?.();
        await this.components.stop();
        await this.components.afterStop?.();
        this.safeDispatchEvent('stop', { detail: this });
        log$2('libp2p has stopped');
    }
    isStarted() {
        return this.#started;
    }
    getConnections(peerId) {
        return this.components.connectionManager.getConnections(peerId);
    }
    getDialQueue() {
        return this.components.connectionManager.getDialQueue();
    }
    getPeers() {
        const peerSet = new PeerSet();
        for (const conn of this.components.connectionManager.getConnections()) {
            peerSet.add(conn.remotePeer);
        }
        return Array.from(peerSet);
    }
    async dial(peer, options = {}) {
        return this.components.connectionManager.openConnection(peer, options);
    }
    async dialProtocol(peer, protocols, options = {}) {
        if (protocols == null) {
            throw new CodeError$3('no protocols were provided to open a stream', codes.ERR_INVALID_PROTOCOLS_FOR_STREAM);
        }
        protocols = Array.isArray(protocols) ? protocols : [protocols];
        if (protocols.length === 0) {
            throw new CodeError$3('no protocols were provided to open a stream', codes.ERR_INVALID_PROTOCOLS_FOR_STREAM);
        }
        const connection = await this.dial(peer, options);
        return connection.newStream(protocols, options);
    }
    getMultiaddrs() {
        return this.components.addressManager.getAddresses();
    }
    getProtocols() {
        return this.components.registrar.getProtocols();
    }
    async hangUp(peer, options = {}) {
        if (isMultiaddr$1(peer)) {
            peer = peerIdFromString(peer.getPeerId() ?? '');
        }
        await this.components.connectionManager.closeConnections(peer, options);
    }
    /**
     * Get the public key for the given peer id
     */
    async getPublicKey(peer, options = {}) {
        log$2('getPublicKey %p', peer);
        if (peer.publicKey != null) {
            return peer.publicKey;
        }
        const peerInfo = await this.peerStore.get(peer);
        if (peerInfo.id.publicKey != null) {
            return peerInfo.id.publicKey;
        }
        const peerKey = concat$1([
            fromString$3('/pk/'),
            peer.multihash.digest
        ]);
        // search any available content routing methods
        const bytes = await this.contentRouting.get(peerKey, options);
        // ensure the returned key is valid
        unmarshalPublicKey$1(bytes);
        await this.peerStore.patch(peer, {
            publicKey: bytes
        });
        return bytes;
    }
    async handle(protocols, handler, options) {
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        await Promise.all(protocols.map(async (protocol) => {
            await this.components.registrar.handle(protocol, handler, options);
        }));
    }
    async unhandle(protocols) {
        if (!Array.isArray(protocols)) {
            protocols = [protocols];
        }
        await Promise.all(protocols.map(async (protocol) => {
            await this.components.registrar.unhandle(protocol);
        }));
    }
    async register(protocol, topology) {
        return this.components.registrar.register(protocol, topology);
    }
    unregister(id) {
        this.components.registrar.unregister(id);
    }
    /**
     * Called whenever peer discovery services emit `peer` events and adds peers
     * to the peer store.
     */
    #onDiscoveryPeer(evt) {
        const { detail: peer } = evt;
        if (peer.id.toString() === this.peerId.toString()) {
            log$2.error(new Error(codes.ERR_DISCOVERED_SELF));
            return;
        }
        void this.components.peerStore.merge(peer.id, {
            multiaddrs: peer.multiaddrs,
            protocols: peer.protocols
        })
            .catch(err => { log$2.error(err); });
    }
}
/**
 * Returns a new Libp2pNode instance - this exposes more of the internals than the
 * libp2p interface and is useful for testing and debugging.
 */
async function createLibp2pNode(options) {
    if (options.peerId == null) {
        const datastore = options.datastore;
        if (datastore != null) {
            try {
                // try load the peer id from the keychain
                const keyChain = new DefaultKeyChain({
                    datastore
                }, mergeOptions$1(DefaultKeyChain.generateOptions(), options.keychain));
                options.peerId = await keyChain.exportPeerId('self');
            }
            catch (err) {
                if (err.code !== 'ERR_NOT_FOUND') {
                    throw err;
                }
            }
        }
    }
    if (options.peerId == null) {
        // no peer id in the keychain, create a new peer id
        options.peerId = await createEd25519PeerId();
    }
    return new Libp2pNode(validateConfig(options));
}

/**
 * @packageDocumentation
 *
 * Use the `createLibp2p` function to create a libp2p node.
 *
 * @example
 *
 * ```typescript
 * import { createLibp2p } from 'libp2p'
 *
 * const node = await createLibp2p({
 *   // ...other options
 * })
 * ```
 */
/**
 * Returns a new instance of the Libp2p interface, generating a new PeerId
 * if one is not passed as part of the options.
 *
 * The node will be started unless `start: false` is passed as an option.
 *
 * @example
 *
 * ```js
 * import { createLibp2p } from 'libp2p'
 * import { tcp } from '@libp2p/tcp'
 * import { mplex } from '@libp2p/mplex'
 * import { noise } from '@chainsafe/libp2p-noise'
 * import { yamux } from '@chainsafe/libp2p-yamux'
 *
 * // specify options
 * const options = {
 *   transports: [tcp()],
 *   streamMuxers: [yamux(), mplex()],
 *   connectionEncryption: [noise()]
 * }
 *
 * // create libp2p
 * const libp2p = await createLibp2p(options)
 * ```
 */
async function createLibp2p(options) {
    const node = await createLibp2pNode(options);
    if (options.start !== false) {
        await node.start();
    }
    return node;
}

const version = '0.46.9';

const AGENT_VERSION = `js-libp2p/${version}`;
const IDENTIFY_PROTOCOL_VERSION = '0.1.0';
const MULTICODEC_IDENTIFY_PROTOCOL_NAME = 'id';
const MULTICODEC_IDENTIFY_PUSH_PROTOCOL_NAME = 'id/push';
const MULTICODEC_IDENTIFY_PROTOCOL_VERSION = '1.0.0';
const MULTICODEC_IDENTIFY_PUSH_PROTOCOL_VERSION = '1.0.0';

/**
 * @packageDocumentation
 *
 * This module makes it easy to send and receive length-prefixed Protobuf encoded
 * messages over streams.
 *
 * @example
 *
 * ```typescript
 * import { pbStream } from 'it-protobuf-stream'
 * import { MessageType } from './src/my-message-type.js'
 *
 * // RequestType and ResponseType have been generate from `.proto` files and have
 * // `.encode` and `.decode` methods for serialization/deserialization
 *
 * const stream = pbStream(duplex)
 *
 * // write a message to the stream
 * stream.write({
 *   foo: 'bar'
 * }, MessageType)
 *
 * // read a message from the stream
 * const res = await stream.read(MessageType)
 * ```
 */
function pbStream(duplex, opts) {
    const lp = lpStream(duplex, opts);
    const W = {
        read: async (proto, options) => {
            // readLP, decode
            const value = await lp.read(options);
            return proto.decode(value);
        },
        write: async (data, proto, options) => {
            // encode, writeLP
            await lp.write(proto.encode(data), options);
        },
        pb: (proto) => {
            return {
                read: async (options) => W.read(proto, options),
                write: async (d, options) => W.write(d, proto, options),
                unwrap: () => W
            };
        },
        unwrap: () => {
            return lp.unwrap();
        }
    };
    return W;
}

/* eslint-disable import/export */
/* eslint-disable complexity */
/* eslint-disable @typescript-eslint/no-namespace */
/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */
/* eslint-disable @typescript-eslint/no-empty-interface */
var Identify;
(function (Identify) {
    let _codec;
    Identify.codec = () => {
        if (_codec == null) {
            _codec = message$1((obj, w, opts = {}) => {
                if (opts.lengthDelimited !== false) {
                    w.fork();
                }
                if (obj.protocolVersion != null) {
                    w.uint32(42);
                    w.string(obj.protocolVersion);
                }
                if (obj.agentVersion != null) {
                    w.uint32(50);
                    w.string(obj.agentVersion);
                }
                if (obj.publicKey != null) {
                    w.uint32(10);
                    w.bytes(obj.publicKey);
                }
                if (obj.listenAddrs != null) {
                    for (const value of obj.listenAddrs) {
                        w.uint32(18);
                        w.bytes(value);
                    }
                }
                if (obj.observedAddr != null) {
                    w.uint32(34);
                    w.bytes(obj.observedAddr);
                }
                if (obj.protocols != null) {
                    for (const value of obj.protocols) {
                        w.uint32(26);
                        w.string(value);
                    }
                }
                if (obj.signedPeerRecord != null) {
                    w.uint32(66);
                    w.bytes(obj.signedPeerRecord);
                }
                if (opts.lengthDelimited !== false) {
                    w.ldelim();
                }
            }, (reader, length) => {
                const obj = {
                    listenAddrs: [],
                    protocols: []
                };
                const end = length == null ? reader.len : reader.pos + length;
                while (reader.pos < end) {
                    const tag = reader.uint32();
                    switch (tag >>> 3) {
                        case 5:
                            obj.protocolVersion = reader.string();
                            break;
                        case 6:
                            obj.agentVersion = reader.string();
                            break;
                        case 1:
                            obj.publicKey = reader.bytes();
                            break;
                        case 2:
                            obj.listenAddrs.push(reader.bytes());
                            break;
                        case 4:
                            obj.observedAddr = reader.bytes();
                            break;
                        case 3:
                            obj.protocols.push(reader.string());
                            break;
                        case 8:
                            obj.signedPeerRecord = reader.bytes();
                            break;
                        default:
                            reader.skipType(tag & 7);
                            break;
                    }
                }
                return obj;
            });
        }
        return _codec;
    };
    Identify.encode = (obj) => {
        return encodeMessage(obj, Identify.codec());
    };
    Identify.decode = (buf) => {
        return decodeMessage$1(buf, Identify.codec());
    };
})(Identify || (Identify = {}));

const log$1 = logger$2('libp2p:identify');
// https://github.com/libp2p/go-libp2p/blob/8d2e54e1637041d5cf4fac1e531287560bd1f4ac/p2p/protocol/identify/id.go#L52
const MAX_IDENTIFY_MESSAGE_SIZE = 1024 * 8;
const defaultValues = {
    protocolPrefix: 'ipfs',
    agentVersion: AGENT_VERSION,
    // https://github.com/libp2p/go-libp2p/blob/8d2e54e1637041d5cf4fac1e531287560bd1f4ac/p2p/protocol/identify/id.go#L48
    timeout: 60000,
    maxInboundStreams: 1,
    maxOutboundStreams: 1,
    maxPushIncomingStreams: 1,
    maxPushOutgoingStreams: 1,
    maxObservedAddresses: 10,
    maxIdentifyMessageSize: 8192,
    runOnConnectionOpen: true,
    runOnTransientConnection: true
};
class DefaultIdentifyService {
    identifyProtocolStr;
    identifyPushProtocolStr;
    host;
    started;
    timeout;
    peerId;
    peerStore;
    registrar;
    connectionManager;
    addressManager;
    maxInboundStreams;
    maxOutboundStreams;
    maxPushIncomingStreams;
    maxPushOutgoingStreams;
    maxIdentifyMessageSize;
    maxObservedAddresses;
    events;
    runOnTransientConnection;
    constructor(components, init) {
        this.started = false;
        this.peerId = components.peerId;
        this.peerStore = components.peerStore;
        this.registrar = components.registrar;
        this.addressManager = components.addressManager;
        this.connectionManager = components.connectionManager;
        this.events = components.events;
        this.identifyProtocolStr = `/${init.protocolPrefix ?? defaultValues.protocolPrefix}/${MULTICODEC_IDENTIFY_PROTOCOL_NAME}/${MULTICODEC_IDENTIFY_PROTOCOL_VERSION}`;
        this.identifyPushProtocolStr = `/${init.protocolPrefix ?? defaultValues.protocolPrefix}/${MULTICODEC_IDENTIFY_PUSH_PROTOCOL_NAME}/${MULTICODEC_IDENTIFY_PUSH_PROTOCOL_VERSION}`;
        this.timeout = init.timeout ?? defaultValues.timeout;
        this.maxInboundStreams = init.maxInboundStreams ?? defaultValues.maxInboundStreams;
        this.maxOutboundStreams = init.maxOutboundStreams ?? defaultValues.maxOutboundStreams;
        this.maxPushIncomingStreams = init.maxPushIncomingStreams ?? defaultValues.maxPushIncomingStreams;
        this.maxPushOutgoingStreams = init.maxPushOutgoingStreams ?? defaultValues.maxPushOutgoingStreams;
        this.maxIdentifyMessageSize = init.maxIdentifyMessageSize ?? defaultValues.maxIdentifyMessageSize;
        this.maxObservedAddresses = init.maxObservedAddresses ?? defaultValues.maxObservedAddresses;
        this.runOnTransientConnection = init.runOnTransientConnection ?? defaultValues.runOnTransientConnection;
        // Store self host metadata
        this.host = {
            protocolVersion: `${init.protocolPrefix ?? defaultValues.protocolPrefix}/${IDENTIFY_PROTOCOL_VERSION}`,
            agentVersion: init.agentVersion ?? defaultValues.agentVersion
        };
        if (init.runOnConnectionOpen ?? defaultValues.runOnConnectionOpen) {
            // When a new connection happens, trigger identify
            components.events.addEventListener('connection:open', (evt) => {
                const connection = evt.detail;
                this.identify(connection).catch(err => { log$1.error('error during identify trigged by connection:open', err); });
            });
        }
        // When self peer record changes, trigger identify-push
        components.events.addEventListener('self:peer:update', (evt) => {
            void this.push().catch(err => { log$1.error(err); });
        });
        // Append user agent version to default AGENT_VERSION depending on the environment
        if (this.host.agentVersion === AGENT_VERSION) {
            if (isNode || isElectronMain) {
                this.host.agentVersion += ` UserAgent=${globalThis.process.version}`;
            }
            else if (isBrowser || isWebWorker || isElectronRenderer || isReactNative) {
                this.host.agentVersion += ` UserAgent=${globalThis.navigator.userAgent}`;
            }
        }
    }
    isStarted() {
        return this.started;
    }
    async start() {
        if (this.started) {
            return;
        }
        await this.peerStore.merge(this.peerId, {
            metadata: {
                AgentVersion: fromString$3(this.host.agentVersion),
                ProtocolVersion: fromString$3(this.host.protocolVersion)
            }
        });
        await this.registrar.handle(this.identifyProtocolStr, (data) => {
            void this._handleIdentify(data).catch(err => {
                log$1.error(err);
            });
        }, {
            maxInboundStreams: this.maxInboundStreams,
            maxOutboundStreams: this.maxOutboundStreams,
            runOnTransientConnection: this.runOnTransientConnection
        });
        await this.registrar.handle(this.identifyPushProtocolStr, (data) => {
            void this._handlePush(data).catch(err => {
                log$1.error(err);
            });
        }, {
            maxInboundStreams: this.maxPushIncomingStreams,
            maxOutboundStreams: this.maxPushOutgoingStreams,
            runOnTransientConnection: this.runOnTransientConnection
        });
        this.started = true;
    }
    async stop() {
        await this.registrar.unhandle(this.identifyProtocolStr);
        await this.registrar.unhandle(this.identifyPushProtocolStr);
        this.started = false;
    }
    /**
     * Send an Identify Push update to the list of connections
     */
    async pushToConnections(connections) {
        const listenAddresses = this.addressManager.getAddresses().map(ma => ma.decapsulateCode(getProtocol$1('p2p').code));
        const peerRecord = new PeerRecord({
            peerId: this.peerId,
            multiaddrs: listenAddresses
        });
        const signedPeerRecord = await RecordEnvelope.seal(peerRecord, this.peerId);
        const supportedProtocols = this.registrar.getProtocols();
        const peer = await this.peerStore.get(this.peerId);
        const agentVersion = toString$9(peer.metadata.get('AgentVersion') ?? fromString$3(this.host.agentVersion));
        const protocolVersion = toString$9(peer.metadata.get('ProtocolVersion') ?? fromString$3(this.host.protocolVersion));
        const pushes = connections.map(async (connection) => {
            let stream;
            const signal = AbortSignal.timeout(this.timeout);
            try {
                // fails on node < 15.4
                eventsExports.setMaxListeners?.(Infinity, signal);
            }
            catch { }
            try {
                stream = await connection.newStream([this.identifyPushProtocolStr], {
                    signal,
                    runOnTransientConnection: this.runOnTransientConnection
                });
                const pb = pbStream(stream, {
                    maxDataLength: this.maxIdentifyMessageSize ?? MAX_IDENTIFY_MESSAGE_SIZE
                }).pb(Identify);
                await pb.write({
                    listenAddrs: listenAddresses.map(ma => ma.bytes),
                    signedPeerRecord: signedPeerRecord.marshal(),
                    protocols: supportedProtocols,
                    agentVersion,
                    protocolVersion
                }, {
                    signal
                });
                await stream.close({
                    signal
                });
            }
            catch (err) {
                // Just log errors
                log$1.error('could not push identify update to peer', err);
                stream?.abort(err);
            }
        });
        await Promise.all(pushes);
    }
    /**
     * Calls `push` on all peer connections
     */
    async push() {
        // Do not try to push if we are not running
        if (!this.isStarted()) {
            return;
        }
        const connections = [];
        await Promise.all(this.connectionManager.getConnections().map(async (conn) => {
            try {
                const peer = await this.peerStore.get(conn.remotePeer);
                if (!peer.protocols.includes(this.identifyPushProtocolStr)) {
                    return;
                }
                connections.push(conn);
            }
            catch (err) {
                if (err.code !== codes.ERR_NOT_FOUND) {
                    throw err;
                }
            }
        }));
        await this.pushToConnections(connections);
    }
    async _identify(connection, options = {}) {
        let stream;
        options.signal = options.signal ?? AbortSignal.timeout(this.timeout);
        try {
            stream = await connection.newStream([this.identifyProtocolStr], {
                ...options,
                runOnTransientConnection: this.runOnTransientConnection
            });
            const pb = pbStream(stream, {
                maxDataLength: this.maxIdentifyMessageSize ?? MAX_IDENTIFY_MESSAGE_SIZE
            }).pb(Identify);
            const message = await pb.read(options);
            await stream.close(options);
            return message;
        }
        catch (err) {
            log$1.error('error while reading identify message', err);
            stream?.abort(err);
            throw err;
        }
    }
    async identify(connection, options = {}) {
        const message = await this._identify(connection, options);
        const { publicKey, protocols, observedAddr } = message;
        if (publicKey == null) {
            throw new CodeError$3('public key was missing from identify message', codes.ERR_MISSING_PUBLIC_KEY);
        }
        const id = await peerIdFromKeys(publicKey);
        if (!connection.remotePeer.equals(id)) {
            throw new CodeError$3('identified peer does not match the expected peer', codes.ERR_INVALID_PEER);
        }
        if (this.peerId.equals(id)) {
            throw new CodeError$3('identified peer is our own peer id?', codes.ERR_INVALID_PEER);
        }
        // Get the observedAddr if there is one
        const cleanObservedAddr = getCleanMultiaddr(observedAddr);
        log$1('identify completed for peer %p and protocols %o', id, protocols);
        log$1('our observed address is %a', cleanObservedAddr);
        if (cleanObservedAddr != null &&
            this.addressManager.getObservedAddrs().length < (this.maxObservedAddresses ?? Infinity)) {
            log$1('storing our observed address %a', cleanObservedAddr);
            this.addressManager.addObservedAddr(cleanObservedAddr);
        }
        const signedPeerRecord = await this.#consumeIdentifyMessage(connection.remotePeer, message);
        const result = {
            peerId: id,
            protocolVersion: message.protocolVersion,
            agentVersion: message.agentVersion,
            publicKey: message.publicKey,
            listenAddrs: message.listenAddrs.map(buf => multiaddr$1(buf)),
            observedAddr: message.observedAddr == null ? undefined : multiaddr$1(message.observedAddr),
            protocols: message.protocols,
            signedPeerRecord
        };
        this.events.safeDispatchEvent('peer:identify', { detail: result });
        return result;
    }
    /**
     * Sends the `Identify` response with the Signed Peer Record
     * to the requesting peer over the given `connection`
     */
    async _handleIdentify(data) {
        const { connection, stream } = data;
        const signal = AbortSignal.timeout(this.timeout);
        try {
            // fails on node < 15.4
            eventsExports.setMaxListeners?.(Infinity, signal);
        }
        catch { }
        try {
            const publicKey = this.peerId.publicKey ?? new Uint8Array(0);
            const peerData = await this.peerStore.get(this.peerId);
            const multiaddrs = this.addressManager.getAddresses().map(ma => ma.decapsulateCode(getProtocol$1('p2p').code));
            let signedPeerRecord = peerData.peerRecordEnvelope;
            if (multiaddrs.length > 0 && signedPeerRecord == null) {
                const peerRecord = new PeerRecord({
                    peerId: this.peerId,
                    multiaddrs
                });
                const envelope = await RecordEnvelope.seal(peerRecord, this.peerId);
                signedPeerRecord = envelope.marshal().subarray();
            }
            const pb = pbStream(stream).pb(Identify);
            await pb.write({
                protocolVersion: this.host.protocolVersion,
                agentVersion: this.host.agentVersion,
                publicKey,
                listenAddrs: multiaddrs.map(addr => addr.bytes),
                signedPeerRecord,
                observedAddr: connection.remoteAddr.bytes,
                protocols: peerData.protocols
            }, {
                signal
            });
            await stream.close({
                signal
            });
        }
        catch (err) {
            log$1.error('could not respond to identify request', err);
            stream.abort(err);
        }
    }
    /**
     * Reads the Identify Push message from the given `connection`
     */
    async _handlePush(data) {
        const { connection, stream } = data;
        try {
            if (this.peerId.equals(connection.remotePeer)) {
                throw new Error('received push from ourselves?');
            }
            const options = {
                signal: AbortSignal.timeout(this.timeout)
            };
            const pb = pbStream(stream, {
                maxDataLength: this.maxIdentifyMessageSize ?? MAX_IDENTIFY_MESSAGE_SIZE
            }).pb(Identify);
            const message = await pb.read(options);
            await stream.close(options);
            await this.#consumeIdentifyMessage(connection.remotePeer, message);
        }
        catch (err) {
            log$1.error('received invalid message', err);
            stream.abort(err);
            return;
        }
        log$1('handled push from %p', connection.remotePeer);
    }
    async #consumeIdentifyMessage(remotePeer, message) {
        log$1('received identify from %p', remotePeer);
        if (message == null) {
            throw new Error('Message was null or undefined');
        }
        const peer = {
            addresses: message.listenAddrs.map(buf => ({
                isCertified: false,
                multiaddr: multiaddr$1(buf)
            })),
            protocols: message.protocols,
            metadata: new Map(),
            peerRecordEnvelope: message.signedPeerRecord
        };
        let output;
        // if the peer record has been sent, prefer the addresses in the record as they are signed by the remote peer
        if (message.signedPeerRecord != null) {
            log$1('received signedPeerRecord in push from %p', remotePeer);
            let peerRecordEnvelope = message.signedPeerRecord;
            const envelope = await RecordEnvelope.openAndCertify(peerRecordEnvelope, PeerRecord.DOMAIN);
            let peerRecord = PeerRecord.createFromProtobuf(envelope.payload);
            // Verify peerId
            if (!peerRecord.peerId.equals(envelope.peerId)) {
                throw new Error('signing key does not match PeerId in the PeerRecord');
            }
            // Make sure remote peer is the one sending the record
            if (!remotePeer.equals(peerRecord.peerId)) {
                throw new Error('signing key does not match remote PeerId');
            }
            let existingPeer;
            try {
                existingPeer = await this.peerStore.get(peerRecord.peerId);
            }
            catch (err) {
                if (err.code !== 'ERR_NOT_FOUND') {
                    throw err;
                }
            }
            if (existingPeer != null) {
                // don't lose any existing metadata
                peer.metadata = existingPeer.metadata;
                // if we have previously received a signed record for this peer, compare it to the incoming one
                if (existingPeer.peerRecordEnvelope != null) {
                    const storedEnvelope = await RecordEnvelope.createFromProtobuf(existingPeer.peerRecordEnvelope);
                    const storedRecord = PeerRecord.createFromProtobuf(storedEnvelope.payload);
                    // ensure seq is greater than, or equal to, the last received
                    if (storedRecord.seqNumber >= peerRecord.seqNumber) {
                        log$1('sequence number was lower or equal to existing sequence number - stored: %d received: %d', storedRecord.seqNumber, peerRecord.seqNumber);
                        peerRecord = storedRecord;
                        peerRecordEnvelope = existingPeer.peerRecordEnvelope;
                    }
                }
            }
            // store the signed record for next time
            peer.peerRecordEnvelope = peerRecordEnvelope;
            // override the stored addresses with the signed multiaddrs
            peer.addresses = peerRecord.multiaddrs.map(multiaddr => ({
                isCertified: true,
                multiaddr
            }));
            output = {
                seq: peerRecord.seqNumber,
                addresses: peerRecord.multiaddrs
            };
        }
        else {
            log$1('%p did not send a signed peer record', remotePeer);
        }
        if (message.agentVersion != null) {
            peer.metadata.set('AgentVersion', fromString$3(message.agentVersion));
        }
        if (message.protocolVersion != null) {
            peer.metadata.set('ProtocolVersion', fromString$3(message.protocolVersion));
        }
        await this.peerStore.patch(remotePeer, peer);
        return output;
    }
}
/**
 * Takes the `addr` and converts it to a Multiaddr if possible
 */
function getCleanMultiaddr(addr) {
    if (addr != null && addr.length > 0) {
        try {
            return multiaddr$1(addr);
        }
        catch {
        }
    }
}

function identifyService(init = {}) {
    return (components) => new DefaultIdentifyService(components, init);
}

const PING_LENGTH = 32;
const PROTOCOL_VERSION = '1.0.0';
const PROTOCOL_NAME = 'ping';
const PROTOCOL_PREFIX = 'ipfs';
const TIMEOUT = 10000;
// See https://github.com/libp2p/specs/blob/d4b5fb0152a6bb86cfd9ea/ping/ping.md?plain=1#L38-L43
// The dialing peer MUST NOT keep more than one outbound stream for the ping protocol per peer.
// The listening peer SHOULD accept at most two streams per peer since cross-stream behavior is
// non-linear and stream writes occur asynchronously. The listening peer may perceive the
// dialing peer closing and opening the wrong streams (for instance, closing stream B and
// opening stream A even though the dialing peer is opening stream B and closing stream A).
const MAX_INBOUND_STREAMS = 2;
const MAX_OUTBOUND_STREAMS = 1;

const log = logger$2('libp2p:ping');
class DefaultPingService {
    protocol;
    components;
    started;
    timeout;
    maxInboundStreams;
    maxOutboundStreams;
    runOnTransientConnection;
    constructor(components, init) {
        this.components = components;
        this.started = false;
        this.protocol = `/${init.protocolPrefix ?? PROTOCOL_PREFIX}/${PROTOCOL_NAME}/${PROTOCOL_VERSION}`;
        this.timeout = init.timeout ?? TIMEOUT;
        this.maxInboundStreams = init.maxInboundStreams ?? MAX_INBOUND_STREAMS;
        this.maxOutboundStreams = init.maxOutboundStreams ?? MAX_OUTBOUND_STREAMS;
        this.runOnTransientConnection = init.runOnTransientConnection ?? true;
    }
    async start() {
        await this.components.registrar.handle(this.protocol, this.handleMessage, {
            maxInboundStreams: this.maxInboundStreams,
            maxOutboundStreams: this.maxOutboundStreams,
            runOnTransientConnection: this.runOnTransientConnection
        });
        this.started = true;
    }
    async stop() {
        await this.components.registrar.unhandle(this.protocol);
        this.started = false;
    }
    isStarted() {
        return this.started;
    }
    /**
     * A handler to register with Libp2p to process ping messages
     */
    handleMessage(data) {
        log('incoming ping from %p', data.connection.remotePeer);
        const { stream } = data;
        const start = Date.now();
        void pipe(stream, stream)
            .catch(err => {
            log.error('incoming ping from %p failed with error', data.connection.remotePeer, err);
        })
            .finally(() => {
            const ms = Date.now() - start;
            log('incoming ping from %p complete in %dms', data.connection.remotePeer, ms);
        });
    }
    /**
     * Ping a given peer and wait for its response, getting the operation latency.
     *
     * @param {PeerId|Multiaddr} peer
     * @returns {Promise<number>}
     */
    async ping(peer, options = {}) {
        log('pinging %p', peer);
        const start = Date.now();
        const data = randomBytes$3(PING_LENGTH);
        const connection = await this.components.connectionManager.openConnection(peer, options);
        let stream;
        let onAbort = () => { };
        options.signal = options.signal ?? AbortSignal.timeout(this.timeout);
        try {
            stream = await connection.newStream(this.protocol, {
                ...options,
                runOnTransientConnection: this.runOnTransientConnection
            });
            onAbort = () => {
                stream?.abort(new CodeError$3('ping timeout', codes.ERR_TIMEOUT));
            };
            // make stream abortable
            options.signal.addEventListener('abort', onAbort, { once: true });
            const result = await pipe([data], stream, async (source) => first(source));
            const ms = Date.now() - start;
            if (result == null) {
                throw new CodeError$3(`Did not receive a ping ack after ${ms}ms`, codes.ERR_WRONG_PING_ACK);
            }
            if (!equals$4(data, result.subarray())) {
                throw new CodeError$3(`Received wrong ping ack after ${ms}ms`, codes.ERR_WRONG_PING_ACK);
            }
            log('ping %p complete in %dms', connection.remotePeer, ms);
            return ms;
        }
        catch (err) {
            log.error('error while pinging %p', connection.remotePeer, err);
            stream?.abort(err);
            throw err;
        }
        finally {
            options.signal.removeEventListener('abort', onAbort);
            if (stream != null) {
                await stream.close();
            }
        }
    }
}
function pingService(init = {}) {
    return (components) => new DefaultPingService(components, init);
}

const DEFAULT_NODE_REQUIREMENTS = {
    lightPush: 1,
    filter: 1,
    store: 1
};
/**
 * Create a Waku node that uses Waku Light Push, Filter and Store to send and
 * receive messages, enabling low resource consumption.
 * Uses Waku Filter V2 by default.
 */
async function createLightNode(options) {
    const libp2pOptions = options?.libp2p ?? {};
    const peerDiscovery = libp2pOptions.peerDiscovery ?? [];
    if (options?.defaultBootstrap) {
        peerDiscovery.push(...defaultPeerDiscoveries());
        Object.assign(libp2pOptions, { peerDiscovery });
    }
    const libp2p = await defaultLibp2p(undefined, libp2pOptions, options?.userAgent);
    const store = wakuStore(options);
    const lightPush = wakuLightPush(options);
    const filter = wakuFilter(options);
    return new WakuNode(options ?? {}, libp2p, store, lightPush, filter);
}
/**
 * Create a Waku node that uses Waku Relay to send and receive messages,
 * enabling some privacy preserving properties.
 */
async function createRelayNode(options) {
    const libp2pOptions = options?.libp2p ?? {};
    const peerDiscovery = libp2pOptions.peerDiscovery ?? [];
    if (options?.defaultBootstrap) {
        peerDiscovery.push(...defaultPeerDiscoveries());
        Object.assign(libp2pOptions, { peerDiscovery });
    }
    const libp2p = await defaultLibp2p(wakuGossipSub(options), libp2pOptions, options?.userAgent);
    const relay = wakuRelay(options);
    return new WakuNode(options ?? {}, libp2p, undefined, undefined, undefined, relay);
}
/**
 * Create a Waku node that uses all Waku protocols.
 *
 * This helper is not recommended except if:
 * - you are interfacing with nwaku v0.11 or below
 * - you are doing some form of testing
 *
 * If you are building a full node, it is recommended to use
 * [nwaku](github.com/status-im/nwaku) and its JSON RPC API or wip REST API.
 *
 * @see https://github.com/status-im/nwaku/issues/1085
 * @internal
 */
async function createFullNode(options) {
    const libp2pOptions = options?.libp2p ?? {};
    const peerDiscovery = libp2pOptions.peerDiscovery ?? [];
    if (options?.defaultBootstrap) {
        peerDiscovery.push(...defaultPeerDiscoveries());
        Object.assign(libp2pOptions, { peerDiscovery });
    }
    const libp2p = await defaultLibp2p(wakuGossipSub(options), libp2pOptions, options?.userAgent);
    const store = wakuStore(options);
    const lightPush = wakuLightPush(options);
    const filter = wakuFilter(options);
    const relay = wakuRelay(options);
    return new WakuNode(options ?? {}, libp2p, store, lightPush, filter, relay);
}
function defaultPeerDiscoveries() {
    const discoveries = [
        wakuDnsDiscovery([enrTree["PROD"]], DEFAULT_NODE_REQUIREMENTS),
        wakuPeerExchangeDiscovery()
    ];
    return discoveries;
}
async function defaultLibp2p(wakuGossipSub, options, userAgent) {
    const pubsubService = wakuGossipSub
        ? { pubsub: wakuGossipSub }
        : {};
    return createLibp2p({
        connectionManager: {
            minConnections: 1
        },
        transports: [webSockets({ filter: all })],
        streamMuxers: [mplex()],
        connectionEncryption: [noise()],
        ...options,
        services: {
            identify: identifyService({
                agentVersion: userAgent ?? DefaultUserAgent
            }),
            ping: pingService(),
            ...pubsubService,
            ...options?.services
        }
    }); // TODO: make libp2p include it;
}

export { DecodedMessage, Decoder$e as Decoder, EPeersByDiscoveryEvents, Encoder$e as Encoder, PageDirection$1 as PageDirection, Protocols, SendError, Tags, WakuNode, bytesToUtf8, createDecoder, createEncoder, createFullNode, createLightNode, createRelayNode, defaultLibp2p, defaultPeerDiscoveries, index as relay, utf8ToBytes$4 as utf8ToBytes, index$5 as utils, waitForRemotePeer, index$1 as waku };
